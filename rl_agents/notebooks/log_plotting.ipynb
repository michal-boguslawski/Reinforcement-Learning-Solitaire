{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad12913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f11e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"BipedalWalker/PPO/reward-actions\"\n",
    "LOG_PATH = f\"/app/rl_agents/logs/{EXPERIMENT_NAME}/app.log\"\n",
    "REFRESH_SEC = 2\n",
    "SMOOTH_WINDOW = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f71a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_pattern = re.compile(\n",
    "    r\"mean reward: (?P<reward>-?\\d+\\.\\d+), mean length: (?P<length>\\d+\\.\\d+)\"\n",
    ")\n",
    "\n",
    "loss_pattern = re.compile(\n",
    "    r\"policy_loss\\s+(?P<policy>[-+]?\\d*\\.?\\d+)\\s+\"\n",
    "    r\"critic_loss\\s+(?P<critic>[-+]?\\d*\\.?\\d+)\\s+\"\n",
    "    r\"entropy\\s+(?P<entropy>[-+]?\\d*\\.?\\d+)\\s+\"\n",
    "    r\"loss\\s+(?P<total>[-+]?\\d*\\.?\\d+)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6a149da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 3671\n"
     ]
    }
   ],
   "source": [
    "with open(LOG_PATH, \"r\") as f:\n",
    "    lines = list(f)\n",
    "\n",
    "print(\"Total lines:\", len(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ae92c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_logs():\n",
    "    rewards, lengths = [], []\n",
    "    policy, critic, entropy, total = [], [], [], []\n",
    "\n",
    "    with open(LOG_PATH, \"r\") as f:\n",
    "        for line in f:\n",
    "            m = episode_pattern.search(line)\n",
    "            if m:\n",
    "                rewards.append(float(m.group(\"reward\")))\n",
    "                lengths.append(float(m.group(\"length\")))\n",
    "\n",
    "            m = loss_pattern.search(line)\n",
    "            if m:\n",
    "                policy.append(float(m.group(\"policy\")))\n",
    "                critic.append(float(m.group(\"critic\")))\n",
    "                entropy.append(float(m.group(\"entropy\")))\n",
    "                total.append(float(m.group(\"total\")))\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame({\"reward\": rewards, \"length\": lengths}),\n",
    "        pd.DataFrame({\n",
    "            \"policy\": policy,\n",
    "            \"critic\": critic,\n",
    "            \"entropy\": entropy,\n",
    "            \"total\": total,\n",
    "        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9786a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        df_ep, df_loss = read_logs()\n",
    "    except FileNotFoundError:\n",
    "        time.sleep(REFRESH_SEC)\n",
    "        continue\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "    # --- Episode reward ---\n",
    "    if len(df_ep):\n",
    "        ax[0, 0].plot(df_ep[\"reward\"], alpha=0.3, label=\"raw\")\n",
    "        ax[0, 0].plot(df_ep[\"reward\"].rolling(SMOOTH_WINDOW).mean(), linewidth=2, label=f\"smoothed {SMOOTH_WINDOW}\")\n",
    "        ax[0, 0].plot(df_ep[\"reward\"].rolling(SMOOTH_WINDOW*10).mean(), linewidth=2, label=f\"smoothed {SMOOTH_WINDOW*10}\")\n",
    "        window = SMOOTH_WINDOW * 10\n",
    "        rolling = df_ep[\"reward\"].rolling(window, min_periods=window // 2)\n",
    "\n",
    "        median = rolling.median()\n",
    "        q25 = rolling.quantile(0.25)\n",
    "        q75 = rolling.quantile(0.75)\n",
    "\n",
    "        ax[0, 0].plot(median, linewidth=2, label=\"median\", )\n",
    "        ax[0, 0].fill_between(\n",
    "            q25.index,\n",
    "            q25,\n",
    "            q75,\n",
    "            alpha=0.2,\n",
    "            label=\"IQR (25-75%)\"\n",
    "        )\n",
    "        high = max(df_ep[\"reward\"].quantile(0.95), df_ep[\"reward\"].tail(200).max())\n",
    "        low = df_ep[\"reward\"].quantile(0.05)\n",
    "        diff = high - low\n",
    "        ax[0, 0].set_ylim(low - (high - low) * 0.01, high + (high - low) * 0.01)\n",
    "        ax[0, 0].set_title(\"Episode Reward\")\n",
    "        ax[0, 0].legend()\n",
    "\n",
    "        ax[0, 1].plot(df_ep[\"length\"], alpha=0.3, label=\"raw\")\n",
    "        ax[0, 1].plot(df_ep[\"length\"].rolling(SMOOTH_WINDOW).mean(), linewidth=2, label=f\"smoothed {SMOOTH_WINDOW}\")\n",
    "        ax[0, 1].plot(df_ep[\"length\"].rolling(SMOOTH_WINDOW*10).mean(), linewidth=2, label=f\"smoothed {SMOOTH_WINDOW*10}\")\n",
    "        window = SMOOTH_WINDOW * 10\n",
    "        rolling = df_ep[\"length\"].rolling(window, min_periods=window // 2)\n",
    "\n",
    "        median = rolling.median()\n",
    "        q25 = rolling.quantile(0.25)\n",
    "        q75 = rolling.quantile(0.75)\n",
    "\n",
    "        ax[0, 1].plot(median, linewidth=2, label=\"median\")\n",
    "        ax[0, 1].fill_between(\n",
    "            q25.index,\n",
    "            q25,\n",
    "            q75,\n",
    "            alpha=0.2,\n",
    "            label=\"IQR (25-75%)\"\n",
    "        )\n",
    "        ax[0, 1].set_title(\"Episode Length\")\n",
    "        ax[0, 1].legend()\n",
    "\n",
    "    # --- Entropy ---\n",
    "    if len(df_loss):\n",
    "        ax[1, 0].plot(df_loss[\"entropy\"], alpha=0.3)\n",
    "        ax[1, 0].set_title(\"Policy Entropy\")\n",
    "\n",
    "        # --- Losses ---\n",
    "        ax[1, 1].plot(df_loss[\"policy\"], label=\"policy\", alpha=0.5)\n",
    "        ax[1, 1].plot(df_loss[\"critic\"], label=\"critic\", alpha=0.5)\n",
    "        ax[1, 1].plot(df_loss[\"total\"], label=\"total\", alpha=0.5)\n",
    "\n",
    "        high = df_loss[\"critic\"].quantile(0.95)\n",
    "        low = df_loss[\"critic\"].quantile(0.05)\n",
    "        diff = high - low\n",
    "        ax[1, 1].set_ylim(top=high + (high - low) * 0.01)\n",
    "        ax[1, 1].legend()\n",
    "        ax[1, 1].set_title(\"Losses\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    time.sleep(REFRESH_SEC)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
