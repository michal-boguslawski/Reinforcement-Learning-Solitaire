# PPO
policy:
  type: ppo
  kwargs:
    gamma: 0.995
    lambda_: 0.95
    value_loss_coef: 0.5
    entropy_coef: 0.001
    entropy_decay: 0.99
    lr: 0.0003
    num_epochs: 10
    clip_epsilon: 0.2
    exploration_method: distribution
    advantage_normalize: global

network:
  type: mlp_network
  kwargs:
    distribution: normal
    initial_log_std: 0.