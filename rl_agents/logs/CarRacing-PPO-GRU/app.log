2026-01-09 21:13:21,907 : worker.worker : INFO : ==================== Start training ====================
2026-01-09 21:13:22,372 : worker.worker : INFO : Step 0, Avg Reward 0.0000, Max Reward 0.0000, Loss [0.0]
2026-01-09 21:13:44,303 : worker.worker : INFO : Step 0: 1000 steps, reward = -89.13, truncated = True, terminated = False
2026-01-09 21:13:44,305 : worker.worker : INFO : Covariance matrix:
[[1.7246825 0.        0.       ]
 [0.        1.7246825 0.       ]
 [0.        0.        1.7246825]]
2026-01-09 21:14:25,721 : worker.worker : DEBUG : Step 999, temp mean rewards -52.86
2026-01-09 21:14:35,670 : agent.on_policy : DEBUG : Mean Losses: [-0.060824602561478966, -0.021834918225431467, 0.0232399114918735, 5.060964130982756]
2026-01-09 21:15:19,415 : worker.worker : DEBUG : Step 2000, temp mean rewards -49.83
2026-01-09 21:15:31,124 : agent.on_policy : DEBUG : Mean Losses: [-0.06211662572168279, -0.02269213938852772, 0.02174817065006209, 5.029857282340527]
2026-01-09 21:16:15,443 : worker.worker : DEBUG : Step 3001, temp mean rewards -47.33
2026-01-09 21:16:28,419 : agent.on_policy : DEBUG : Mean Losses: [-0.0642371805399307, -0.02319283644326333, 0.017911392692985827, 5.000004147365689]
2026-01-09 21:17:13,066 : worker.worker : DEBUG : Step 4002, temp mean rewards -45.33
2026-01-09 21:17:26,103 : agent.on_policy : DEBUG : Mean Losses: [-0.06182185931393178, -0.021795289516740014, 0.019407098780902743, 4.973012026026845]
2026-01-09 21:18:09,466 : worker.worker : INFO : Step 5000, Avg Reward -45.3295, Max Reward -39.3202, Loss [-0.06225007, -0.0223788, 0.02057664, 5.0159594]
2026-01-09 21:18:09,629 : worker.worker : DEBUG : Step 5003, temp mean rewards -34.43
2026-01-09 21:18:27,499 : agent.on_policy : DEBUG : Mean Losses: [-0.061855258759169376, -0.021953349376417464, 0.01886845625067508, 4.933613847196102]
2026-01-09 21:19:10,318 : worker.worker : DEBUG : Step 6004, temp mean rewards -32.84
2026-01-09 21:19:28,916 : agent.on_policy : DEBUG : Mean Losses: [-0.06125539920758456, -0.02181859144857299, 0.018964270695505547, 4.891894411295652]
2026-01-09 21:20:10,558 : worker.worker : DEBUG : Step 7005, temp mean rewards -31.55
2026-01-09 21:20:29,951 : agent.on_policy : DEBUG : Mean Losses: [-0.060743202942830976, -0.021616941619868157, 0.018694618897006875, 4.847357180714607]
2026-01-09 21:21:11,831 : worker.worker : DEBUG : Step 8006, temp mean rewards -30.33
2026-01-09 21:21:34,081 : agent.on_policy : DEBUG : Mean Losses: [-0.0606785527212196, -0.02040397958007816, 0.015446155301287946, 4.799765184894204]
2026-01-09 21:22:11,230 : worker.worker : DEBUG : Step 9007, temp mean rewards -29.07
2026-01-09 21:22:29,298 : agent.on_policy : DEBUG : Mean Losses: [-0.060722564352909104, -0.021167211106512696, 0.016005067811966, 4.755788819491864]
2026-01-09 21:23:03,032 : worker.worker : INFO : Step 10000, Avg Reward -29.0664, Max Reward -24.0174, Loss [-0.061051, -0.02139201, 0.01759571, 4.84568389]
2026-01-09 21:23:03,348 : worker.worker : DEBUG : Step 10008, temp mean rewards -21.36
2026-01-09 21:23:20,754 : agent.on_policy : DEBUG : Mean Losses: [-0.056291021588549484, -0.017117215404869057, 0.015845381876442844, 4.709649816155434]
2026-01-09 21:23:55,020 : worker.worker : DEBUG : Step 11009, temp mean rewards -20.29
2026-01-09 21:24:15,048 : agent.on_policy : DEBUG : Mean Losses: [-0.05666842321370495, -0.017628496598263155, 0.01508679290316195, 4.658332403004169]
2026-01-09 21:24:49,402 : worker.worker : DEBUG : Step 12010, temp mean rewards -19.50
2026-01-09 21:25:11,232 : agent.on_policy : DEBUG : Mean Losses: [-0.055380528392561246, -0.016543435958374174, 0.014535345353488082, 4.61047660857439]
2026-01-09 21:25:43,663 : worker.worker : DEBUG : Step 13011, temp mean rewards -18.75
2026-01-09 21:26:05,913 : agent.on_policy : DEBUG : Mean Losses: [-0.053284644837549425, -0.01420477593801479, 0.01325921042571281, 4.57094750739634]
2026-01-09 21:26:38,555 : worker.worker : DEBUG : Step 14012, temp mean rewards -18.25
2026-01-09 21:27:02,062 : agent.on_policy : DEBUG : Mean Losses: [-0.05553719398303656, -0.015520007429950055, 0.010641171935571948, 4.533777360618115]
2026-01-09 21:27:33,532 : worker.worker : INFO : Step 15000, Avg Reward -18.2470, Max Reward -16.2345, Loss [-0.05543236, -0.01620279, 0.01387358, 4.61663674]
2026-01-09 21:27:34,121 : worker.worker : DEBUG : Step 15013, temp mean rewards -14.65
2026-01-09 21:27:59,929 : agent.on_policy : DEBUG : Mean Losses: [-0.0532897347555263, -0.014221479197294684, 0.011787928865709318, 4.496222100406885]
2026-01-09 21:28:31,302 : worker.worker : DEBUG : Step 16014, temp mean rewards -14.22
2026-01-09 21:28:57,992 : agent.on_policy : DEBUG : Mean Losses: [-0.053866776140057485, -0.014835166889952234, 0.011128234914565382, 4.459572778269648]
2026-01-09 21:29:28,411 : worker.worker : DEBUG : Step 17015, temp mean rewards -14.05
2026-01-09 21:29:56,580 : agent.on_policy : DEBUG : Mean Losses: [-0.054622727028618104, -0.015064179947148659, 0.009409283597608464, 4.42631899304688]
2026-01-09 21:30:25,849 : worker.worker : DEBUG : Step 18016, temp mean rewards -13.74
2026-01-09 21:30:52,511 : agent.on_policy : DEBUG : Mean Losses: [-0.05298444656073116, -0.013239584514576564, 0.008227700311968534, 4.385871334373951]
2026-01-09 21:31:17,942 : worker.worker : DEBUG : Step 19017, temp mean rewards -13.59
2026-01-09 21:31:45,682 : agent.on_policy : DEBUG : Mean Losses: [-0.05278007313754642, -0.013034650841308348, 0.0075617571015328625, 4.352630185335874]
2026-01-09 21:32:10,726 : worker.worker : INFO : Step 20000, Avg Reward -13.5861, Max Reward -12.8163, Loss [-0.05350875, -0.01407901, 0.00962298, 4.42412308]
2026-01-09 21:32:11,526 : worker.worker : DEBUG : Step 20018, temp mean rewards -12.49
2026-01-09 21:32:40,964 : agent.on_policy : DEBUG : Mean Losses: [-0.05512142439838499, -0.015421731247579373, 0.007006468756161155, 4.320292841270566]
2026-01-09 21:33:05,762 : worker.worker : DEBUG : Step 21019, temp mean rewards -12.19
2026-01-09 21:33:35,034 : agent.on_policy : DEBUG : Mean Losses: [-0.051679365047311875, -0.012238486170463147, 0.0069267301903991555, 4.290424480289221]
2026-01-09 21:33:57,164 : worker.worker : DEBUG : Step 22020, temp mean rewards -11.96
2026-01-09 21:34:28,065 : agent.on_policy : DEBUG : Mean Losses: [-0.05211399185209302, -0.013322955830881255, 0.007703903869457918, 4.264298892766237]
2026-01-09 21:34:52,045 : worker.worker : DEBUG : Step 23021, temp mean rewards -12.19
2026-01-09 21:35:25,960 : agent.on_policy : DEBUG : Mean Losses: [-0.05251791145274183, -0.0139929984426999, 0.007686654133165405, 4.236824100092053]
2026-01-09 21:35:48,351 : worker.worker : DEBUG : Step 24022, temp mean rewards -12.27
2026-01-09 21:36:24,128 : agent.on_policy : DEBUG : Mean Losses: [-0.052893415065773296, -0.014081238056678557, 0.006594184033860273, 4.210926995053887]
2026-01-09 21:36:44,525 : worker.worker : INFO : Step 25000, Avg Reward -12.2749, Max Reward -11.5027, Loss [-0.05286522, -0.01381148, 0.00718359, 4.26455346]
2026-01-09 21:36:45,734 : worker.worker : DEBUG : Step 25023, temp mean rewards -11.49
2026-01-09 21:37:22,368 : agent.on_policy : DEBUG : Mean Losses: [-0.04926445130113279, -0.010578696799348109, 0.006339288438384471, 4.185539963841438]
2026-01-09 21:37:42,915 : worker.worker : DEBUG : Step 26024, temp mean rewards -11.16
2026-01-09 21:38:20,579 : agent.on_policy : DEBUG : Mean Losses: [-0.049738965106371325, -0.01129887254719506, 0.006179259525768544, 4.152972326055169]
2026-01-09 21:38:40,154 : worker.worker : DEBUG : Step 27025, temp mean rewards -11.07
2026-01-09 21:39:17,346 : agent.on_policy : DEBUG : Mean Losses: [-0.049347376264631745, -0.010795936905014968, 0.005377221035639224, 4.124005076661706]
2026-01-09 21:39:33,661 : worker.worker : DEBUG : Step 28026, temp mean rewards -10.90
2026-01-09 21:40:09,807 : agent.on_policy : DEBUG : Mean Losses: [-0.05108331831143005, -0.0129792961946805, 0.005601480486860311, 4.090476320311427]
2026-01-09 21:40:25,349 : worker.worker : DEBUG : Step 29027, temp mean rewards -10.83
2026-01-09 21:41:04,693 : agent.on_policy : DEBUG : Mean Losses: [-0.05114438076125225, -0.013417779021983734, 0.0056763605967827145, 4.056478292867541]
2026-01-09 21:41:18,731 : worker.worker : INFO : Step 30000, Avg Reward -10.8301, Max Reward -10.3703, Loss [-0.0501157, -0.01181412, 0.00583472, 4.1218944]
2026-01-09 21:41:20,050 : worker.worker : DEBUG : Step 30028, temp mean rewards -11.33
2026-01-09 21:42:00,679 : agent.on_policy : DEBUG : Mean Losses: [-0.04949329472729005, -0.012088089002645575, 0.0057297136722585405, 4.027006344497204]
2026-01-09 21:42:14,715 : worker.worker : DEBUG : Step 31029, temp mean rewards -10.67
2026-01-09 21:42:56,433 : agent.on_policy : DEBUG : Mean Losses: [-0.04956850179005414, -0.012265597674468155, 0.005365438761446839, 3.9985624490305782]
2026-01-09 21:43:09,644 : worker.worker : DEBUG : Step 32030, temp mean rewards -10.55
2026-01-09 21:43:51,394 : agent.on_policy : DEBUG : Mean Losses: [-0.05329031789005967, -0.01624280714040651, 0.005479973713025288, 3.9787498524412515]
2026-01-09 21:44:03,061 : worker.worker : DEBUG : Step 33031, temp mean rewards -10.61
2026-01-09 21:44:44,893 : agent.on_policy : DEBUG : Mean Losses: [-0.05115690485108644, -0.01419888179807458, 0.005272243613045191, 3.9594145702198147]
2026-01-09 21:44:55,718 : worker.worker : DEBUG : Step 34032, temp mean rewards -10.59
2026-01-09 21:45:41,632 : agent.on_policy : DEBUG : Mean Losses: [-0.05397767933172872, -0.01728484084833326, 0.0052808157882324736, 3.933324722386897]
2026-01-09 21:45:50,641 : worker.worker : INFO : Step 35000, Avg Reward -10.5906, Max Reward -10.0141, Loss [-0.05149734, -0.01441604, 0.00542564, 3.97941159]
2026-01-09 21:45:52,202 : worker.worker : DEBUG : Step 35033, temp mean rewards -10.60
2026-01-09 21:46:39,817 : agent.on_policy : DEBUG : Mean Losses: [-0.05439558337384369, -0.017964616495373776, 0.005226892566851405, 3.904441397823393]
2026-01-09 21:46:49,428 : worker.worker : DEBUG : Step 36034, temp mean rewards -10.83
2026-01-09 21:47:38,084 : agent.on_policy : DEBUG : Mean Losses: [-0.056304093485232444, -0.020583633973819813, 0.006119513659946563, 3.878021721728146]
2026-01-09 21:47:46,723 : worker.worker : DEBUG : Step 37035, temp mean rewards -10.70
2026-01-09 21:48:37,937 : agent.on_policy : DEBUG : Mean Losses: [-0.056315234457724725, -0.02089238394091808, 0.006238984007946513, 3.854234340041876]
2026-01-09 21:48:45,421 : worker.worker : DEBUG : Step 38036, temp mean rewards -10.85
2026-01-09 21:49:35,580 : agent.on_policy : DEBUG : Mean Losses: [-0.0529886290198192, -0.017495866799799843, 0.005564450236396112, 3.8274988209828735]
2026-01-09 21:49:41,109 : worker.worker : DEBUG : Step 39037, temp mean rewards -10.86
2026-01-09 21:50:27,862 : agent.on_policy : DEBUG : Mean Losses: [-0.05271408143744338, -0.017588422059634467, 0.005791302498496975, 3.802131150662899]
2026-01-09 21:50:30,567 : worker.worker : INFO : Step 40000, Avg Reward -10.8631, Max Reward -10.4274, Loss [-0.05454352, -0.01890498, 0.00578823, 3.85326549]
2026-01-09 21:50:32,318 : worker.worker : DEBUG : Step 40038, temp mean rewards -10.26
2026-01-09 21:51:22,561 : agent.on_policy : DEBUG : Mean Losses: [-0.05373773163591977, -0.018637538125403807, 0.005544413963835382, 3.787240136042237]
2026-01-09 21:51:26,224 : worker.worker : DEBUG : Step 41039, temp mean rewards -10.41
2026-01-09 21:52:19,109 : agent.on_policy : DEBUG : Mean Losses: [-0.04943920254445402, -0.014597100723767653, 0.005733199844452486, 3.770870256610215]
2026-01-09 21:52:21,511 : worker.worker : DEBUG : Step 42040, temp mean rewards -10.45
2026-01-09 21:53:12,053 : agent.on_policy : DEBUG : Mean Losses: [-0.051201647710695394, -0.016718626145984673, 0.006108530595459172, 3.7537287842482328]
2026-01-09 21:53:13,559 : worker.worker : DEBUG : Step 43041, temp mean rewards -10.39
2026-01-09 21:54:06,292 : agent.on_policy : DEBUG : Mean Losses: [-0.04937318739102921, -0.015241157034512298, 0.006512810832061788, 3.738843675330281]
2026-01-09 21:54:06,824 : worker.worker : DEBUG : Step 44042, temp mean rewards -10.46
2026-01-09 21:54:55,426 : worker.worker : INFO : Step 45000, Avg Reward -10.4613, Max Reward -10.1997, Loss [-0.05093794, -0.01629861, 0.00597474, 3.76267071]
2026-01-09 21:54:57,845 : worker.worker : DEBUG : Step 45043, temp mean rewards -10.17
2026-01-09 21:55:06,806 : agent.on_policy : DEBUG : Mean Losses: [-0.05175560332572786, -0.018202117403779992, 0.007201973810231266, 3.715447367541492]
2026-01-09 21:55:57,941 : worker.worker : DEBUG : Step 46044, temp mean rewards -10.22
2026-01-09 21:56:07,770 : agent.on_policy : DEBUG : Mean Losses: [-0.05420663295080885, -0.019960315529897344, 0.005199708648868295, 3.6846172600984572]
2026-01-09 21:56:56,659 : worker.worker : DEBUG : Step 47045, temp mean rewards -10.43
2026-01-09 21:57:07,740 : agent.on_policy : DEBUG : Mean Losses: [-0.05217075834370917, -0.01911862711597223, 0.007236712456617056, 3.6670488357543944]
2026-01-09 21:57:55,028 : worker.worker : DEBUG : Step 48046, temp mean rewards -10.18
2026-01-09 21:58:07,743 : agent.on_policy : DEBUG : Mean Losses: [-0.04922339510521852, -0.0160301371019159, 0.006678314923842521, 3.6532416244968773]
2026-01-09 21:58:53,518 : worker.worker : DEBUG : Step 49047, temp mean rewards -10.65
2026-01-09 21:59:07,053 : agent.on_policy : DEBUG : Mean Losses: [-0.049828909439384006, -0.018548797743460455, 0.010233071035824538, 3.6396648030728103]
2026-01-09 21:59:48,926 : worker.worker : INFO : Step 50000, Avg Reward -10.6515, Max Reward -9.4272, Loss [-0.05143706, -0.018372, 0.00730996, 3.67200398]
2026-01-09 22:00:08,387 : worker.worker : INFO : Step 50000: 1000 steps, reward = -92.28, truncated = True, terminated = False
2026-01-09 22:00:08,388 : worker.worker : INFO : Covariance matrix:
[[ 0.7469212   0.0942064  -0.0645875 ]
 [ 0.0942064   0.49128497 -0.36215958]
 [-0.0645875  -0.36215958  1.0763834 ]]
2026-01-09 22:00:10,824 : worker.worker : DEBUG : Step 50048, temp mean rewards -11.81
2026-01-09 22:00:25,504 : agent.on_policy : DEBUG : Mean Losses: [-0.052045249842922206, -0.02103282049383779, 0.010408998645614531, 3.6216929415240884]
2026-01-09 22:01:09,658 : worker.worker : DEBUG : Step 51049, temp mean rewards -12.93
2026-01-09 22:01:25,800 : agent.on_policy : DEBUG : Mean Losses: [-0.04896614493773086, -0.01937621674805996, 0.012752013030902277, 3.596593540534377]
2026-01-09 22:02:08,083 : worker.worker : DEBUG : Step 52050, temp mean rewards -13.00
2026-01-09 22:02:23,592 : agent.on_policy : DEBUG : Mean Losses: [-0.05099441043275874, -0.02054694975977327, 0.010667348876512505, 3.578113586269319]
2026-01-09 22:03:00,327 : worker.worker : DEBUG : Step 53051, temp mean rewards -13.66
2026-01-09 22:03:16,764 : agent.on_policy : DEBUG : Mean Losses: [-0.051372506603365765, -0.02281607204458851, 0.01412895588697154, 3.5620913211256267]
2026-01-09 22:03:51,734 : worker.worker : DEBUG : Step 54052, temp mean rewards -13.68
2026-01-09 22:04:10,310 : agent.on_policy : DEBUG : Mean Losses: [-0.04975408027385129, -0.020453697049742914, 0.012401821678717794, 3.550129477493465]
2026-01-09 22:04:43,518 : worker.worker : INFO : Step 55000, Avg Reward -13.6756, Max Reward -11.8079, Loss [-0.05062648, -0.02084515, 0.01207183, 3.58172417]
2026-01-09 22:04:46,148 : worker.worker : DEBUG : Step 55053, temp mean rewards -10.55
2026-01-09 22:05:05,673 : agent.on_policy : DEBUG : Mean Losses: [-0.05260769584565424, -0.022408182058279637, 0.010262139472003185, 3.5330584244802594]
2026-01-09 22:05:39,823 : worker.worker : DEBUG : Step 56054, temp mean rewards -11.48
2026-01-09 22:06:00,596 : agent.on_policy : DEBUG : Mean Losses: [-0.05173328194214264, -0.02253190263104443, 0.011866459471227131, 3.5134609773755074]
2026-01-09 22:06:34,644 : worker.worker : DEBUG : Step 57055, temp mean rewards -11.89
2026-01-09 22:06:56,909 : agent.on_policy : DEBUG : Mean Losses: [-0.05268439027568093, -0.023425971056076376, 0.01143196318579669, 3.4974401628598573]
2026-01-09 22:07:29,715 : worker.worker : DEBUG : Step 58056, temp mean rewards -11.63
2026-01-09 22:07:53,112 : agent.on_policy : DEBUG : Mean Losses: [-0.0526536127566942, -0.021481585563378758, 0.007252323671606576, 3.479818975739181]
2026-01-09 22:08:25,713 : worker.worker : DEBUG : Step 59057, temp mean rewards -11.31
2026-01-09 22:08:50,174 : agent.on_policy : DEBUG : Mean Losses: [-0.049966971343383196, -0.020070511932499358, 0.009319553994639306, 3.4556237107142804]
