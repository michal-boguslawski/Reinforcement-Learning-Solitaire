env_kwargs:
  id: LunarLander-v3
  num_envs: 8
  vectorization_mode: async
experiment_name: LunarLanderContinuous-PPO
network:
  kwargs:
    backbone_kwargs: {}
    backbone_name: mlp
    distribution: categorical
    feature_extractor_name: shared
    head_kwargs: {}
    head_name: actor_critic
    initial_log_std: -1.0
    num_features: 64
    policy_name: actor_critic
policy:
  kwargs:
    advantage_normalize: batch
    clip_epsilon: 0.2
    entropy_coef: 0.001
    entropy_decay: 0.99
    exploration_method: distribution
    gamma: 0.99
    lambda_: 0.95
    lr: 0.0003
    num_epochs: 10
    value_loss_coef: 0.5
  type: ppo
train_kwargs:
  batch_size: 1024
  minibatch_size: 128
  num_steps: 100000
worker_kwargs:
  device: auto
  record_step: 20000
