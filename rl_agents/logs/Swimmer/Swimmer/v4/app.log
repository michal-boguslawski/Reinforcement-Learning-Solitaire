2026-02-15 19:28:33,519 : worker.worker : INFO : Current device cuda
2026-02-15 19:28:33,641 : OpenGL.platform.ctypesloader : DEBUG : Loaded libEGL.so => libEGL.so <CDLL 'libEGL.so', handle 151bf240 at 0x7f2c78acde80>
2026-02-15 19:28:33,641 : OpenGL.platform.ctypesloader : DEBUG : Loaded libOpenGL.so => libOpenGL.so <CDLL 'libOpenGL.so', handle 151c08d0 at 0x7f2c78aa2810>
2026-02-15 19:28:33,643 : OpenGL.acceleratesupport : DEBUG : OpenGL_accelerate module loaded
2026-02-15 19:28:33,649 : OpenGL.arrays.arraydatatype : DEBUG : Using accelerated ArrayDatatype
2026-02-15 19:28:33,657 : OpenGL.platform.ctypesloader : DEBUG : Loaded libOpenGL.so => libOpenGL.so <CDLL 'libOpenGL.so', handle 151c08d0 at 0x7f2c7878bbc0>
2026-02-15 19:28:33,742 : envs.wrappers : INFO : PowerObsRewardWrapper attached with params [-0.05, -0.01, -0.005, 0.0, -0.01, 0.0, 0.0, 0.0] None [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0] 0.99
2026-02-15 19:28:33,765 : envs.wrappers : INFO : PowerObsRewardWrapper attached with params [-0.05, -0.01, -0.005, 0.0, -0.01, 0.0, 0.0, 0.0] None [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0] 0.99
2026-02-15 19:28:33,772 : envs.wrappers : INFO : PowerObsRewardWrapper attached with params [-0.05, -0.01, -0.005, 0.0, -0.01, 0.0, 0.0, 0.0] None [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0] 0.99
2026-02-15 19:28:33,779 : envs.wrappers : INFO : PowerObsRewardWrapper attached with params [-0.05, -0.01, -0.005, 0.0, -0.01, 0.0, 0.0, 0.0] None [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0] 0.99
2026-02-15 19:28:33,787 : envs.wrappers : INFO : PowerObsRewardWrapper attached with params [-0.05, -0.01, -0.005, 0.0, -0.01, 0.0, 0.0, 0.0] None [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0] 0.99
2026-02-15 19:28:33,795 : envs.wrappers : INFO : PowerObsRewardWrapper attached with params [-0.05, -0.01, -0.005, 0.0, -0.01, 0.0, 0.0, 0.0] None [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0] 0.99
2026-02-15 19:28:33,803 : envs.wrappers : INFO : PowerObsRewardWrapper attached with params [-0.05, -0.01, -0.005, 0.0, -0.01, 0.0, 0.0, 0.0] None [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0] 0.99
2026-02-15 19:28:33,811 : envs.wrappers : INFO : PowerObsRewardWrapper attached with params [-0.05, -0.01, -0.005, 0.0, -0.01, 0.0, 0.0, 0.0] None [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0] 0.99
2026-02-15 19:28:33,819 : envs.wrappers : INFO : PowerObsRewardWrapper attached with params [-0.05, -0.01, -0.005, 0.0, -0.01, 0.0, 0.0, 0.0] None [0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0] 0.99
2026-02-15 19:28:35,104 : worker.worker : INFO : ==================== Start training ====================
2026-02-15 19:28:35,488 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 19:28:41,576 : evaluate.evaluate : INFO : Final state tensor([-1.5612e+00,  1.7458e+00, -6.0252e-01, -7.2369e-02,  5.4497e-02,
         6.0775e-02,  1.5105e-04, -3.3763e-02])
2026-02-15 19:28:41,577 : evaluate.evaluate : INFO : Evaluation results: mean = 21.48, std = 0.00, min = 21.48, max = 21.48, count = 1
2026-02-15 19:28:41,577 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 19:28:41,579 : evaluate.evaluate : INFO : Covariance matrix:
[0.18973666 0.18973666]
2026-02-15 19:57:42,496 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 19:57:48,259 : evaluate.evaluate : INFO : Final state tensor([-2.1116e+00,  1.7462e+00,  4.1888e-02, -1.3907e-01,  2.4760e-01,
         4.3654e-01, -9.9293e-04, -1.2679e+00])
2026-02-15 19:57:48,259 : evaluate.evaluate : INFO : Evaluation results: mean = 130.82, std = 0.00, min = 130.82, max = 130.82, count = 1
2026-02-15 19:57:48,260 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 19:57:48,261 : evaluate.evaluate : INFO : Covariance matrix:
[0.15712331 0.10835027]
2026-02-15 20:26:18,723 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 20:26:24,532 : evaluate.evaluate : INFO : Final state tensor([-2.2972,  1.7464,  0.6507,  0.1816,  0.0314,  0.0467,  0.0032, -0.2422])
2026-02-15 20:26:24,532 : evaluate.evaluate : INFO : Evaluation results: mean = 135.69, std = 0.00, min = 135.69, max = 135.69, count = 1
2026-02-15 20:26:24,532 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 20:26:24,533 : evaluate.evaluate : INFO : Covariance matrix:
[0.16808918 0.09257063]
2026-02-15 20:55:50,827 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 20:55:56,811 : evaluate.evaluate : INFO : Final state tensor([-2.0467e+00,  1.7464e+00, -8.0622e-02, -2.3070e-01,  3.0345e-01,
         5.3026e-01,  1.2611e-03, -1.4904e+00])
2026-02-15 20:55:56,811 : evaluate.evaluate : INFO : Evaluation results: mean = 129.55, std = 0.00, min = 129.55, max = 129.55, count = 1
2026-02-15 20:55:56,811 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 20:55:56,812 : evaluate.evaluate : INFO : Covariance matrix:
[0.16769643 0.07720122]
2026-02-15 21:25:14,841 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 21:25:20,564 : evaluate.evaluate : INFO : Final state tensor([-2.0849,  1.7465, -0.1116, -0.2744,  0.3617,  0.6151,  0.0031, -1.7320])
2026-02-15 21:25:20,564 : evaluate.evaluate : INFO : Evaluation results: mean = 132.50, std = 0.00, min = 132.50, max = 132.50, count = 1
2026-02-15 21:25:20,565 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 21:25:20,566 : evaluate.evaluate : INFO : Covariance matrix:
[0.17638522 0.05956022]
2026-02-15 21:54:35,931 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 21:54:41,176 : evaluate.evaluate : INFO : Final state tensor([-2.3289,  1.7467,  0.8111,  0.2146,  0.0397,  0.0723, -0.0142, -0.3200])
2026-02-15 21:54:41,177 : evaluate.evaluate : INFO : Evaluation results: mean = 128.75, std = 0.00, min = 128.75, max = 128.75, count = 1
2026-02-15 21:54:41,177 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 21:54:41,178 : evaluate.evaluate : INFO : Covariance matrix:
[0.15565252 0.05040135]
2026-02-15 22:22:33,486 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 22:22:39,212 : evaluate.evaluate : INFO : Final state tensor([-2.3097e+00,  1.7465e+00,  5.8360e-01,  1.2851e-01,  7.5145e-02,
         1.0603e-01, -2.1832e-03, -3.7362e-01])
2026-02-15 22:22:39,213 : evaluate.evaluate : INFO : Evaluation results: mean = 131.49, std = 0.00, min = 131.49, max = 131.49, count = 1
2026-02-15 22:22:39,213 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 22:22:39,214 : evaluate.evaluate : INFO : Covariance matrix:
[0.13709946 0.04189117]
2026-02-15 22:54:16,183 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 22:54:22,664 : evaluate.evaluate : INFO : Final state tensor([-2.2123e+00,  1.7465e+00,  6.0585e-01,  9.7069e-02,  1.0719e-01,
         1.3454e-01,  1.3813e-03, -4.7069e-01])
2026-02-15 22:54:22,664 : evaluate.evaluate : INFO : Evaluation results: mean = 126.03, std = 0.00, min = 126.03, max = 126.03, count = 1
2026-02-15 22:54:22,664 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 22:54:22,665 : evaluate.evaluate : INFO : Covariance matrix:
[0.1143543  0.03560502]
2026-02-15 23:26:09,953 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 23:26:16,455 : evaluate.evaluate : INFO : Final state tensor([-2.3173e+00,  1.7465e+00,  7.1454e-01,  1.4086e-01,  8.9916e-02,
         1.2156e-01,  2.0179e-05, -4.5985e-01])
2026-02-15 23:26:16,456 : evaluate.evaluate : INFO : Evaluation results: mean = 129.38, std = 0.00, min = 129.38, max = 129.38, count = 1
2026-02-15 23:26:16,456 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 23:26:16,458 : evaluate.evaluate : INFO : Covariance matrix:
[0.10158418 0.0281995 ]
2026-02-15 23:58:05,308 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-15 23:58:11,401 : evaluate.evaluate : INFO : Final state tensor([-2.2747e+00,  1.7464e+00,  8.0441e-01,  1.5077e-01,  7.9544e-02,
         8.5902e-02,  2.8788e-04, -3.6210e-01])
2026-02-15 23:58:11,401 : evaluate.evaluate : INFO : Evaluation results: mean = 127.61, std = 0.00, min = 127.61, max = 127.61, count = 1
2026-02-15 23:58:11,401 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-15 23:58:11,402 : evaluate.evaluate : INFO : Covariance matrix:
[0.09470743 0.02394093]
2026-02-16 00:29:50,645 : network.model : INFO : Saved model to logs/Swimmer/Swimmer/v4/model.pt
2026-02-16 00:29:56,768 : evaluate.evaluate : INFO : Final state tensor([-1.9003,  1.3608,  0.6479,  0.9815, -0.2428, -1.6258,  1.3232,  1.7427])
2026-02-16 00:29:56,769 : evaluate.evaluate : INFO : Evaluation results: mean = 123.40, std = 0.00, min = 123.40, max = 123.40, count = 1
2026-02-16 00:29:56,769 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1
2026-02-16 00:29:56,770 : evaluate.evaluate : INFO : Covariance matrix:
[0.08530172 0.02210202]
2026-02-16 00:39:46,033 : evaluate.evaluate : INFO : Final state tensor([-2.2196,  1.6496,  0.8676,  0.8248, -0.3245, -1.1941,  1.2139,  0.4521])
2026-02-16 00:39:46,034 : evaluate.evaluate : INFO : Evaluation results: mean = 125.29, std = 2.44, min = 117.19, max = 131.26, count = 1000
2026-02-16 00:39:46,034 : evaluate.evaluate : INFO : Evaluation lengths: mean = 1000.00, std = 0.00, min = 1000.00, max = 1000.00, count = 1000
2026-02-16 00:39:46,035 : evaluate.evaluate : INFO : Covariance matrix:
[0.08530172 0.02210202]
2026-02-16 00:39:46,088 : worker.worker : INFO : ==================== End training ====================
