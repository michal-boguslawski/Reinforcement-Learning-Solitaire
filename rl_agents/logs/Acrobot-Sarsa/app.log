2026-01-17 13:15:36,003 : worker.worker : INFO : ==================== Start training ====================
2026-01-17 13:15:36,019 : worker.worker : INFO : Step 0, Avg Reward 0.0000, Max Reward 0.0000, Loss [0.0]
2026-01-17 13:15:36,024 : network.model : INFO : Saved model to logs/Acrobot-Sarsa/model.pt
2026-01-17 13:15:40,516 : evaluate.evaluate : INFO : Evaluation results: mean = -500.00, std = 0.00, min = -500.00, max = -500.00, count = 1
2026-01-17 13:15:42,360 : agent.on_policy : DEBUG : Mean Losses: [6.32667601108551]
2026-01-17 13:15:42,500 : agent.on_policy : DEBUG : Mean Losses: [6.230027079582214]
2026-01-17 13:15:42,626 : agent.on_policy : DEBUG : Mean Losses: [6.1928322315216064]
2026-01-17 13:15:42,761 : agent.on_policy : DEBUG : Mean Losses: [6.108346045017242]
2026-01-17 13:15:42,915 : agent.on_policy : DEBUG : Mean Losses: [6.1383026242256165]
2026-01-17 13:15:43,191 : agent.on_policy : DEBUG : Mean Losses: [6.107811450958252]
2026-01-17 13:15:43,365 : agent.on_policy : DEBUG : Mean Losses: [6.029856979846954]
2026-01-17 13:15:43,488 : agent.on_policy : DEBUG : Mean Losses: [5.903696179389954]
2026-01-17 13:15:43,625 : agent.on_policy : DEBUG : Mean Losses: [5.8756866455078125]
2026-01-17 13:15:43,752 : agent.on_policy : DEBUG : Mean Losses: [5.841388821601868]
2026-01-17 13:15:43,877 : agent.on_policy : DEBUG : Mean Losses: [5.652494490146637]
2026-01-17 13:15:44,021 : agent.on_policy : DEBUG : Mean Losses: [5.6041935086250305]
2026-01-17 13:15:44,150 : agent.on_policy : DEBUG : Mean Losses: [5.549814939498901]
2026-01-17 13:15:44,284 : agent.on_policy : DEBUG : Mean Losses: [5.534097373485565]
2026-01-17 13:15:44,413 : agent.on_policy : DEBUG : Mean Losses: [5.528713643550873]
2026-01-17 13:15:44,480 : worker.worker : DEBUG : Step 499, finished rewards -476.08, envs finished 8
2026-01-17 13:15:44,586 : agent.on_policy : DEBUG : Mean Losses: [3.763846665620804]
2026-01-17 13:15:44,719 : agent.on_policy : DEBUG : Mean Losses: [5.929583787918091]
2026-01-17 13:15:44,849 : agent.on_policy : DEBUG : Mean Losses: [5.88205361366272]
2026-01-17 13:15:44,985 : agent.on_policy : DEBUG : Mean Losses: [5.858337759971619]
2026-01-17 13:15:45,111 : agent.on_policy : DEBUG : Mean Losses: [5.858781039714813]
2026-01-17 13:15:45,306 : agent.on_policy : DEBUG : Mean Losses: [5.7794800996780396]
2026-01-17 13:15:45,431 : agent.on_policy : DEBUG : Mean Losses: [5.731384873390198]
2026-01-17 13:15:45,563 : agent.on_policy : DEBUG : Mean Losses: [5.675668656826019]
2026-01-17 13:15:45,836 : agent.on_policy : DEBUG : Mean Losses: [5.606876850128174]
2026-01-17 13:15:45,978 : agent.on_policy : DEBUG : Mean Losses: [5.48103392124176]
2026-01-17 13:15:46,102 : agent.on_policy : DEBUG : Mean Losses: [5.420842111110687]
2026-01-17 13:15:46,234 : agent.on_policy : DEBUG : Mean Losses: [5.41739946603775]
2026-01-17 13:15:46,486 : agent.on_policy : DEBUG : Mean Losses: [5.3042349219322205]
2026-01-17 13:15:46,607 : agent.on_policy : DEBUG : Mean Losses: [5.234836459159851]
2026-01-17 13:15:46,743 : agent.on_policy : DEBUG : Mean Losses: [5.230751097202301]
2026-01-17 13:15:46,865 : agent.on_policy : DEBUG : Mean Losses: [5.250734448432922]
2026-01-17 13:15:46,892 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.95
2026-01-17 13:15:46,901 : worker.worker : DEBUG : Step 1000, finished rewards -474.38, envs finished 8
2026-01-17 13:15:47,014 : agent.on_policy : DEBUG : Mean Losses: [4.2603583335876465]
2026-01-17 13:15:47,179 : agent.on_policy : DEBUG : Mean Losses: [5.717907965183258]
2026-01-17 13:15:47,302 : agent.on_policy : DEBUG : Mean Losses: [5.6757760643959045]
2026-01-17 13:15:47,483 : agent.on_policy : DEBUG : Mean Losses: [5.669456303119659]
2026-01-17 13:15:47,609 : agent.on_policy : DEBUG : Mean Losses: [5.635265111923218]
2026-01-17 13:15:47,761 : agent.on_policy : DEBUG : Mean Losses: [5.524082124233246]
2026-01-17 13:15:47,889 : agent.on_policy : DEBUG : Mean Losses: [5.421583592891693]
2026-01-17 13:15:48,019 : agent.on_policy : DEBUG : Mean Losses: [5.344672799110413]
2026-01-17 13:15:48,143 : agent.on_policy : DEBUG : Mean Losses: [5.2469563484191895]
2026-01-17 13:15:48,268 : agent.on_policy : DEBUG : Mean Losses: [5.2069993019104]
2026-01-17 13:15:48,409 : agent.on_policy : DEBUG : Mean Losses: [5.0797014236450195]
2026-01-17 13:15:48,568 : agent.on_policy : DEBUG : Mean Losses: [5.2151618003845215]
2026-01-17 13:15:48,693 : agent.on_policy : DEBUG : Mean Losses: [5.227287709712982]
2026-01-17 13:15:48,844 : agent.on_policy : DEBUG : Mean Losses: [5.2736817598342896]
2026-01-17 13:15:49,093 : agent.on_policy : DEBUG : Mean Losses: [5.236276865005493]
2026-01-17 13:15:49,183 : worker.worker : DEBUG : Step 1501, finished rewards -476.66, envs finished 8
2026-01-17 13:15:49,241 : agent.on_policy : DEBUG : Mean Losses: [3.977905362844467]
2026-01-17 13:15:49,472 : agent.on_policy : DEBUG : Mean Losses: [5.591876566410065]
2026-01-17 13:15:49,637 : agent.on_policy : DEBUG : Mean Losses: [5.506482660770416]
2026-01-17 13:15:49,802 : agent.on_policy : DEBUG : Mean Losses: [5.4308900237083435]
2026-01-17 13:15:49,930 : agent.on_policy : DEBUG : Mean Losses: [5.4484743475914]
2026-01-17 13:15:50,074 : agent.on_policy : DEBUG : Mean Losses: [5.429007530212402]
2026-01-17 13:15:50,215 : agent.on_policy : DEBUG : Mean Losses: [5.324472665786743]
2026-01-17 13:15:50,342 : agent.on_policy : DEBUG : Mean Losses: [5.208153665065765]
2026-01-17 13:15:50,512 : agent.on_policy : DEBUG : Mean Losses: [5.20583438873291]
2026-01-17 13:15:50,653 : agent.on_policy : DEBUG : Mean Losses: [5.1367639899253845]
2026-01-17 13:15:50,795 : agent.on_policy : DEBUG : Mean Losses: [5.120117127895355]
2026-01-17 13:15:50,959 : agent.on_policy : DEBUG : Mean Losses: [5.088756620883942]
2026-01-17 13:15:51,088 : agent.on_policy : DEBUG : Mean Losses: [5.073364555835724]
2026-01-17 13:15:51,230 : agent.on_policy : DEBUG : Mean Losses: [5.077463269233704]
2026-01-17 13:15:51,387 : agent.on_policy : DEBUG : Mean Losses: [5.054832577705383]
2026-01-17 13:15:51,548 : agent.on_policy : DEBUG : Mean Losses: [5.0282028913497925]
2026-01-17 13:15:51,609 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.9025
2026-01-17 13:15:51,620 : worker.worker : DEBUG : Step 2002, finished rewards -477.46, envs finished 8
2026-01-17 13:15:51,741 : agent.on_policy : DEBUG : Mean Losses: [3.4368116557598114]
2026-01-17 13:15:51,950 : agent.on_policy : DEBUG : Mean Losses: [5.329875290393829]
2026-01-17 13:15:52,138 : agent.on_policy : DEBUG : Mean Losses: [5.228342652320862]
2026-01-17 13:15:52,263 : agent.on_policy : DEBUG : Mean Losses: [5.171761155128479]
2026-01-17 13:15:52,423 : agent.on_policy : DEBUG : Mean Losses: [5.1709083914756775]
2026-01-17 13:15:52,615 : agent.on_policy : DEBUG : Mean Losses: [5.201821506023407]
2026-01-17 13:15:52,764 : agent.on_policy : DEBUG : Mean Losses: [5.160906612873077]
2026-01-17 13:15:52,887 : agent.on_policy : DEBUG : Mean Losses: [5.1514317989349365]
2026-01-17 13:15:53,030 : agent.on_policy : DEBUG : Mean Losses: [5.1451122760772705]
2026-01-17 13:15:53,156 : agent.on_policy : DEBUG : Mean Losses: [5.1003066301345825]
2026-01-17 13:15:53,287 : agent.on_policy : DEBUG : Mean Losses: [5.050305366516113]
2026-01-17 13:15:53,414 : agent.on_policy : DEBUG : Mean Losses: [4.966903507709503]
2026-01-17 13:15:53,575 : agent.on_policy : DEBUG : Mean Losses: [4.972979784011841]
2026-01-17 13:15:53,698 : agent.on_policy : DEBUG : Mean Losses: [4.881206512451172]
2026-01-17 13:15:53,845 : agent.on_policy : DEBUG : Mean Losses: [4.8610429763793945]
2026-01-17 13:15:53,980 : agent.on_policy : DEBUG : Mean Losses: [4.764352858066559]
2026-01-17 13:15:54,020 : worker.worker : DEBUG : Step 2503, finished rewards -478.11, envs finished 8
2026-01-17 13:15:54,194 : agent.on_policy : DEBUG : Mean Losses: [5.300225079059601]
2026-01-17 13:15:54,319 : agent.on_policy : DEBUG : Mean Losses: [5.206026971340179]
2026-01-17 13:15:54,462 : agent.on_policy : DEBUG : Mean Losses: [5.120070278644562]
2026-01-17 13:15:54,593 : agent.on_policy : DEBUG : Mean Losses: [5.0180933475494385]
2026-01-17 13:15:54,730 : agent.on_policy : DEBUG : Mean Losses: [4.903216540813446]
2026-01-17 13:15:54,936 : agent.on_policy : DEBUG : Mean Losses: [4.741006016731262]
2026-01-17 13:15:54,385 : agent.on_policy : DEBUG : Mean Losses: [4.707004964351654]
2026-01-17 13:15:54,495 : agent.on_policy : DEBUG : Mean Losses: [4.683133542537689]
2026-01-17 13:15:54,612 : agent.on_policy : DEBUG : Mean Losses: [4.568447709083557]
2026-01-17 13:15:54,733 : agent.on_policy : DEBUG : Mean Losses: [4.607890546321869]
2026-01-17 13:15:54,853 : agent.on_policy : DEBUG : Mean Losses: [4.607531726360321]
2026-01-17 13:15:54,969 : agent.on_policy : DEBUG : Mean Losses: [4.545381844043732]
2026-01-17 13:15:55,116 : agent.on_policy : DEBUG : Mean Losses: [4.423291802406311]
2026-01-17 13:15:55,226 : agent.on_policy : DEBUG : Mean Losses: [4.348424553871155]
2026-01-17 13:15:55,351 : agent.on_policy : DEBUG : Mean Losses: [4.134731739759445]
2026-01-17 13:15:55,430 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.8573749999999999
2026-01-17 13:15:55,451 : worker.worker : DEBUG : Step 3004, finished rewards -461.91, envs finished 8
2026-01-17 13:15:55,535 : agent.on_policy : DEBUG : Mean Losses: [4.0438631772994995]
2026-01-17 13:15:55,674 : agent.on_policy : DEBUG : Mean Losses: [5.063171684741974]
2026-01-17 13:15:55,815 : agent.on_policy : DEBUG : Mean Losses: [5.0300750732421875]
2026-01-17 13:15:55,950 : agent.on_policy : DEBUG : Mean Losses: [4.968937993049622]
2026-01-17 13:15:56,080 : agent.on_policy : DEBUG : Mean Losses: [4.920509040355682]
2026-01-17 13:15:56,203 : agent.on_policy : DEBUG : Mean Losses: [4.851281762123108]
2026-01-17 13:15:56,438 : agent.on_policy : DEBUG : Mean Losses: [4.821380317211151]
2026-01-17 13:15:56,568 : agent.on_policy : DEBUG : Mean Losses: [4.729622662067413]
2026-01-17 13:15:56,701 : agent.on_policy : DEBUG : Mean Losses: [4.658403724431992]
2026-01-17 13:15:56,831 : agent.on_policy : DEBUG : Mean Losses: [4.546906501054764]
2026-01-17 13:15:56,963 : agent.on_policy : DEBUG : Mean Losses: [4.538836717605591]
2026-01-17 13:15:57,090 : agent.on_policy : DEBUG : Mean Losses: [4.556345492601395]
2026-01-17 13:15:57,217 : agent.on_policy : DEBUG : Mean Losses: [4.4986061453819275]
2026-01-17 13:15:57,346 : agent.on_policy : DEBUG : Mean Losses: [4.460088521242142]
2026-01-17 13:15:57,520 : agent.on_policy : DEBUG : Mean Losses: [4.41120171546936]
2026-01-17 13:15:57,654 : agent.on_policy : DEBUG : Mean Losses: [4.422041952610016]
2026-01-17 13:15:57,727 : worker.worker : DEBUG : Step 3505, finished rewards -474.93, envs finished 8
2026-01-17 13:15:57,834 : agent.on_policy : DEBUG : Mean Losses: [4.48560756444931]
2026-01-17 13:15:57,962 : agent.on_policy : DEBUG : Mean Losses: [4.931029498577118]
2026-01-17 13:15:58,113 : agent.on_policy : DEBUG : Mean Losses: [4.866397380828857]
2026-01-17 13:15:58,239 : agent.on_policy : DEBUG : Mean Losses: [4.763999700546265]
2026-01-17 13:15:58,405 : agent.on_policy : DEBUG : Mean Losses: [4.688378632068634]
2026-01-17 13:15:58,643 : agent.on_policy : DEBUG : Mean Losses: [4.649772644042969]
2026-01-17 13:15:58,773 : agent.on_policy : DEBUG : Mean Losses: [4.586276292800903]
2026-01-17 13:15:58,920 : agent.on_policy : DEBUG : Mean Losses: [4.502037703990936]
2026-01-17 13:15:59,041 : agent.on_policy : DEBUG : Mean Losses: [4.390702128410339]
2026-01-17 13:15:59,199 : agent.on_policy : DEBUG : Mean Losses: [4.248533636331558]
2026-01-17 13:15:59,321 : agent.on_policy : DEBUG : Mean Losses: [4.3324757516384125]
2026-01-17 13:15:59,477 : agent.on_policy : DEBUG : Mean Losses: [4.182877153158188]
2026-01-17 13:15:59,612 : agent.on_policy : DEBUG : Mean Losses: [4.187107115983963]
2026-01-17 13:15:59,782 : agent.on_policy : DEBUG : Mean Losses: [4.318495690822601]
2026-01-17 13:15:59,943 : agent.on_policy : DEBUG : Mean Losses: [4.263642072677612]
2026-01-17 13:16:00,066 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.8145062499999999
2026-01-17 13:16:00,127 : agent.on_policy : DEBUG : Mean Losses: [4.259885609149933]
2026-01-17 13:16:00,153 : worker.worker : DEBUG : Step 4006, finished rewards -469.79, envs finished 8
2026-01-17 13:16:00,314 : agent.on_policy : DEBUG : Mean Losses: [6.1152637004852295]
2026-01-17 13:16:00,499 : agent.on_policy : DEBUG : Mean Losses: [4.679636895656586]
2026-01-17 13:16:00,623 : agent.on_policy : DEBUG : Mean Losses: [4.583019196987152]
2026-01-17 13:16:00,781 : agent.on_policy : DEBUG : Mean Losses: [4.452593207359314]
2026-01-17 13:16:00,903 : agent.on_policy : DEBUG : Mean Losses: [4.284941583871841]
2026-01-17 13:16:01,050 : agent.on_policy : DEBUG : Mean Losses: [4.252839356660843]
2026-01-17 13:16:01,196 : agent.on_policy : DEBUG : Mean Losses: [4.217368543148041]
2026-01-17 13:16:01,324 : agent.on_policy : DEBUG : Mean Losses: [4.183486878871918]
2026-01-17 13:16:01,473 : agent.on_policy : DEBUG : Mean Losses: [4.0816061198711395]
2026-01-17 13:16:01,652 : agent.on_policy : DEBUG : Mean Losses: [3.977717339992523]
2026-01-17 13:16:01,785 : agent.on_policy : DEBUG : Mean Losses: [4.1430865824222565]
2026-01-17 13:16:01,940 : agent.on_policy : DEBUG : Mean Losses: [3.963872492313385]
2026-01-17 13:16:02,137 : agent.on_policy : DEBUG : Mean Losses: [4.083263695240021]
2026-01-17 13:16:02,307 : agent.on_policy : DEBUG : Mean Losses: [3.9755513668060303]
2026-01-17 13:16:02,442 : agent.on_policy : DEBUG : Mean Losses: [3.9650059640407562]
2026-01-17 13:16:02,480 : worker.worker : DEBUG : Step 4489, finished rewards -309.70, envs finished 1
2026-01-17 13:16:02,541 : worker.worker : DEBUG : Step 4507, finished rewards -469.23, envs finished 7
2026-01-17 13:16:02,597 : agent.on_policy : DEBUG : Mean Losses: [7.895187258720398]
2026-01-17 13:16:02,743 : agent.on_policy : DEBUG : Mean Losses: [4.605666220188141]
2026-01-17 13:16:02,897 : agent.on_policy : DEBUG : Mean Losses: [4.547143578529358]
2026-01-17 13:16:03,023 : agent.on_policy : DEBUG : Mean Losses: [4.499832808971405]
2026-01-17 13:16:03,198 : agent.on_policy : DEBUG : Mean Losses: [4.458175212144852]
2026-01-17 13:16:03,336 : agent.on_policy : DEBUG : Mean Losses: [4.45580193400383]
2026-01-17 13:16:03,475 : agent.on_policy : DEBUG : Mean Losses: [4.3633227944374084]
2026-01-17 13:16:03,605 : agent.on_policy : DEBUG : Mean Losses: [4.319634288549423]
2026-01-17 13:16:03,763 : agent.on_policy : DEBUG : Mean Losses: [4.239145249128342]
2026-01-17 13:16:03,887 : agent.on_policy : DEBUG : Mean Losses: [4.1744727194309235]
2026-01-17 13:16:04,111 : agent.on_policy : DEBUG : Mean Losses: [4.118211179971695]
2026-01-17 13:16:04,285 : agent.on_policy : DEBUG : Mean Losses: [4.010351717472076]
2026-01-17 13:16:04,430 : agent.on_policy : DEBUG : Mean Losses: [4.083768844604492]
2026-01-17 13:16:04,606 : agent.on_policy : DEBUG : Mean Losses: [4.078311085700989]
2026-01-17 13:16:04,737 : agent.on_policy : DEBUG : Mean Losses: [4.025901794433594]
2026-01-17 13:16:04,833 : worker.worker : DEBUG : Step 4990, finished rewards -475.80, envs finished 1
2026-01-17 13:16:04,893 : agent.on_policy : DEBUG : Mean Losses: [4.285047769546509]
2026-01-17 13:16:04,917 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.7737809374999999
2026-01-17 13:16:04,924 : worker.worker : INFO : Step 5000, Avg Reward -458.5509, Max Reward -309.7006, Loss [4.95060137]
2026-01-17 13:16:04,951 : worker.worker : DEBUG : Step 5008, finished rewards -477.43, envs finished 7
2026-01-17 13:16:05,065 : agent.on_policy : DEBUG : Mean Losses: [5.719811201095581]
2026-01-17 13:16:05,219 : agent.on_policy : DEBUG : Mean Losses: [4.418893814086914]
2026-01-17 13:16:05,349 : agent.on_policy : DEBUG : Mean Losses: [4.325412690639496]
2026-01-17 13:16:05,480 : agent.on_policy : DEBUG : Mean Losses: [4.244060724973679]
2026-01-17 13:16:05,618 : agent.on_policy : DEBUG : Mean Losses: [4.19039511680603]
2026-01-17 13:16:05,745 : agent.on_policy : DEBUG : Mean Losses: [4.159350574016571]
2026-01-17 13:16:05,899 : agent.on_policy : DEBUG : Mean Losses: [4.084921211004257]
2026-01-17 13:16:06,043 : agent.on_policy : DEBUG : Mean Losses: [4.054591566324234]
2026-01-17 13:16:06,183 : agent.on_policy : DEBUG : Mean Losses: [4.072379797697067]
2026-01-17 13:16:06,330 : agent.on_policy : DEBUG : Mean Losses: [4.00709456205368]
2026-01-17 13:16:06,454 : agent.on_policy : DEBUG : Mean Losses: [3.8350855708122253]
2026-01-17 13:16:06,603 : agent.on_policy : DEBUG : Mean Losses: [3.7667603194713593]
2026-01-17 13:16:06,777 : agent.on_policy : DEBUG : Mean Losses: [3.688404142856598]
2026-01-17 13:16:06,912 : agent.on_policy : DEBUG : Mean Losses: [3.7239483892917633]
2026-01-17 13:16:07,135 : agent.on_policy : DEBUG : Mean Losses: [3.7156315743923187]
2026-01-17 13:16:07,200 : worker.worker : DEBUG : Step 5491, finished rewards -481.53, envs finished 1
2026-01-17 13:16:07,313 : agent.on_policy : DEBUG : Mean Losses: [4.0629494190216064]
2026-01-17 13:16:07,329 : worker.worker : DEBUG : Step 5509, finished rewards -467.31, envs finished 7
2026-01-17 13:16:07,460 : agent.on_policy : DEBUG : Mean Losses: [6.277405560016632]
2026-01-17 13:16:07,640 : agent.on_policy : DEBUG : Mean Losses: [4.22201868891716]
2026-01-17 13:16:07,767 : agent.on_policy : DEBUG : Mean Losses: [4.162238389253616]
2026-01-17 13:16:07,913 : agent.on_policy : DEBUG : Mean Losses: [4.042690873146057]
2026-01-17 13:16:08,044 : agent.on_policy : DEBUG : Mean Losses: [3.9683762788772583]
2026-01-17 13:16:08,206 : agent.on_policy : DEBUG : Mean Losses: [3.936718165874481]
2026-01-17 13:16:08,352 : agent.on_policy : DEBUG : Mean Losses: [3.84046670794487]
2026-01-17 13:16:08,512 : agent.on_policy : DEBUG : Mean Losses: [3.858375996351242]
2026-01-17 13:16:08,636 : agent.on_policy : DEBUG : Mean Losses: [3.8936721086502075]
2026-01-17 13:16:08,745 : worker.worker : DEBUG : Step 5808, finished rewards -165.59, envs finished 1
2026-01-17 13:16:08,956 : agent.on_policy : DEBUG : Mean Losses: [7.396240055561066]
2026-01-17 13:16:09,115 : agent.on_policy : DEBUG : Mean Losses: [3.910125881433487]
2026-01-17 13:16:09,261 : agent.on_policy : DEBUG : Mean Losses: [3.9169385135173798]
2026-01-17 13:16:09,400 : agent.on_policy : DEBUG : Mean Losses: [3.825752764940262]
2026-01-17 13:16:09,560 : agent.on_policy : DEBUG : Mean Losses: [3.8485745191574097]
2026-01-17 13:16:09,688 : agent.on_policy : DEBUG : Mean Losses: [3.7586608231067657]
2026-01-17 13:16:09,721 : worker.worker : DEBUG : Step 5992, finished rewards -465.81, envs finished 1
2026-01-17 13:16:09,745 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.7350918906249998
2026-01-17 13:16:09,785 : worker.worker : DEBUG : Step 6010, finished rewards -480.14, envs finished 6
2026-01-17 13:16:09,853 : agent.on_policy : DEBUG : Mean Losses: [6.135826528072357]
2026-01-17 13:16:09,995 : agent.on_policy : DEBUG : Mean Losses: [4.046664386987686]
2026-01-17 13:16:10,120 : agent.on_policy : DEBUG : Mean Losses: [4.002426773309708]
2026-01-17 13:16:10,273 : agent.on_policy : DEBUG : Mean Losses: [3.950329601764679]
2026-01-17 13:16:10,423 : agent.on_policy : DEBUG : Mean Losses: [3.860299736261368]
2026-01-17 13:16:10,562 : agent.on_policy : DEBUG : Mean Losses: [3.7915103435516357]
2026-01-17 13:16:10,700 : agent.on_policy : DEBUG : Mean Losses: [3.779089868068695]
2026-01-17 13:16:10,838 : agent.on_policy : DEBUG : Mean Losses: [3.7139604091644287]
2026-01-17 13:16:11,000 : agent.on_policy : DEBUG : Mean Losses: [3.6577922701835632]
2026-01-17 13:16:11,164 : agent.on_policy : DEBUG : Mean Losses: [3.571114957332611]
2026-01-17 13:16:11,182 : worker.worker : DEBUG : Step 6309, finished rewards -473.76, envs finished 1
2026-01-17 13:16:11,324 : agent.on_policy : DEBUG : Mean Losses: [4.007779061794281]
2026-01-17 13:16:11,517 : agent.on_policy : DEBUG : Mean Losses: [3.4810990691184998]
2026-01-17 13:16:11,695 : agent.on_policy : DEBUG : Mean Losses: [3.6167067289352417]
2026-01-17 13:16:11,917 : agent.on_policy : DEBUG : Mean Losses: [3.593060940504074]
2026-01-17 13:16:12,089 : agent.on_policy : DEBUG : Mean Losses: [3.55381840467453]
2026-01-17 13:16:12,192 : worker.worker : DEBUG : Step 6493, finished rewards -445.45, envs finished 1
2026-01-17 13:16:12,284 : agent.on_policy : DEBUG : Mean Losses: [4.205688565969467]
2026-01-17 13:16:12,356 : worker.worker : DEBUG : Step 6511, finished rewards -475.58, envs finished 6
2026-01-17 13:16:12,496 : agent.on_policy : DEBUG : Mean Losses: [6.601699680089951]
2026-01-17 13:16:12,719 : agent.on_policy : DEBUG : Mean Losses: [3.9904647767543793]
2026-01-17 13:16:12,933 : agent.on_policy : DEBUG : Mean Losses: [3.908801794052124]
2026-01-17 13:16:13,151 : agent.on_policy : DEBUG : Mean Losses: [3.8272038400173187]
2026-01-17 13:16:13,395 : agent.on_policy : DEBUG : Mean Losses: [3.6989507377147675]
2026-01-17 13:16:13,638 : agent.on_policy : DEBUG : Mean Losses: [3.576549082994461]
2026-01-17 13:16:13,855 : agent.on_policy : DEBUG : Mean Losses: [3.46179336309433]
2026-01-17 13:16:14,043 : agent.on_policy : DEBUG : Mean Losses: [3.429528146982193]
2026-01-17 13:16:14,239 : agent.on_policy : DEBUG : Mean Losses: [3.360633373260498]
2026-01-17 13:16:14,331 : worker.worker : DEBUG : Step 6810, finished rewards -481.33, envs finished 1
2026-01-17 13:16:14,442 : agent.on_policy : DEBUG : Mean Losses: [3.8616496324539185]
2026-01-17 13:16:14,666 : agent.on_policy : DEBUG : Mean Losses: [3.533678859472275]
2026-01-17 13:16:14,882 : agent.on_policy : DEBUG : Mean Losses: [3.7072307467460632]
2026-01-17 13:16:15,091 : agent.on_policy : DEBUG : Mean Losses: [3.4148511588573456]
2026-01-17 13:16:15,281 : worker.worker : DEBUG : Step 6940, finished rewards -267.55, envs finished 1
2026-01-17 13:16:15,371 : agent.on_policy : DEBUG : Mean Losses: [7.394045174121857]
2026-01-17 13:16:15,564 : agent.on_policy : DEBUG : Mean Losses: [3.588010400533676]
2026-01-17 13:16:15,632 : worker.worker : DEBUG : Step 6994, finished rewards -478.53, envs finished 1
2026-01-17 13:16:15,648 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.6983372960937497
2026-01-17 13:16:15,749 : agent.on_policy : DEBUG : Mean Losses: [4.256551593542099]
2026-01-17 13:16:15,764 : worker.worker : DEBUG : Step 7012, finished rewards -472.83, envs finished 5
2026-01-17 13:16:15,957 : agent.on_policy : DEBUG : Mean Losses: [5.557623267173767]
2026-01-17 13:16:16,135 : agent.on_policy : DEBUG : Mean Losses: [3.8238970041275024]
2026-01-17 13:16:16,318 : agent.on_policy : DEBUG : Mean Losses: [3.712005376815796]
2026-01-17 13:16:16,495 : agent.on_policy : DEBUG : Mean Losses: [3.6414552330970764]
2026-01-17 13:16:16,677 : agent.on_policy : DEBUG : Mean Losses: [3.5900070667266846]
2026-01-17 13:16:16,868 : agent.on_policy : DEBUG : Mean Losses: [3.5045026540756226]
2026-01-17 13:16:17,085 : agent.on_policy : DEBUG : Mean Losses: [3.499549925327301]
2026-01-17 13:16:17,271 : agent.on_policy : DEBUG : Mean Losses: [3.4841480553150177]
2026-01-17 13:16:17,470 : agent.on_policy : DEBUG : Mean Losses: [3.4099168181419373]
2026-01-17 13:16:17,531 : worker.worker : DEBUG : Step 7311, finished rewards -471.80, envs finished 1
2026-01-17 13:16:17,636 : agent.on_policy : DEBUG : Mean Losses: [4.056947022676468]
2026-01-17 13:16:17,753 : agent.on_policy : DEBUG : Mean Losses: [3.3813514411449432]
2026-01-17 13:16:17,911 : agent.on_policy : DEBUG : Mean Losses: [3.3460626006126404]
2026-01-17 13:16:18,054 : agent.on_policy : DEBUG : Mean Losses: [3.2423479557037354]
2026-01-17 13:16:18,106 : worker.worker : DEBUG : Step 7441, finished rewards -481.92, envs finished 1
2026-01-17 13:16:18,219 : agent.on_policy : DEBUG : Mean Losses: [3.8223592340946198]
2026-01-17 13:16:18,401 : agent.on_policy : DEBUG : Mean Losses: [3.281605452299118]
2026-01-17 13:16:18,425 : worker.worker : DEBUG : Step 7495, finished rewards -461.25, envs finished 1
2026-01-17 13:16:18,496 : worker.worker : DEBUG : Step 7513, finished rewards -477.40, envs finished 5
2026-01-17 13:16:18,608 : agent.on_policy : DEBUG : Mean Losses: [6.688337922096252]
2026-01-17 13:16:18,819 : agent.on_policy : DEBUG : Mean Losses: [3.6309476792812347]
2026-01-17 13:16:19,119 : agent.on_policy : DEBUG : Mean Losses: [3.554622143507004]
2026-01-17 13:16:19,384 : agent.on_policy : DEBUG : Mean Losses: [3.429064989089966]
2026-01-17 13:16:19,581 : agent.on_policy : DEBUG : Mean Losses: [3.3650512993335724]
2026-01-17 13:16:19,748 : agent.on_policy : DEBUG : Mean Losses: [3.3181059062480927]
2026-01-17 13:16:19,882 : agent.on_policy : DEBUG : Mean Losses: [3.3424666821956635]
2026-01-17 13:16:20,024 : agent.on_policy : DEBUG : Mean Losses: [3.289034456014633]
2026-01-17 13:16:20,152 : agent.on_policy : DEBUG : Mean Losses: [3.1177280843257904]
2026-01-17 13:16:20,308 : agent.on_policy : DEBUG : Mean Losses: [3.1132104992866516]
2026-01-17 13:16:20,322 : worker.worker : DEBUG : Step 7812, finished rewards -456.63, envs finished 1
2026-01-17 13:16:20,456 : agent.on_policy : DEBUG : Mean Losses: [3.5881713032722473]
2026-01-17 13:16:20,611 : agent.on_policy : DEBUG : Mean Losses: [3.1736327707767487]
2026-01-17 13:16:20,736 : agent.on_policy : DEBUG : Mean Losses: [3.1150529086589813]
2026-01-17 13:16:20,910 : agent.on_policy : DEBUG : Mean Losses: [3.1002317667007446]
2026-01-17 13:16:20,937 : worker.worker : DEBUG : Step 7942, finished rewards -488.83, envs finished 1
2026-01-17 13:16:21,092 : agent.on_policy : DEBUG : Mean Losses: [3.6837718188762665]
2026-01-17 13:16:21,179 : worker.worker : DEBUG : Step 7996, finished rewards -456.45, envs finished 1
2026-01-17 13:16:21,185 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.6634204312890623
2026-01-17 13:16:21,245 : agent.on_policy : DEBUG : Mean Losses: [4.066815763711929]
2026-01-17 13:16:21,306 : worker.worker : DEBUG : Step 8014, finished rewards -469.28, envs finished 5
2026-01-17 13:16:21,456 : agent.on_policy : DEBUG : Mean Losses: [6.932681500911713]
2026-01-17 13:16:21,665 : agent.on_policy : DEBUG : Mean Losses: [3.495496392250061]
2026-01-17 13:16:21,883 : agent.on_policy : DEBUG : Mean Losses: [3.455591559410095]
2026-01-17 13:16:22,084 : agent.on_policy : DEBUG : Mean Losses: [3.356521248817444]
2026-01-17 13:16:22,271 : agent.on_policy : DEBUG : Mean Losses: [3.297026365995407]
2026-01-17 13:16:22,404 : agent.on_policy : DEBUG : Mean Losses: [3.2161787152290344]
2026-01-17 13:16:22,600 : agent.on_policy : DEBUG : Mean Losses: [3.2405817210674286]
2026-01-17 13:16:22,870 : agent.on_policy : DEBUG : Mean Losses: [3.1722719371318817]
2026-01-17 13:16:23,037 : agent.on_policy : DEBUG : Mean Losses: [3.1073990166187286]
2026-01-17 13:16:23,117 : worker.worker : DEBUG : Step 8313, finished rewards -478.59, envs finished 1
2026-01-17 13:16:23,181 : agent.on_policy : DEBUG : Mean Losses: [3.7822344601154327]
2026-01-17 13:16:23,341 : agent.on_policy : DEBUG : Mean Losses: [3.048697292804718]
2026-01-17 13:16:23,475 : agent.on_policy : DEBUG : Mean Losses: [3.0371786057949066]
2026-01-17 13:16:23,613 : agent.on_policy : DEBUG : Mean Losses: [3.0137088894844055]
2026-01-17 13:16:23,710 : worker.worker : DEBUG : Step 8443, finished rewards -485.78, envs finished 1
2026-01-17 13:16:23,811 : agent.on_policy : DEBUG : Mean Losses: [3.6849790811538696]
2026-01-17 13:16:23,974 : agent.on_policy : DEBUG : Mean Losses: [3.00299072265625]
2026-01-17 13:16:24,026 : worker.worker : DEBUG : Step 8497, finished rewards -494.22, envs finished 1
2026-01-17 13:16:24,129 : agent.on_policy : DEBUG : Mean Losses: [3.898362398147583]
2026-01-17 13:16:24,139 : worker.worker : DEBUG : Step 8515, finished rewards -465.60, envs finished 5
2026-01-17 13:16:23,487 : agent.on_policy : DEBUG : Mean Losses: [5.035437971353531]
2026-01-17 13:16:23,593 : agent.on_policy : DEBUG : Mean Losses: [3.2239507138729095]
2026-01-17 13:16:23,728 : agent.on_policy : DEBUG : Mean Losses: [3.1493418514728546]
2026-01-17 13:16:23,846 : agent.on_policy : DEBUG : Mean Losses: [3.165764421224594]
2026-01-17 13:16:23,993 : agent.on_policy : DEBUG : Mean Losses: [3.1089667081832886]
2026-01-17 13:16:24,108 : agent.on_policy : DEBUG : Mean Losses: [3.0201111435890198]
2026-01-17 13:16:24,261 : agent.on_policy : DEBUG : Mean Losses: [3.084781289100647]
2026-01-17 13:16:24,387 : agent.on_policy : DEBUG : Mean Losses: [3.0570934414863586]
2026-01-17 13:16:24,505 : agent.on_policy : DEBUG : Mean Losses: [3.0763213634490967]
2026-01-17 13:16:24,555 : worker.worker : DEBUG : Step 8814, finished rewards -448.78, envs finished 1
2026-01-17 13:16:24,658 : agent.on_policy : DEBUG : Mean Losses: [3.9030863642692566]
2026-01-17 13:16:24,807 : agent.on_policy : DEBUG : Mean Losses: [2.9829062819480896]
2026-01-17 13:16:24,915 : agent.on_policy : DEBUG : Mean Losses: [2.914382368326187]
2026-01-17 13:16:25,062 : agent.on_policy : DEBUG : Mean Losses: [2.956781327724457]
2026-01-17 13:16:25,112 : worker.worker : DEBUG : Step 8944, finished rewards -478.44, envs finished 1
2026-01-17 13:16:25,225 : agent.on_policy : DEBUG : Mean Losses: [3.699170768260956]
2026-01-17 13:16:25,261 : worker.worker : DEBUG : Step 8968, finished rewards -317.32, envs finished 1
2026-01-17 13:16:25,397 : agent.on_policy : DEBUG : Mean Losses: [5.937755614519119]
2026-01-17 13:16:25,422 : worker.worker : DEBUG : Step 8998, finished rewards -474.90, envs finished 1
2026-01-17 13:16:25,423 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.6302494097246091
2026-01-17 13:16:25,484 : worker.worker : DEBUG : Step 9016, finished rewards -481.98, envs finished 4
2026-01-17 13:16:25,546 : agent.on_policy : DEBUG : Mean Losses: [6.82881623506546]
2026-01-17 13:16:25,697 : agent.on_policy : DEBUG : Mean Losses: [3.2309645116329193]
2026-01-17 13:16:25,820 : agent.on_policy : DEBUG : Mean Losses: [3.1468566954135895]
2026-01-17 13:16:25,957 : agent.on_policy : DEBUG : Mean Losses: [3.133123368024826]
2026-01-17 13:16:26,121 : agent.on_policy : DEBUG : Mean Losses: [3.0680995881557465]
2026-01-17 13:16:26,247 : agent.on_policy : DEBUG : Mean Losses: [2.997034788131714]
2026-01-17 13:16:26,394 : agent.on_policy : DEBUG : Mean Losses: [2.912987768650055]
2026-01-17 13:16:26,513 : agent.on_policy : DEBUG : Mean Losses: [2.9194976091384888]
2026-01-17 13:16:26,647 : agent.on_policy : DEBUG : Mean Losses: [2.879468321800232]
2026-01-17 13:16:26,799 : agent.on_policy : DEBUG : Mean Losses: [2.848670393228531]
2026-01-17 13:16:26,808 : worker.worker : DEBUG : Step 9315, finished rewards -457.72, envs finished 1
2026-01-17 13:16:26,933 : agent.on_policy : DEBUG : Mean Losses: [3.2981092035770416]
2026-01-17 13:16:27,082 : agent.on_policy : DEBUG : Mean Losses: [2.90371835231781]
2026-01-17 13:16:27,218 : agent.on_policy : DEBUG : Mean Losses: [2.8696904480457306]
2026-01-17 13:16:27,408 : agent.on_policy : DEBUG : Mean Losses: [2.7990683019161224]
2026-01-17 13:16:27,432 : worker.worker : DEBUG : Step 9445, finished rewards -480.97, envs finished 1
2026-01-17 13:16:27,530 : worker.worker : DEBUG : Step 9469, finished rewards -472.62, envs finished 1
2026-01-17 13:16:27,602 : agent.on_policy : DEBUG : Mean Losses: [4.289421260356903]
2026-01-17 13:16:27,690 : worker.worker : DEBUG : Step 9499, finished rewards -476.82, envs finished 1
2026-01-17 13:16:27,749 : agent.on_policy : DEBUG : Mean Losses: [4.088518142700195]
2026-01-17 13:16:27,790 : worker.worker : DEBUG : Step 9517, finished rewards -483.40, envs finished 4
2026-01-17 13:16:27,906 : agent.on_policy : DEBUG : Mean Losses: [6.5813621282577515]
2026-01-17 13:16:28,067 : agent.on_policy : DEBUG : Mean Losses: [2.9956196546554565]
2026-01-17 13:16:28,213 : agent.on_policy : DEBUG : Mean Losses: [2.919641762971878]
2026-01-17 13:16:28,369 : agent.on_policy : DEBUG : Mean Losses: [2.898545116186142]
2026-01-17 13:16:28,682 : agent.on_policy : DEBUG : Mean Losses: [2.8932991921901703]
2026-01-17 13:16:28,810 : agent.on_policy : DEBUG : Mean Losses: [2.8949527740478516]
2026-01-17 13:16:28,944 : agent.on_policy : DEBUG : Mean Losses: [2.894391506910324]
2026-01-17 13:16:29,105 : agent.on_policy : DEBUG : Mean Losses: [2.8706112802028656]
2026-01-17 13:16:29,232 : agent.on_policy : DEBUG : Mean Losses: [2.8437677919864655]
2026-01-17 13:16:29,312 : worker.worker : DEBUG : Step 9816, finished rewards -456.46, envs finished 1
2026-01-17 13:16:29,389 : agent.on_policy : DEBUG : Mean Losses: [3.8293953239917755]
2026-01-17 13:16:29,534 : agent.on_policy : DEBUG : Mean Losses: [2.904383361339569]
2026-01-17 13:16:29,723 : agent.on_policy : DEBUG : Mean Losses: [2.894685983657837]
2026-01-17 13:16:29,872 : agent.on_policy : DEBUG : Mean Losses: [2.796192765235901]
2026-01-17 13:16:29,952 : worker.worker : DEBUG : Step 9946, finished rewards -474.95, envs finished 1
2026-01-17 13:16:30,021 : agent.on_policy : DEBUG : Mean Losses: [3.759049713611603]
2026-01-17 13:16:30,104 : worker.worker : DEBUG : Step 9970, finished rewards -490.35, envs finished 1
2026-01-17 13:16:30,205 : agent.on_policy : DEBUG : Mean Losses: [3.826563149690628]
2026-01-17 13:16:30,251 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.5987369392383786
2026-01-17 13:16:30,260 : worker.worker : DEBUG : Step 10000, finished rewards -486.55, envs finished 1
2026-01-17 13:16:30,262 : worker.worker : INFO : Step 10000, Avg Reward -456.4571, Max Reward -165.5853, Loss [3.75327589]
2026-01-17 13:16:30,418 : agent.on_policy : DEBUG : Mean Losses: [4.176272243261337]
2026-01-17 13:16:30,428 : worker.worker : DEBUG : Step 10018, finished rewards -486.57, envs finished 4
2026-01-17 13:16:30,649 : agent.on_policy : DEBUG : Mean Losses: [4.168203055858612]
2026-01-17 13:16:30,781 : agent.on_policy : DEBUG : Mean Losses: [2.93735334277153]
2026-01-17 13:16:30,936 : agent.on_policy : DEBUG : Mean Losses: [2.845025658607483]
2026-01-17 13:16:31,069 : agent.on_policy : DEBUG : Mean Losses: [2.6971172988414764]
2026-01-17 13:16:31,256 : agent.on_policy : DEBUG : Mean Losses: [2.6179207265377045]
2026-01-17 13:16:31,453 : agent.on_policy : DEBUG : Mean Losses: [2.542187601327896]
2026-01-17 13:16:31,733 : agent.on_policy : DEBUG : Mean Losses: [2.4823705554008484]
2026-01-17 13:16:31,903 : agent.on_policy : DEBUG : Mean Losses: [2.5263011753559113]
2026-01-17 13:16:32,067 : agent.on_policy : DEBUG : Mean Losses: [2.455219089984894]
2026-01-17 13:16:32,119 : worker.worker : DEBUG : Step 10317, finished rewards -475.17, envs finished 1
2026-01-17 13:16:32,278 : agent.on_policy : DEBUG : Mean Losses: [3.4808117747306824]
2026-01-17 13:16:32,465 : agent.on_policy : DEBUG : Mean Losses: [2.5229135751724243]
2026-01-17 13:16:32,596 : agent.on_policy : DEBUG : Mean Losses: [2.5664261281490326]
2026-01-17 13:16:32,751 : agent.on_policy : DEBUG : Mean Losses: [2.5375871658325195]
2026-01-17 13:16:32,795 : worker.worker : DEBUG : Step 10447, finished rewards -476.78, envs finished 1
2026-01-17 13:16:32,888 : agent.on_policy : DEBUG : Mean Losses: [3.5993362963199615]
2026-01-17 13:16:32,910 : worker.worker : DEBUG : Step 10471, finished rewards -476.57, envs finished 1
2026-01-17 13:16:33,037 : agent.on_policy : DEBUG : Mean Losses: [3.344850093126297]
2026-01-17 13:16:33,064 : worker.worker : DEBUG : Step 10501, finished rewards -477.83, envs finished 1
2026-01-17 13:16:33,127 : worker.worker : DEBUG : Step 10519, finished rewards -469.07, envs finished 4
2026-01-17 13:16:33,223 : agent.on_policy : DEBUG : Mean Losses: [7.5551150143146515]
2026-01-17 13:16:33,374 : agent.on_policy : DEBUG : Mean Losses: [2.7513837218284607]
2026-01-17 13:16:33,507 : agent.on_policy : DEBUG : Mean Losses: [2.714292287826538]
2026-01-17 13:16:33,667 : agent.on_policy : DEBUG : Mean Losses: [2.633865177631378]
2026-01-17 13:16:33,874 : agent.on_policy : DEBUG : Mean Losses: [2.5605644285678864]
2026-01-17 13:16:34,047 : agent.on_policy : DEBUG : Mean Losses: [2.5423494279384613]
2026-01-17 13:16:34,173 : agent.on_policy : DEBUG : Mean Losses: [2.4664078652858734]
2026-01-17 13:16:34,323 : agent.on_policy : DEBUG : Mean Losses: [2.3886409997940063]
2026-01-17 13:16:34,469 : agent.on_policy : DEBUG : Mean Losses: [2.252011239528656]
2026-01-17 13:16:34,515 : worker.worker : DEBUG : Step 10799, finished rewards -219.46, envs finished 1
2026-01-17 13:16:34,630 : agent.on_policy : DEBUG : Mean Losses: [6.529731720685959]
2026-01-17 13:16:34,639 : worker.worker : DEBUG : Step 10818, finished rewards -469.49, envs finished 1
2026-01-17 13:16:34,802 : agent.on_policy : DEBUG : Mean Losses: [2.814788967370987]
2026-01-17 13:16:34,928 : agent.on_policy : DEBUG : Mean Losses: [2.442883998155594]
2026-01-17 13:16:35,086 : agent.on_policy : DEBUG : Mean Losses: [2.413880780339241]
2026-01-17 13:16:35,219 : agent.on_policy : DEBUG : Mean Losses: [2.3797640949487686]
2026-01-17 13:16:35,310 : worker.worker : DEBUG : Step 10972, finished rewards -469.05, envs finished 1
2026-01-17 13:16:35,383 : agent.on_policy : DEBUG : Mean Losses: [3.6492569744586945]
2026-01-17 13:16:35,467 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.5688000922764596
2026-01-17 13:16:35,480 : worker.worker : DEBUG : Step 11002, finished rewards -473.51, envs finished 1
2026-01-17 13:16:35,544 : agent.on_policy : DEBUG : Mean Losses: [4.13149881362915]
2026-01-17 13:16:35,581 : worker.worker : DEBUG : Step 11020, finished rewards -476.28, envs finished 4
2026-01-17 13:16:35,706 : agent.on_policy : DEBUG : Mean Losses: [7.026642262935638]
2026-01-17 13:16:35,855 : agent.on_policy : DEBUG : Mean Losses: [2.6468550860881805]
2026-01-17 13:16:35,977 : agent.on_policy : DEBUG : Mean Losses: [2.481279104948044]
2026-01-17 13:16:36,115 : agent.on_policy : DEBUG : Mean Losses: [2.439476400613785]
2026-01-17 13:16:36,252 : agent.on_policy : DEBUG : Mean Losses: [2.222957029938698]
2026-01-17 13:16:36,325 : worker.worker : DEBUG : Step 11189, finished rewards -267.13, envs finished 1
2026-01-17 13:16:36,430 : agent.on_policy : DEBUG : Mean Losses: [6.901801496744156]
2026-01-17 13:16:36,563 : agent.on_policy : DEBUG : Mean Losses: [2.350805163383484]
2026-01-17 13:16:36,708 : agent.on_policy : DEBUG : Mean Losses: [2.322959154844284]
2026-01-17 13:16:36,876 : agent.on_policy : DEBUG : Mean Losses: [2.3581740260124207]
2026-01-17 13:16:36,968 : worker.worker : DEBUG : Step 11319, finished rewards -470.41, envs finished 1
2026-01-17 13:16:37,066 : agent.on_policy : DEBUG : Mean Losses: [3.6770856976509094]
2026-01-17 13:16:37,213 : agent.on_policy : DEBUG : Mean Losses: [2.525763362646103]
2026-01-17 13:16:37,349 : agent.on_policy : DEBUG : Mean Losses: [2.3536794185638428]
2026-01-17 13:16:37,497 : agent.on_policy : DEBUG : Mean Losses: [2.2812725007534027]
2026-01-17 13:16:37,633 : agent.on_policy : DEBUG : Mean Losses: [2.283016562461853]
2026-01-17 13:16:37,698 : worker.worker : DEBUG : Step 11473, finished rewards -481.03, envs finished 1
2026-01-17 13:16:37,811 : agent.on_policy : DEBUG : Mean Losses: [3.4827961176633835]
2026-01-17 13:16:37,852 : worker.worker : DEBUG : Step 11503, finished rewards -483.19, envs finished 1
2026-01-17 13:16:37,955 : agent.on_policy : DEBUG : Mean Losses: [3.9064259082078934]
2026-01-17 13:16:37,959 : worker.worker : DEBUG : Step 11521, finished rewards -472.05, envs finished 4
2026-01-17 13:16:38,115 : agent.on_policy : DEBUG : Mean Losses: [3.2202780544757843]
2026-01-17 13:16:38,241 : agent.on_policy : DEBUG : Mean Losses: [2.384507864713669]
2026-01-17 13:16:38,400 : agent.on_policy : DEBUG : Mean Losses: [2.3851128816604614]
2026-01-17 13:16:38,524 : agent.on_policy : DEBUG : Mean Losses: [2.2667912542819977]
2026-01-17 13:16:38,683 : agent.on_policy : DEBUG : Mean Losses: [2.312267169356346]
2026-01-17 13:16:38,745 : worker.worker : DEBUG : Step 11690, finished rewards -479.19, envs finished 1
2026-01-17 13:16:38,956 : agent.on_policy : DEBUG : Mean Losses: [3.4061940908432007]
2026-01-17 13:16:39,141 : agent.on_policy : DEBUG : Mean Losses: [2.227725178003311]
2026-01-17 13:16:39,269 : agent.on_policy : DEBUG : Mean Losses: [2.0576295852661133]
2026-01-17 13:16:39,435 : agent.on_policy : DEBUG : Mean Losses: [1.9717562794685364]
2026-01-17 13:16:39,469 : worker.worker : DEBUG : Step 11820, finished rewards -457.85, envs finished 1
2026-01-17 13:16:39,582 : agent.on_policy : DEBUG : Mean Losses: [3.323487877845764]
2026-01-17 13:16:39,742 : agent.on_policy : DEBUG : Mean Losses: [2.0898619443178177]
2026-01-17 13:16:39,938 : agent.on_policy : DEBUG : Mean Losses: [2.05162650346756]
2026-01-17 13:16:40,130 : agent.on_policy : DEBUG : Mean Losses: [1.945284143090248]
2026-01-17 13:16:40,329 : agent.on_policy : DEBUG : Mean Losses: [1.8403257057070732]
2026-01-17 13:16:40,356 : worker.worker : DEBUG : Step 11974, finished rewards -489.24, envs finished 1
2026-01-17 13:16:40,476 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.5403600876626365
2026-01-17 13:16:40,558 : agent.on_policy : DEBUG : Mean Losses: [2.6142041832208633]
2026-01-17 13:16:40,577 : worker.worker : DEBUG : Step 12004, finished rewards -450.61, envs finished 1
2026-01-17 13:16:40,683 : worker.worker : DEBUG : Step 12022, finished rewards -466.70, envs finished 4
2026-01-17 13:16:40,816 : agent.on_policy : DEBUG : Mean Losses: [8.493618100881577]
2026-01-17 13:16:41,039 : agent.on_policy : DEBUG : Mean Losses: [2.392637699842453]
2026-01-17 13:16:41,294 : agent.on_policy : DEBUG : Mean Losses: [2.35509991645813]
2026-01-17 13:16:41,541 : agent.on_policy : DEBUG : Mean Losses: [2.3200418949127197]
2026-01-17 13:16:41,743 : agent.on_policy : DEBUG : Mean Losses: [2.243117570877075]
2026-01-17 13:16:41,899 : worker.worker : DEBUG : Step 12191, finished rewards -477.73, envs finished 1
2026-01-17 13:16:41,972 : agent.on_policy : DEBUG : Mean Losses: [3.590113803744316]
2026-01-17 13:16:42,146 : agent.on_policy : DEBUG : Mean Losses: [2.264321267604828]
2026-01-17 13:16:42,361 : agent.on_policy : DEBUG : Mean Losses: [2.246146947145462]
2026-01-17 13:16:42,610 : agent.on_policy : DEBUG : Mean Losses: [2.1997390687465668]
2026-01-17 13:16:42,759 : agent.on_policy : DEBUG : Mean Losses: [2.204450950026512]
2026-01-17 13:16:42,765 : worker.worker : DEBUG : Step 12321, finished rewards -491.48, envs finished 1
2026-01-17 13:16:42,921 : agent.on_policy : DEBUG : Mean Losses: [2.394229531288147]
2026-01-17 13:16:43,071 : agent.on_policy : DEBUG : Mean Losses: [2.1891702115535736]
2026-01-17 13:16:43,242 : agent.on_policy : DEBUG : Mean Losses: [2.1559288799762726]
2026-01-17 13:16:43,408 : agent.on_policy : DEBUG : Mean Losses: [2.0510571748018265]
2026-01-17 13:16:43,490 : worker.worker : DEBUG : Step 12475, finished rewards -491.28, envs finished 1
2026-01-17 13:16:43,494 : worker.worker : DEBUG : Step 12476, finished rewards -319.35, envs finished 1
2026-01-17 13:16:43,574 : agent.on_policy : DEBUG : Mean Losses: [8.351292625069618]
2026-01-17 13:16:43,697 : worker.worker : DEBUG : Step 12505, finished rewards -479.90, envs finished 1
2026-01-17 13:16:43,788 : agent.on_policy : DEBUG : Mean Losses: [4.098128601908684]
2026-01-17 13:16:43,833 : worker.worker : DEBUG : Step 12523, finished rewards -484.20, envs finished 3
2026-01-17 13:16:43,967 : agent.on_policy : DEBUG : Mean Losses: [5.924212753772736]
2026-01-17 13:16:44,105 : agent.on_policy : DEBUG : Mean Losses: [2.1154076606035233]
2026-01-17 13:16:44,271 : agent.on_policy : DEBUG : Mean Losses: [2.0635574609041214]
2026-01-17 13:16:44,406 : agent.on_policy : DEBUG : Mean Losses: [2.065255805850029]
2026-01-17 13:16:44,565 : agent.on_policy : DEBUG : Mean Losses: [1.9593204110860825]
2026-01-17 13:16:44,626 : worker.worker : DEBUG : Step 12692, finished rewards -492.93, envs finished 1
2026-01-17 13:16:44,732 : agent.on_policy : DEBUG : Mean Losses: [3.440051183104515]
2026-01-17 13:16:44,877 : agent.on_policy : DEBUG : Mean Losses: [2.055432140827179]
2026-01-17 13:16:45,008 : agent.on_policy : DEBUG : Mean Losses: [2.0789298117160797]
2026-01-17 13:16:45,169 : agent.on_policy : DEBUG : Mean Losses: [1.9532338082790375]
2026-01-17 13:16:45,228 : worker.worker : DEBUG : Step 12822, finished rewards -481.94, envs finished 1
2026-01-17 13:16:45,303 : agent.on_policy : DEBUG : Mean Losses: [3.3790779411792755]
2026-01-17 13:16:45,458 : agent.on_policy : DEBUG : Mean Losses: [1.9851361066102982]
2026-01-17 13:16:45,597 : agent.on_policy : DEBUG : Mean Losses: [1.989099383354187]
2026-01-17 13:16:45,739 : agent.on_policy : DEBUG : Mean Losses: [1.9145933240652084]
2026-01-17 13:16:45,936 : agent.on_policy : DEBUG : Mean Losses: [1.8478073924779892]
2026-01-17 13:16:45,982 : worker.worker : DEBUG : Step 12976, finished rewards -476.33, envs finished 1
2026-01-17 13:16:45,985 : worker.worker : DEBUG : Step 12977, finished rewards -472.78, envs finished 1
2026-01-17 13:16:46,073 : agent.on_policy : DEBUG : Mean Losses: [4.77944903075695]
2026-01-17 13:16:46,092 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.5133420832795047
2026-01-17 13:16:46,114 : worker.worker : DEBUG : Step 13006, finished rewards -476.03, envs finished 1
2026-01-17 13:16:46,229 : agent.on_policy : DEBUG : Mean Losses: [3.7823349684476852]
2026-01-17 13:16:46,230 : worker.worker : DEBUG : Step 13024, finished rewards -475.10, envs finished 3
2026-01-17 13:16:46,388 : agent.on_policy : DEBUG : Mean Losses: [2.088624268770218]
2026-01-17 13:16:46,551 : agent.on_policy : DEBUG : Mean Losses: [2.066881388425827]
2026-01-17 13:16:46,696 : agent.on_policy : DEBUG : Mean Losses: [2.053613618016243]
2026-01-17 13:16:46,836 : agent.on_policy : DEBUG : Mean Losses: [1.914444088935852]
2026-01-17 13:16:46,973 : agent.on_policy : DEBUG : Mean Losses: [1.8412084430456161]
2026-01-17 13:16:47,012 : worker.worker : DEBUG : Step 13193, finished rewards -466.30, envs finished 1
2026-01-17 13:16:47,124 : agent.on_policy : DEBUG : Mean Losses: [3.0429505556821823]
2026-01-17 13:16:47,280 : agent.on_policy : DEBUG : Mean Losses: [1.8032839447259903]
2026-01-17 13:16:47,418 : agent.on_policy : DEBUG : Mean Losses: [1.7376194149255753]
2026-01-17 13:16:47,594 : agent.on_policy : DEBUG : Mean Losses: [1.7187337279319763]
2026-01-17 13:16:47,635 : worker.worker : DEBUG : Step 13323, finished rewards -486.74, envs finished 1
2026-01-17 13:16:47,783 : agent.on_policy : DEBUG : Mean Losses: [3.073545143008232]
2026-01-17 13:16:47,973 : agent.on_policy : DEBUG : Mean Losses: [1.6565076857805252]
2026-01-17 13:16:48,199 : agent.on_policy : DEBUG : Mean Losses: [1.7097380310297012]
2026-01-17 13:16:48,381 : agent.on_policy : DEBUG : Mean Losses: [1.6991915851831436]
2026-01-17 13:16:48,592 : agent.on_policy : DEBUG : Mean Losses: [1.5990460366010666]
2026-01-17 13:16:48,612 : worker.worker : DEBUG : Step 13477, finished rewards -466.65, envs finished 1
2026-01-17 13:16:48,618 : worker.worker : DEBUG : Step 13478, finished rewards -483.10, envs finished 1
2026-01-17 13:16:48,781 : agent.on_policy : DEBUG : Mean Losses: [3.3767847418785095]
2026-01-17 13:16:48,797 : worker.worker : DEBUG : Step 13507, finished rewards -485.30, envs finished 1
2026-01-17 13:16:48,873 : worker.worker : DEBUG : Step 13525, finished rewards -456.49, envs finished 3
2026-01-17 13:16:49,046 : agent.on_policy : DEBUG : Mean Losses: [7.325577586889267]
2026-01-17 13:16:49,305 : agent.on_policy : DEBUG : Mean Losses: [1.9225326031446457]
2026-01-17 13:16:49,492 : agent.on_policy : DEBUG : Mean Losses: [1.8796749114990234]
2026-01-17 13:16:49,794 : agent.on_policy : DEBUG : Mean Losses: [1.8402798026800156]
2026-01-17 13:16:49,970 : agent.on_policy : DEBUG : Mean Losses: [1.7000955641269684]
2026-01-17 13:16:50,083 : worker.worker : DEBUG : Step 13694, finished rewards -456.73, envs finished 1
2026-01-17 13:16:50,173 : agent.on_policy : DEBUG : Mean Losses: [3.5172749906778336]
2026-01-17 13:16:50,370 : agent.on_policy : DEBUG : Mean Losses: [1.7817134112119675]
2026-01-17 13:16:50,561 : agent.on_policy : DEBUG : Mean Losses: [1.7088313549757004]
2026-01-17 13:16:50,770 : agent.on_policy : DEBUG : Mean Losses: [1.6909787356853485]
2026-01-17 13:16:50,960 : agent.on_policy : DEBUG : Mean Losses: [1.6578168720006943]
2026-01-17 13:16:50,962 : worker.worker : DEBUG : Step 13824, finished rewards -479.76, envs finished 1
2026-01-17 13:16:51,163 : agent.on_policy : DEBUG : Mean Losses: [1.6200844496488571]
2026-01-17 13:16:51,336 : agent.on_policy : DEBUG : Mean Losses: [1.6206658780574799]
2026-01-17 13:16:51,528 : agent.on_policy : DEBUG : Mean Losses: [1.5083662196993828]
2026-01-17 13:16:51,575 : worker.worker : DEBUG : Step 13935, finished rewards -290.50, envs finished 1
2026-01-17 13:16:51,749 : agent.on_policy : DEBUG : Mean Losses: [7.535971567034721]
2026-01-17 13:16:51,858 : worker.worker : DEBUG : Step 13978, finished rewards -479.49, envs finished 1
2026-01-17 13:16:51,863 : worker.worker : DEBUG : Step 13979, finished rewards -472.48, envs finished 1
2026-01-17 13:16:51,965 : agent.on_policy : DEBUG : Mean Losses: [5.084774404764175]
2026-01-17 13:16:52,044 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.48767497911552943
2026-01-17 13:16:52,240 : agent.on_policy : DEBUG : Mean Losses: [1.7660041004419327]
2026-01-17 13:16:52,279 : worker.worker : DEBUG : Step 14026, finished rewards -478.86, envs finished 3
2026-01-17 13:16:52,442 : agent.on_policy : DEBUG : Mean Losses: [5.999948143959045]
2026-01-17 13:16:52,663 : agent.on_policy : DEBUG : Mean Losses: [1.8949317038059235]
2026-01-17 13:16:52,880 : agent.on_policy : DEBUG : Mean Losses: [1.9057676196098328]
2026-01-17 13:16:53,078 : agent.on_policy : DEBUG : Mean Losses: [1.8229135572910309]
2026-01-17 13:16:53,275 : agent.on_policy : DEBUG : Mean Losses: [1.843090146780014]
2026-01-17 13:16:53,341 : worker.worker : DEBUG : Step 14195, finished rewards -492.67, envs finished 1
2026-01-17 13:16:52,694 : agent.on_policy : DEBUG : Mean Losses: [3.440973773598671]
2026-01-17 13:16:52,881 : agent.on_policy : DEBUG : Mean Losses: [1.8221019804477692]
2026-01-17 13:16:53,064 : agent.on_policy : DEBUG : Mean Losses: [1.7552995085716248]
2026-01-17 13:16:53,241 : agent.on_policy : DEBUG : Mean Losses: [1.7319275885820389]
2026-01-17 13:16:53,310 : worker.worker : DEBUG : Step 14325, finished rewards -492.95, envs finished 1
2026-01-17 13:16:53,439 : agent.on_policy : DEBUG : Mean Losses: [3.3992897868156433]
2026-01-17 13:16:53,612 : agent.on_policy : DEBUG : Mean Losses: [1.6096304208040237]
2026-01-17 13:16:53,740 : agent.on_policy : DEBUG : Mean Losses: [1.5134567469358444]
2026-01-17 13:16:53,884 : agent.on_policy : DEBUG : Mean Losses: [1.521841675043106]
2026-01-17 13:16:53,900 : worker.worker : DEBUG : Step 14436, finished rewards -484.22, envs finished 1
2026-01-17 13:16:54,055 : agent.on_policy : DEBUG : Mean Losses: [2.4518792778253555]
2026-01-17 13:16:54,099 : worker.worker : DEBUG : Step 14479, finished rewards -488.16, envs finished 1
2026-01-17 13:16:54,103 : worker.worker : DEBUG : Step 14480, finished rewards -485.48, envs finished 1
2026-01-17 13:16:54,197 : agent.on_policy : DEBUG : Mean Losses: [4.945581212639809]
2026-01-17 13:16:54,302 : worker.worker : DEBUG : Step 14527, finished rewards -483.91, envs finished 3
2026-01-17 13:16:54,382 : agent.on_policy : DEBUG : Mean Losses: [6.950134664773941]
2026-01-17 13:16:54,555 : agent.on_policy : DEBUG : Mean Losses: [1.7750670313835144]
2026-01-17 13:16:54,682 : agent.on_policy : DEBUG : Mean Losses: [1.7572603672742844]
2026-01-17 13:16:54,837 : agent.on_policy : DEBUG : Mean Losses: [1.7418870627880096]
2026-01-17 13:16:54,991 : agent.on_policy : DEBUG : Mean Losses: [1.704838827252388]
2026-01-17 13:16:55,136 : agent.on_policy : DEBUG : Mean Losses: [1.6576726585626602]
2026-01-17 13:16:55,174 : worker.worker : DEBUG : Step 14696, finished rewards -480.57, envs finished 1
2026-01-17 13:16:55,301 : agent.on_policy : DEBUG : Mean Losses: [2.830060139298439]
2026-01-17 13:16:55,461 : agent.on_policy : DEBUG : Mean Losses: [1.4236077666282654]
2026-01-17 13:16:55,600 : agent.on_policy : DEBUG : Mean Losses: [1.4104400724172592]
2026-01-17 13:16:55,745 : agent.on_policy : DEBUG : Mean Losses: [1.3814250752329826]
2026-01-17 13:16:55,784 : worker.worker : DEBUG : Step 14826, finished rewards -481.83, envs finished 1
2026-01-17 13:16:55,893 : agent.on_policy : DEBUG : Mean Losses: [2.914816975593567]
2026-01-17 13:16:56,050 : agent.on_policy : DEBUG : Mean Losses: [1.4815758168697357]
2026-01-17 13:16:56,183 : agent.on_policy : DEBUG : Mean Losses: [1.4003700017929077]
2026-01-17 13:16:56,265 : worker.worker : DEBUG : Step 14937, finished rewards -472.02, envs finished 1
2026-01-17 13:16:56,346 : agent.on_policy : DEBUG : Mean Losses: [3.9987808912992477]
2026-01-17 13:16:56,513 : agent.on_policy : DEBUG : Mean Losses: [1.3949573338031769]
2026-01-17 13:16:56,527 : worker.worker : DEBUG : Step 14980, finished rewards -480.21, envs finished 1
2026-01-17 13:16:56,532 : worker.worker : DEBUG : Step 14981, finished rewards -478.79, envs finished 1
2026-01-17 13:16:56,589 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.46329123015975293
2026-01-17 13:16:56,600 : worker.worker : INFO : Step 15000, Avg Reward -463.0256, Max Reward -219.4561, Loss [2.74994045]
2026-01-17 13:16:56,710 : agent.on_policy : DEBUG : Mean Losses: [3.258147932589054]
2026-01-17 13:16:56,779 : worker.worker : DEBUG : Step 15028, finished rewards -482.80, envs finished 3
2026-01-17 13:16:56,870 : agent.on_policy : DEBUG : Mean Losses: [7.054297938942909]
2026-01-17 13:16:57,010 : agent.on_policy : DEBUG : Mean Losses: [1.6201158463954926]
2026-01-17 13:16:57,190 : agent.on_policy : DEBUG : Mean Losses: [1.5169065743684769]
2026-01-17 13:16:57,327 : agent.on_policy : DEBUG : Mean Losses: [1.5052162557840347]
2026-01-17 13:16:57,573 : agent.on_policy : DEBUG : Mean Losses: [1.5008444488048553]
2026-01-17 13:16:57,682 : worker.worker : DEBUG : Step 15197, finished rewards -490.09, envs finished 1
2026-01-17 13:16:57,756 : agent.on_policy : DEBUG : Mean Losses: [3.344170331954956]
2026-01-17 13:16:57,905 : agent.on_policy : DEBUG : Mean Losses: [1.4131872355937958]
2026-01-17 13:16:58,041 : agent.on_policy : DEBUG : Mean Losses: [1.2495813518762589]
2026-01-17 13:16:58,203 : agent.on_policy : DEBUG : Mean Losses: [1.2383253425359726]
2026-01-17 13:16:58,298 : worker.worker : DEBUG : Step 15327, finished rewards -470.66, envs finished 1
2026-01-17 13:16:58,379 : agent.on_policy : DEBUG : Mean Losses: [3.307627350091934]
2026-01-17 13:16:58,655 : agent.on_policy : DEBUG : Mean Losses: [1.2837926298379898]
2026-01-17 13:16:58,802 : agent.on_policy : DEBUG : Mean Losses: [1.2053186111152172]
2026-01-17 13:16:58,992 : agent.on_policy : DEBUG : Mean Losses: [1.1888766139745712]
2026-01-17 13:16:59,031 : worker.worker : DEBUG : Step 15438, finished rewards -484.57, envs finished 1
2026-01-17 13:16:59,126 : agent.on_policy : DEBUG : Mean Losses: [3.3726072758436203]
2026-01-17 13:16:59,219 : worker.worker : DEBUG : Step 15481, finished rewards -462.80, envs finished 1
2026-01-17 13:16:59,222 : worker.worker : DEBUG : Step 15482, finished rewards -483.42, envs finished 1
2026-01-17 13:16:59,314 : agent.on_policy : DEBUG : Mean Losses: [5.038360506296158]
2026-01-17 13:16:59,472 : agent.on_policy : DEBUG : Mean Losses: [1.1871925666928291]
2026-01-17 13:16:59,500 : worker.worker : DEBUG : Step 15529, finished rewards -472.79, envs finished 3
2026-01-17 13:16:59,617 : agent.on_policy : DEBUG : Mean Losses: [5.685246549546719]
2026-01-17 13:16:59,780 : agent.on_policy : DEBUG : Mean Losses: [1.3010074123740196]
2026-01-17 13:16:59,922 : agent.on_policy : DEBUG : Mean Losses: [1.157776728272438]
2026-01-17 13:16:59,939 : worker.worker : DEBUG : Step 15620, finished rewards -291.68, envs finished 1
2026-01-17 13:17:00,065 : agent.on_policy : DEBUG : Mean Losses: [3.5003414005041122]
2026-01-17 13:17:00,248 : agent.on_policy : DEBUG : Mean Losses: [1.3099025785923004]
2026-01-17 13:17:00,383 : agent.on_policy : DEBUG : Mean Losses: [1.35819511115551]
2026-01-17 13:17:00,538 : agent.on_policy : DEBUG : Mean Losses: [1.2793371193110943]
2026-01-17 13:17:00,676 : agent.on_policy : DEBUG : Mean Losses: [1.277105674147606]
2026-01-17 13:17:00,807 : agent.on_policy : DEBUG : Mean Losses: [1.2334895431995392]
2026-01-17 13:17:00,880 : worker.worker : DEBUG : Step 15828, finished rewards -420.58, envs finished 1
2026-01-17 13:17:00,987 : agent.on_policy : DEBUG : Mean Losses: [3.2615606635808945]
2026-01-17 13:17:01,162 : agent.on_policy : DEBUG : Mean Losses: [1.208330400288105]
2026-01-17 13:17:01,341 : agent.on_policy : DEBUG : Mean Losses: [1.2035684883594513]
2026-01-17 13:17:01,592 : agent.on_policy : DEBUG : Mean Losses: [1.1500512212514877]
2026-01-17 13:17:01,610 : worker.worker : DEBUG : Step 15939, finished rewards -487.38, envs finished 1
2026-01-17 13:17:01,804 : agent.on_policy : DEBUG : Mean Losses: [1.8031742051243782]
2026-01-17 13:17:01,850 : worker.worker : DEBUG : Step 15982, finished rewards -488.63, envs finished 1
2026-01-17 13:17:01,854 : worker.worker : DEBUG : Step 15983, finished rewards -481.80, envs finished 1
2026-01-17 13:17:01,908 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.44012666865176525
2026-01-17 13:17:01,964 : agent.on_policy : DEBUG : Mean Losses: [4.830702781677246]
2026-01-17 13:17:02,083 : worker.worker : DEBUG : Step 16030, finished rewards -480.84, envs finished 3
2026-01-17 13:17:02,172 : agent.on_policy : DEBUG : Mean Losses: [7.326495595276356]
2026-01-17 13:17:02,373 : agent.on_policy : DEBUG : Mean Losses: [1.2988932952284813]
2026-01-17 13:17:02,504 : agent.on_policy : DEBUG : Mean Losses: [1.174941748380661]
2026-01-17 13:17:02,621 : worker.worker : DEBUG : Step 16121, finished rewards -467.84, envs finished 1
2026-01-17 13:17:02,701 : agent.on_policy : DEBUG : Mean Losses: [3.342403843998909]
2026-01-17 13:17:02,862 : agent.on_policy : DEBUG : Mean Losses: [1.2060929164290428]
2026-01-17 13:17:02,992 : agent.on_policy : DEBUG : Mean Losses: [1.1772510707378387]
2026-01-17 13:17:03,162 : agent.on_policy : DEBUG : Mean Losses: [1.1019902974367142]
2026-01-17 13:17:03,343 : agent.on_policy : DEBUG : Mean Losses: [1.0258903503417969]
2026-01-17 13:17:03,505 : agent.on_policy : DEBUG : Mean Losses: [0.9479663595557213]
2026-01-17 13:17:03,644 : agent.on_policy : DEBUG : Mean Losses: [0.7999224588274956]
2026-01-17 13:17:03,659 : worker.worker : DEBUG : Step 16323, finished rewards -357.77, envs finished 1
2026-01-17 13:17:03,814 : agent.on_policy : DEBUG : Mean Losses: [2.644593846052885]
2026-01-17 13:17:03,957 : agent.on_policy : DEBUG : Mean Losses: [0.8358345255255699]
2026-01-17 13:17:04,104 : agent.on_policy : DEBUG : Mean Losses: [0.7284350655972958]
2026-01-17 13:17:04,187 : worker.worker : DEBUG : Step 16440, finished rewards -485.90, envs finished 1
2026-01-17 13:17:04,288 : agent.on_policy : DEBUG : Mean Losses: [3.6087152399122715]
2026-01-17 13:17:04,436 : agent.on_policy : DEBUG : Mean Losses: [0.8503870144486427]
2026-01-17 13:17:04,445 : worker.worker : DEBUG : Step 16483, finished rewards -460.63, envs finished 1
2026-01-17 13:17:04,449 : worker.worker : DEBUG : Step 16484, finished rewards -463.33, envs finished 1
2026-01-17 13:17:04,573 : agent.on_policy : DEBUG : Mean Losses: [2.6215861663222313]
2026-01-17 13:17:04,652 : worker.worker : DEBUG : Step 16531, finished rewards -464.59, envs finished 3
2026-01-17 13:17:04,759 : agent.on_policy : DEBUG : Mean Losses: [7.250952899456024]
2026-01-17 13:17:04,924 : agent.on_policy : DEBUG : Mean Losses: [1.1484215706586838]
2026-01-17 13:17:05,053 : agent.on_policy : DEBUG : Mean Losses: [1.0796587616205215]
2026-01-17 13:17:05,152 : worker.worker : DEBUG : Step 16622, finished rewards -464.19, envs finished 1
2026-01-17 13:17:05,331 : agent.on_policy : DEBUG : Mean Losses: [3.067188538610935]
2026-01-17 13:17:05,462 : agent.on_policy : DEBUG : Mean Losses: [1.064482793211937]
2026-01-17 13:17:05,661 : agent.on_policy : DEBUG : Mean Losses: [1.0345598012208939]
2026-01-17 13:17:05,806 : agent.on_policy : DEBUG : Mean Losses: [1.0403504222631454]
2026-01-17 13:17:05,935 : agent.on_policy : DEBUG : Mean Losses: [0.9377237856388092]
2026-01-17 13:17:06,088 : agent.on_policy : DEBUG : Mean Losses: [0.9456001818180084]
2026-01-17 13:17:06,154 : worker.worker : DEBUG : Step 16824, finished rewards -460.81, envs finished 1
2026-01-17 13:17:06,225 : agent.on_policy : DEBUG : Mean Losses: [3.170665018260479]
2026-01-17 13:17:06,394 : agent.on_policy : DEBUG : Mean Losses: [0.962442971765995]
2026-01-17 13:17:06,518 : agent.on_policy : DEBUG : Mean Losses: [0.9228421747684479]
2026-01-17 13:17:06,680 : agent.on_policy : DEBUG : Mean Losses: [0.9652200192213058]
2026-01-17 13:17:06,726 : worker.worker : DEBUG : Step 16941, finished rewards -466.24, envs finished 1
2026-01-17 13:17:06,834 : agent.on_policy : DEBUG : Mean Losses: [3.342039979994297]
2026-01-17 13:17:06,915 : worker.worker : DEBUG : Step 16984, finished rewards -479.36, envs finished 1
2026-01-17 13:17:06,920 : worker.worker : DEBUG : Step 16985, finished rewards -486.05, envs finished 1
2026-01-17 13:17:07,003 : agent.on_policy : DEBUG : Mean Losses: [5.303896069526672]
2026-01-17 13:17:07,039 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.41812033521917696
2026-01-17 13:17:07,243 : agent.on_policy : DEBUG : Mean Losses: [0.933613583445549]
2026-01-17 13:17:07,278 : worker.worker : DEBUG : Step 17032, finished rewards -480.77, envs finished 3
2026-01-17 13:17:07,398 : agent.on_policy : DEBUG : Mean Losses: [5.526729568839073]
2026-01-17 13:17:07,557 : agent.on_policy : DEBUG : Mean Losses: [1.038462832570076]
2026-01-17 13:17:07,716 : agent.on_policy : DEBUG : Mean Losses: [0.9893884062767029]
2026-01-17 13:17:07,733 : worker.worker : DEBUG : Step 17123, finished rewards -488.41, envs finished 1
2026-01-17 13:17:07,933 : agent.on_policy : DEBUG : Mean Losses: [1.743616797029972]
2026-01-17 13:17:08,100 : agent.on_policy : DEBUG : Mean Losses: [0.8882080670446157]
2026-01-17 13:17:08,234 : agent.on_policy : DEBUG : Mean Losses: [0.8545566387474537]
2026-01-17 13:17:08,406 : agent.on_policy : DEBUG : Mean Losses: [0.7202516319230199]
2026-01-17 13:17:08,533 : agent.on_policy : DEBUG : Mean Losses: [0.6413187626749277]
2026-01-17 13:17:08,686 : agent.on_policy : DEBUG : Mean Losses: [0.6139995567500591]
2026-01-17 13:17:08,741 : worker.worker : DEBUG : Step 17325, finished rewards -478.42, envs finished 1
2026-01-17 13:17:08,980 : agent.on_policy : DEBUG : Mean Losses: [2.537309273146093]
2026-01-17 13:17:09,123 : agent.on_policy : DEBUG : Mean Losses: [0.6507974956184626]
2026-01-17 13:17:09,296 : agent.on_policy : DEBUG : Mean Losses: [0.6468447931110859]
2026-01-17 13:17:09,442 : agent.on_policy : DEBUG : Mean Losses: [0.6457763407379389]
2026-01-17 13:17:09,452 : worker.worker : DEBUG : Step 17442, finished rewards -430.00, envs finished 1
2026-01-17 13:17:09,591 : agent.on_policy : DEBUG : Mean Losses: [1.3082668408751488]
2026-01-17 13:17:09,644 : worker.worker : DEBUG : Step 17485, finished rewards -474.17, envs finished 1
2026-01-17 13:17:09,647 : worker.worker : DEBUG : Step 17486, finished rewards -480.92, envs finished 1
2026-01-17 13:17:09,771 : agent.on_policy : DEBUG : Mean Losses: [4.783769473433495]
2026-01-17 13:17:09,859 : worker.worker : DEBUG : Step 17533, finished rewards -464.05, envs finished 3
2026-01-17 13:17:09,924 : agent.on_policy : DEBUG : Mean Losses: [8.01897119730711]
2026-01-17 13:17:10,109 : agent.on_policy : DEBUG : Mean Losses: [0.9808645471930504]
2026-01-17 13:17:10,251 : agent.on_policy : DEBUG : Mean Losses: [0.9746174216270447]
2026-01-17 13:17:10,333 : worker.worker : DEBUG : Step 17624, finished rewards -489.31, envs finished 1
2026-01-17 13:17:10,426 : agent.on_policy : DEBUG : Mean Losses: [3.262337975203991]
2026-01-17 13:17:10,590 : agent.on_policy : DEBUG : Mean Losses: [0.9987016767263412]
2026-01-17 13:17:10,732 : agent.on_policy : DEBUG : Mean Losses: [0.9636783823370934]
2026-01-17 13:17:10,994 : agent.on_policy : DEBUG : Mean Losses: [0.9221202507615089]
2026-01-17 13:17:11,152 : agent.on_policy : DEBUG : Mean Losses: [0.8972393050789833]
2026-01-17 13:17:11,317 : agent.on_policy : DEBUG : Mean Losses: [0.8845537453889847]
2026-01-17 13:17:11,489 : agent.on_policy : DEBUG : Mean Losses: [0.8820780366659164]
2026-01-17 13:17:11,500 : worker.worker : DEBUG : Step 17826, finished rewards -485.87, envs finished 1
2026-01-17 13:17:11,685 : agent.on_policy : DEBUG : Mean Losses: [1.3423336669802666]
2026-01-17 13:17:11,917 : agent.on_policy : DEBUG : Mean Losses: [0.7852530814707279]
2026-01-17 13:17:12,067 : agent.on_policy : DEBUG : Mean Losses: [0.7308771423995495]
2026-01-17 13:17:12,145 : worker.worker : DEBUG : Step 17943, finished rewards -485.22, envs finished 1
2026-01-17 13:17:12,243 : agent.on_policy : DEBUG : Mean Losses: [3.9267199635505676]
2026-01-17 13:17:12,439 : agent.on_policy : DEBUG : Mean Losses: [0.7284364178776741]
2026-01-17 13:17:12,448 : worker.worker : DEBUG : Step 17986, finished rewards -479.89, envs finished 1
2026-01-17 13:17:12,453 : worker.worker : DEBUG : Step 17987, finished rewards -491.69, envs finished 1
2026-01-17 13:17:12,504 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.3972143184582181
2026-01-17 13:17:12,628 : agent.on_policy : DEBUG : Mean Losses: [2.0812243223190308]
2026-01-17 13:17:12,708 : worker.worker : DEBUG : Step 18034, finished rewards -482.94, envs finished 3
2026-01-17 13:17:12,845 : agent.on_policy : DEBUG : Mean Losses: [7.5599596202373505]
2026-01-17 13:17:13,002 : agent.on_policy : DEBUG : Mean Losses: [0.9028274789452553]
2026-01-17 13:17:13,139 : agent.on_policy : DEBUG : Mean Losses: [0.764464009553194]
2026-01-17 13:17:13,191 : worker.worker : DEBUG : Step 18125, finished rewards -480.94, envs finished 1
2026-01-17 13:17:13,316 : agent.on_policy : DEBUG : Mean Losses: [2.787511885166168]
2026-01-17 13:17:13,518 : agent.on_policy : DEBUG : Mean Losses: [0.7899028807878494]
2026-01-17 13:17:13,653 : agent.on_policy : DEBUG : Mean Losses: [0.7676391005516052]
2026-01-17 13:17:13,823 : agent.on_policy : DEBUG : Mean Losses: [0.7050002962350845]
2026-01-17 13:17:13,955 : agent.on_policy : DEBUG : Mean Losses: [0.6867980528622866]
2026-01-17 13:17:14,103 : agent.on_policy : DEBUG : Mean Losses: [0.6392275765538216]
2026-01-17 13:17:14,175 : worker.worker : DEBUG : Step 18327, finished rewards -456.06, envs finished 1
2026-01-17 13:17:14,205 : worker.worker : DEBUG : Step 18334, finished rewards -175.53, envs finished 1
2026-01-17 13:17:14,288 : agent.on_policy : DEBUG : Mean Losses: [9.253905527293682]
2026-01-17 13:17:14,462 : agent.on_policy : DEBUG : Mean Losses: [0.7318838983774185]
2026-01-17 13:17:14,598 : agent.on_policy : DEBUG : Mean Losses: [0.6756319291889668]
2026-01-17 13:17:14,763 : agent.on_policy : DEBUG : Mean Losses: [0.6791644394397736]
2026-01-17 13:17:14,799 : worker.worker : DEBUG : Step 18444, finished rewards -492.43, envs finished 1
2026-01-17 13:17:14,926 : agent.on_policy : DEBUG : Mean Losses: [3.039910227060318]
2026-01-17 13:17:15,031 : worker.worker : DEBUG : Step 18487, finished rewards -482.99, envs finished 1
2026-01-17 13:17:15,036 : worker.worker : DEBUG : Step 18488, finished rewards -461.98, envs finished 1
2026-01-17 13:17:15,119 : agent.on_policy : DEBUG : Mean Losses: [5.761111199855804]
2026-01-17 13:17:15,280 : agent.on_policy : DEBUG : Mean Losses: [0.6270222589373589]
2026-01-17 13:17:15,304 : worker.worker : DEBUG : Step 18535, finished rewards -485.98, envs finished 2
2026-01-17 13:17:15,474 : agent.on_policy : DEBUG : Mean Losses: [3.644509896636009]
2026-01-17 13:17:15,615 : agent.on_policy : DEBUG : Mean Losses: [0.644534882158041]
2026-01-17 13:17:15,752 : agent.on_policy : DEBUG : Mean Losses: [0.5941755846142769]
2026-01-17 13:17:15,764 : worker.worker : DEBUG : Step 18626, finished rewards -485.66, envs finished 1
2026-01-17 13:17:15,924 : agent.on_policy : DEBUG : Mean Losses: [1.190214715898037]
2026-01-17 13:17:16,077 : agent.on_policy : DEBUG : Mean Losses: [0.5815642662346363]
2026-01-17 13:17:16,208 : agent.on_policy : DEBUG : Mean Losses: [0.5251933801919222]
2026-01-17 13:17:16,367 : agent.on_policy : DEBUG : Mean Losses: [0.5312714148312807]
2026-01-17 13:17:16,518 : agent.on_policy : DEBUG : Mean Losses: [0.503873273730278]
2026-01-17 13:17:16,659 : agent.on_policy : DEBUG : Mean Losses: [0.478289607912302]
2026-01-17 13:17:16,706 : worker.worker : DEBUG : Step 18828, finished rewards -477.15, envs finished 1
2026-01-17 13:17:16,734 : worker.worker : DEBUG : Step 18835, finished rewards -482.37, envs finished 1
2026-01-17 13:17:16,829 : agent.on_policy : DEBUG : Mean Losses: [4.967653665691614]
2026-01-17 13:17:16,983 : agent.on_policy : DEBUG : Mean Losses: [0.5071004722267389]
2026-01-17 13:17:17,139 : agent.on_policy : DEBUG : Mean Losses: [0.4913727901875973]
2026-01-17 13:17:17,306 : agent.on_policy : DEBUG : Mean Losses: [0.42758363857865334]
2026-01-17 13:17:17,311 : worker.worker : DEBUG : Step 18945, finished rewards -466.06, envs finished 1
2026-01-17 13:17:17,465 : agent.on_policy : DEBUG : Mean Losses: [0.8181543201208115]
2026-01-17 13:17:17,516 : worker.worker : DEBUG : Step 18988, finished rewards -472.71, envs finished 1
2026-01-17 13:17:17,522 : worker.worker : DEBUG : Step 18989, finished rewards -456.08, envs finished 1
2026-01-17 13:17:17,568 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.37735360253530714
2026-01-17 13:17:17,647 : agent.on_policy : DEBUG : Mean Losses: [4.818506978452206]
2026-01-17 13:17:17,745 : worker.worker : DEBUG : Step 19036, finished rewards -485.00, envs finished 2
2026-01-17 13:17:17,819 : agent.on_policy : DEBUG : Mean Losses: [5.611154280602932]
2026-01-17 13:17:17,987 : agent.on_policy : DEBUG : Mean Losses: [0.5565197728574276]
2026-01-17 13:17:18,228 : agent.on_policy : DEBUG : Mean Losses: [0.5070019084960222]
2026-01-17 13:17:18,329 : worker.worker : DEBUG : Step 19127, finished rewards -472.48, envs finished 1
2026-01-17 13:17:18,423 : agent.on_policy : DEBUG : Mean Losses: [3.041904356330633]
2026-01-17 13:17:18,584 : agent.on_policy : DEBUG : Mean Losses: [0.5073254741728306]
2026-01-17 13:17:18,721 : agent.on_policy : DEBUG : Mean Losses: [0.5294235348701477]
2026-01-17 13:17:18,909 : agent.on_policy : DEBUG : Mean Losses: [0.481411162763834]
2026-01-17 13:17:19,123 : agent.on_policy : DEBUG : Mean Losses: [0.5270749256014824]
2026-01-17 13:17:19,387 : agent.on_policy : DEBUG : Mean Losses: [0.47479306161403656]
2026-01-17 13:17:19,550 : agent.on_policy : DEBUG : Mean Losses: [0.4400655645877123]
2026-01-17 13:17:19,555 : worker.worker : DEBUG : Step 19329, finished rewards -467.50, envs finished 1
2026-01-17 13:17:19,582 : worker.worker : DEBUG : Step 19336, finished rewards -478.21, envs finished 1
2026-01-17 13:17:19,706 : agent.on_policy : DEBUG : Mean Losses: [2.5151624865829945]
2026-01-17 13:17:19,856 : agent.on_policy : DEBUG : Mean Losses: [0.4189529977738857]
2026-01-17 13:17:19,986 : agent.on_policy : DEBUG : Mean Losses: [0.3490814659744501]
2026-01-17 13:17:20,069 : worker.worker : DEBUG : Step 19446, finished rewards -468.86, envs finished 1
2026-01-17 13:17:20,173 : agent.on_policy : DEBUG : Mean Losses: [3.8137507401406765]
2026-01-17 13:17:20,333 : agent.on_policy : DEBUG : Mean Losses: [0.35466652223840356]
2026-01-17 13:17:20,337 : worker.worker : DEBUG : Step 19489, finished rewards -484.15, envs finished 1
2026-01-17 13:17:20,341 : worker.worker : DEBUG : Step 19490, finished rewards -474.97, envs finished 1
2026-01-17 13:17:20,482 : agent.on_policy : DEBUG : Mean Losses: [1.3368452405557036]
2026-01-17 13:17:20,547 : worker.worker : DEBUG : Step 19537, finished rewards -474.76, envs finished 2
2026-01-17 13:17:20,679 : agent.on_policy : DEBUG : Mean Losses: [5.309974636882544]
2026-01-17 13:17:20,877 : agent.on_policy : DEBUG : Mean Losses: [0.4941641204059124]
2026-01-17 13:17:21,073 : agent.on_policy : DEBUG : Mean Losses: [0.4816034510731697]
2026-01-17 13:17:21,118 : worker.worker : DEBUG : Step 19628, finished rewards -475.33, envs finished 1
2026-01-17 13:17:21,229 : agent.on_policy : DEBUG : Mean Losses: [2.6595532074570656]
2026-01-17 13:17:21,386 : agent.on_policy : DEBUG : Mean Losses: [0.4685955196619034]
2026-01-17 13:17:21,530 : agent.on_policy : DEBUG : Mean Losses: [0.4719458855688572]
2026-01-17 13:17:21,748 : agent.on_policy : DEBUG : Mean Losses: [0.4008451383560896]
2026-01-17 13:17:21,880 : agent.on_policy : DEBUG : Mean Losses: [0.38054252229630947]
2026-01-17 13:17:22,035 : agent.on_policy : DEBUG : Mean Losses: [0.33801873214542866]
2026-01-17 13:17:22,115 : worker.worker : DEBUG : Step 19830, finished rewards -474.89, envs finished 1
2026-01-17 13:17:22,147 : worker.worker : DEBUG : Step 19837, finished rewards -478.80, envs finished 1
2026-01-17 13:17:22,245 : agent.on_policy : DEBUG : Mean Losses: [5.598540714941919]
2026-01-17 13:17:22,400 : agent.on_policy : DEBUG : Mean Losses: [0.40547596383839846]
2026-01-17 13:17:22,526 : agent.on_policy : DEBUG : Mean Losses: [0.38329957239329815]
2026-01-17 13:17:22,590 : worker.worker : DEBUG : Step 19917, finished rewards -258.97, envs finished 1
2026-01-17 13:17:21,956 : agent.on_policy : DEBUG : Mean Losses: [5.492146145552397]
2026-01-17 13:17:21,994 : worker.worker : DEBUG : Step 19947, finished rewards -477.61, envs finished 1
2026-01-17 13:17:22,116 : agent.on_policy : DEBUG : Mean Losses: [2.8926038071513176]
2026-01-17 13:17:22,194 : worker.worker : DEBUG : Step 19990, finished rewards -488.68, envs finished 1
2026-01-17 13:17:22,198 : worker.worker : DEBUG : Step 19991, finished rewards -489.09, envs finished 1
2026-01-17 13:17:22,227 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.35848592240854177
2026-01-17 13:17:22,292 : agent.on_policy : DEBUG : Mean Losses: [5.656803485006094]
2026-01-17 13:17:22,293 : worker.worker : INFO : Step 20000, Avg Reward -462.9480, Max Reward -175.5316, Loss [1.89598679]
2026-01-17 13:17:22,442 : agent.on_policy : DEBUG : Mean Losses: [0.4512193463742733]
2026-01-17 13:17:22,461 : worker.worker : DEBUG : Step 20038, finished rewards -486.76, envs finished 1
2026-01-17 13:17:22,580 : agent.on_policy : DEBUG : Mean Losses: [1.9318489655852318]
2026-01-17 13:17:22,731 : agent.on_policy : DEBUG : Mean Losses: [0.39387211576104164]
2026-01-17 13:17:22,843 : agent.on_policy : DEBUG : Mean Losses: [0.30056130327284336]
2026-01-17 13:17:22,847 : worker.worker : DEBUG : Step 20129, finished rewards -486.56, envs finished 1
2026-01-17 13:17:23,031 : agent.on_policy : DEBUG : Mean Losses: [0.6291718818247318]
2026-01-17 13:17:23,200 : agent.on_policy : DEBUG : Mean Losses: [0.28955101035535336]
2026-01-17 13:17:23,327 : agent.on_policy : DEBUG : Mean Losses: [0.2265436016023159]
2026-01-17 13:17:23,474 : agent.on_policy : DEBUG : Mean Losses: [0.20471436670050025]
2026-01-17 13:17:23,599 : agent.on_policy : DEBUG : Mean Losses: [0.19053730787709355]
2026-01-17 13:17:23,837 : agent.on_policy : DEBUG : Mean Losses: [0.20799915306270123]
2026-01-17 13:17:23,866 : worker.worker : DEBUG : Step 20331, finished rewards -482.85, envs finished 1
2026-01-17 13:17:23,890 : worker.worker : DEBUG : Step 20338, finished rewards -458.21, envs finished 1
2026-01-17 13:17:23,989 : agent.on_policy : DEBUG : Mean Losses: [4.913643370382488]
2026-01-17 13:17:24,138 : agent.on_policy : DEBUG : Mean Losses: [0.22612981428392231]
2026-01-17 13:17:24,262 : agent.on_policy : DEBUG : Mean Losses: [0.1957286794204265]
2026-01-17 13:17:24,270 : worker.worker : DEBUG : Step 20418, finished rewards -455.91, envs finished 1
2026-01-17 13:17:24,425 : agent.on_policy : DEBUG : Mean Losses: [0.8490694328211248]
2026-01-17 13:17:24,426 : worker.worker : DEBUG : Step 20448, finished rewards -474.89, envs finished 1
2026-01-17 13:17:24,580 : agent.on_policy : DEBUG : Mean Losses: [0.24972091289237142]
2026-01-17 13:17:24,614 : worker.worker : DEBUG : Step 20491, finished rewards -465.75, envs finished 1
2026-01-17 13:17:24,618 : worker.worker : DEBUG : Step 20492, finished rewards -486.12, envs finished 1
2026-01-17 13:17:24,724 : agent.on_policy : DEBUG : Mean Losses: [4.623821904882789]
2026-01-17 13:17:24,817 : worker.worker : DEBUG : Step 20539, finished rewards -460.23, envs finished 1
2026-01-17 13:17:24,901 : agent.on_policy : DEBUG : Mean Losses: [3.0940997134894133]
2026-01-17 13:17:25,054 : agent.on_policy : DEBUG : Mean Losses: [0.3161853486672044]
2026-01-17 13:17:25,197 : agent.on_policy : DEBUG : Mean Losses: [0.2380647319369018]
2026-01-17 13:17:25,297 : worker.worker : DEBUG : Step 20630, finished rewards -461.91, envs finished 1
2026-01-17 13:17:25,398 : agent.on_policy : DEBUG : Mean Losses: [3.0898646619170904]
2026-01-17 13:17:25,550 : agent.on_policy : DEBUG : Mean Losses: [0.3106583934277296]
2026-01-17 13:17:25,696 : agent.on_policy : DEBUG : Mean Losses: [0.30059284064918756]
2026-01-17 13:17:25,867 : agent.on_policy : DEBUG : Mean Losses: [0.2523594852536917]
2026-01-17 13:17:25,993 : agent.on_policy : DEBUG : Mean Losses: [0.15332597866654396]
2026-01-17 13:17:26,144 : agent.on_policy : DEBUG : Mean Losses: [0.165060774423182]
2026-01-17 13:17:26,318 : agent.on_policy : DEBUG : Mean Losses: [0.2015493311919272]
2026-01-17 13:17:26,319 : worker.worker : DEBUG : Step 20832, finished rewards -467.87, envs finished 1
2026-01-17 13:17:26,327 : worker.worker : DEBUG : Step 20834, finished rewards -358.99, envs finished 1
2026-01-17 13:17:26,482 : agent.on_policy : DEBUG : Mean Losses: [1.7812398471869528]
2026-01-17 13:17:26,630 : agent.on_policy : DEBUG : Mean Losses: [1.094842305406928]
2026-01-17 13:17:26,703 : worker.worker : DEBUG : Step 20919, finished rewards -485.91, envs finished 1
2026-01-17 13:17:26,788 : agent.on_policy : DEBUG : Mean Losses: [3.5596803268417716]
2026-01-17 13:17:26,862 : worker.worker : DEBUG : Step 20949, finished rewards -484.78, envs finished 1
2026-01-17 13:17:26,964 : agent.on_policy : DEBUG : Mean Losses: [3.9911070112138987]
2026-01-17 13:17:27,116 : agent.on_policy : DEBUG : Mean Losses: [0.558301005512476]
2026-01-17 13:17:27,117 : worker.worker : DEBUG : Step 20992, finished rewards -451.34, envs finished 1
2026-01-17 13:17:27,122 : worker.worker : DEBUG : Step 20993, finished rewards -465.47, envs finished 1
2026-01-17 13:17:27,144 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.34056162628811465
2026-01-17 13:17:27,259 : agent.on_policy : DEBUG : Mean Losses: [0.6268054209649563]
2026-01-17 13:17:27,323 : worker.worker : DEBUG : Step 21040, finished rewards -409.56, envs finished 1
2026-01-17 13:17:27,453 : agent.on_policy : DEBUG : Mean Losses: [2.7676931410096586]
2026-01-17 13:17:27,618 : agent.on_policy : DEBUG : Mean Losses: [0.20882955053821206]
2026-01-17 13:17:27,763 : agent.on_policy : DEBUG : Mean Losses: [0.1993078999221325]
2026-01-17 13:17:27,806 : worker.worker : DEBUG : Step 21131, finished rewards -462.30, envs finished 1
2026-01-17 13:17:27,913 : agent.on_policy : DEBUG : Mean Losses: [2.362835494801402]
2026-01-17 13:17:28,075 : agent.on_policy : DEBUG : Mean Losses: [0.16928313951939344]
2026-01-17 13:17:28,204 : agent.on_policy : DEBUG : Mean Losses: [0.17298265313729644]
2026-01-17 13:17:28,360 : agent.on_policy : DEBUG : Mean Losses: [0.15464045759290457]
2026-01-17 13:17:28,527 : agent.on_policy : DEBUG : Mean Losses: [0.14757734071463346]
2026-01-17 13:17:28,796 : agent.on_policy : DEBUG : Mean Losses: [0.14395605400204659]
2026-01-17 13:17:28,858 : worker.worker : DEBUG : Step 21333, finished rewards -474.13, envs finished 1
2026-01-17 13:17:28,864 : worker.worker : DEBUG : Step 21335, finished rewards -469.18, envs finished 1
2026-01-17 13:17:28,940 : agent.on_policy : DEBUG : Mean Losses: [5.726308013545349]
2026-01-17 13:17:29,121 : agent.on_policy : DEBUG : Mean Losses: [0.19524990301579237]
2026-01-17 13:17:29,251 : agent.on_policy : DEBUG : Mean Losses: [0.202571508474648]
2026-01-17 13:17:29,300 : worker.worker : DEBUG : Step 21420, finished rewards -484.21, envs finished 1
2026-01-17 13:17:29,420 : agent.on_policy : DEBUG : Mean Losses: [2.4650837797671556]
2026-01-17 13:17:29,472 : worker.worker : DEBUG : Step 21450, finished rewards -463.59, envs finished 1
2026-01-17 13:17:29,620 : agent.on_policy : DEBUG : Mean Losses: [2.643450994975865]
2026-01-17 13:17:29,755 : worker.worker : DEBUG : Step 21493, finished rewards -482.16, envs finished 1
2026-01-17 13:17:29,769 : worker.worker : DEBUG : Step 21494, finished rewards -482.49, envs finished 1
2026-01-17 13:17:29,903 : agent.on_policy : DEBUG : Mean Losses: [5.7429545149207115]
2026-01-17 13:17:30,112 : agent.on_policy : DEBUG : Mean Losses: [0.18640188360586762]
2026-01-17 13:17:30,134 : worker.worker : DEBUG : Step 21541, finished rewards -483.31, envs finished 1
2026-01-17 13:17:30,267 : agent.on_policy : DEBUG : Mean Losses: [1.5630076173692942]
2026-01-17 13:17:30,478 : agent.on_policy : DEBUG : Mean Losses: [0.2337450198829174]
2026-01-17 13:17:30,644 : agent.on_policy : DEBUG : Mean Losses: [0.2106166547164321]
2026-01-17 13:17:30,645 : worker.worker : DEBUG : Step 21632, finished rewards -491.07, envs finished 1
2026-01-17 13:17:30,788 : agent.on_policy : DEBUG : Mean Losses: [0.17757739312946796]
2026-01-17 13:17:30,973 : agent.on_policy : DEBUG : Mean Losses: [0.18311103619635105]
2026-01-17 13:17:31,119 : agent.on_policy : DEBUG : Mean Losses: [0.15355399483814836]
2026-01-17 13:17:31,305 : agent.on_policy : DEBUG : Mean Losses: [0.11596022872254252]
2026-01-17 13:17:31,432 : agent.on_policy : DEBUG : Mean Losses: [0.0961818010546267]
2026-01-17 13:17:31,705 : agent.on_policy : DEBUG : Mean Losses: [1.2827160375891253]
2026-01-17 13:17:31,709 : worker.worker : DEBUG : Step 21825, finished rewards -340.26, envs finished 1
2026-01-17 13:17:31,757 : worker.worker : DEBUG : Step 21836, finished rewards -487.08, envs finished 1
2026-01-17 13:17:31,966 : agent.on_policy : DEBUG : Mean Losses: [3.1925463567022234]
2026-01-17 13:17:32,175 : agent.on_policy : DEBUG : Mean Losses: [0.11258631222881377]
2026-01-17 13:17:32,413 : agent.on_policy : DEBUG : Mean Losses: [0.06923335790634155]
2026-01-17 13:17:32,418 : worker.worker : DEBUG : Step 21921, finished rewards -490.16, envs finished 1
2026-01-17 13:17:32,570 : worker.worker : DEBUG : Step 21951, finished rewards -478.34, envs finished 1
2026-01-17 13:17:32,654 : agent.on_policy : DEBUG : Mean Losses: [4.094901982927695]
2026-01-17 13:17:32,814 : agent.on_policy : DEBUG : Mean Losses: [0.09580212226137519]
2026-01-17 13:17:32,850 : worker.worker : DEBUG : Step 21994, finished rewards -468.04, envs finished 1
2026-01-17 13:17:32,856 : worker.worker : DEBUG : Step 21995, finished rewards -478.90, envs finished 1
2026-01-17 13:17:32,869 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.3235335449737089
2026-01-17 13:17:32,970 : agent.on_policy : DEBUG : Mean Losses: [4.502148969564587]
2026-01-17 13:17:33,058 : worker.worker : DEBUG : Step 22042, finished rewards -481.17, envs finished 1
2026-01-17 13:17:33,157 : agent.on_policy : DEBUG : Mean Losses: [3.0701800992246717]
2026-01-17 13:17:33,379 : agent.on_policy : DEBUG : Mean Losses: [0.11714801797643304]
2026-01-17 13:17:33,537 : agent.on_policy : DEBUG : Mean Losses: [0.11092613218352199]
2026-01-17 13:17:33,611 : worker.worker : DEBUG : Step 22133, finished rewards -465.70, envs finished 1
2026-01-17 13:17:33,713 : agent.on_policy : DEBUG : Mean Losses: [2.971102827694267]
2026-01-17 13:17:33,867 : agent.on_policy : DEBUG : Mean Losses: [0.10911241685971618]
2026-01-17 13:17:34,008 : agent.on_policy : DEBUG : Mean Losses: [0.13146375678479671]
2026-01-17 13:17:34,174 : agent.on_policy : DEBUG : Mean Losses: [0.09841334912925959]
2026-01-17 13:17:34,326 : agent.on_policy : DEBUG : Mean Losses: [0.17741020256653428]
2026-01-17 13:17:34,354 : worker.worker : DEBUG : Step 22279, finished rewards -308.96, envs finished 1
2026-01-17 13:17:34,467 : agent.on_policy : DEBUG : Mean Losses: [3.894393184222281]
2026-01-17 13:17:34,551 : worker.worker : DEBUG : Step 22326, finished rewards -448.46, envs finished 1
2026-01-17 13:17:34,652 : agent.on_policy : DEBUG : Mean Losses: [3.0691780536435544]
2026-01-17 13:17:34,834 : agent.on_policy : DEBUG : Mean Losses: [0.13763991370797157]
2026-01-17 13:17:34,989 : agent.on_policy : DEBUG : Mean Losses: [0.09968626173213124]
2026-01-17 13:17:35,060 : worker.worker : DEBUG : Step 22422, finished rewards -455.62, envs finished 1
2026-01-17 13:17:35,164 : agent.on_policy : DEBUG : Mean Losses: [3.0294665349647403]
2026-01-17 13:17:35,223 : worker.worker : DEBUG : Step 22452, finished rewards -491.06, envs finished 1
2026-01-17 13:17:35,323 : agent.on_policy : DEBUG : Mean Losses: [3.9055808819830418]
2026-01-17 13:17:35,420 : worker.worker : DEBUG : Step 22495, finished rewards -481.34, envs finished 1
2026-01-17 13:17:35,490 : agent.on_policy : DEBUG : Mean Losses: [3.1252769976854324]
2026-01-17 13:17:35,491 : worker.worker : DEBUG : Step 22496, finished rewards -481.11, envs finished 1
2026-01-17 13:17:35,650 : agent.on_policy : DEBUG : Mean Losses: [0.13069870229810476]
2026-01-17 13:17:35,710 : worker.worker : DEBUG : Step 22543, finished rewards -489.30, envs finished 1
2026-01-17 13:17:35,847 : agent.on_policy : DEBUG : Mean Losses: [2.710882198996842]
2026-01-17 13:17:35,991 : agent.on_policy : DEBUG : Mean Losses: [0.09274172503501177]
2026-01-17 13:17:36,129 : agent.on_policy : DEBUG : Mean Losses: [0.0890479264780879]
2026-01-17 13:17:36,173 : worker.worker : DEBUG : Step 22634, finished rewards -486.18, envs finished 1
2026-01-17 13:17:36,292 : agent.on_policy : DEBUG : Mean Losses: [2.2779389526695013]
2026-01-17 13:17:36,447 : agent.on_policy : DEBUG : Mean Losses: [0.08602931769564748]
2026-01-17 13:17:36,578 : agent.on_policy : DEBUG : Mean Losses: [0.0906422771513462]
2026-01-17 13:17:36,739 : agent.on_policy : DEBUG : Mean Losses: [0.06657510017976165]
2026-01-17 13:17:36,834 : worker.worker : DEBUG : Step 22780, finished rewards -478.39, envs finished 1
2026-01-17 13:17:36,919 : agent.on_policy : DEBUG : Mean Losses: [3.151916392147541]
2026-01-17 13:17:37,109 : agent.on_policy : DEBUG : Mean Losses: [0.04942391801159829]
2026-01-17 13:17:37,147 : worker.worker : DEBUG : Step 22827, finished rewards -492.30, envs finished 1
2026-01-17 13:17:37,249 : agent.on_policy : DEBUG : Mean Losses: [2.368547605990898]
2026-01-17 13:17:37,418 : agent.on_policy : DEBUG : Mean Losses: [0.06661037297453731]
2026-01-17 13:17:37,554 : agent.on_policy : DEBUG : Mean Losses: [0.07102851860690862]
2026-01-17 13:17:37,612 : worker.worker : DEBUG : Step 22923, finished rewards -486.22, envs finished 1
2026-01-17 13:17:37,815 : agent.on_policy : DEBUG : Mean Losses: [2.3700668564997613]
2026-01-17 13:17:37,841 : worker.worker : DEBUG : Step 22953, finished rewards -484.16, envs finished 1
2026-01-17 13:17:37,955 : agent.on_policy : DEBUG : Mean Losses: [2.4062524484470487]
2026-01-17 13:17:38,040 : worker.worker : DEBUG : Step 22996, finished rewards -487.05, envs finished 1
2026-01-17 13:17:38,044 : worker.worker : DEBUG : Step 22997, finished rewards -476.58, envs finished 1
2026-01-17 13:17:38,048 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.30735686772502346
2026-01-17 13:17:38,144 : agent.on_policy : DEBUG : Mean Losses: [5.855714787263423]
2026-01-17 13:17:38,292 : agent.on_policy : DEBUG : Mean Losses: [0.11389694036915898]
2026-01-17 13:17:38,308 : worker.worker : DEBUG : Step 23044, finished rewards -477.56, envs finished 1
2026-01-17 13:17:38,467 : agent.on_policy : DEBUG : Mean Losses: [1.3075694218277931]
2026-01-17 13:17:38,630 : agent.on_policy : DEBUG : Mean Losses: [0.07789202418643981]
2026-01-17 13:17:38,732 : worker.worker : DEBUG : Step 23135, finished rewards -492.03, envs finished 1
2026-01-17 13:17:38,819 : agent.on_policy : DEBUG : Mean Losses: [3.14464315737132]
2026-01-17 13:17:39,101 : agent.on_policy : DEBUG : Mean Losses: [0.06919765868224204]
2026-01-17 13:17:39,282 : agent.on_policy : DEBUG : Mean Losses: [0.059713350754464045]
2026-01-17 13:17:39,457 : agent.on_policy : DEBUG : Mean Losses: [0.06669699063058943]
2026-01-17 13:17:39,596 : agent.on_policy : DEBUG : Mean Losses: [0.06291178823448718]
2026-01-17 13:17:39,659 : worker.worker : DEBUG : Step 23281, finished rewards -482.10, envs finished 1
2026-01-17 13:17:39,759 : agent.on_policy : DEBUG : Mean Losses: [2.8602693929569796]
2026-01-17 13:17:39,886 : agent.on_policy : DEBUG : Mean Losses: [0.04585708549711853]
2026-01-17 13:17:39,887 : worker.worker : DEBUG : Step 23328, finished rewards -492.64, envs finished 1
2026-01-17 13:17:40,058 : agent.on_policy : DEBUG : Mean Losses: [0.048429657239466906]
2026-01-17 13:17:40,192 : agent.on_policy : DEBUG : Mean Losses: [0.04993907501921058]
2026-01-17 13:17:40,344 : agent.on_policy : DEBUG : Mean Losses: [0.06743858382105827]
2026-01-17 13:17:40,345 : worker.worker : DEBUG : Step 23424, finished rewards -482.61, envs finished 1
2026-01-17 13:17:40,439 : worker.worker : DEBUG : Step 23454, finished rewards -475.44, envs finished 1
2026-01-17 13:17:40,501 : agent.on_policy : DEBUG : Mean Losses: [4.461436942452565]
2026-01-17 13:17:40,668 : agent.on_policy : DEBUG : Mean Losses: [0.05225779570173472]
2026-01-17 13:17:40,696 : worker.worker : DEBUG : Step 23497, finished rewards -472.75, envs finished 1
2026-01-17 13:17:40,700 : worker.worker : DEBUG : Step 23498, finished rewards -492.30, envs finished 1
2026-01-17 13:17:40,818 : agent.on_policy : DEBUG : Mean Losses: [4.424937571398914]
2026-01-17 13:17:40,917 : worker.worker : DEBUG : Step 23545, finished rewards -476.87, envs finished 1
2026-01-17 13:17:41,013 : agent.on_policy : DEBUG : Mean Losses: [3.150371063966304]
2026-01-17 13:17:41,172 : agent.on_policy : DEBUG : Mean Losses: [0.053451384184882045]
2026-01-17 13:17:41,306 : agent.on_policy : DEBUG : Mean Losses: [0.037692113663069904]
2026-01-17 13:17:41,395 : worker.worker : DEBUG : Step 23636, finished rewards -475.47, envs finished 1
2026-01-17 13:17:41,546 : agent.on_policy : DEBUG : Mean Losses: [2.986600678297691]
2026-01-17 13:17:41,756 : agent.on_policy : DEBUG : Mean Losses: [0.07450506207533181]
2026-01-17 13:17:41,969 : agent.on_policy : DEBUG : Mean Losses: [0.07064401597017422]
2026-01-17 13:17:42,142 : agent.on_policy : DEBUG : Mean Losses: [0.02545751357683912]
2026-01-17 13:17:42,333 : agent.on_policy : DEBUG : Mean Losses: [0.03258514543995261]
2026-01-17 13:17:42,354 : worker.worker : DEBUG : Step 23782, finished rewards -483.52, envs finished 1
2026-01-17 13:17:42,537 : agent.on_policy : DEBUG : Mean Losses: [1.7420373008353636]
2026-01-17 13:17:42,617 : worker.worker : DEBUG : Step 23829, finished rewards -495.55, envs finished 1
2026-01-17 13:17:42,732 : agent.on_policy : DEBUG : Mean Losses: [3.047131597297266]
2026-01-17 13:17:42,932 : agent.on_policy : DEBUG : Mean Losses: [0.06489758100360632]
2026-01-17 13:17:43,138 : agent.on_policy : DEBUG : Mean Losses: [0.06414434855105355]
2026-01-17 13:17:43,214 : worker.worker : DEBUG : Step 23925, finished rewards -450.25, envs finished 1
2026-01-17 13:17:43,326 : agent.on_policy : DEBUG : Mean Losses: [3.111554679577239]
2026-01-17 13:17:43,410 : worker.worker : DEBUG : Step 23955, finished rewards -475.47, envs finished 1
2026-01-17 13:17:43,550 : agent.on_policy : DEBUG : Mean Losses: [3.9789602803066373]
2026-01-17 13:17:43,659 : worker.worker : DEBUG : Step 23998, finished rewards -473.73, envs finished 1
2026-01-17 13:17:43,661 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.2919890243387723
2026-01-17 13:17:43,667 : worker.worker : DEBUG : Step 23999, finished rewards -463.43, envs finished 1
2026-01-17 13:17:43,771 : agent.on_policy : DEBUG : Mean Losses: [6.494739210233092]
2026-01-17 13:17:43,974 : agent.on_policy : DEBUG : Mean Losses: [0.07021497376263142]
2026-01-17 13:17:44,033 : worker.worker : DEBUG : Step 24046, finished rewards -495.19, envs finished 1
2026-01-17 13:17:44,180 : agent.on_policy : DEBUG : Mean Losses: [2.690309191122651]
2026-01-17 13:17:44,360 : agent.on_policy : DEBUG : Mean Losses: [0.0516730067320168]
2026-01-17 13:17:44,555 : agent.on_policy : DEBUG : Mean Losses: [0.03120613656938076]
2026-01-17 13:17:44,587 : worker.worker : DEBUG : Step 24137, finished rewards -461.87, envs finished 1
2026-01-17 13:17:44,747 : agent.on_policy : DEBUG : Mean Losses: [2.1596757356019225]
2026-01-17 13:17:45,019 : agent.on_policy : DEBUG : Mean Losses: [0.022665521246381104]
2026-01-17 13:17:45,219 : agent.on_policy : DEBUG : Mean Losses: [0.022524045722093433]
2026-01-17 13:17:45,419 : agent.on_policy : DEBUG : Mean Losses: [0.019118943717330694]
2026-01-17 13:17:45,526 : worker.worker : DEBUG : Step 24283, finished rewards -481.21, envs finished 1
2026-01-17 13:17:45,607 : agent.on_policy : DEBUG : Mean Losses: [3.1845602738903835]
2026-01-17 13:17:45,760 : agent.on_policy : DEBUG : Mean Losses: [0.03648309642449021]
2026-01-17 13:17:45,795 : worker.worker : DEBUG : Step 24330, finished rewards -487.90, envs finished 1
2026-01-17 13:17:45,900 : agent.on_policy : DEBUG : Mean Losses: [2.304795057163574]
2026-01-17 13:17:46,102 : agent.on_policy : DEBUG : Mean Losses: [0.040137267496902496]
2026-01-17 13:17:46,232 : agent.on_policy : DEBUG : Mean Losses: [0.048224445490632206]
2026-01-17 13:17:46,286 : worker.worker : DEBUG : Step 24426, finished rewards -473.00, envs finished 1
2026-01-17 13:17:46,419 : agent.on_policy : DEBUG : Mean Losses: [2.3520836213137954]
2026-01-17 13:17:46,442 : worker.worker : DEBUG : Step 24456, finished rewards -482.01, envs finished 1
2026-01-17 13:17:46,487 : worker.worker : DEBUG : Step 24468, finished rewards -343.61, envs finished 1
2026-01-17 13:17:46,578 : agent.on_policy : DEBUG : Mean Losses: [8.419186405371875]
2026-01-17 13:17:46,657 : worker.worker : DEBUG : Step 24499, finished rewards -468.00, envs finished 1
2026-01-17 13:17:46,769 : agent.on_policy : DEBUG : Mean Losses: [2.9627154441550374]
2026-01-17 13:17:46,918 : agent.on_policy : DEBUG : Mean Losses: [0.04330292879603803]
2026-01-17 13:17:46,928 : worker.worker : DEBUG : Step 24547, finished rewards -483.01, envs finished 1
2026-01-17 13:17:47,072 : agent.on_policy : DEBUG : Mean Losses: [1.0076104662148282]
2026-01-17 13:17:47,219 : agent.on_policy : DEBUG : Mean Losses: [0.03831769130192697]
2026-01-17 13:17:47,317 : worker.worker : DEBUG : Step 24638, finished rewards -475.57, envs finished 1
2026-01-17 13:17:47,382 : agent.on_policy : DEBUG : Mean Losses: [3.2105697749648243]
2026-01-17 13:17:47,536 : agent.on_policy : DEBUG : Mean Losses: [0.04310265905223787]
2026-01-17 13:17:47,684 : agent.on_policy : DEBUG : Mean Losses: [0.04834368440788239]
2026-01-17 13:17:47,819 : agent.on_policy : DEBUG : Mean Losses: [1.5309399150428362]
2026-01-17 13:17:48,000 : agent.on_policy : DEBUG : Mean Losses: [0.14941271964926273]
2026-01-17 13:17:48,046 : worker.worker : DEBUG : Step 24784, finished rewards -469.20, envs finished 1
2026-01-17 13:17:48,147 : agent.on_policy : DEBUG : Mean Losses: [2.915287505136803]
2026-01-17 13:17:48,288 : worker.worker : DEBUG : Step 24831, finished rewards -473.01, envs finished 1
2026-01-17 13:17:48,349 : agent.on_policy : DEBUG : Mean Losses: [3.3163877276238054]
2026-01-17 13:17:48,535 : agent.on_policy : DEBUG : Mean Losses: [0.0980911529622972]
2026-01-17 13:17:48,686 : agent.on_policy : DEBUG : Mean Losses: [0.15030631754780188]
2026-01-17 13:17:48,790 : worker.worker : DEBUG : Step 24927, finished rewards -485.43, envs finished 1
2026-01-17 13:17:48,862 : agent.on_policy : DEBUG : Mean Losses: [3.424311775364913]
2026-01-17 13:17:48,968 : worker.worker : DEBUG : Step 24957, finished rewards -476.32, envs finished 1
2026-01-17 13:17:49,023 : agent.on_policy : DEBUG : Mean Losses: [4.711493957671337]
2026-01-17 13:17:49,051 : worker.worker : DEBUG : Step 24969, finished rewards -431.30, envs finished 1
2026-01-17 13:17:49,323 : agent.on_policy : DEBUG : Mean Losses: [2.1927932035177946]
2026-01-17 13:17:49,342 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.27738957312183365
2026-01-17 13:17:49,349 : worker.worker : DEBUG : Step 25000, finished rewards -495.99, envs finished 1
2026-01-17 13:17:49,351 : worker.worker : INFO : Step 25000, Avg Reward -468.9534, Max Reward -308.9602, Loss [1.34785568]
2026-01-17 13:17:49,469 : agent.on_policy : DEBUG : Mean Losses: [2.0534745622135233]
2026-01-17 13:17:49,560 : worker.worker : DEBUG : Step 25048, finished rewards -480.35, envs finished 1
2026-01-17 13:17:49,658 : agent.on_policy : DEBUG : Mean Losses: [3.1609236319200136]
2026-01-17 13:17:49,806 : agent.on_policy : DEBUG : Mean Losses: [0.05269909172784537]
2026-01-17 13:17:49,931 : agent.on_policy : DEBUG : Mean Losses: [0.06104036618489772]
2026-01-17 13:17:50,006 : worker.worker : DEBUG : Step 25139, finished rewards -482.06, envs finished 1
2026-01-17 13:17:50,114 : agent.on_policy : DEBUG : Mean Losses: [2.9972584983333945]
2026-01-17 13:17:50,251 : agent.on_policy : DEBUG : Mean Losses: [0.048487500520423055]
2026-01-17 13:17:50,419 : agent.on_policy : DEBUG : Mean Losses: [0.05375133961206302]
2026-01-17 13:17:50,604 : agent.on_policy : DEBUG : Mean Losses: [0.0475792366778478]
2026-01-17 13:17:50,757 : agent.on_policy : DEBUG : Mean Losses: [0.05700850789435208]
2026-01-17 13:17:50,784 : worker.worker : DEBUG : Step 25285, finished rewards -464.33, envs finished 1
2026-01-17 13:17:50,907 : agent.on_policy : DEBUG : Mean Losses: [1.4983229239005595]
2026-01-17 13:17:50,988 : worker.worker : DEBUG : Step 25332, finished rewards -465.94, envs finished 1
2026-01-17 13:17:51,093 : agent.on_policy : DEBUG : Mean Losses: [3.027988738846034]
2026-01-17 13:17:51,242 : agent.on_policy : DEBUG : Mean Losses: [0.05138456751592457]
2026-01-17 13:17:51,380 : agent.on_policy : DEBUG : Mean Losses: [0.03925953950965777]
2026-01-17 13:17:51,463 : worker.worker : DEBUG : Step 25428, finished rewards -481.19, envs finished 1
2026-01-17 13:17:51,575 : agent.on_policy : DEBUG : Mean Losses: [2.989526207529707]
2026-01-17 13:17:51,643 : worker.worker : DEBUG : Step 25458, finished rewards -488.15, envs finished 1
2026-01-17 13:17:51,709 : worker.worker : DEBUG : Step 25470, finished rewards -488.21, envs finished 1
2026-01-17 13:17:51,794 : agent.on_policy : DEBUG : Mean Losses: [7.100447000935674]
2026-01-17 13:17:51,272 : worker.worker : DEBUG : Step 25501, finished rewards -482.23, envs finished 1
2026-01-17 13:17:51,372 : agent.on_policy : DEBUG : Mean Losses: [3.2547196380328387]
2026-01-17 13:17:51,563 : agent.on_policy : DEBUG : Mean Losses: [0.04204615135677159]
2026-01-17 13:17:51,600 : worker.worker : DEBUG : Step 25549, finished rewards -462.20, envs finished 1
2026-01-17 13:17:51,705 : agent.on_policy : DEBUG : Mean Losses: [2.6319701892789453]
2026-01-17 13:17:51,872 : agent.on_policy : DEBUG : Mean Losses: [0.022583264828426763]
2026-01-17 13:17:52,069 : agent.on_policy : DEBUG : Mean Losses: [0.021912449155934155]
2026-01-17 13:17:52,098 : worker.worker : DEBUG : Step 25640, finished rewards -484.86, envs finished 1
2026-01-17 13:17:52,266 : agent.on_policy : DEBUG : Mean Losses: [2.0474679195322096]
2026-01-17 13:17:52,398 : agent.on_policy : DEBUG : Mean Losses: [0.03721034456975758]
2026-01-17 13:17:52,551 : agent.on_policy : DEBUG : Mean Losses: [0.2290576077066362]
2026-01-17 13:17:52,600 : worker.worker : DEBUG : Step 25744, finished rewards -166.07, envs finished 1
2026-01-17 13:17:52,699 : agent.on_policy : DEBUG : Mean Losses: [7.528479380533099]
2026-01-17 13:17:52,797 : worker.worker : DEBUG : Step 25786, finished rewards -474.55, envs finished 1
2026-01-17 13:17:52,878 : agent.on_policy : DEBUG : Mean Losses: [3.178802551701665]
2026-01-17 13:17:53,034 : agent.on_policy : DEBUG : Mean Losses: [0.025583805865608156]
2026-01-17 13:17:53,065 : worker.worker : DEBUG : Step 25833, finished rewards -494.10, envs finished 1
2026-01-17 13:17:53,183 : agent.on_policy : DEBUG : Mean Losses: [2.1886947554448852]
2026-01-17 13:17:53,333 : agent.on_policy : DEBUG : Mean Losses: [0.03705772553803399]
2026-01-17 13:17:53,461 : agent.on_policy : DEBUG : Mean Losses: [0.051344793289899826]
2026-01-17 13:17:53,501 : worker.worker : DEBUG : Step 25929, finished rewards -488.26, envs finished 1
2026-01-17 13:17:53,606 : agent.on_policy : DEBUG : Mean Losses: [2.235678541008383]
2026-01-17 13:17:53,683 : worker.worker : DEBUG : Step 25971, finished rewards -493.87, envs finished 1
2026-01-17 13:17:53,788 : agent.on_policy : DEBUG : Mean Losses: [3.004905666457489]
2026-01-17 13:17:53,836 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.263520094465742
2026-01-17 13:17:53,850 : worker.worker : DEBUG : Step 26002, finished rewards -455.64, envs finished 1
2026-01-17 13:17:53,940 : agent.on_policy : DEBUG : Mean Losses: [2.987365614506416]
2026-01-17 13:17:54,112 : agent.on_policy : DEBUG : Mean Losses: [0.02457096314174123]
2026-01-17 13:17:54,119 : worker.worker : DEBUG : Step 26050, finished rewards -490.73, envs finished 1
2026-01-17 13:17:54,241 : agent.on_policy : DEBUG : Mean Losses: [0.7094925536948722]
2026-01-17 13:17:54,426 : agent.on_policy : DEBUG : Mean Losses: [0.01925795729039237]
2026-01-17 13:17:54,528 : worker.worker : DEBUG : Step 26141, finished rewards -490.78, envs finished 1
2026-01-17 13:17:54,603 : agent.on_policy : DEBUG : Mean Losses: [3.2402389036142267]
2026-01-17 13:17:54,755 : agent.on_policy : DEBUG : Mean Losses: [0.029993909178301692]
2026-01-17 13:17:54,919 : agent.on_policy : DEBUG : Mean Losses: [0.013917315169237554]
2026-01-17 13:17:55,071 : agent.on_policy : DEBUG : Mean Losses: [0.013348610722459853]
2026-01-17 13:17:55,091 : worker.worker : DEBUG : Step 26245, finished rewards -467.60, envs finished 1
2026-01-17 13:17:55,218 : agent.on_policy : DEBUG : Mean Losses: [1.5028476042789407]
2026-01-17 13:17:55,285 : worker.worker : DEBUG : Step 26287, finished rewards -483.91, envs finished 1
2026-01-17 13:17:55,409 : agent.on_policy : DEBUG : Mean Losses: [2.7841550890589133]
2026-01-17 13:17:55,499 : worker.worker : DEBUG : Step 26334, finished rewards -476.36, envs finished 1
2026-01-17 13:17:55,570 : agent.on_policy : DEBUG : Mean Losses: [3.2370590968057513]
2026-01-17 13:17:55,720 : agent.on_policy : DEBUG : Mean Losses: [0.03105197160039097]
2026-01-17 13:17:55,841 : agent.on_policy : DEBUG : Mean Losses: [0.02422643311729189]
2026-01-17 13:17:55,943 : worker.worker : DEBUG : Step 26430, finished rewards -484.48, envs finished 1
2026-01-17 13:17:56,020 : agent.on_policy : DEBUG : Mean Losses: [3.264212815396604]
2026-01-17 13:17:56,173 : agent.on_policy : DEBUG : Mean Losses: [0.1830563591211103]
2026-01-17 13:17:56,196 : worker.worker : DEBUG : Step 26472, finished rewards -463.00, envs finished 1
2026-01-17 13:17:56,318 : agent.on_policy : DEBUG : Mean Losses: [1.3900771658372832]
2026-01-17 13:17:56,352 : worker.worker : DEBUG : Step 26503, finished rewards -486.63, envs finished 1
2026-01-17 13:17:56,496 : agent.on_policy : DEBUG : Mean Losses: [1.8855962417437695]
2026-01-17 13:17:56,581 : worker.worker : DEBUG : Step 26551, finished rewards -469.21, envs finished 1
2026-01-17 13:17:56,701 : agent.on_policy : DEBUG : Mean Losses: [3.142823076050263]
2026-01-17 13:17:56,875 : agent.on_policy : DEBUG : Mean Losses: [0.02025269973091781]
2026-01-17 13:17:57,026 : agent.on_policy : DEBUG : Mean Losses: [0.015659477678127587]
2026-01-17 13:17:57,093 : worker.worker : DEBUG : Step 26642, finished rewards -488.57, envs finished 1
2026-01-17 13:17:57,193 : agent.on_policy : DEBUG : Mean Losses: [2.974411063012667]
2026-01-17 13:17:57,368 : agent.on_policy : DEBUG : Mean Losses: [0.05769457932910882]
2026-01-17 13:17:57,522 : agent.on_policy : DEBUG : Mean Losses: [0.03315298739471473]
2026-01-17 13:17:57,620 : worker.worker : DEBUG : Step 26746, finished rewards -481.94, envs finished 1
2026-01-17 13:17:57,708 : agent.on_policy : DEBUG : Mean Losses: [4.425680988235399]
2026-01-17 13:17:57,952 : agent.on_policy : DEBUG : Mean Losses: [0.03419664053944871]
2026-01-17 13:17:57,976 : worker.worker : DEBUG : Step 26788, finished rewards -490.82, envs finished 1
2026-01-17 13:17:58,138 : agent.on_policy : DEBUG : Mean Losses: [1.2734008213155903]
2026-01-17 13:17:58,205 : worker.worker : DEBUG : Step 26835, finished rewards -468.06, envs finished 1
2026-01-17 13:17:58,304 : agent.on_policy : DEBUG : Mean Losses: [3.0190115907171275]
2026-01-17 13:17:58,438 : agent.on_policy : DEBUG : Mean Losses: [0.06420996897213627]
2026-01-17 13:17:58,664 : agent.on_policy : DEBUG : Mean Losses: [1.0165327204304049]
2026-01-17 13:17:58,792 : worker.worker : DEBUG : Step 26931, finished rewards -490.36, envs finished 1
2026-01-17 13:17:58,907 : agent.on_policy : DEBUG : Mean Losses: [3.3399485604604706]
2026-01-17 13:17:59,030 : worker.worker : DEBUG : Step 26973, finished rewards -475.37, envs finished 1
2026-01-17 13:17:59,098 : agent.on_policy : DEBUG : Mean Losses: [3.2853704154258594]
2026-01-17 13:17:59,176 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.25034408974245487
2026-01-17 13:17:59,202 : worker.worker : DEBUG : Step 27004, finished rewards -489.92, envs finished 1
2026-01-17 13:17:59,261 : agent.on_policy : DEBUG : Mean Losses: [3.242450814228505]
2026-01-17 13:17:59,411 : agent.on_policy : DEBUG : Mean Losses: [0.01291101225069724]
2026-01-17 13:17:59,448 : worker.worker : DEBUG : Step 27052, finished rewards -494.74, envs finished 1
2026-01-17 13:17:59,554 : agent.on_policy : DEBUG : Mean Losses: [2.5503584826074075]
2026-01-17 13:17:59,720 : agent.on_policy : DEBUG : Mean Losses: [0.012607678268977907]
2026-01-17 13:17:59,870 : agent.on_policy : DEBUG : Mean Losses: [0.008194441026716959]
2026-01-17 13:17:59,896 : worker.worker : DEBUG : Step 27143, finished rewards -493.44, envs finished 1
2026-01-17 13:18:00,024 : agent.on_policy : DEBUG : Mean Losses: [1.8907571713789366]
2026-01-17 13:18:00,197 : agent.on_policy : DEBUG : Mean Losses: [0.007915203925222158]
2026-01-17 13:18:00,357 : agent.on_policy : DEBUG : Mean Losses: [0.009329324137070216]
2026-01-17 13:18:00,419 : worker.worker : DEBUG : Step 27247, finished rewards -483.08, envs finished 1
2026-01-17 13:18:00,530 : agent.on_policy : DEBUG : Mean Losses: [3.593923003092641]
2026-01-17 13:18:00,612 : worker.worker : DEBUG : Step 27289, finished rewards -485.79, envs finished 1
2026-01-17 13:18:00,698 : agent.on_policy : DEBUG : Mean Losses: [3.2270217724435497]
2026-01-17 13:18:00,865 : agent.on_policy : DEBUG : Mean Losses: [0.006066119123715907]
2026-01-17 13:18:00,887 : worker.worker : DEBUG : Step 27336, finished rewards -495.43, envs finished 1
2026-01-17 13:18:01,015 : agent.on_policy : DEBUG : Mean Losses: [2.0616810352075845]
2026-01-17 13:18:01,219 : agent.on_policy : DEBUG : Mean Losses: [0.011891425208887085]
2026-01-17 13:18:01,423 : agent.on_policy : DEBUG : Mean Losses: [0.01167852315120399]
2026-01-17 13:18:01,457 : worker.worker : DEBUG : Step 27432, finished rewards -494.08, envs finished 1
2026-01-17 13:18:01,625 : agent.on_policy : DEBUG : Mean Losses: [2.068021976854652]
2026-01-17 13:18:01,730 : worker.worker : DEBUG : Step 27474, finished rewards -486.65, envs finished 1
2026-01-17 13:18:01,878 : agent.on_policy : DEBUG : Mean Losses: [3.002092527487548]
2026-01-17 13:18:01,927 : worker.worker : DEBUG : Step 27505, finished rewards -483.32, envs finished 1
2026-01-17 13:18:02,020 : agent.on_policy : DEBUG : Mean Losses: [2.9450031493906863]
2026-01-17 13:18:02,210 : agent.on_policy : DEBUG : Mean Losses: [0.009409469697857276]
2026-01-17 13:18:02,215 : worker.worker : DEBUG : Step 27553, finished rewards -494.00, envs finished 1
2026-01-17 13:18:02,407 : agent.on_policy : DEBUG : Mean Losses: [0.38059773412533104]
2026-01-17 13:18:02,585 : agent.on_policy : DEBUG : Mean Losses: [0.013961151678813621]
2026-01-17 13:18:02,675 : worker.worker : DEBUG : Step 27644, finished rewards -477.87, envs finished 1
2026-01-17 13:18:02,760 : agent.on_policy : DEBUG : Mean Losses: [3.2659523757756688]
2026-01-17 13:18:02,913 : agent.on_policy : DEBUG : Mean Losses: [0.014870349143166095]
2026-01-17 13:18:03,067 : agent.on_policy : DEBUG : Mean Losses: [0.01720794808352366]
2026-01-17 13:18:03,248 : agent.on_policy : DEBUG : Mean Losses: [0.021022194356191903]
2026-01-17 13:18:03,261 : worker.worker : DEBUG : Step 27748, finished rewards -482.86, envs finished 1
2026-01-17 13:18:03,451 : agent.on_policy : DEBUG : Mean Losses: [1.284064830862917]
2026-01-17 13:18:03,502 : worker.worker : DEBUG : Step 27790, finished rewards -487.61, envs finished 1
2026-01-17 13:18:03,628 : agent.on_policy : DEBUG : Mean Losses: [2.7470313498051837]
2026-01-17 13:18:03,718 : worker.worker : DEBUG : Step 27837, finished rewards -483.21, envs finished 1
2026-01-17 13:18:03,785 : agent.on_policy : DEBUG : Mean Losses: [3.287760187406093]
2026-01-17 13:18:03,946 : agent.on_policy : DEBUG : Mean Losses: [0.030738431436475366]
2026-01-17 13:18:04,101 : agent.on_policy : DEBUG : Mean Losses: [0.05760670325253159]
2026-01-17 13:18:04,204 : worker.worker : DEBUG : Step 27933, finished rewards -479.53, envs finished 1
2026-01-17 13:18:04,307 : agent.on_policy : DEBUG : Mean Losses: [3.3871197550470242]
2026-01-17 13:18:04,531 : agent.on_policy : DEBUG : Mean Losses: [0.04205802992510144]
2026-01-17 13:18:04,554 : worker.worker : DEBUG : Step 27975, finished rewards -473.82, envs finished 1
2026-01-17 13:18:04,628 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.2378268852553321
2026-01-17 13:18:04,665 : agent.on_policy : DEBUG : Mean Losses: [1.901828867612494]
2026-01-17 13:18:04,686 : worker.worker : DEBUG : Step 28006, finished rewards -494.85, envs finished 1
2026-01-17 13:18:04,838 : agent.on_policy : DEBUG : Mean Losses: [1.7121493706654292]
2026-01-17 13:18:04,901 : worker.worker : DEBUG : Step 28054, finished rewards -487.76, envs finished 1
2026-01-17 13:18:04,981 : agent.on_policy : DEBUG : Mean Losses: [3.144640215439722]
2026-01-17 13:18:05,144 : agent.on_policy : DEBUG : Mean Losses: [0.014653701044153422]
2026-01-17 13:18:05,287 : agent.on_policy : DEBUG : Mean Losses: [0.01501617836765945]
2026-01-17 13:18:05,355 : worker.worker : DEBUG : Step 28145, finished rewards -495.48, envs finished 1
2026-01-17 13:18:05,473 : agent.on_policy : DEBUG : Mean Losses: [2.927792496928305]
2026-01-17 13:18:05,662 : agent.on_policy : DEBUG : Mean Losses: [0.013483583665220067]
2026-01-17 13:18:05,803 : agent.on_policy : DEBUG : Mean Losses: [0.01663488903432153]
2026-01-17 13:18:05,892 : worker.worker : DEBUG : Step 28249, finished rewards -489.22, envs finished 1
2026-01-17 13:18:05,986 : agent.on_policy : DEBUG : Mean Losses: [4.400154579197988]
2026-01-17 13:18:06,142 : agent.on_policy : DEBUG : Mean Losses: [0.026263036532327533]
2026-01-17 13:18:06,151 : worker.worker : DEBUG : Step 28291, finished rewards -490.65, envs finished 1
2026-01-17 13:18:06,331 : agent.on_policy : DEBUG : Mean Losses: [1.0289162672124803]
2026-01-17 13:18:06,390 : worker.worker : DEBUG : Step 28338, finished rewards -471.05, envs finished 1
2026-01-17 13:18:06,502 : agent.on_policy : DEBUG : Mean Losses: [3.0015612663992215]
2026-01-17 13:18:06,642 : agent.on_policy : DEBUG : Mean Losses: [0.018258979835081846]
2026-01-17 13:18:06,822 : agent.on_policy : DEBUG : Mean Losses: [0.026775343263579998]
2026-01-17 13:18:06,878 : worker.worker : DEBUG : Step 28434, finished rewards -482.10, envs finished 1
2026-01-17 13:18:06,972 : agent.on_policy : DEBUG : Mean Losses: [3.0219090335594956]
2026-01-17 13:18:07,102 : worker.worker : DEBUG : Step 28476, finished rewards -471.17, envs finished 1
2026-01-17 13:18:07,243 : agent.on_policy : DEBUG : Mean Losses: [3.3262386611895636]
2026-01-17 13:18:07,359 : worker.worker : DEBUG : Step 28507, finished rewards -486.59, envs finished 1
2026-01-17 13:18:07,440 : agent.on_policy : DEBUG : Mean Losses: [3.2570952682290226]
2026-01-17 13:18:07,605 : agent.on_policy : DEBUG : Mean Losses: [0.009646005142712966]
2026-01-17 13:18:07,640 : worker.worker : DEBUG : Step 28555, finished rewards -493.60, envs finished 1
2026-01-17 13:18:07,774 : agent.on_policy : DEBUG : Mean Losses: [2.461075463841553]
2026-01-17 13:18:07,968 : agent.on_policy : DEBUG : Mean Losses: [0.024744076159549877]
2026-01-17 13:18:08,117 : agent.on_policy : DEBUG : Mean Losses: [0.039195350371301174]
2026-01-17 13:18:08,145 : worker.worker : DEBUG : Step 28646, finished rewards -494.70, envs finished 1
2026-01-17 13:18:08,280 : agent.on_policy : DEBUG : Mean Losses: [1.7284961573895998]
2026-01-17 13:18:08,447 : agent.on_policy : DEBUG : Mean Losses: [0.03334727720357478]
2026-01-17 13:18:08,582 : agent.on_policy : DEBUG : Mean Losses: [0.05837824605987407]
2026-01-17 13:18:08,644 : worker.worker : DEBUG : Step 28750, finished rewards -487.45, envs finished 1
2026-01-17 13:18:08,770 : agent.on_policy : DEBUG : Mean Losses: [3.502010777941905]
2026-01-17 13:18:08,870 : worker.worker : DEBUG : Step 28792, finished rewards -487.13, envs finished 1
2026-01-17 13:18:09,084 : agent.on_policy : DEBUG : Mean Losses: [3.219983455404872]
2026-01-17 13:18:09,230 : agent.on_policy : DEBUG : Mean Losses: [0.20073273821617477]
2026-01-17 13:18:09,271 : worker.worker : DEBUG : Step 28839, finished rewards -496.01, envs finished 1
2026-01-17 13:18:09,401 : agent.on_policy : DEBUG : Mean Losses: [2.3366256009976496]
2026-01-17 13:18:09,552 : agent.on_policy : DEBUG : Mean Losses: [0.3704781327105593]
2026-01-17 13:18:09,638 : worker.worker : DEBUG : Step 28927, finished rewards -340.15, envs finished 1
2026-01-17 13:18:09,691 : agent.on_policy : DEBUG : Mean Losses: [7.668040766380727]
2026-01-17 13:18:09,875 : agent.on_policy : DEBUG : Mean Losses: [0.006390308175468817]
2026-01-17 13:18:09,930 : worker.worker : DEBUG : Step 28977, finished rewards -488.47, envs finished 1
2026-01-17 13:18:10,059 : agent.on_policy : DEBUG : Mean Losses: [2.9410072187311016]
2026-01-17 13:18:10,088 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.2259355409925655
2026-01-17 13:18:10,135 : worker.worker : DEBUG : Step 29008, finished rewards -494.24, envs finished 1
2026-01-17 13:18:10,225 : agent.on_policy : DEBUG : Mean Losses: [2.9098408004501835]
2026-01-17 13:18:10,488 : agent.on_policy : DEBUG : Mean Losses: [0.04295757820364088]
2026-01-17 13:18:10,490 : worker.worker : DEBUG : Step 29056, finished rewards -487.85, envs finished 1
2026-01-17 13:18:10,679 : agent.on_policy : DEBUG : Mean Losses: [0.04912056552711874]
2026-01-17 13:18:10,871 : agent.on_policy : DEBUG : Mean Losses: [0.03629324631765485]
2026-01-17 13:18:10,976 : worker.worker : DEBUG : Step 29147, finished rewards -475.14, envs finished 1
2026-01-17 13:18:11,068 : agent.on_policy : DEBUG : Mean Losses: [3.2769652954884805]
2026-01-17 13:18:11,230 : agent.on_policy : DEBUG : Mean Losses: [0.016038487490732223]
2026-01-17 13:18:11,393 : agent.on_policy : DEBUG : Mean Losses: [0.02427293357322924]
2026-01-17 13:18:11,553 : agent.on_policy : DEBUG : Mean Losses: [0.050617862259969115]
2026-01-17 13:18:11,575 : worker.worker : DEBUG : Step 29251, finished rewards -474.71, envs finished 1
2026-01-17 13:18:11,736 : agent.on_policy : DEBUG : Mean Losses: [1.0062710472993786]
2026-01-17 13:18:11,778 : worker.worker : DEBUG : Step 29293, finished rewards -475.22, envs finished 1
2026-01-17 13:18:11,883 : agent.on_policy : DEBUG : Mean Losses: [2.6592968667391688]
2026-01-17 13:18:12,009 : worker.worker : DEBUG : Step 29340, finished rewards -492.34, envs finished 1
2026-01-17 13:18:12,098 : agent.on_policy : DEBUG : Mean Losses: [3.2861674207961187]
2026-01-17 13:18:12,244 : agent.on_policy : DEBUG : Mean Losses: [0.013542350032366812]
2026-01-17 13:18:12,391 : agent.on_policy : DEBUG : Mean Losses: [0.014653679798357189]
2026-01-17 13:18:12,509 : worker.worker : DEBUG : Step 29428, finished rewards -484.54, envs finished 1
2026-01-17 13:18:12,624 : agent.on_policy : DEBUG : Mean Losses: [3.095794534892775]
2026-01-17 13:18:12,824 : agent.on_policy : DEBUG : Mean Losses: [0.006625571186305024]
2026-01-17 13:18:12,846 : worker.worker : DEBUG : Step 29478, finished rewards -490.75, envs finished 1
2026-01-17 13:18:13,011 : agent.on_policy : DEBUG : Mean Losses: [1.719257060205564]
2026-01-17 13:18:13,035 : worker.worker : DEBUG : Step 29509, finished rewards -494.42, envs finished 1
2026-01-17 13:18:13,188 : agent.on_policy : DEBUG : Mean Losses: [1.5128551900270395]
2026-01-17 13:18:13,258 : worker.worker : DEBUG : Step 29557, finished rewards -495.00, envs finished 1
2026-01-17 13:18:13,357 : agent.on_policy : DEBUG : Mean Losses: [3.110569021460833]
2026-01-17 13:18:13,591 : agent.on_policy : DEBUG : Mean Losses: [0.011342140118358657]
2026-01-17 13:18:13,727 : agent.on_policy : DEBUG : Mean Losses: [0.0170576004893519]
2026-01-17 13:18:13,805 : worker.worker : DEBUG : Step 29648, finished rewards -489.68, envs finished 1
2026-01-17 13:18:13,925 : agent.on_policy : DEBUG : Mean Losses: [2.8992826762550976]
2026-01-17 13:18:14,078 : agent.on_policy : DEBUG : Mean Losses: [0.026798485312610865]
2026-01-17 13:18:14,270 : agent.on_policy : DEBUG : Mean Losses: [0.051898011908633634]
2026-01-17 13:18:14,347 : worker.worker : DEBUG : Step 29752, finished rewards -489.08, envs finished 1
2026-01-17 13:18:14,463 : agent.on_policy : DEBUG : Mean Losses: [4.455502268043347]
2026-01-17 13:18:14,663 : agent.on_policy : DEBUG : Mean Losses: [0.08608227811055258]
2026-01-17 13:18:14,672 : worker.worker : DEBUG : Step 29794, finished rewards -473.29, envs finished 1
2026-01-17 13:18:14,862 : agent.on_policy : DEBUG : Mean Losses: [0.7893635919754161]
2026-01-17 13:18:14,929 : worker.worker : DEBUG : Step 29841, finished rewards -487.27, envs finished 1
2026-01-17 13:18:15,097 : agent.on_policy : DEBUG : Mean Losses: [2.9609849501866847]
2026-01-17 13:18:15,267 : agent.on_policy : DEBUG : Mean Losses: [0.027537222485989332]
2026-01-17 13:18:15,341 : worker.worker : DEBUG : Step 29911, finished rewards -302.59, envs finished 1
2026-01-17 13:18:15,460 : agent.on_policy : DEBUG : Mean Losses: [6.641348064906197]
2026-01-17 13:18:15,487 : worker.worker : DEBUG : Step 29929, finished rewards -486.30, envs finished 1
2026-01-17 13:18:15,619 : agent.on_policy : DEBUG : Mean Losses: [2.23573060054332]
2026-01-17 13:18:15,768 : agent.on_policy : DEBUG : Mean Losses: [0.025189523468725383]
2026-01-17 13:18:15,813 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.2146387639429372
2026-01-17 13:18:15,820 : worker.worker : INFO : Step 30000, Avg Reward -475.8734, Max Reward -166.0723, Loss [1.46508696]
2026-01-17 13:18:15,859 : worker.worker : DEBUG : Step 30010, finished rewards -483.81, envs finished 1
2026-01-17 13:18:15,930 : agent.on_policy : DEBUG : Mean Losses: [3.243860892369412]
2026-01-17 13:18:16,083 : agent.on_policy : DEBUG : Mean Losses: [0.016092875215690583]
2026-01-17 13:18:16,109 : worker.worker : DEBUG : Step 30058, finished rewards -487.81, envs finished 1
2026-01-17 13:18:16,229 : agent.on_policy : DEBUG : Mean Losses: [2.351751016220078]
2026-01-17 13:18:16,410 : agent.on_policy : DEBUG : Mean Losses: [0.016537651827093214]
2026-01-17 13:18:16,550 : agent.on_policy : DEBUG : Mean Losses: [0.06392951146699488]
2026-01-17 13:18:16,578 : worker.worker : DEBUG : Step 30149, finished rewards -484.45, envs finished 1
2026-01-17 13:18:16,724 : agent.on_policy : DEBUG : Mean Losses: [1.5404805038124323]
2026-01-17 13:18:16,879 : agent.on_policy : DEBUG : Mean Losses: [0.14431110676378012]
2026-01-17 13:18:17,025 : agent.on_policy : DEBUG : Mean Losses: [0.3743024757131934]
2026-01-17 13:18:17,076 : worker.worker : DEBUG : Step 30253, finished rewards -469.46, envs finished 1
2026-01-17 13:18:17,207 : agent.on_policy : DEBUG : Mean Losses: [3.6212473195046186]
2026-01-17 13:18:17,290 : worker.worker : DEBUG : Step 30295, finished rewards -473.69, envs finished 1
2026-01-17 13:18:17,395 : agent.on_policy : DEBUG : Mean Losses: [3.4359798803925514]
2026-01-17 13:18:17,659 : agent.on_policy : DEBUG : Mean Losses: [0.4023242946714163]
2026-01-17 13:18:17,679 : worker.worker : DEBUG : Step 30342, finished rewards -468.59, envs finished 1
2026-01-17 13:18:17,802 : agent.on_policy : DEBUG : Mean Losses: [1.9011983666568995]
2026-01-17 13:18:17,971 : agent.on_policy : DEBUG : Mean Losses: [0.2149284710176289]
2026-01-17 13:18:18,009 : worker.worker : DEBUG : Step 30412, finished rewards -456.20, envs finished 1
2026-01-17 13:18:18,073 : worker.worker : DEBUG : Step 30430, finished rewards -455.33, envs finished 1
2026-01-17 13:18:18,125 : agent.on_policy : DEBUG : Mean Losses: [5.855273270048201]
2026-01-17 13:18:18,273 : agent.on_policy : DEBUG : Mean Losses: [0.15562887722626328]
2026-01-17 13:18:18,401 : agent.on_policy : DEBUG : Mean Losses: [0.10978374863043427]
2026-01-17 13:18:18,465 : worker.worker : DEBUG : Step 30511, finished rewards -447.16, envs finished 1
2026-01-17 13:18:18,591 : agent.on_policy : DEBUG : Mean Losses: [2.855262734927237]
2026-01-17 13:18:18,688 : worker.worker : DEBUG : Step 30559, finished rewards -460.80, envs finished 1
2026-01-17 13:18:18,754 : agent.on_policy : DEBUG : Mean Losses: [3.289470593445003]
2026-01-17 13:18:18,904 : agent.on_policy : DEBUG : Mean Losses: [0.08544704644009471]
2026-01-17 13:18:19,041 : agent.on_policy : DEBUG : Mean Losses: [0.036076128017157316]
2026-01-17 13:18:19,196 : worker.worker : DEBUG : Step 30650, finished rewards -475.74, envs finished 1
2026-01-17 13:18:19,368 : agent.on_policy : DEBUG : Mean Losses: [3.1507149890530854]
2026-01-17 13:18:19,547 : agent.on_policy : DEBUG : Mean Losses: [0.016021779912989587]
2026-01-17 13:18:19,734 : agent.on_policy : DEBUG : Mean Losses: [0.01290288777090609]
2026-01-17 13:18:19,862 : agent.on_policy : DEBUG : Mean Losses: [0.018237273674458265]
2026-01-17 13:18:19,872 : worker.worker : DEBUG : Step 30754, finished rewards -469.64, envs finished 1
2026-01-17 13:18:20,007 : agent.on_policy : DEBUG : Mean Losses: [0.7134748816024512]
2026-01-17 13:18:20,062 : worker.worker : DEBUG : Step 30796, finished rewards -479.11, envs finished 1
2026-01-17 13:18:20,192 : agent.on_policy : DEBUG : Mean Losses: [2.540209573460743]
2026-01-17 13:18:20,275 : worker.worker : DEBUG : Step 30843, finished rewards -482.45, envs finished 1
2026-01-17 13:18:20,352 : agent.on_policy : DEBUG : Mean Losses: [3.214592720963992]
2026-01-17 13:18:20,508 : agent.on_policy : DEBUG : Mean Losses: [0.025466232444159687]
2026-01-17 13:18:20,645 : agent.on_policy : DEBUG : Mean Losses: [0.04126783035462722]
2026-01-17 13:18:20,654 : worker.worker : DEBUG : Step 30913, finished rewards -475.64, envs finished 1
2026-01-17 13:18:20,734 : worker.worker : DEBUG : Step 30931, finished rewards -480.63, envs finished 1
2026-01-17 13:18:20,847 : agent.on_policy : DEBUG : Mean Losses: [3.3999113336903974]
2026-01-17 13:18:21,000 : agent.on_policy : DEBUG : Mean Losses: [0.041388824058230966]
2026-01-17 13:18:20,291 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.20390682574579033
2026-01-17 13:18:20,359 : agent.on_policy : DEBUG : Mean Losses: [0.06414617091650143]
2026-01-17 13:18:20,371 : worker.worker : DEBUG : Step 31012, finished rewards -491.09, envs finished 1
2026-01-17 13:18:20,536 : agent.on_policy : DEBUG : Mean Losses: [1.3049493970174808]
2026-01-17 13:18:20,591 : worker.worker : DEBUG : Step 31060, finished rewards -473.56, envs finished 1
2026-01-17 13:18:20,667 : agent.on_policy : DEBUG : Mean Losses: [3.059491685242392]
2026-01-17 13:18:20,805 : agent.on_policy : DEBUG : Mean Losses: [0.03933709498960525]
2026-01-17 13:18:20,988 : agent.on_policy : DEBUG : Mean Losses: [0.15100532630458474]
2026-01-17 13:18:21,046 : worker.worker : DEBUG : Step 31151, finished rewards -471.52, envs finished 1
2026-01-17 13:18:21,198 : agent.on_policy : DEBUG : Mean Losses: [3.0203503167722374]
2026-01-17 13:18:21,350 : agent.on_policy : DEBUG : Mean Losses: [0.954267606139183]
2026-01-17 13:18:21,471 : worker.worker : DEBUG : Step 31225, finished rewards -222.44, envs finished 1
2026-01-17 13:18:21,586 : agent.on_policy : DEBUG : Mean Losses: [4.546340842964128]
2026-01-17 13:18:21,677 : worker.worker : DEBUG : Step 31255, finished rewards -484.37, envs finished 1
2026-01-17 13:18:21,781 : agent.on_policy : DEBUG : Mean Losses: [4.259422772563994]
2026-01-17 13:18:21,956 : agent.on_policy : DEBUG : Mean Losses: [0.0461100647225976]
2026-01-17 13:18:22,135 : agent.on_policy : DEBUG : Mean Losses: [0.04990641446784139]
2026-01-17 13:18:22,207 : worker.worker : DEBUG : Step 31344, finished rewards -488.06, envs finished 1
2026-01-17 13:18:22,319 : agent.on_policy : DEBUG : Mean Losses: [2.8682091125519946]
2026-01-17 13:18:22,450 : agent.on_policy : DEBUG : Mean Losses: [0.03696760244201869]
2026-01-17 13:18:22,531 : worker.worker : DEBUG : Step 31414, finished rewards -481.80, envs finished 1
2026-01-17 13:18:22,714 : agent.on_policy : DEBUG : Mean Losses: [3.1353460922837257]
2026-01-17 13:18:22,757 : worker.worker : DEBUG : Step 31432, finished rewards -484.51, envs finished 1
2026-01-17 13:18:22,884 : agent.on_policy : DEBUG : Mean Losses: [2.0769574642181396]
2026-01-17 13:18:23,051 : agent.on_policy : DEBUG : Mean Losses: [0.029189909575507045]
2026-01-17 13:18:23,148 : worker.worker : DEBUG : Step 31513, finished rewards -481.59, envs finished 1
2026-01-17 13:18:23,256 : agent.on_policy : DEBUG : Mean Losses: [3.1878401176363695]
2026-01-17 13:18:23,418 : agent.on_policy : DEBUG : Mean Losses: [0.011598383251111954]
2026-01-17 13:18:23,446 : worker.worker : DEBUG : Step 31561, finished rewards -479.94, envs finished 1
2026-01-17 13:18:23,566 : agent.on_policy : DEBUG : Mean Losses: [2.2084332263329998]
2026-01-17 13:18:23,718 : agent.on_policy : DEBUG : Mean Losses: [0.0089066882210318]
2026-01-17 13:18:23,852 : agent.on_policy : DEBUG : Mean Losses: [0.00862176512600854]
2026-01-17 13:18:23,876 : worker.worker : DEBUG : Step 31652, finished rewards -496.60, envs finished 1
2026-01-17 13:18:24,045 : agent.on_policy : DEBUG : Mean Losses: [1.2766279982752167]
2026-01-17 13:18:24,185 : agent.on_policy : DEBUG : Mean Losses: [0.019363413972314447]
2026-01-17 13:18:24,240 : worker.worker : DEBUG : Step 31726, finished rewards -490.44, envs finished 1
2026-01-17 13:18:24,356 : agent.on_policy : DEBUG : Mean Losses: [2.7428483575349674]
2026-01-17 13:18:24,399 : worker.worker : DEBUG : Step 31756, finished rewards -489.58, envs finished 1
2026-01-17 13:18:24,507 : agent.on_policy : DEBUG : Mean Losses: [3.1535851736553013]
2026-01-17 13:18:24,668 : agent.on_policy : DEBUG : Mean Losses: [0.02191460522590205]
2026-01-17 13:18:24,809 : agent.on_policy : DEBUG : Mean Losses: [0.02856061066268012]
2026-01-17 13:18:24,841 : worker.worker : DEBUG : Step 31845, finished rewards -492.57, envs finished 1
2026-01-17 13:18:25,016 : agent.on_policy : DEBUG : Mean Losses: [1.5165044102468528]
2026-01-17 13:18:25,146 : agent.on_policy : DEBUG : Mean Losses: [0.03485356562305242]
2026-01-17 13:18:25,201 : worker.worker : DEBUG : Step 31915, finished rewards -479.47, envs finished 1
2026-01-17 13:18:25,260 : worker.worker : DEBUG : Step 31933, finished rewards -484.23, envs finished 1
2026-01-17 13:18:25,347 : agent.on_policy : DEBUG : Mean Losses: [5.717273683054373]
2026-01-17 13:18:25,536 : agent.on_policy : DEBUG : Mean Losses: [0.048595905187539756]
2026-01-17 13:18:25,628 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.1937114844585008
2026-01-17 13:18:25,668 : agent.on_policy : DEBUG : Mean Losses: [0.09955863992217928]
2026-01-17 13:18:25,726 : worker.worker : DEBUG : Step 32014, finished rewards -492.99, envs finished 1
2026-01-17 13:18:25,851 : agent.on_policy : DEBUG : Mean Losses: [2.771384014224168]
2026-01-17 13:18:25,944 : worker.worker : DEBUG : Step 32062, finished rewards -463.50, envs finished 1
2026-01-17 13:18:26,011 : agent.on_policy : DEBUG : Mean Losses: [3.2598509681993164]
2026-01-17 13:18:26,164 : agent.on_policy : DEBUG : Mean Losses: [0.01801923755556345]
2026-01-17 13:18:26,300 : agent.on_policy : DEBUG : Mean Losses: [0.016242316691204906]
2026-01-17 13:18:26,391 : worker.worker : DEBUG : Step 32153, finished rewards -494.20, envs finished 1
2026-01-17 13:18:26,490 : agent.on_policy : DEBUG : Mean Losses: [3.1866702231927775]
2026-01-17 13:18:26,646 : agent.on_policy : DEBUG : Mean Losses: [0.021905592875555158]
2026-01-17 13:18:26,776 : agent.on_policy : DEBUG : Mean Losses: [0.02307911985553801]
2026-01-17 13:18:26,792 : worker.worker : DEBUG : Step 32227, finished rewards -484.36, envs finished 1
2026-01-17 13:18:26,954 : agent.on_policy : DEBUG : Mean Losses: [1.8169788681552745]
2026-01-17 13:18:26,960 : worker.worker : DEBUG : Step 32257, finished rewards -487.88, envs finished 1
2026-01-17 13:18:27,145 : agent.on_policy : DEBUG : Mean Losses: [2.9010654201265424]
2026-01-17 13:18:27,146 : worker.worker : DEBUG : Step 32288, finished rewards -307.19, envs finished 1
2026-01-17 13:18:27,308 : agent.on_policy : DEBUG : Mean Losses: [0.08416729283635505]
2026-01-17 13:18:27,435 : agent.on_policy : DEBUG : Mean Losses: [0.03806299912685063]
2026-01-17 13:18:27,623 : agent.on_policy : DEBUG : Mean Losses: [0.08280729473335668]
2026-01-17 13:18:27,791 : agent.on_policy : DEBUG : Mean Losses: [0.2920711986371316]
2026-01-17 13:18:27,793 : worker.worker : DEBUG : Step 32416, finished rewards -494.94, envs finished 1
2026-01-17 13:18:27,856 : worker.worker : DEBUG : Step 32434, finished rewards -486.37, envs finished 1
2026-01-17 13:18:27,972 : agent.on_policy : DEBUG : Mean Losses: [3.3281757633085363]
2026-01-17 13:18:28,152 : agent.on_policy : DEBUG : Mean Losses: [0.04889345125411637]
2026-01-17 13:18:28,303 : agent.on_policy : DEBUG : Mean Losses: [0.4719221747072879]
2026-01-17 13:18:28,318 : worker.worker : DEBUG : Step 32515, finished rewards -460.43, envs finished 1
2026-01-17 13:18:28,460 : agent.on_policy : DEBUG : Mean Losses: [0.8717733387020417]
2026-01-17 13:18:28,523 : worker.worker : DEBUG : Step 32563, finished rewards -494.52, envs finished 1
2026-01-17 13:18:28,668 : agent.on_policy : DEBUG : Mean Losses: [3.034048924804665]
2026-01-17 13:18:29,012 : agent.on_policy : DEBUG : Mean Losses: [0.014895057014655322]
2026-01-17 13:18:29,181 : agent.on_policy : DEBUG : Mean Losses: [0.052366287796758115]
2026-01-17 13:18:29,231 : worker.worker : DEBUG : Step 32654, finished rewards -482.64, envs finished 1
2026-01-17 13:18:29,390 : agent.on_policy : DEBUG : Mean Losses: [2.7825347573962063]
2026-01-17 13:18:29,587 : agent.on_policy : DEBUG : Mean Losses: [0.0645376699976623]
2026-01-17 13:18:29,668 : worker.worker : DEBUG : Step 32728, finished rewards -491.21, envs finished 1
2026-01-17 13:18:29,757 : agent.on_policy : DEBUG : Mean Losses: [3.2360731065273285]
2026-01-17 13:18:29,857 : worker.worker : DEBUG : Step 32758, finished rewards -493.15, envs finished 1
2026-01-17 13:18:29,963 : agent.on_policy : DEBUG : Mean Losses: [4.2840936575084925]
2026-01-17 13:18:30,047 : worker.worker : DEBUG : Step 32789, finished rewards -480.72, envs finished 1
2026-01-17 13:18:30,183 : agent.on_policy : DEBUG : Mean Losses: [3.1293150353012607]
2026-01-17 13:18:30,338 : agent.on_policy : DEBUG : Mean Losses: [0.06098198110703379]
2026-01-17 13:18:30,490 : agent.on_policy : DEBUG : Mean Losses: [0.021606207999866456]
2026-01-17 13:18:30,666 : agent.on_policy : DEBUG : Mean Losses: [0.013699586997972801]
2026-01-17 13:18:30,723 : worker.worker : DEBUG : Step 32917, finished rewards -473.98, envs finished 1
2026-01-17 13:18:30,806 : agent.on_policy : DEBUG : Mean Losses: [3.1188789150328375]
2026-01-17 13:18:30,838 : worker.worker : DEBUG : Step 32935, finished rewards -493.62, envs finished 1
2026-01-17 13:18:30,956 : agent.on_policy : DEBUG : Mean Losses: [1.9089275158476084]
2026-01-17 13:18:31,117 : agent.on_policy : DEBUG : Mean Losses: [0.012420637358445674]
2026-01-17 13:18:31,141 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.18402591023557577
2026-01-17 13:18:31,204 : worker.worker : DEBUG : Step 33016, finished rewards -474.81, envs finished 1
2026-01-17 13:18:31,321 : agent.on_policy : DEBUG : Mean Losses: [3.1946496464370284]
2026-01-17 13:18:31,506 : agent.on_policy : DEBUG : Mean Losses: [0.006866546726087108]
2026-01-17 13:18:31,542 : worker.worker : DEBUG : Step 33064, finished rewards -495.42, envs finished 1
2026-01-17 13:18:31,734 : agent.on_policy : DEBUG : Mean Losses: [2.0871476496977266]
2026-01-17 13:18:31,911 : agent.on_policy : DEBUG : Mean Losses: [0.04924543300876394]
2026-01-17 13:18:32,036 : agent.on_policy : DEBUG : Mean Losses: [0.019979823293397203]
2026-01-17 13:18:32,051 : worker.worker : DEBUG : Step 33155, finished rewards -485.17, envs finished 1
2026-01-17 13:18:32,249 : agent.on_policy : DEBUG : Mean Losses: [1.0171038543339819]
2026-01-17 13:18:32,433 : agent.on_policy : DEBUG : Mean Losses: [0.009607675281586125]
2026-01-17 13:18:32,494 : worker.worker : DEBUG : Step 33229, finished rewards -489.90, envs finished 1
2026-01-17 13:18:32,672 : agent.on_policy : DEBUG : Mean Losses: [2.6716684555867687]
2026-01-17 13:18:32,711 : worker.worker : DEBUG : Step 33259, finished rewards -490.44, envs finished 1
2026-01-17 13:18:32,853 : agent.on_policy : DEBUG : Mean Losses: [2.9739732058224035]
2026-01-17 13:18:32,905 : worker.worker : DEBUG : Step 33290, finished rewards -492.39, envs finished 1
2026-01-17 13:18:33,038 : agent.on_policy : DEBUG : Mean Losses: [2.359394025639631]
2026-01-17 13:18:33,185 : agent.on_policy : DEBUG : Mean Losses: [0.007099745649611577]
2026-01-17 13:18:33,361 : agent.on_policy : DEBUG : Mean Losses: [0.009082507836865261]
2026-01-17 13:18:33,522 : agent.on_policy : DEBUG : Mean Losses: [0.005941907758824527]
2026-01-17 13:18:33,552 : worker.worker : DEBUG : Step 33418, finished rewards -496.79, envs finished 1
2026-01-17 13:18:33,606 : worker.worker : DEBUG : Step 33436, finished rewards -495.26, envs finished 1
2026-01-17 13:18:33,664 : agent.on_policy : DEBUG : Mean Losses: [5.642163580225315]
2026-01-17 13:18:33,830 : agent.on_policy : DEBUG : Mean Losses: [0.007218921615276486]
2026-01-17 13:18:33,968 : agent.on_policy : DEBUG : Mean Losses: [0.004014963749796152]
2026-01-17 13:18:34,026 : worker.worker : DEBUG : Step 33517, finished rewards -491.21, envs finished 1
2026-01-17 13:18:34,149 : agent.on_policy : DEBUG : Mean Losses: [2.678926352513372]
2026-01-17 13:18:34,238 : worker.worker : DEBUG : Step 33565, finished rewards -491.51, envs finished 1
2026-01-17 13:18:34,314 : agent.on_policy : DEBUG : Mean Losses: [3.303684358499595]
2026-01-17 13:18:34,507 : agent.on_policy : DEBUG : Mean Losses: [0.0021394726863945834]
2026-01-17 13:18:34,645 : agent.on_policy : DEBUG : Mean Losses: [0.0035619885893538594]
2026-01-17 13:18:34,735 : worker.worker : DEBUG : Step 33656, finished rewards -494.11, envs finished 1
2026-01-17 13:18:34,852 : agent.on_policy : DEBUG : Mean Losses: [3.2212854301033076]
2026-01-17 13:18:35,019 : agent.on_policy : DEBUG : Mean Losses: [0.002982265505124815]
2026-01-17 13:18:35,151 : agent.on_policy : DEBUG : Mean Losses: [0.0032152627245523036]
2026-01-17 13:18:35,162 : worker.worker : DEBUG : Step 33730, finished rewards -496.16, envs finished 1
2026-01-17 13:18:35,394 : agent.on_policy : DEBUG : Mean Losses: [0.7196168295413372]
2026-01-17 13:18:35,397 : worker.worker : DEBUG : Step 33760, finished rewards -494.13, envs finished 1
2026-01-17 13:18:35,574 : worker.worker : DEBUG : Step 33791, finished rewards -497.32, envs finished 1
2026-01-17 13:18:35,623 : agent.on_policy : DEBUG : Mean Losses: [3.3282355139090214]
2026-01-17 13:18:35,768 : agent.on_policy : DEBUG : Mean Losses: [0.00629374643904157]
2026-01-17 13:18:35,938 : agent.on_policy : DEBUG : Mean Losses: [0.005997153130010702]
2026-01-17 13:18:36,070 : agent.on_policy : DEBUG : Mean Losses: [0.003754781835596077]
2026-01-17 13:18:36,182 : worker.worker : DEBUG : Step 33919, finished rewards -489.89, envs finished 1
2026-01-17 13:18:36,252 : agent.on_policy : DEBUG : Mean Losses: [3.3416463469038717]
2026-01-17 13:18:36,320 : worker.worker : DEBUG : Step 33937, finished rewards -494.59, envs finished 1
2026-01-17 13:18:36,424 : agent.on_policy : DEBUG : Mean Losses: [2.971123665556661]
2026-01-17 13:18:36,585 : agent.on_policy : DEBUG : Mean Losses: [0.0033669689000817016]
2026-01-17 13:18:36,631 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.17482461472379698
2026-01-17 13:18:36,721 : agent.on_policy : DEBUG : Mean Losses: [0.0025988907218561508]
2026-01-17 13:18:36,728 : worker.worker : DEBUG : Step 34018, finished rewards -494.60, envs finished 1
2026-01-17 13:18:36,889 : agent.on_policy : DEBUG : Mean Losses: [0.7275244386109989]
2026-01-17 13:18:36,941 : worker.worker : DEBUG : Step 34066, finished rewards -494.54, envs finished 1
2026-01-17 13:18:37,071 : agent.on_policy : DEBUG : Mean Losses: [3.05105208515306]
2026-01-17 13:18:37,237 : agent.on_policy : DEBUG : Mean Losses: [0.09353060671128333]
2026-01-17 13:18:37,405 : agent.on_policy : DEBUG : Mean Losses: [0.2423048036871478]
2026-01-17 13:18:37,444 : worker.worker : DEBUG : Step 34157, finished rewards -486.01, envs finished 1
2026-01-17 13:18:37,584 : agent.on_policy : DEBUG : Mean Losses: [2.7761879228055477]
2026-01-17 13:18:37,746 : agent.on_policy : DEBUG : Mean Losses: [0.7710442000534385]
2026-01-17 13:18:37,824 : worker.worker : DEBUG : Step 34231, finished rewards -472.57, envs finished 1
2026-01-17 13:18:37,925 : agent.on_policy : DEBUG : Mean Losses: [2.9917552056722343]
2026-01-17 13:18:38,002 : worker.worker : DEBUG : Step 34261, finished rewards -486.13, envs finished 1
2026-01-17 13:18:38,097 : agent.on_policy : DEBUG : Mean Losses: [4.248101556673646]
2026-01-17 13:18:38,173 : worker.worker : DEBUG : Step 34292, finished rewards -471.51, envs finished 1
2026-01-17 13:18:38,268 : agent.on_policy : DEBUG : Mean Losses: [3.170482028508559]
2026-01-17 13:18:38,444 : agent.on_policy : DEBUG : Mean Losses: [0.10463377146515995]
2026-01-17 13:18:38,578 : agent.on_policy : DEBUG : Mean Losses: [0.12879140372388065]
2026-01-17 13:18:38,740 : agent.on_policy : DEBUG : Mean Losses: [0.17167859815526754]
2026-01-17 13:18:38,809 : worker.worker : DEBUG : Step 34420, finished rewards -479.83, envs finished 1
2026-01-17 13:18:38,957 : agent.on_policy : DEBUG : Mean Losses: [3.1050793200847693]
2026-01-17 13:18:38,996 : worker.worker : DEBUG : Step 34438, finished rewards -472.74, envs finished 1
2026-01-17 13:18:39,198 : agent.on_policy : DEBUG : Mean Losses: [1.7422211667289957]
2026-01-17 13:18:39,414 : agent.on_policy : DEBUG : Mean Losses: [0.04067530843894929]
2026-01-17 13:18:39,476 : worker.worker : DEBUG : Step 34519, finished rewards -476.82, envs finished 1
2026-01-17 13:18:39,561 : agent.on_policy : DEBUG : Mean Losses: [3.189847377128899]
2026-01-17 13:18:39,722 : agent.on_policy : DEBUG : Mean Losses: [0.026158950058743358]
2026-01-17 13:18:39,751 : worker.worker : DEBUG : Step 34567, finished rewards -466.55, envs finished 1
2026-01-17 13:18:39,874 : agent.on_policy : DEBUG : Mean Losses: [1.8975315652787685]
2026-01-17 13:18:40,038 : agent.on_policy : DEBUG : Mean Losses: [0.1052806552615948]
2026-01-17 13:18:40,180 : agent.on_policy : DEBUG : Mean Losses: [0.3353641885332763]
2026-01-17 13:18:40,194 : worker.worker : DEBUG : Step 34658, finished rewards -475.94, envs finished 1
2026-01-17 13:18:40,350 : agent.on_policy : DEBUG : Mean Losses: [1.2306823942053597]
2026-01-17 13:18:40,521 : agent.on_policy : DEBUG : Mean Losses: [0.4926956659764983]
2026-01-17 13:18:40,555 : worker.worker : DEBUG : Step 34732, finished rewards -496.05, envs finished 1
2026-01-17 13:18:40,681 : agent.on_policy : DEBUG : Mean Losses: [2.8203367656096816]
2026-01-17 13:18:40,741 : worker.worker : DEBUG : Step 34762, finished rewards -492.29, envs finished 1
2026-01-17 13:18:40,878 : agent.on_policy : DEBUG : Mean Losses: [3.0071288648759946]
2026-01-17 13:18:40,904 : worker.worker : DEBUG : Step 34793, finished rewards -455.09, envs finished 1
2026-01-17 13:18:41,013 : agent.on_policy : DEBUG : Mean Losses: [2.0742037254967727]
2026-01-17 13:18:41,185 : agent.on_policy : DEBUG : Mean Losses: [0.04013545680209063]
2026-01-17 13:18:41,316 : agent.on_policy : DEBUG : Mean Losses: [0.09888220112770796]
2026-01-17 13:18:41,486 : agent.on_policy : DEBUG : Mean Losses: [0.11512156657408923]
2026-01-17 13:18:41,529 : worker.worker : DEBUG : Step 34921, finished rewards -484.15, envs finished 1
2026-01-17 13:18:41,624 : worker.worker : DEBUG : Step 34939, finished rewards -495.54, envs finished 1
2026-01-17 13:18:41,797 : agent.on_policy : DEBUG : Mean Losses: [5.4971150702331215]
2026-01-17 13:18:42,028 : agent.on_policy : DEBUG : Mean Losses: [0.03733138181269169]
2026-01-17 13:18:42,122 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.16608338398760714
2026-01-17 13:18:42,131 : worker.worker : INFO : Step 35000, Avg Reward -477.4181, Max Reward -222.4354, Loss [1.36909662]
2026-01-17 13:18:42,234 : agent.on_policy : DEBUG : Mean Losses: [0.06538687832653522]
2026-01-17 13:18:42,298 : worker.worker : DEBUG : Step 35020, finished rewards -491.57, envs finished 1
2026-01-17 13:18:42,440 : agent.on_policy : DEBUG : Mean Losses: [2.643796667922288]
2026-01-17 13:18:42,558 : worker.worker : DEBUG : Step 35068, finished rewards -485.96, envs finished 1
2026-01-17 13:18:42,659 : agent.on_policy : DEBUG : Mean Losses: [3.327341626980342]
2026-01-17 13:18:42,842 : agent.on_policy : DEBUG : Mean Losses: [0.08410063060000539]
2026-01-17 13:18:42,986 : agent.on_policy : DEBUG : Mean Losses: [0.4649935362394899]
2026-01-17 13:18:43,074 : worker.worker : DEBUG : Step 35159, finished rewards -462.87, envs finished 1
2026-01-17 13:18:43,168 : agent.on_policy : DEBUG : Mean Losses: [2.7585463754367083]
2026-01-17 13:18:43,323 : agent.on_policy : DEBUG : Mean Losses: [0.1188348849536851]
2026-01-17 13:18:43,463 : agent.on_policy : DEBUG : Mean Losses: [0.35094808670692146]
2026-01-17 13:18:43,469 : worker.worker : DEBUG : Step 35233, finished rewards -488.04, envs finished 1
2026-01-17 13:18:43,587 : worker.worker : DEBUG : Step 35263, finished rewards -474.97, envs finished 1
2026-01-17 13:18:43,666 : agent.on_policy : DEBUG : Mean Losses: [4.3985129301436245]
2026-01-17 13:18:43,819 : worker.worker : DEBUG : Step 35294, finished rewards -470.66, envs finished 1
2026-01-17 13:18:43,884 : agent.on_policy : DEBUG : Mean Losses: [3.2945108227431774]
2026-01-17 13:18:44,050 : agent.on_policy : DEBUG : Mean Losses: [0.10730841965414584]
2026-01-17 13:18:44,181 : agent.on_policy : DEBUG : Mean Losses: [0.38090536248637363]
2026-01-17 13:18:44,332 : agent.on_policy : DEBUG : Mean Losses: [0.48343855259008706]
2026-01-17 13:18:44,411 : worker.worker : DEBUG : Step 35416, finished rewards -259.38, envs finished 1
2026-01-17 13:18:44,431 : worker.worker : DEBUG : Step 35422, finished rewards -490.75, envs finished 1
2026-01-17 13:18:44,502 : agent.on_policy : DEBUG : Mean Losses: [10.377625297056511]
2026-01-17 13:18:44,563 : worker.worker : DEBUG : Step 35440, finished rewards -458.65, envs finished 1
2026-01-17 13:18:44,678 : agent.on_policy : DEBUG : Mean Losses: [2.6304244508501142]
2026-01-17 13:18:44,841 : agent.on_policy : DEBUG : Mean Losses: [0.03202115138992667]
2026-01-17 13:18:44,968 : agent.on_policy : DEBUG : Mean Losses: [0.04685050342231989]
2026-01-17 13:18:45,133 : agent.on_policy : DEBUG : Mean Losses: [0.027948830393142998]
2026-01-17 13:18:45,180 : worker.worker : DEBUG : Step 35569, finished rewards -492.25, envs finished 1
2026-01-17 13:18:45,267 : agent.on_policy : DEBUG : Mean Losses: [2.9556802884908393]
2026-01-17 13:18:45,423 : agent.on_policy : DEBUG : Mean Losses: [0.01860496570589021]
2026-01-17 13:18:45,585 : agent.on_policy : DEBUG : Mean Losses: [0.025080802850425243]
2026-01-17 13:18:45,638 : worker.worker : DEBUG : Step 35660, finished rewards -490.13, envs finished 1
2026-01-17 13:18:45,791 : agent.on_policy : DEBUG : Mean Losses: [2.5770937998313457]
2026-01-17 13:18:46,004 : agent.on_policy : DEBUG : Mean Losses: [0.008306011673994362]
2026-01-17 13:18:46,105 : worker.worker : DEBUG : Step 35734, finished rewards -495.06, envs finished 1
2026-01-17 13:18:46,229 : agent.on_policy : DEBUG : Mean Losses: [3.159259229316376]
2026-01-17 13:18:46,322 : worker.worker : DEBUG : Step 35764, finished rewards -487.62, envs finished 1
2026-01-17 13:18:46,446 : agent.on_policy : DEBUG : Mean Losses: [4.128493154770695]
2026-01-17 13:18:46,537 : worker.worker : DEBUG : Step 35795, finished rewards -490.01, envs finished 1
2026-01-17 13:18:46,668 : agent.on_policy : DEBUG : Mean Losses: [3.0455360081978142]
2026-01-17 13:18:46,870 : agent.on_policy : DEBUG : Mean Losses: [0.021538583911024034]
2026-01-17 13:18:47,081 : agent.on_policy : DEBUG : Mean Losses: [0.041972884559072554]
2026-01-17 13:18:47,284 : agent.on_policy : DEBUG : Mean Losses: [0.0380821930593811]
2026-01-17 13:18:47,330 : worker.worker : DEBUG : Step 35917, finished rewards -488.38, envs finished 1
2026-01-17 13:18:47,356 : worker.worker : DEBUG : Step 35923, finished rewards -491.40, envs finished 1
2026-01-17 13:18:47,464 : agent.on_policy : DEBUG : Mean Losses: [5.714796147192828]
2026-01-17 13:18:47,490 : worker.worker : DEBUG : Step 35941, finished rewards -485.88, envs finished 1
2026-01-17 13:18:47,678 : agent.on_policy : DEBUG : Mean Losses: [1.5563320241053589]
2026-01-17 13:18:47,786 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.15777921478822676
2026-01-17 13:18:47,863 : agent.on_policy : DEBUG : Mean Losses: [0.06957385642454028]
2026-01-17 13:18:48,057 : agent.on_policy : DEBUG : Mean Losses: [0.18916146631818265]
2026-01-17 13:18:48,263 : agent.on_policy : DEBUG : Mean Losses: [1.0555230248719454]
2026-01-17 13:18:48,297 : worker.worker : DEBUG : Step 36070, finished rewards -488.97, envs finished 1
2026-01-17 13:18:48,537 : agent.on_policy : DEBUG : Mean Losses: [3.669802524498664]
2026-01-17 13:18:48,547 : worker.worker : DEBUG : Step 36097, finished rewards -287.26, envs finished 1
2026-01-17 13:18:48,727 : agent.on_policy : DEBUG : Mean Losses: [0.9553778518456966]
2026-01-17 13:18:48,875 : agent.on_policy : DEBUG : Mean Losses: [0.06044038274558261]
2026-01-17 13:18:49,040 : agent.on_policy : DEBUG : Mean Losses: [0.05243516416521743]
2026-01-17 13:18:49,260 : agent.on_policy : DEBUG : Mean Losses: [0.05405750233330764]
2026-01-17 13:18:49,377 : worker.worker : DEBUG : Step 36235, finished rewards -491.14, envs finished 1
2026-01-17 13:18:49,530 : agent.on_policy : DEBUG : Mean Losses: [2.5646977096330374]
2026-01-17 13:18:49,555 : worker.worker : DEBUG : Step 36265, finished rewards -474.81, envs finished 1
2026-01-17 13:18:49,675 : agent.on_policy : DEBUG : Mean Losses: [2.483882881642785]
2026-01-17 13:18:49,712 : worker.worker : DEBUG : Step 36296, finished rewards -496.62, envs finished 1
2026-01-17 13:18:49,843 : agent.on_policy : DEBUG : Mean Losses: [2.133180499775335]
2026-01-17 13:18:49,995 : agent.on_policy : DEBUG : Mean Losses: [0.06791255669668317]
2026-01-17 13:18:50,129 : agent.on_policy : DEBUG : Mean Losses: [0.013415972556686029]
2026-01-17 13:18:49,961 : agent.on_policy : DEBUG : Mean Losses: [0.01323560340097174]
2026-01-17 13:18:49,967 : worker.worker : DEBUG : Step 36418, finished rewards -496.38, envs finished 1
2026-01-17 13:18:49,993 : worker.worker : DEBUG : Step 36424, finished rewards -473.71, envs finished 1
2026-01-17 13:18:50,059 : worker.worker : DEBUG : Step 36442, finished rewards -497.79, envs finished 1
2026-01-17 13:18:50,172 : agent.on_policy : DEBUG : Mean Losses: [6.038247611082625]
2026-01-17 13:18:50,304 : agent.on_policy : DEBUG : Mean Losses: [0.00573268486186862]
2026-01-17 13:18:50,466 : agent.on_policy : DEBUG : Mean Losses: [0.0076766358251916245]
2026-01-17 13:18:50,642 : agent.on_policy : DEBUG : Mean Losses: [0.010302769107511267]
2026-01-17 13:18:50,736 : worker.worker : DEBUG : Step 36571, finished rewards -495.97, envs finished 1
2026-01-17 13:18:50,827 : agent.on_policy : DEBUG : Mean Losses: [3.274945587007096]
2026-01-17 13:18:50,935 : worker.worker : DEBUG : Step 36598, finished rewards -492.82, envs finished 1
2026-01-17 13:18:51,035 : agent.on_policy : DEBUG : Mean Losses: [3.1689341808087192]
2026-01-17 13:18:51,176 : agent.on_policy : DEBUG : Mean Losses: [0.003534644638421014]
2026-01-17 13:18:51,300 : agent.on_policy : DEBUG : Mean Losses: [0.004251077843946405]
2026-01-17 13:18:51,462 : agent.on_policy : DEBUG : Mean Losses: [0.009063488279934973]
2026-01-17 13:18:51,625 : agent.on_policy : DEBUG : Mean Losses: [0.015162243915256113]
2026-01-17 13:18:51,627 : worker.worker : DEBUG : Step 36736, finished rewards -494.71, envs finished 1
2026-01-17 13:18:51,720 : worker.worker : DEBUG : Step 36766, finished rewards -494.81, envs finished 1
2026-01-17 13:18:51,788 : agent.on_policy : DEBUG : Mean Losses: [4.582766096864361]
2026-01-17 13:18:51,911 : worker.worker : DEBUG : Step 36797, finished rewards -492.69, envs finished 1
2026-01-17 13:18:51,975 : agent.on_policy : DEBUG : Mean Losses: [3.313416446209885]
2026-01-17 13:18:52,124 : agent.on_policy : DEBUG : Mean Losses: [0.021100558922626078]
2026-01-17 13:18:52,249 : agent.on_policy : DEBUG : Mean Losses: [0.0672165768337436]
2026-01-17 13:18:52,445 : agent.on_policy : DEBUG : Mean Losses: [0.0620591735932976]
2026-01-17 13:18:52,531 : worker.worker : DEBUG : Step 36919, finished rewards -492.73, envs finished 1
2026-01-17 13:18:52,562 : worker.worker : DEBUG : Step 36925, finished rewards -486.91, envs finished 1
2026-01-17 13:18:52,650 : agent.on_policy : DEBUG : Mean Losses: [6.5159682016819715]
2026-01-17 13:18:52,725 : worker.worker : DEBUG : Step 36943, finished rewards -487.12, envs finished 1
2026-01-17 13:18:52,858 : agent.on_policy : DEBUG : Mean Losses: [2.78919274371583]
2026-01-17 13:18:53,002 : agent.on_policy : DEBUG : Mean Losses: [0.047971095074899495]
2026-01-17 13:18:53,038 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.14989025404881542
2026-01-17 13:18:53,143 : agent.on_policy : DEBUG : Mean Losses: [0.023373660631477833]
2026-01-17 13:18:53,312 : agent.on_policy : DEBUG : Mean Losses: [0.05687636020593345]
2026-01-17 13:18:53,356 : worker.worker : DEBUG : Step 37072, finished rewards -481.25, envs finished 1
2026-01-17 13:18:53,451 : agent.on_policy : DEBUG : Mean Losses: [2.97185151046142]
2026-01-17 13:18:53,481 : worker.worker : DEBUG : Step 37099, finished rewards -490.30, envs finished 1
2026-01-17 13:18:53,593 : agent.on_policy : DEBUG : Mean Losses: [2.5052482223836705]
2026-01-17 13:18:53,752 : agent.on_policy : DEBUG : Mean Losses: [0.050425987341441214]
2026-01-17 13:18:53,880 : agent.on_policy : DEBUG : Mean Losses: [0.05096099991351366]
2026-01-17 13:18:54,032 : agent.on_policy : DEBUG : Mean Losses: [0.048307613062206656]
2026-01-17 13:18:54,094 : worker.worker : DEBUG : Step 37237, finished rewards -479.33, envs finished 1
2026-01-17 13:18:54,179 : agent.on_policy : DEBUG : Mean Losses: [3.092249314999208]
2026-01-17 13:18:54,245 : worker.worker : DEBUG : Step 37267, finished rewards -487.58, envs finished 1
2026-01-17 13:18:54,356 : agent.on_policy : DEBUG : Mean Losses: [4.039648922625929]
2026-01-17 13:18:54,402 : worker.worker : DEBUG : Step 37298, finished rewards -468.87, envs finished 1
2026-01-17 13:18:54,489 : agent.on_policy : DEBUG : Mean Losses: [3.0059928549453616]
2026-01-17 13:18:54,637 : agent.on_policy : DEBUG : Mean Losses: [0.027669041068293154]
2026-01-17 13:18:54,763 : agent.on_policy : DEBUG : Mean Losses: [0.1360323242843151]
2026-01-17 13:18:54,958 : agent.on_policy : DEBUG : Mean Losses: [0.2591686511877924]
2026-01-17 13:18:54,989 : worker.worker : DEBUG : Step 37420, finished rewards -480.95, envs finished 1
2026-01-17 13:18:55,010 : worker.worker : DEBUG : Step 37426, finished rewards -480.40, envs finished 1
2026-01-17 13:18:55,099 : agent.on_policy : DEBUG : Mean Losses: [5.551169801969081]
2026-01-17 13:18:55,113 : worker.worker : DEBUG : Step 37444, finished rewards -481.51, envs finished 1
2026-01-17 13:18:55,378 : agent.on_policy : DEBUG : Mean Losses: [1.2978303041309118]
2026-01-17 13:18:55,509 : agent.on_policy : DEBUG : Mean Losses: [0.025872578262351453]
2026-01-17 13:18:55,679 : agent.on_policy : DEBUG : Mean Losses: [0.019922476378269494]
2026-01-17 13:18:55,814 : agent.on_policy : DEBUG : Mean Losses: [0.020732789067551494]
2026-01-17 13:18:55,835 : worker.worker : DEBUG : Step 37573, finished rewards -495.60, envs finished 1
2026-01-17 13:18:55,952 : agent.on_policy : DEBUG : Mean Losses: [1.5252645642030984]
2026-01-17 13:18:55,953 : worker.worker : DEBUG : Step 37600, finished rewards -492.20, envs finished 1
2026-01-17 13:18:56,123 : agent.on_policy : DEBUG : Mean Losses: [0.034636083291843534]
2026-01-17 13:18:56,271 : agent.on_policy : DEBUG : Mean Losses: [0.0583722956944257]
2026-01-17 13:18:56,425 : agent.on_policy : DEBUG : Mean Losses: [0.07230916537810117]
2026-01-17 13:18:56,564 : agent.on_policy : DEBUG : Mean Losses: [0.058703008107841015]
2026-01-17 13:18:56,607 : worker.worker : DEBUG : Step 37738, finished rewards -486.56, envs finished 1
2026-01-17 13:18:56,728 : agent.on_policy : DEBUG : Mean Losses: [2.3466056550387293]
2026-01-17 13:18:56,763 : worker.worker : DEBUG : Step 37768, finished rewards -468.55, envs finished 1
2026-01-17 13:18:56,886 : agent.on_policy : DEBUG : Mean Losses: [2.2101071679499]
2026-01-17 13:18:56,919 : worker.worker : DEBUG : Step 37799, finished rewards -486.65, envs finished 1
2026-01-17 13:18:57,081 : agent.on_policy : DEBUG : Mean Losses: [1.9036857774481177]
2026-01-17 13:18:57,219 : agent.on_policy : DEBUG : Mean Losses: [0.28379029454663396]
2026-01-17 13:18:57,412 : agent.on_policy : DEBUG : Mean Losses: [1.087256008759141]
2026-01-17 13:18:57,609 : agent.on_policy : DEBUG : Mean Losses: [2.8436693362891674]
2026-01-17 13:18:57,613 : worker.worker : DEBUG : Step 37921, finished rewards -462.18, envs finished 1
2026-01-17 13:18:57,646 : worker.worker : DEBUG : Step 37927, finished rewards -464.78, envs finished 1
2026-01-17 13:18:57,677 : worker.worker : DEBUG : Step 37934, finished rewards -358.35, envs finished 1
2026-01-17 13:18:57,807 : agent.on_policy : DEBUG : Mean Losses: [8.432932468946092]
2026-01-17 13:18:57,866 : worker.worker : DEBUG : Step 37963, finished rewards -231.80, envs finished 1
2026-01-17 13:18:58,012 : agent.on_policy : DEBUG : Mean Losses: [4.139787109917961]
2026-01-17 13:18:58,072 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.14239574134637464
2026-01-17 13:18:58,215 : agent.on_policy : DEBUG : Mean Losses: [0.019083773280726746]
2026-01-17 13:18:58,419 : agent.on_policy : DEBUG : Mean Losses: [0.02124202821869403]
2026-01-17 13:18:58,517 : worker.worker : DEBUG : Step 38074, finished rewards -497.03, envs finished 1
2026-01-17 13:18:58,619 : agent.on_policy : DEBUG : Mean Losses: [3.3390364290680736]
2026-01-17 13:18:58,834 : agent.on_policy : DEBUG : Mean Losses: [0.48164142813766375]
2026-01-17 13:18:59,124 : agent.on_policy : DEBUG : Mean Losses: [0.48074861816712655]
2026-01-17 13:18:59,363 : agent.on_policy : DEBUG : Mean Losses: [0.5243106400012039]
2026-01-17 13:18:59,455 : worker.worker : DEBUG : Step 38200, finished rewards -271.93, envs finished 1
2026-01-17 13:18:59,557 : agent.on_policy : DEBUG : Mean Losses: [5.9369920623721555]
2026-01-17 13:18:59,702 : worker.worker : DEBUG : Step 38239, finished rewards -491.78, envs finished 1
2026-01-17 13:18:59,757 : agent.on_policy : DEBUG : Mean Losses: [3.3475594888441265]
2026-01-17 13:18:59,884 : worker.worker : DEBUG : Step 38269, finished rewards -497.12, envs finished 1
2026-01-17 13:18:59,958 : agent.on_policy : DEBUG : Mean Losses: [4.5579318075906485]
2026-01-17 13:19:00,150 : agent.on_policy : DEBUG : Mean Losses: [0.06746383667632472]
2026-01-17 13:19:00,428 : agent.on_policy : DEBUG : Mean Losses: [0.04995680433057714]
2026-01-17 13:19:00,651 : agent.on_policy : DEBUG : Mean Losses: [0.03223323027486913]
2026-01-17 13:19:00,822 : agent.on_policy : DEBUG : Mean Losses: [0.02241939411032945]
2026-01-17 13:19:00,909 : worker.worker : DEBUG : Step 38422, finished rewards -481.92, envs finished 1
2026-01-17 13:19:00,937 : worker.worker : DEBUG : Step 38428, finished rewards -494.08, envs finished 1
2026-01-17 13:19:01,053 : agent.on_policy : DEBUG : Mean Losses: [6.453082393738441]
2026-01-17 13:19:01,063 : worker.worker : DEBUG : Step 38435, finished rewards -495.20, envs finished 1
2026-01-17 13:19:01,245 : agent.on_policy : DEBUG : Mean Losses: [1.0282936712319497]
2026-01-17 13:19:01,247 : worker.worker : DEBUG : Step 38464, finished rewards -495.03, envs finished 1
2026-01-17 13:19:01,459 : agent.on_policy : DEBUG : Mean Losses: [0.0170007660635747]
2026-01-17 13:19:01,701 : agent.on_policy : DEBUG : Mean Losses: [0.009898759017232805]
2026-01-17 13:19:01,978 : agent.on_policy : DEBUG : Mean Losses: [0.059770585445221514]
2026-01-17 13:19:02,051 : worker.worker : DEBUG : Step 38575, finished rewards -494.38, envs finished 1
2026-01-17 13:19:02,228 : agent.on_policy : DEBUG : Mean Losses: [2.8967481869040057]
2026-01-17 13:19:02,460 : agent.on_policy : DEBUG : Mean Losses: [0.08690251398365945]
2026-01-17 13:19:02,722 : agent.on_policy : DEBUG : Mean Losses: [0.18362938123755157]
2026-01-17 13:19:02,862 : agent.on_policy : DEBUG : Mean Losses: [0.08905239519663155]
2026-01-17 13:19:02,919 : worker.worker : DEBUG : Step 38701, finished rewards -491.67, envs finished 1
2026-01-17 13:19:03,044 : agent.on_policy : DEBUG : Mean Losses: [2.745907123957295]
2026-01-17 13:19:03,101 : worker.worker : DEBUG : Step 38740, finished rewards -480.12, envs finished 1
2026-01-17 13:19:03,199 : agent.on_policy : DEBUG : Mean Losses: [3.2220135287498124]
2026-01-17 13:19:03,279 : worker.worker : DEBUG : Step 38770, finished rewards -470.77, envs finished 1
2026-01-17 13:19:03,424 : agent.on_policy : DEBUG : Mean Losses: [3.652442172082374]
2026-01-17 13:19:03,629 : agent.on_policy : DEBUG : Mean Losses: [0.2017407332896255]
2026-01-17 13:19:03,849 : agent.on_policy : DEBUG : Mean Losses: [0.1775068484712392]
2026-01-17 13:19:04,064 : agent.on_policy : DEBUG : Mean Losses: [0.19800046950695105]
2026-01-17 13:19:04,250 : agent.on_policy : DEBUG : Mean Losses: [0.16178746323566884]
2026-01-17 13:19:04,293 : worker.worker : DEBUG : Step 38923, finished rewards -477.92, envs finished 1
2026-01-17 13:19:04,318 : worker.worker : DEBUG : Step 38929, finished rewards -466.16, envs finished 1
2026-01-17 13:19:04,351 : worker.worker : DEBUG : Step 38936, finished rewards -494.60, envs finished 1
2026-01-17 13:19:04,477 : agent.on_policy : DEBUG : Mean Losses: [8.548435052158311]
2026-01-17 13:19:04,572 : worker.worker : DEBUG : Step 38965, finished rewards -481.72, envs finished 1
2026-01-17 13:19:04,695 : agent.on_policy : DEBUG : Mean Losses: [3.0479556106729433]
2026-01-17 13:19:04,772 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.1352759542790559
2026-01-17 13:19:04,956 : agent.on_policy : DEBUG : Mean Losses: [0.03151677126879804]
2026-01-17 13:19:05,099 : agent.on_policy : DEBUG : Mean Losses: [0.11732840308104642]
2026-01-17 13:19:05,239 : agent.on_policy : DEBUG : Mean Losses: [0.04416936822235584]
2026-01-17 13:19:05,261 : worker.worker : DEBUG : Step 39076, finished rewards -497.18, envs finished 1
2026-01-17 13:19:05,405 : agent.on_policy : DEBUG : Mean Losses: [1.3152734220493585]
2026-01-17 13:19:05,575 : agent.on_policy : DEBUG : Mean Losses: [0.0406184121966362]
2026-01-17 13:19:05,740 : agent.on_policy : DEBUG : Mean Losses: [0.037224787985906005]
2026-01-17 13:19:05,922 : agent.on_policy : DEBUG : Mean Losses: [0.18698998435866088]
2026-01-17 13:19:05,931 : worker.worker : DEBUG : Step 39202, finished rewards -474.91, envs finished 1
2026-01-17 13:19:06,093 : agent.on_policy : DEBUG : Mean Losses: [0.6873707568156533]
2026-01-17 13:19:06,121 : worker.worker : DEBUG : Step 39241, finished rewards -496.49, envs finished 1
2026-01-17 13:19:06,226 : agent.on_policy : DEBUG : Mean Losses: [2.2421128194546327]
2026-01-17 13:19:06,252 : worker.worker : DEBUG : Step 39271, finished rewards -487.18, envs finished 1
2026-01-17 13:19:06,396 : agent.on_policy : DEBUG : Mean Losses: [1.9179801642894745]
2026-01-17 13:19:06,540 : agent.on_policy : DEBUG : Mean Losses: [0.009958644674043171]
2026-01-17 13:19:06,685 : agent.on_policy : DEBUG : Mean Losses: [0.012085546331945807]
2026-01-17 13:19:06,862 : agent.on_policy : DEBUG : Mean Losses: [0.011855026939883828]
2026-01-17 13:19:07,029 : agent.on_policy : DEBUG : Mean Losses: [0.014677754137665033]
2026-01-17 13:19:07,032 : worker.worker : DEBUG : Step 39424, finished rewards -493.70, envs finished 1
2026-01-17 13:19:07,057 : worker.worker : DEBUG : Step 39430, finished rewards -493.94, envs finished 1
2026-01-17 13:19:07,083 : worker.worker : DEBUG : Step 39437, finished rewards -492.98, envs finished 1
2026-01-17 13:19:07,212 : agent.on_policy : DEBUG : Mean Losses: [4.403646991355345]
2026-01-17 13:19:07,282 : worker.worker : DEBUG : Step 39466, finished rewards -490.06, envs finished 1
2026-01-17 13:19:07,465 : agent.on_policy : DEBUG : Mean Losses: [2.3626826198305935]
2026-01-17 13:19:07,610 : agent.on_policy : DEBUG : Mean Losses: [0.016690371267031878]
2026-01-17 13:19:07,812 : agent.on_policy : DEBUG : Mean Losses: [0.14857425075024366]
2026-01-17 13:19:07,894 : worker.worker : DEBUG : Step 39577, finished rewards -486.92, envs finished 1
2026-01-17 13:19:07,973 : agent.on_policy : DEBUG : Mean Losses: [3.345944754779339]
2026-01-17 13:19:08,174 : agent.on_policy : DEBUG : Mean Losses: [1.092663191491738]
2026-01-17 13:19:08,314 : agent.on_policy : DEBUG : Mean Losses: [1.114325345493853]
2026-01-17 13:19:08,471 : agent.on_policy : DEBUG : Mean Losses: [2.031065743183717]
2026-01-17 13:19:08,473 : worker.worker : DEBUG : Step 39680, finished rewards -260.21, envs finished 1
2026-01-17 13:19:08,547 : worker.worker : DEBUG : Step 39703, finished rewards -482.46, envs finished 1
2026-01-17 13:19:08,629 : agent.on_policy : DEBUG : Mean Losses: [3.449453315231949]
2026-01-17 13:19:08,726 : worker.worker : DEBUG : Step 39742, finished rewards -475.32, envs finished 1
2026-01-17 13:19:08,813 : agent.on_policy : DEBUG : Mean Losses: [3.2428474640473723]
2026-01-17 13:19:09,028 : agent.on_policy : DEBUG : Mean Losses: [0.06298744259402156]
2026-01-17 13:19:09,296 : agent.on_policy : DEBUG : Mean Losses: [0.5186425592983142]
2026-01-17 13:19:09,430 : agent.on_policy : DEBUG : Mean Losses: [1.4610142960445955]
2026-01-17 13:19:09,507 : worker.worker : DEBUG : Step 39857, finished rewards -301.04, envs finished 1
2026-01-17 13:19:09,652 : agent.on_policy : DEBUG : Mean Losses: [6.91474112845026]
2026-01-17 13:19:09,733 : worker.worker : DEBUG : Step 39899, finished rewards -191.03, envs finished 1
2026-01-17 13:19:09,808 : agent.on_policy : DEBUG : Mean Losses: [7.629492564010434]
2026-01-17 13:19:09,917 : worker.worker : DEBUG : Step 39931, finished rewards -458.22, envs finished 1
2026-01-17 13:19:09,982 : agent.on_policy : DEBUG : Mean Losses: [4.56454982914147]
2026-01-17 13:19:09,990 : worker.worker : DEBUG : Step 39938, finished rewards -437.99, envs finished 1
2026-01-17 13:19:10,107 : worker.worker : DEBUG : Step 39967, finished rewards -492.34, envs finished 1
2026-01-17 13:19:10,158 : agent.on_policy : DEBUG : Mean Losses: [3.8184640284162015]
2026-01-17 13:19:10,286 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.1285121565651031
2026-01-17 13:19:10,352 : agent.on_policy : DEBUG : Mean Losses: [0.3410425069741905]
2026-01-17 13:19:10,353 : worker.worker : INFO : Step 40000, Avg Reward -464.3168, Max Reward -191.0343, Loss [1.6002149]
2026-01-17 13:19:10,625 : agent.on_policy : DEBUG : Mean Losses: [0.2425398863852024]
2026-01-17 13:19:10,806 : agent.on_policy : DEBUG : Mean Losses: [0.10226199077442288]
2026-01-17 13:19:11,003 : agent.on_policy : DEBUG : Mean Losses: [0.07831391878426075]
2026-01-17 13:19:11,188 : agent.on_policy : DEBUG : Mean Losses: [0.07467679830733687]
2026-01-17 13:19:11,320 : agent.on_policy : DEBUG : Mean Losses: [0.12789010163396597]
2026-01-17 13:19:11,402 : worker.worker : DEBUG : Step 40181, finished rewards -480.65, envs finished 1
2026-01-17 13:19:11,507 : agent.on_policy : DEBUG : Mean Losses: [4.3447592398151755]
2026-01-17 13:19:11,557 : worker.worker : DEBUG : Step 40204, finished rewards -481.02, envs finished 1
2026-01-17 13:19:11,666 : agent.on_policy : DEBUG : Mean Losses: [3.2176765548065305]
2026-01-17 13:19:11,761 : worker.worker : DEBUG : Step 40243, finished rewards -472.11, envs finished 1
2026-01-17 13:19:11,872 : agent.on_policy : DEBUG : Mean Losses: [3.712793556973338]
2026-01-17 13:19:11,988 : worker.worker : DEBUG : Step 40283, finished rewards -200.58, envs finished 1
2026-01-17 13:19:12,097 : agent.on_policy : DEBUG : Mean Losses: [6.1447325753979385]
2026-01-17 13:19:12,214 : worker.worker : DEBUG : Step 40314, finished rewards -316.01, envs finished 1
2026-01-17 13:19:12,305 : agent.on_policy : DEBUG : Mean Losses: [6.532446159981191]
2026-01-17 13:19:12,462 : agent.on_policy : DEBUG : Mean Losses: [1.6016692090779543]
2026-01-17 13:19:12,569 : worker.worker : DEBUG : Step 40382, finished rewards -344.74, envs finished 1
2026-01-17 13:19:12,661 : agent.on_policy : DEBUG : Mean Losses: [7.004851280478761]
2026-01-17 13:19:12,666 : worker.worker : DEBUG : Step 40385, finished rewards -307.97, envs finished 1
2026-01-17 13:19:12,872 : agent.on_policy : DEBUG : Mean Losses: [1.7255549170076847]
2026-01-17 13:19:12,888 : worker.worker : DEBUG : Step 40421, finished rewards -328.75, envs finished 1
2026-01-17 13:19:13,074 : agent.on_policy : DEBUG : Mean Losses: [3.841256244806573]
2026-01-17 13:19:13,089 : worker.worker : DEBUG : Step 40453, finished rewards -146.92, envs finished 1
2026-01-17 13:19:13,213 : agent.on_policy : DEBUG : Mean Losses: [3.1446035041008145]
2026-01-17 13:19:13,366 : agent.on_policy : DEBUG : Mean Losses: [1.266096246894449]
2026-01-17 13:19:13,516 : agent.on_policy : DEBUG : Mean Losses: [2.4527156727854162]
2026-01-17 13:19:13,591 : worker.worker : DEBUG : Step 40551, finished rewards -145.19, envs finished 2
2026-01-17 13:19:13,755 : agent.on_policy : DEBUG : Mean Losses: [6.797430942184292]
2026-01-17 13:19:13,904 : agent.on_policy : DEBUG : Mean Losses: [1.6759716011583805]
2026-01-17 13:19:14,009 : worker.worker : DEBUG : Step 40637, finished rewards -123.67, envs finished 1
2026-01-17 13:19:14,083 : agent.on_policy : DEBUG : Mean Losses: [7.033184185624123]
2026-01-17 13:19:14,234 : agent.on_policy : DEBUG : Mean Losses: [3.5168228708207607]
2026-01-17 13:19:14,361 : agent.on_policy : DEBUG : Mean Losses: [5.734243430197239]
2026-01-17 13:19:14,367 : worker.worker : DEBUG : Step 40705, finished rewards -470.40, envs finished 1
2026-01-17 13:19:14,380 : worker.worker : DEBUG : Step 40707, finished rewards -134.17, envs finished 1
2026-01-17 13:19:14,419 : worker.worker : DEBUG : Step 40713, finished rewards -168.47, envs finished 1
2026-01-17 13:19:14,556 : agent.on_policy : DEBUG : Mean Losses: [10.708111276850104]
2026-01-17 13:19:14,586 : worker.worker : DEBUG : Step 40742, finished rewards -228.92, envs finished 1
2026-01-17 13:19:14,669 : worker.worker : DEBUG : Step 40764, finished rewards -81.87, envs finished 1
2026-01-17 13:19:14,673 : worker.worker : DEBUG : Step 40765, finished rewards -83.16, envs finished 1
2026-01-17 13:19:14,745 : agent.on_policy : DEBUG : Mean Losses: [12.550658865366131]
2026-01-17 13:19:14,806 : worker.worker : DEBUG : Step 40784, finished rewards -355.78, envs finished 1
2026-01-17 13:19:14,920 : agent.on_policy : DEBUG : Mean Losses: [4.302889853250235]
2026-01-17 13:19:15,079 : agent.on_policy : DEBUG : Mean Losses: [1.2778581101447344]
2026-01-17 13:19:15,304 : agent.on_policy : DEBUG : Mean Losses: [2.616976724937558]
2026-01-17 13:19:15,432 : agent.on_policy : DEBUG : Mean Losses: [2.32309553027153]
2026-01-17 13:19:15,621 : agent.on_policy : DEBUG : Mean Losses: [5.26458677649498]
2026-01-17 13:19:15,673 : worker.worker : DEBUG : Step 40944, finished rewards -181.39, envs finished 1
2026-01-17 13:19:15,775 : agent.on_policy : DEBUG : Mean Losses: [11.578762292861938]
2026-01-17 13:19:15,809 : worker.worker : DEBUG : Step 40968, finished rewards -69.68, envs finished 1
2026-01-17 13:19:15,822 : worker.worker : DEBUG : Step 40971, finished rewards -124.37, envs finished 1
2026-01-17 13:19:15,868 : worker.worker : DEBUG : Step 40984, finished rewards -141.03, envs finished 1
2026-01-17 13:19:15,943 : agent.on_policy : DEBUG : Mean Losses: [14.955670289695263]
2026-01-17 13:19:15,965 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.12208654873684793
2026-01-17 13:19:16,014 : worker.worker : DEBUG : Step 41014, finished rewards -170.61, envs finished 1
2026-01-17 13:19:16,040 : worker.worker : DEBUG : Step 41017, finished rewards -150.15, envs finished 1
2026-01-17 13:19:16,131 : agent.on_policy : DEBUG : Mean Losses: [11.64344515837729]
2026-01-17 13:19:16,232 : worker.worker : DEBUG : Step 41050, finished rewards -161.94, envs finished 1
2026-01-17 13:19:16,413 : agent.on_policy : DEBUG : Mean Losses: [6.647383987903595]
2026-01-17 13:19:16,436 : worker.worker : DEBUG : Step 41061, finished rewards -149.23, envs finished 1
2026-01-17 13:19:16,585 : agent.on_policy : DEBUG : Mean Losses: [5.4931418895721436]
2026-01-17 13:19:16,729 : agent.on_policy : DEBUG : Mean Losses: [2.4313020408153534]
2026-01-17 13:19:16,820 : worker.worker : DEBUG : Step 41145, finished rewards -59.06, envs finished 1
2026-01-17 13:19:16,914 : agent.on_policy : DEBUG : Mean Losses: [8.216373026371002]
2026-01-17 13:19:16,931 : worker.worker : DEBUG : Step 41157, finished rewards -93.97, envs finished 1
2026-01-17 13:19:17,004 : worker.worker : DEBUG : Step 41174, finished rewards -31.73, envs finished 1
2026-01-17 13:19:17,105 : agent.on_policy : DEBUG : Mean Losses: [10.75077012181282]
2026-01-17 13:19:17,126 : worker.worker : DEBUG : Step 41189, finished rewards -45.84, envs finished 1
2026-01-17 13:19:17,136 : worker.worker : DEBUG : Step 41191, finished rewards -88.38, envs finished 1
2026-01-17 13:19:17,300 : agent.on_policy : DEBUG : Mean Losses: [8.767309069633484]
2026-01-17 13:19:17,339 : worker.worker : DEBUG : Step 41227, finished rewards -89.08, envs finished 1
2026-01-17 13:19:17,500 : agent.on_policy : DEBUG : Mean Losses: [6.902887433767319]
2026-01-17 13:19:17,695 : agent.on_policy : DEBUG : Mean Losses: [4.450368780642748]
2026-01-17 13:19:17,725 : worker.worker : DEBUG : Step 41288, finished rewards -12.25, envs finished 1
2026-01-17 13:19:17,775 : worker.worker : DEBUG : Step 41302, finished rewards -100.50, envs finished 1
2026-01-17 13:19:17,795 : worker.worker : DEBUG : Step 41307, finished rewards -33.97, envs finished 1
2026-01-17 13:19:17,874 : agent.on_policy : DEBUG : Mean Losses: [13.431867957115173]
2026-01-17 13:19:17,900 : worker.worker : DEBUG : Step 41318, finished rewards -135.40, envs finished 1
2026-01-17 13:19:17,950 : worker.worker : DEBUG : Step 41332, finished rewards -33.56, envs finished 1
2026-01-17 13:19:18,042 : agent.on_policy : DEBUG : Mean Losses: [9.02346870303154]
2026-01-17 13:19:18,144 : worker.worker : DEBUG : Step 41366, finished rewards -35.09, envs finished 1
2026-01-17 13:19:18,245 : agent.on_policy : DEBUG : Mean Losses: [5.204231083393097]
2026-01-17 13:19:18,414 : agent.on_policy : DEBUG : Mean Losses: [2.2879930287599564]
2026-01-17 13:19:18,504 : worker.worker : DEBUG : Step 41437, finished rewards -113.76, envs finished 1
2026-01-17 13:19:18,571 : agent.on_policy : DEBUG : Mean Losses: [7.950332581996918]
2026-01-17 13:19:18,599 : worker.worker : DEBUG : Step 41446, finished rewards -18.21, envs finished 1
2026-01-17 13:19:18,645 : worker.worker : DEBUG : Step 41457, finished rewards -42.22, envs finished 1
2026-01-17 13:19:18,664 : worker.worker : DEBUG : Step 41460, finished rewards -19.07, envs finished 1
2026-01-17 13:19:18,763 : agent.on_policy : DEBUG : Mean Losses: [12.073724836111069]
2026-01-17 13:19:18,938 : agent.on_policy : DEBUG : Mean Losses: [3.128862500190735]
2026-01-17 13:19:18,976 : worker.worker : DEBUG : Step 41513, finished rewards -72.24, envs finished 1
2026-01-17 13:19:18,999 : worker.worker : DEBUG : Step 41519, finished rewards -33.01, envs finished 1
2026-01-17 13:19:19,004 : worker.worker : DEBUG : Step 41520, finished rewards -142.53, envs finished 1
2026-01-17 13:19:19,043 : worker.worker : DEBUG : Step 41531, finished rewards -63.91, envs finished 1
2026-01-17 13:19:19,106 : agent.on_policy : DEBUG : Mean Losses: [16.015277087688446]
2026-01-17 13:19:19,305 : agent.on_policy : DEBUG : Mean Losses: [2.723141148686409]
2026-01-17 13:19:19,553 : agent.on_policy : DEBUG : Mean Losses: [2.5911604464054108]
2026-01-17 13:19:19,616 : worker.worker : DEBUG : Step 41618, finished rewards -36.17, envs finished 1
2026-01-17 13:19:19,637 : worker.worker : DEBUG : Step 41622, finished rewards -44.86, envs finished 2
2026-01-17 13:19:19,765 : agent.on_policy : DEBUG : Mean Losses: [13.206324636936188]
2026-01-17 13:19:19,519 : agent.on_policy : DEBUG : Mean Losses: [2.5485852658748627]
2026-01-17 13:19:19,119 : worker.worker : DEBUG : Step 41672, finished rewards -32.90, envs finished 1
2026-01-17 13:19:19,231 : agent.on_policy : DEBUG : Mean Losses: [5.2756126299500465]
2026-01-17 13:19:19,235 : worker.worker : DEBUG : Step 41697, finished rewards -48.71, envs finished 1
2026-01-17 13:19:19,262 : worker.worker : DEBUG : Step 41704, finished rewards -57.90, envs finished 1
2026-01-17 13:19:19,275 : worker.worker : DEBUG : Step 41705, finished rewards -49.21, envs finished 1
2026-01-17 13:19:19,417 : agent.on_policy : DEBUG : Mean Losses: [7.6849628165364265]
2026-01-17 13:19:19,489 : worker.worker : DEBUG : Step 41749, finished rewards -13.05, envs finished 1
2026-01-17 13:19:19,585 : agent.on_policy : DEBUG : Mean Losses: [5.8227578997612]
2026-01-17 13:19:19,621 : worker.worker : DEBUG : Step 41772, finished rewards -25.63, envs finished 1
2026-01-17 13:19:19,676 : worker.worker : DEBUG : Step 41790, finished rewards -39.76, envs finished 1
2026-01-17 13:19:19,725 : agent.on_policy : DEBUG : Mean Losses: [8.52578379958868]
2026-01-17 13:19:19,880 : agent.on_policy : DEBUG : Mean Losses: [1.80558580160141]
2026-01-17 13:19:19,911 : worker.worker : DEBUG : Step 41833, finished rewards -38.92, envs finished 1
2026-01-17 13:19:19,952 : worker.worker : DEBUG : Step 41844, finished rewards -22.66, envs finished 1
2026-01-17 13:19:20,043 : agent.on_policy : DEBUG : Mean Losses: [9.841554909944534]
2026-01-17 13:19:20,218 : agent.on_policy : DEBUG : Mean Losses: [2.7882177531719208]
2026-01-17 13:19:20,273 : worker.worker : DEBUG : Step 41906, finished rewards -64.28, envs finished 1
2026-01-17 13:19:20,297 : worker.worker : DEBUG : Step 41911, finished rewards -68.80, envs finished 1
2026-01-17 13:19:20,312 : worker.worker : DEBUG : Step 41914, finished rewards -33.79, envs finished 1
2026-01-17 13:19:20,330 : worker.worker : DEBUG : Step 41917, finished rewards -23.54, envs finished 1
2026-01-17 13:19:20,442 : agent.on_policy : DEBUG : Mean Losses: [16.924969732761383]
2026-01-17 13:19:20,559 : worker.worker : DEBUG : Step 41947, finished rewards -64.62, envs finished 1
2026-01-17 13:19:20,643 : agent.on_policy : DEBUG : Mean Losses: [2.4580501317977905]
2026-01-17 13:19:20,654 : worker.worker : DEBUG : Step 41955, finished rewards -40.44, envs finished 1
2026-01-17 13:19:20,816 : agent.on_policy : DEBUG : Mean Losses: [2.6501614302396774]
2026-01-17 13:19:20,856 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.11598222130000553
2026-01-17 13:19:20,957 : agent.on_policy : DEBUG : Mean Losses: [1.693438544869423]
2026-01-17 13:19:21,167 : agent.on_policy : DEBUG : Mean Losses: [2.424698330461979]
2026-01-17 13:19:21,204 : worker.worker : DEBUG : Step 42063, finished rewards -34.82, envs finished 1
2026-01-17 13:19:21,213 : worker.worker : DEBUG : Step 42066, finished rewards -31.21, envs finished 1
2026-01-17 13:19:21,301 : agent.on_policy : DEBUG : Mean Losses: [10.481040760874748]
2026-01-17 13:19:21,403 : worker.worker : DEBUG : Step 42106, finished rewards -41.80, envs finished 1
2026-01-17 13:19:21,421 : worker.worker : DEBUG : Step 42111, finished rewards -34.98, envs finished 1
2026-01-17 13:19:21,551 : agent.on_policy : DEBUG : Mean Losses: [9.640269994735718]
2026-01-17 13:19:21,568 : worker.worker : DEBUG : Step 42113, finished rewards -66.54, envs finished 1
2026-01-17 13:19:21,685 : worker.worker : DEBUG : Step 42130, finished rewards -76.58, envs finished 1
2026-01-17 13:19:21,801 : agent.on_policy : DEBUG : Mean Losses: [6.212358105927706]
2026-01-17 13:19:21,892 : worker.worker : DEBUG : Step 42168, finished rewards -164.75, envs finished 1
2026-01-17 13:19:21,994 : agent.on_policy : DEBUG : Mean Losses: [6.1447459775954485]
2026-01-17 13:19:22,198 : agent.on_policy : DEBUG : Mean Losses: [1.9652588590979576]
2026-01-17 13:19:22,206 : worker.worker : DEBUG : Step 42210, finished rewards -33.21, envs finished 1
2026-01-17 13:19:22,260 : worker.worker : DEBUG : Step 42222, finished rewards -32.20, envs finished 1
2026-01-17 13:19:22,406 : agent.on_policy : DEBUG : Mean Losses: [6.37888203561306]
2026-01-17 13:19:22,432 : worker.worker : DEBUG : Step 42247, finished rewards -48.77, envs finished 1
2026-01-17 13:19:22,495 : worker.worker : DEBUG : Step 42267, finished rewards -34.47, envs finished 1
2026-01-17 13:19:22,572 : agent.on_policy : DEBUG : Mean Losses: [9.434836510568857]
2026-01-17 13:19:22,580 : worker.worker : DEBUG : Step 42273, finished rewards -22.38, envs finished 1
2026-01-17 13:19:22,601 : worker.worker : DEBUG : Step 42276, finished rewards -34.73, envs finished 1
2026-01-17 13:19:22,645 : worker.worker : DEBUG : Step 42288, finished rewards -45.13, envs finished 1
2026-01-17 13:19:22,751 : agent.on_policy : DEBUG : Mean Losses: [6.1451040813699365]
2026-01-17 13:19:22,780 : worker.worker : DEBUG : Step 42313, finished rewards -23.68, envs finished 1
2026-01-17 13:19:22,919 : agent.on_policy : DEBUG : Mean Losses: [4.144384725950658]
2026-01-17 13:19:22,963 : worker.worker : DEBUG : Step 42349, finished rewards -20.06, envs finished 1
2026-01-17 13:19:23,077 : agent.on_policy : DEBUG : Mean Losses: [4.942817995324731]
2026-01-17 13:19:23,150 : worker.worker : DEBUG : Step 42387, finished rewards -17.18, envs finished 1
2026-01-17 13:19:23,263 : agent.on_policy : DEBUG : Mean Losses: [6.245581191033125]
2026-01-17 13:19:23,272 : worker.worker : DEBUG : Step 42402, finished rewards -14.59, envs finished 1
2026-01-17 13:19:23,317 : worker.worker : DEBUG : Step 42411, finished rewards -19.06, envs finished 1
2026-01-17 13:19:23,357 : worker.worker : DEBUG : Step 42420, finished rewards -54.63, envs finished 1
2026-01-17 13:19:23,387 : worker.worker : DEBUG : Step 42425, finished rewards -26.09, envs finished 1
2026-01-17 13:19:23,463 : agent.on_policy : DEBUG : Mean Losses: [13.48508532345295]
2026-01-17 13:19:23,509 : worker.worker : DEBUG : Step 42446, finished rewards -32.04, envs finished 1
2026-01-17 13:19:23,629 : agent.on_policy : DEBUG : Mean Losses: [5.194590833038092]
2026-01-17 13:19:23,792 : agent.on_policy : DEBUG : Mean Losses: [1.573657087981701]
2026-01-17 13:19:23,797 : worker.worker : DEBUG : Step 42497, finished rewards -26.19, envs finished 1
2026-01-17 13:19:23,979 : agent.on_policy : DEBUG : Mean Losses: [1.715542770922184]
2026-01-17 13:19:23,997 : worker.worker : DEBUG : Step 42533, finished rewards -24.90, envs finished 1
2026-01-17 13:19:24,070 : worker.worker : DEBUG : Step 42556, finished rewards -29.91, envs finished 1
2026-01-17 13:19:24,135 : agent.on_policy : DEBUG : Mean Losses: [9.083687752485275]
2026-01-17 13:19:24,185 : worker.worker : DEBUG : Step 42571, finished rewards -113.96, envs finished 1
2026-01-17 13:19:24,304 : agent.on_policy : DEBUG : Mean Losses: [6.32682342082262]
2026-01-17 13:19:24,306 : worker.worker : DEBUG : Step 42592, finished rewards -38.69, envs finished 1
2026-01-17 13:19:24,311 : worker.worker : DEBUG : Step 42593, finished rewards -23.97, envs finished 1
2026-01-17 13:19:24,431 : worker.worker : DEBUG : Step 42621, finished rewards -61.45, envs finished 1
2026-01-17 13:19:24,506 : agent.on_policy : DEBUG : Mean Losses: [6.871056638658047]
2026-01-17 13:19:24,678 : agent.on_policy : DEBUG : Mean Losses: [1.9857442080974579]
2026-01-17 13:19:24,685 : worker.worker : DEBUG : Step 42658, finished rewards -33.06, envs finished 1
2026-01-17 13:19:24,826 : agent.on_policy : DEBUG : Mean Losses: [2.9633061923086643]
2026-01-17 13:19:24,847 : worker.worker : DEBUG : Step 42692, finished rewards -78.57, envs finished 1
2026-01-17 13:19:24,967 : agent.on_policy : DEBUG : Mean Losses: [3.584163073450327]
2026-01-17 13:19:25,042 : worker.worker : DEBUG : Step 42736, finished rewards -42.13, envs finished 1
2026-01-17 13:19:25,066 : worker.worker : DEBUG : Step 42742, finished rewards -23.59, envs finished 1
2026-01-17 13:19:25,075 : worker.worker : DEBUG : Step 42744, finished rewards -28.56, envs finished 1
2026-01-17 13:19:25,082 : worker.worker : DEBUG : Step 42745, finished rewards -39.94, envs finished 2
2026-01-17 13:19:25,171 : agent.on_policy : DEBUG : Mean Losses: [23.175616297870874]
2026-01-17 13:19:25,197 : worker.worker : DEBUG : Step 42761, finished rewards -20.54, envs finished 1
2026-01-17 13:19:25,321 : agent.on_policy : DEBUG : Mean Losses: [3.527218647301197]
2026-01-17 13:19:25,339 : worker.worker : DEBUG : Step 42787, finished rewards -11.81, envs finished 1
2026-01-17 13:19:25,534 : agent.on_policy : DEBUG : Mean Losses: [1.978689767420292]
2026-01-17 13:19:25,621 : worker.worker : DEBUG : Step 42840, finished rewards -24.96, envs finished 1
2026-01-17 13:19:25,709 : agent.on_policy : DEBUG : Mean Losses: [5.449777763336897]
2026-01-17 13:19:25,868 : agent.on_policy : DEBUG : Mean Losses: [2.3429160490632057]
2026-01-17 13:19:25,870 : worker.worker : DEBUG : Step 42880, finished rewards -13.99, envs finished 1
2026-01-17 13:19:25,896 : worker.worker : DEBUG : Step 42887, finished rewards -28.69, envs finished 1
2026-01-17 13:19:25,969 : worker.worker : DEBUG : Step 42908, finished rewards -39.25, envs finished 1
2026-01-17 13:19:26,036 : agent.on_policy : DEBUG : Mean Losses: [9.619120888411999]
2026-01-17 13:19:26,084 : worker.worker : DEBUG : Step 42922, finished rewards -46.06, envs finished 1
2026-01-17 13:19:26,094 : worker.worker : DEBUG : Step 42924, finished rewards -18.75, envs finished 1
2026-01-17 13:19:26,144 : worker.worker : DEBUG : Step 42937, finished rewards -50.40, envs finished 1
2026-01-17 13:19:26,207 : agent.on_policy : DEBUG : Mean Losses: [12.712180118076503]
2026-01-17 13:19:26,359 : agent.on_policy : DEBUG : Mean Losses: [1.005108905956149]
2026-01-17 13:19:26,409 : worker.worker : DEBUG : Step 42992, finished rewards -40.55, envs finished 1
2026-01-17 13:19:26,431 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.11018311023500525
2026-01-17 13:19:26,511 : agent.on_policy : DEBUG : Mean Losses: [3.615621284581721]
2026-01-17 13:19:26,609 : worker.worker : DEBUG : Step 43032, finished rewards -61.71, envs finished 1
2026-01-17 13:19:26,697 : agent.on_policy : DEBUG : Mean Losses: [5.88814353197813]
2026-01-17 13:19:26,773 : worker.worker : DEBUG : Step 43061, finished rewards -49.63, envs finished 1
2026-01-17 13:19:26,868 : agent.on_policy : DEBUG : Mean Losses: [8.345632564276457]
2026-01-17 13:19:26,879 : worker.worker : DEBUG : Step 43075, finished rewards -27.61, envs finished 1
2026-01-17 13:19:26,885 : worker.worker : DEBUG : Step 43077, finished rewards -64.91, envs finished 1
2026-01-17 13:19:26,919 : worker.worker : DEBUG : Step 43084, finished rewards -48.69, envs finished 1
2026-01-17 13:19:27,091 : agent.on_policy : DEBUG : Mean Losses: [8.450007101520896]
2026-01-17 13:19:27,231 : agent.on_policy : DEBUG : Mean Losses: [1.2299666805192828]
2026-01-17 13:19:27,269 : worker.worker : DEBUG : Step 43144, finished rewards -74.51, envs finished 1
2026-01-17 13:19:27,347 : worker.worker : DEBUG : Step 43167, finished rewards -45.14, envs finished 1
2026-01-17 13:19:27,394 : agent.on_policy : DEBUG : Mean Losses: [8.73739056289196]
2026-01-17 13:19:27,644 : agent.on_policy : DEBUG : Mean Losses: [1.7128519769757986]
2026-01-17 13:19:27,650 : worker.worker : DEBUG : Step 43201, finished rewards -45.18, envs finished 1
2026-01-17 13:19:27,665 : worker.worker : DEBUG : Step 43203, finished rewards -10.95, envs finished 1
2026-01-17 13:19:27,682 : worker.worker : DEBUG : Step 43205, finished rewards -137.99, envs finished 1
2026-01-17 13:19:27,695 : worker.worker : DEBUG : Step 43207, finished rewards -24.90, envs finished 1
2026-01-17 13:19:27,891 : agent.on_policy : DEBUG : Mean Losses: [8.495434533804655]
2026-01-17 13:19:27,909 : worker.worker : DEBUG : Step 43238, finished rewards -32.76, envs finished 1
2026-01-17 13:19:27,968 : worker.worker : DEBUG : Step 43255, finished rewards -42.20, envs finished 1
2026-01-17 13:19:28,052 : agent.on_policy : DEBUG : Mean Losses: [7.336944608017802]
2026-01-17 13:19:28,244 : agent.on_policy : DEBUG : Mean Losses: [0.9480973165482283]
2026-01-17 13:19:28,260 : worker.worker : DEBUG : Step 43301, finished rewards -32.88, envs finished 1
2026-01-17 13:19:28,302 : worker.worker : DEBUG : Step 43312, finished rewards -22.87, envs finished 1
2026-01-17 13:19:28,398 : agent.on_policy : DEBUG : Mean Losses: [6.850670866668224]
2026-01-17 13:19:28,489 : worker.worker : DEBUG : Step 43347, finished rewards -25.09, envs finished 1
2026-01-17 13:19:28,525 : worker.worker : DEBUG : Step 43355, finished rewards -31.47, envs finished 1
2026-01-17 13:19:28,533 : worker.worker : DEBUG : Step 43356, finished rewards -28.18, envs finished 1
2026-01-17 13:19:28,560 : worker.worker : DEBUG : Step 43359, finished rewards -28.48, envs finished 1
2026-01-17 13:19:28,670 : agent.on_policy : DEBUG : Mean Losses: [21.071391105651855]
2026-01-17 13:19:28,925 : agent.on_policy : DEBUG : Mean Losses: [1.0561388693749905]
2026-01-17 13:19:29,009 : worker.worker : DEBUG : Step 43421, finished rewards -42.47, envs finished 1
2026-01-17 13:19:29,085 : agent.on_policy : DEBUG : Mean Losses: [5.705212417989969]
2026-01-17 13:19:29,095 : worker.worker : DEBUG : Step 43425, finished rewards -41.66, envs finished 1
2026-01-17 13:19:29,210 : worker.worker : DEBUG : Step 43444, finished rewards -9.96, envs finished 1
2026-01-17 13:19:29,354 : agent.on_policy : DEBUG : Mean Losses: [5.690462704747915]
2026-01-17 13:19:29,391 : worker.worker : DEBUG : Step 43461, finished rewards -34.01, envs finished 1
2026-01-17 13:19:29,570 : agent.on_policy : DEBUG : Mean Losses: [3.2972409203648567]
2026-01-17 13:19:29,726 : agent.on_policy : DEBUG : Mean Losses: [2.4353388734161854]
2026-01-17 13:19:29,735 : worker.worker : DEBUG : Step 43521, finished rewards -39.05, envs finished 1
2026-01-17 13:19:29,787 : worker.worker : DEBUG : Step 43533, finished rewards -57.56, envs finished 1
2026-01-17 13:19:29,806 : worker.worker : DEBUG : Step 43537, finished rewards -56.19, envs finished 1
2026-01-17 13:19:29,932 : agent.on_policy : DEBUG : Mean Losses: [11.260252073407173]
2026-01-17 13:19:29,958 : worker.worker : DEBUG : Step 43559, finished rewards -65.56, envs finished 1
2026-01-17 13:19:30,106 : agent.on_policy : DEBUG : Mean Losses: [3.6709798853844404]
2026-01-17 13:19:30,155 : worker.worker : DEBUG : Step 43590, finished rewards -43.62, envs finished 1
2026-01-17 13:19:30,256 : worker.worker : DEBUG : Step 43613, finished rewards -29.47, envs finished 1
2026-01-17 13:19:30,321 : agent.on_policy : DEBUG : Mean Losses: [8.00853906571865]
2026-01-17 13:19:30,337 : worker.worker : DEBUG : Step 43619, finished rewards -49.17, envs finished 1
2026-01-17 13:19:30,544 : agent.on_policy : DEBUG : Mean Losses: [2.5395174492150545]
2026-01-17 13:19:30,623 : worker.worker : DEBUG : Step 43665, finished rewards -101.38, envs finished 1
2026-01-17 13:19:30,791 : agent.on_policy : DEBUG : Mean Losses: [4.63031735830009]
2026-01-17 13:19:30,823 : worker.worker : DEBUG : Step 43688, finished rewards -41.64, envs finished 1
2026-01-17 13:19:30,834 : worker.worker : DEBUG : Step 43691, finished rewards -29.99, envs finished 1
2026-01-17 13:19:30,852 : worker.worker : DEBUG : Step 43695, finished rewards -32.12, envs finished 1
2026-01-17 13:19:30,951 : agent.on_policy : DEBUG : Mean Losses: [11.70861279591918]
2026-01-17 13:19:31,038 : worker.worker : DEBUG : Step 43733, finished rewards -41.70, envs finished 1
2026-01-17 13:19:31,149 : agent.on_policy : DEBUG : Mean Losses: [5.905735718086362]
2026-01-17 13:19:31,230 : worker.worker : DEBUG : Step 43764, finished rewards -37.96, envs finished 1
2026-01-17 13:19:31,345 : agent.on_policy : DEBUG : Mean Losses: [4.1725942343473434]
2026-01-17 13:19:31,421 : worker.worker : DEBUG : Step 43792, finished rewards -51.09, envs finished 1
2026-01-17 13:19:31,543 : agent.on_policy : DEBUG : Mean Losses: [6.634355083107948]
2026-01-17 13:19:31,634 : worker.worker : DEBUG : Step 43831, finished rewards -66.26, envs finished 1
2026-01-17 13:19:31,641 : worker.worker : DEBUG : Step 43833, finished rewards -19.03, envs finished 1
2026-01-17 13:19:31,806 : agent.on_policy : DEBUG : Mean Losses: [12.815469592809677]
2026-01-17 13:19:31,846 : worker.worker : DEBUG : Step 43843, finished rewards -31.81, envs finished 1
2026-01-17 13:19:31,924 : worker.worker : DEBUG : Step 43854, finished rewards -55.86, envs finished 1
2026-01-17 13:19:32,059 : agent.on_policy : DEBUG : Mean Losses: [6.843505738303065]
2026-01-17 13:19:32,238 : agent.on_policy : DEBUG : Mean Losses: [2.9211348462849855]
2026-01-17 13:19:32,268 : worker.worker : DEBUG : Step 43914, finished rewards -61.93, envs finished 1
2026-01-17 13:19:32,324 : worker.worker : DEBUG : Step 43928, finished rewards -53.28, envs finished 1
2026-01-17 13:19:32,440 : agent.on_policy : DEBUG : Mean Losses: [7.863634333014488]
2026-01-17 13:19:32,451 : worker.worker : DEBUG : Step 43936, finished rewards -46.81, envs finished 1
2026-01-17 13:19:32,731 : agent.on_policy : DEBUG : Mean Losses: [1.387102791108191]
2026-01-17 13:19:32,738 : worker.worker : DEBUG : Step 43969, finished rewards -50.80, envs finished 1
2026-01-17 13:19:32,864 : worker.worker : DEBUG : Step 43990, finished rewards -18.21, envs finished 1
2026-01-17 13:19:32,904 : worker.worker : DEBUG : Step 43995, finished rewards -38.98, envs finished 1
2026-01-17 13:19:32,929 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.10467395472325498
2026-01-17 13:19:32,988 : agent.on_policy : DEBUG : Mean Losses: [12.109719797968864]
2026-01-17 13:19:32,997 : worker.worker : DEBUG : Step 44002, finished rewards -35.69, envs finished 1
2026-01-17 13:19:33,009 : worker.worker : DEBUG : Step 44005, finished rewards -41.79, envs finished 1
2026-01-17 13:19:33,205 : agent.on_policy : DEBUG : Mean Losses: [3.9005815722048283]
2026-01-17 13:19:33,488 : agent.on_policy : DEBUG : Mean Losses: [1.0538395214825869]
2026-01-17 13:19:33,566 : worker.worker : DEBUG : Step 44081, finished rewards -30.39, envs finished 1
2026-01-17 13:19:33,707 : agent.on_policy : DEBUG : Mean Losses: [6.010604731738567]
2026-01-17 13:19:33,773 : worker.worker : DEBUG : Step 44111, finished rewards -40.24, envs finished 1
2026-01-17 13:19:33,830 : worker.worker : DEBUG : Step 44124, finished rewards -33.92, envs finished 1
2026-01-17 13:19:33,929 : agent.on_policy : DEBUG : Mean Losses: [9.722132805734873]
2026-01-17 13:19:33,947 : worker.worker : DEBUG : Step 44133, finished rewards -75.71, envs finished 1
2026-01-17 13:19:34,026 : worker.worker : DEBUG : Step 44148, finished rewards -26.72, envs finished 1
2026-01-17 13:19:34,031 : worker.worker : DEBUG : Step 44149, finished rewards -24.87, envs finished 1
2026-01-17 13:19:34,061 : worker.worker : DEBUG : Step 44156, finished rewards -36.93, envs finished 1
2026-01-17 13:19:34,066 : worker.worker : DEBUG : Step 44157, finished rewards -28.32, envs finished 1
2026-01-17 13:19:34,151 : agent.on_policy : DEBUG : Mean Losses: [21.230790432542562]
2026-01-17 13:19:34,364 : agent.on_policy : DEBUG : Mean Losses: [0.6555104814469814]
2026-01-17 13:19:34,501 : worker.worker : DEBUG : Step 44221, finished rewards -17.62, envs finished 1
2026-01-17 13:19:34,599 : agent.on_policy : DEBUG : Mean Losses: [5.0745761804282665]
2026-01-17 13:19:34,808 : agent.on_policy : DEBUG : Mean Losses: [1.5883763693273067]
2026-01-17 13:19:34,845 : worker.worker : DEBUG : Step 44267, finished rewards -22.69, envs finished 1
2026-01-17 13:19:34,909 : worker.worker : DEBUG : Step 44279, finished rewards -39.93, envs finished 1
2026-01-17 13:19:35,060 : agent.on_policy : DEBUG : Mean Losses: [10.136237308382988]
2026-01-17 13:19:35,124 : worker.worker : DEBUG : Step 44301, finished rewards -40.45, envs finished 1
2026-01-17 13:19:35,152 : worker.worker : DEBUG : Step 44305, finished rewards -32.98, envs finished 1
2026-01-17 13:19:35,168 : worker.worker : DEBUG : Step 44307, finished rewards -36.95, envs finished 1
2026-01-17 13:19:35,353 : agent.on_policy : DEBUG : Mean Losses: [13.044688045978546]
2026-01-17 13:19:35,392 : worker.worker : DEBUG : Step 44331, finished rewards -36.91, envs finished 1
2026-01-17 13:19:35,553 : agent.on_policy : DEBUG : Mean Losses: [4.177684722468257]
2026-01-17 13:19:35,635 : worker.worker : DEBUG : Step 44373, finished rewards -27.22, envs finished 1
2026-01-17 13:19:35,742 : agent.on_policy : DEBUG : Mean Losses: [5.345663867890835]
2026-01-17 13:19:35,840 : worker.worker : DEBUG : Step 44410, finished rewards -18.61, envs finished 1
2026-01-17 13:19:35,931 : agent.on_policy : DEBUG : Mean Losses: [6.011256709694862]
2026-01-17 13:19:36,099 : agent.on_policy : DEBUG : Mean Losses: [4.610223390161991]
2026-01-17 13:19:36,124 : worker.worker : DEBUG : Step 44455, finished rewards -14.56, envs finished 2
2026-01-17 13:19:36,184 : worker.worker : DEBUG : Step 44471, finished rewards -36.42, envs finished 1
2026-01-17 13:19:36,198 : worker.worker : DEBUG : Step 44474, finished rewards -39.04, envs finished 1
2026-01-17 13:19:36,282 : agent.on_policy : DEBUG : Mean Losses: [14.617932260036469]
2026-01-17 13:19:36,289 : worker.worker : DEBUG : Step 44481, finished rewards -167.72, envs finished 1
2026-01-17 13:19:36,377 : worker.worker : DEBUG : Step 44505, finished rewards -85.84, envs finished 1
2026-01-17 13:19:36,460 : agent.on_policy : DEBUG : Mean Losses: [4.871210383251309]
2026-01-17 13:19:36,638 : agent.on_policy : DEBUG : Mean Losses: [0.6982003301382065]
2026-01-17 13:19:36,674 : worker.worker : DEBUG : Step 44554, finished rewards -24.80, envs finished 1
2026-01-17 13:19:36,785 : agent.on_policy : DEBUG : Mean Losses: [4.261610832065344]
2026-01-17 13:19:36,892 : worker.worker : DEBUG : Step 44603, finished rewards -25.47, envs finished 1
2026-01-17 13:19:36,906 : worker.worker : DEBUG : Step 44606, finished rewards -18.28, envs finished 1
2026-01-17 13:19:36,988 : agent.on_policy : DEBUG : Mean Losses: [11.002339094877243]
2026-01-17 13:19:37,003 : worker.worker : DEBUG : Step 44612, finished rewards -49.45, envs finished 1
2026-01-17 13:19:37,156 : agent.on_policy : DEBUG : Mean Losses: [4.366576980799437]
2026-01-17 13:19:37,173 : worker.worker : DEBUG : Step 44645, finished rewards -43.96, envs finished 1
2026-01-17 13:19:37,197 : worker.worker : DEBUG : Step 44650, finished rewards -59.22, envs finished 1
2026-01-17 13:19:37,272 : worker.worker : DEBUG : Step 44671, finished rewards -57.97, envs finished 1
2026-01-17 13:19:37,343 : agent.on_policy : DEBUG : Mean Losses: [12.401288306340575]
2026-01-17 13:19:37,455 : worker.worker : DEBUG : Step 44695, finished rewards -51.64, envs finished 1
2026-01-17 13:19:37,551 : agent.on_policy : DEBUG : Mean Losses: [4.315312555991113]
2026-01-17 13:19:37,613 : worker.worker : DEBUG : Step 44719, finished rewards -36.50, envs finished 1
2026-01-17 13:19:37,795 : agent.on_policy : DEBUG : Mean Losses: [3.6255036368966103]
2026-01-17 13:19:37,868 : worker.worker : DEBUG : Step 44746, finished rewards -22.35, envs finished 1
2026-01-17 13:19:37,918 : worker.worker : DEBUG : Step 44757, finished rewards -31.24, envs finished 1
2026-01-17 13:19:38,024 : agent.on_policy : DEBUG : Mean Losses: [8.863474452868104]
2026-01-17 13:19:38,042 : worker.worker : DEBUG : Step 44772, finished rewards -35.32, envs finished 1
2026-01-17 13:19:38,101 : worker.worker : DEBUG : Step 44787, finished rewards -21.72, envs finished 1
2026-01-17 13:19:38,135 : worker.worker : DEBUG : Step 44794, finished rewards -23.69, envs finished 1
2026-01-17 13:19:38,230 : agent.on_policy : DEBUG : Mean Losses: [11.04530087672174]
2026-01-17 13:19:38,393 : agent.on_policy : DEBUG : Mean Losses: [2.3140585180372]
2026-01-17 13:19:38,454 : worker.worker : DEBUG : Step 44847, finished rewards -34.72, envs finished 2
2026-01-17 13:19:38,481 : worker.worker : DEBUG : Step 44854, finished rewards -13.74, envs finished 1
2026-01-17 13:19:38,584 : agent.on_policy : DEBUG : Mean Losses: [12.19172690063715]
2026-01-17 13:19:38,743 : agent.on_policy : DEBUG : Mean Losses: [1.6229809187352657]
2026-01-17 13:19:38,780 : worker.worker : DEBUG : Step 44905, finished rewards -33.89, envs finished 1
2026-01-17 13:19:38,820 : worker.worker : DEBUG : Step 44916, finished rewards -20.13, envs finished 1
2026-01-17 13:19:38,908 : agent.on_policy : DEBUG : Mean Losses: [9.178799539804459]
2026-01-17 13:19:38,920 : worker.worker : DEBUG : Step 44930, finished rewards -44.94, envs finished 1
2026-01-17 13:19:39,103 : worker.worker : DEBUG : Step 44956, finished rewards -36.19, envs finished 1
2026-01-17 13:19:39,232 : agent.on_policy : DEBUG : Mean Losses: [7.747097868472338]
2026-01-17 13:19:39,359 : worker.worker : DEBUG : Step 44991, finished rewards -46.86, envs finished 1
2026-01-17 13:19:39,439 : agent.on_policy : DEBUG : Mean Losses: [5.034245032817125]
2026-01-17 13:19:39,462 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.09944025698709223
2026-01-17 13:19:39,471 : worker.worker : INFO : Step 45000, Avg Reward -67.8144, Max Reward -9.9627, Loss [6.13924521]
2026-01-17 13:19:39,645 : agent.on_policy : DEBUG : Mean Losses: [4.412159522995353]
2026-01-17 13:19:39,650 : worker.worker : DEBUG : Step 45025, finished rewards -49.22, envs finished 1
2026-01-17 13:19:39,667 : worker.worker : DEBUG : Step 45028, finished rewards -42.83, envs finished 1
2026-01-17 13:19:39,758 : worker.worker : DEBUG : Step 45048, finished rewards -55.55, envs finished 1
2026-01-17 13:19:39,768 : worker.worker : DEBUG : Step 45050, finished rewards -26.49, envs finished 1
2026-01-17 13:19:39,860 : agent.on_policy : DEBUG : Mean Losses: [10.266114708036184]
2026-01-17 13:19:39,861 : worker.worker : DEBUG : Step 45056, finished rewards -17.69, envs finished 1
2026-01-17 13:19:40,042 : agent.on_policy : DEBUG : Mean Losses: [1.1522285230457783]
2026-01-17 13:19:40,046 : worker.worker : DEBUG : Step 45089, finished rewards -38.02, envs finished 1
2026-01-17 13:19:40,212 : agent.on_policy : DEBUG : Mean Losses: [2.3521342054009438]
2026-01-17 13:19:40,225 : worker.worker : DEBUG : Step 45123, finished rewards -40.41, envs finished 1
2026-01-17 13:19:40,315 : worker.worker : DEBUG : Step 45150, finished rewards -34.10, envs finished 1
2026-01-17 13:19:40,382 : agent.on_policy : DEBUG : Mean Losses: [7.245802469551563]
2026-01-17 13:19:40,551 : agent.on_policy : DEBUG : Mean Losses: [2.6238885018974543]
2026-01-17 13:19:40,555 : worker.worker : DEBUG : Step 45185, finished rewards -35.48, envs finished 1
2026-01-17 13:19:40,614 : worker.worker : DEBUG : Step 45201, finished rewards -40.81, envs finished 1
2026-01-17 13:19:40,621 : worker.worker : DEBUG : Step 45203, finished rewards -31.08, envs finished 1
2026-01-17 13:19:40,740 : agent.on_policy : DEBUG : Mean Losses: [9.589240046218038]
2026-01-17 13:19:40,762 : worker.worker : DEBUG : Step 45222, finished rewards -43.50, envs finished 1
2026-01-17 13:19:40,800 : worker.worker : DEBUG : Step 45232, finished rewards -48.54, envs finished 1
2026-01-17 13:19:40,898 : agent.on_policy : DEBUG : Mean Losses: [7.058395888656378]
2026-01-17 13:19:41,068 : agent.on_policy : DEBUG : Mean Losses: [1.6251800693571568]
2026-01-17 13:19:41,119 : worker.worker : DEBUG : Step 45295, finished rewards -63.95, envs finished 1
2026-01-17 13:19:41,125 : worker.worker : DEBUG : Step 45297, finished rewards -25.62, envs finished 1
2026-01-17 13:19:41,261 : agent.on_policy : DEBUG : Mean Losses: [8.69446849822998]
2026-01-17 13:19:41,308 : worker.worker : DEBUG : Step 45329, finished rewards -24.16, envs finished 1
2026-01-17 13:19:41,401 : agent.on_policy : DEBUG : Mean Losses: [7.198103159666061]
2026-01-17 13:19:41,421 : worker.worker : DEBUG : Step 45351, finished rewards -90.49, envs finished 1
2026-01-17 13:19:41,454 : worker.worker : DEBUG : Step 45359, finished rewards -33.69, envs finished 1
2026-01-17 13:19:41,492 : worker.worker : DEBUG : Step 45365, finished rewards -34.79, envs finished 1
2026-01-17 13:19:41,583 : agent.on_policy : DEBUG : Mean Losses: [10.383773021399975]
2026-01-17 13:19:41,584 : worker.worker : DEBUG : Step 45376, finished rewards -22.13, envs finished 1
2026-01-17 13:19:41,786 : agent.on_policy : DEBUG : Mean Losses: [1.873806893825531]
2026-01-17 13:19:41,811 : worker.worker : DEBUG : Step 45414, finished rewards -66.06, envs finished 1
2026-01-17 13:19:41,916 : worker.worker : DEBUG : Step 45436, finished rewards -19.87, envs finished 1
2026-01-17 13:19:42,018 : agent.on_policy : DEBUG : Mean Losses: [7.2313435189425945]
2026-01-17 13:19:42,259 : agent.on_policy : DEBUG : Mean Losses: [0.7226174138486385]
2026-01-17 13:19:42,273 : worker.worker : DEBUG : Step 45476, finished rewards -48.31, envs finished 1
2026-01-17 13:19:42,301 : worker.worker : DEBUG : Step 45484, finished rewards -31.30, envs finished 1
2026-01-17 13:19:42,412 : agent.on_policy : DEBUG : Mean Losses: [7.209795992821455]
2026-01-17 13:19:42,461 : worker.worker : DEBUG : Step 45514, finished rewards -25.10, envs finished 1
2026-01-17 13:19:42,486 : worker.worker : DEBUG : Step 45519, finished rewards -35.30, envs finished 1
2026-01-17 13:19:42,636 : agent.on_policy : DEBUG : Mean Losses: [7.60251004807651]
2026-01-17 13:19:42,660 : worker.worker : DEBUG : Step 45540, finished rewards -65.10, envs finished 1
2026-01-17 13:19:42,673 : worker.worker : DEBUG : Step 45542, finished rewards -45.21, envs finished 1
2026-01-17 13:19:42,740 : worker.worker : DEBUG : Step 45557, finished rewards -23.23, envs finished 1
2026-01-17 13:19:42,871 : agent.on_policy : DEBUG : Mean Losses: [9.07963715866208]
2026-01-17 13:19:43,036 : agent.on_policy : DEBUG : Mean Losses: [1.2135235331952572]
2026-01-17 13:19:43,174 : agent.on_policy : DEBUG : Mean Losses: [2.423375491052866]
2026-01-17 13:19:43,202 : worker.worker : DEBUG : Step 45635, finished rewards -34.83, envs finished 2
2026-01-17 13:19:43,274 : worker.worker : DEBUG : Step 45653, finished rewards -72.20, envs finished 1
2026-01-17 13:19:43,302 : worker.worker : DEBUG : Step 45660, finished rewards -23.40, envs finished 1
2026-01-17 13:19:43,383 : agent.on_policy : DEBUG : Mean Losses: [12.060043188743293]
2026-01-17 13:19:43,546 : agent.on_policy : DEBUG : Mean Losses: [2.7100420631468296]
2026-01-17 13:19:43,550 : worker.worker : DEBUG : Step 45697, finished rewards -48.91, envs finished 1
2026-01-17 13:19:43,623 : worker.worker : DEBUG : Step 45719, finished rewards -43.16, envs finished 1
2026-01-17 13:19:43,723 : agent.on_policy : DEBUG : Mean Losses: [4.924821230582893]
2026-01-17 13:19:43,858 : agent.on_policy : DEBUG : Mean Losses: [1.8593702055513859]
2026-01-17 13:19:43,905 : worker.worker : DEBUG : Step 45768, finished rewards -85.38, envs finished 1
2026-01-17 13:19:43,937 : worker.worker : DEBUG : Step 45773, finished rewards -76.57, envs finished 1
2026-01-17 13:19:44,220 : agent.on_policy : DEBUG : Mean Losses: [7.580267995595932]
2026-01-17 13:19:44,300 : worker.worker : DEBUG : Step 45811, finished rewards -46.95, envs finished 1
2026-01-17 13:19:44,430 : agent.on_policy : DEBUG : Mean Losses: [6.434426620602608]
2026-01-17 13:19:44,439 : worker.worker : DEBUG : Step 45825, finished rewards -42.90, envs finished 1
2026-01-17 13:19:44,482 : worker.worker : DEBUG : Step 45831, finished rewards -43.40, envs finished 1
2026-01-17 13:19:44,494 : worker.worker : DEBUG : Step 45833, finished rewards -63.98, envs finished 1
2026-01-17 13:19:44,581 : worker.worker : DEBUG : Step 45851, finished rewards -29.32, envs finished 1
2026-01-17 13:19:44,691 : agent.on_policy : DEBUG : Mean Losses: [11.755314454436302]
2026-01-17 13:19:44,907 : agent.on_policy : DEBUG : Mean Losses: [1.380143005400896]
2026-01-17 13:19:45,114 : agent.on_policy : DEBUG : Mean Losses: [2.374973613768816]
2026-01-17 13:19:45,220 : worker.worker : DEBUG : Step 45947, finished rewards -37.58, envs finished 1
2026-01-17 13:19:45,310 : agent.on_policy : DEBUG : Mean Losses: [5.638135716319084]
2026-01-17 13:19:45,349 : worker.worker : DEBUG : Step 45961, finished rewards -85.40, envs finished 1
2026-01-17 13:19:45,444 : worker.worker : DEBUG : Step 45979, finished rewards -29.00, envs finished 1
2026-01-17 13:19:45,544 : agent.on_policy : DEBUG : Mean Losses: [7.284297667443752]
2026-01-17 13:19:45,628 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.09446824413773762
2026-01-17 13:19:45,772 : agent.on_policy : DEBUG : Mean Losses: [3.2855446338653564]
2026-01-17 13:19:45,859 : worker.worker : DEBUG : Step 46041, finished rewards -58.54, envs finished 1
2026-01-17 13:19:45,876 : worker.worker : DEBUG : Step 46045, finished rewards -66.03, envs finished 1
2026-01-17 13:19:45,971 : agent.on_policy : DEBUG : Mean Losses: [10.406912252306938]
2026-01-17 13:19:46,023 : worker.worker : DEBUG : Step 46057, finished rewards -101.46, envs finished 1
2026-01-17 13:19:46,217 : agent.on_policy : DEBUG : Mean Losses: [5.298712104558945]
2026-01-17 13:19:46,304 : worker.worker : DEBUG : Step 46104, finished rewards -79.42, envs finished 2
2026-01-17 13:19:46,312 : worker.worker : DEBUG : Step 46106, finished rewards -25.43, envs finished 1
2026-01-17 13:19:46,334 : worker.worker : DEBUG : Step 46109, finished rewards -137.52, envs finished 1
2026-01-17 13:19:46,453 : agent.on_policy : DEBUG : Mean Losses: [18.7372934743762]
2026-01-17 13:19:46,654 : agent.on_policy : DEBUG : Mean Losses: [0.5577527154237032]
2026-01-17 13:19:46,682 : worker.worker : DEBUG : Step 46150, finished rewards -40.67, envs finished 1
2026-01-17 13:19:46,876 : agent.on_policy : DEBUG : Mean Losses: [3.1195607222616673]
2026-01-17 13:19:46,922 : worker.worker : DEBUG : Step 46188, finished rewards -16.41, envs finished 2
2026-01-17 13:19:47,058 : agent.on_policy : DEBUG : Mean Losses: [7.930584093555808]
2026-01-17 13:19:47,256 : agent.on_policy : DEBUG : Mean Losses: [1.3829940184950829]
2026-01-17 13:19:47,334 : worker.worker : DEBUG : Step 46255, finished rewards -28.58, envs finished 1
2026-01-17 13:19:47,348 : worker.worker : DEBUG : Step 46258, finished rewards -31.71, envs finished 1
2026-01-17 13:19:47,400 : worker.worker : DEBUG : Step 46269, finished rewards -39.82, envs finished 1
2026-01-17 13:19:47,481 : agent.on_policy : DEBUG : Mean Losses: [14.418084755539894]
2026-01-17 13:19:47,485 : worker.worker : DEBUG : Step 46272, finished rewards -35.66, envs finished 1
2026-01-17 13:19:47,691 : agent.on_policy : DEBUG : Mean Losses: [1.7229300802573562]
2026-01-17 13:19:47,714 : worker.worker : DEBUG : Step 46309, finished rewards 0.31, envs finished 1
2026-01-17 13:19:47,842 : worker.worker : DEBUG : Step 46335, finished rewards -54.10, envs finished 1
2026-01-17 13:19:47,925 : agent.on_policy : DEBUG : Mean Losses: [7.223903052508831]
2026-01-17 13:19:48,049 : worker.worker : DEBUG : Step 46364, finished rewards -51.74, envs finished 1
2026-01-17 13:19:48,149 : agent.on_policy : DEBUG : Mean Losses: [4.960020005702972]
2026-01-17 13:19:48,157 : worker.worker : DEBUG : Step 46370, finished rewards -59.09, envs finished 1
2026-01-17 13:19:48,348 : agent.on_policy : DEBUG : Mean Losses: [2.2645503021776676]
2026-01-17 13:19:48,428 : worker.worker : DEBUG : Step 46417, finished rewards -26.01, envs finished 1
2026-01-17 13:19:48,489 : worker.worker : DEBUG : Step 46425, finished rewards -46.25, envs finished 1
2026-01-17 13:19:48,652 : agent.on_policy : DEBUG : Mean Losses: [11.450915969908237]
2026-01-17 13:19:48,704 : worker.worker : DEBUG : Step 46440, finished rewards -39.76, envs finished 1
2026-01-17 13:19:48,740 : worker.worker : DEBUG : Step 46445, finished rewards -54.53, envs finished 1
2026-01-17 13:19:48,837 : worker.worker : DEBUG : Step 46457, finished rewards -20.53, envs finished 1
2026-01-17 13:19:49,057 : agent.on_policy : DEBUG : Mean Losses: [10.546966072171926]
2026-01-17 13:19:48,404 : worker.worker : DEBUG : Step 46486, finished rewards -28.69, envs finished 1
2026-01-17 13:19:48,410 : worker.worker : DEBUG : Step 46487, finished rewards -0.64, envs finished 1
2026-01-17 13:19:48,773 : agent.on_policy : DEBUG : Mean Losses: [9.332701670005918]
2026-01-17 13:19:49,001 : agent.on_policy : DEBUG : Mean Losses: [1.1266087591648102]
2026-01-17 13:19:49,108 : worker.worker : DEBUG : Step 46556, finished rewards -56.86, envs finished 1
2026-01-17 13:19:49,202 : agent.on_policy : DEBUG : Mean Losses: [4.915378909558058]
2026-01-17 13:19:49,312 : worker.worker : DEBUG : Step 46583, finished rewards -37.29, envs finished 1
2026-01-17 13:19:49,447 : agent.on_policy : DEBUG : Mean Losses: [5.213727317750454]
2026-01-17 13:19:49,513 : worker.worker : DEBUG : Step 46604, finished rewards -1.63, envs finished 1
2026-01-17 13:19:49,570 : worker.worker : DEBUG : Step 46616, finished rewards -42.23, envs finished 1
2026-01-17 13:19:49,577 : worker.worker : DEBUG : Step 46617, finished rewards -35.45, envs finished 1
2026-01-17 13:19:49,707 : agent.on_policy : DEBUG : Mean Losses: [13.31527929380536]
2026-01-17 13:19:49,717 : worker.worker : DEBUG : Step 46625, finished rewards -70.75, envs finished 1
2026-01-17 13:19:49,725 : worker.worker : DEBUG : Step 46626, finished rewards -51.27, envs finished 1
2026-01-17 13:19:49,971 : agent.on_policy : DEBUG : Mean Losses: [2.6255687531083822]
2026-01-17 13:19:50,252 : agent.on_policy : DEBUG : Mean Losses: [1.3488499484956264]
2026-01-17 13:19:50,340 : worker.worker : DEBUG : Step 46698, finished rewards -22.79, envs finished 1
2026-01-17 13:19:50,562 : agent.on_policy : DEBUG : Mean Losses: [4.9399891793727875]
2026-01-17 13:19:50,582 : worker.worker : DEBUG : Step 46724, finished rewards -99.77, envs finished 1
2026-01-17 13:19:50,709 : worker.worker : DEBUG : Step 46743, finished rewards -18.14, envs finished 1
2026-01-17 13:19:50,876 : agent.on_policy : DEBUG : Mean Losses: [8.000267878174782]
2026-01-17 13:19:50,897 : worker.worker : DEBUG : Step 46756, finished rewards -17.01, envs finished 1
2026-01-17 13:19:51,080 : worker.worker : DEBUG : Step 46783, finished rewards -40.83, envs finished 1
2026-01-17 13:19:51,137 : agent.on_policy : DEBUG : Mean Losses: [7.989729315042496]
2026-01-17 13:19:51,138 : worker.worker : DEBUG : Step 46784, finished rewards -41.88, envs finished 1
2026-01-17 13:19:51,198 : worker.worker : DEBUG : Step 46800, finished rewards -38.23, envs finished 1
2026-01-17 13:19:51,334 : agent.on_policy : DEBUG : Mean Losses: [4.879854649305344]
2026-01-17 13:19:51,470 : agent.on_policy : DEBUG : Mean Losses: [1.2145808413624763]
2026-01-17 13:19:51,542 : worker.worker : DEBUG : Step 46860, finished rewards -1.46, envs finished 1
2026-01-17 13:19:51,637 : worker.worker : DEBUG : Step 46877, finished rewards -30.42, envs finished 1
2026-01-17 13:19:51,711 : agent.on_policy : DEBUG : Mean Losses: [9.855489060282707]
2026-01-17 13:19:51,734 : worker.worker : DEBUG : Step 46887, finished rewards -48.80, envs finished 1
2026-01-17 13:19:51,852 : worker.worker : DEBUG : Step 46909, finished rewards -55.56, envs finished 1
2026-01-17 13:19:51,947 : agent.on_policy : DEBUG : Mean Losses: [5.596585653722286]
2026-01-17 13:19:52,156 : agent.on_policy : DEBUG : Mean Losses: [2.7386394441127777]
2026-01-17 13:19:52,165 : worker.worker : DEBUG : Step 46946, finished rewards -58.90, envs finished 1
2026-01-17 13:19:52,206 : worker.worker : DEBUG : Step 46955, finished rewards -36.79, envs finished 1
2026-01-17 13:19:52,347 : agent.on_policy : DEBUG : Mean Losses: [5.89062212407589]
2026-01-17 13:19:52,422 : worker.worker : DEBUG : Step 46991, finished rewards -11.24, envs finished 1
2026-01-17 13:19:52,461 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.08974483193085074
2026-01-17 13:19:52,514 : worker.worker : DEBUG : Step 47007, finished rewards -53.83, envs finished 1
2026-01-17 13:19:52,581 : agent.on_policy : DEBUG : Mean Losses: [10.163398258388042]
2026-01-17 13:19:52,741 : agent.on_policy : DEBUG : Mean Losses: [1.7442292049527168]
2026-01-17 13:19:52,765 : worker.worker : DEBUG : Step 47046, finished rewards -28.53, envs finished 1
2026-01-17 13:19:52,936 : worker.worker : DEBUG : Step 47068, finished rewards 12.27, envs finished 1
2026-01-17 13:19:53,023 : agent.on_policy : DEBUG : Mean Losses: [8.027032308280468]
2026-01-17 13:19:53,032 : worker.worker : DEBUG : Step 47074, finished rewards -35.45, envs finished 1
2026-01-17 13:19:53,206 : agent.on_policy : DEBUG : Mean Losses: [2.4610587246716022]
2026-01-17 13:19:53,332 : agent.on_policy : DEBUG : Mean Losses: [2.2430552393198013]
2026-01-17 13:19:53,395 : worker.worker : DEBUG : Step 47148, finished rewards -53.33, envs finished 1
2026-01-17 13:19:53,435 : worker.worker : DEBUG : Step 47159, finished rewards -64.60, envs finished 1
2026-01-17 13:19:53,530 : agent.on_policy : DEBUG : Mean Losses: [8.428825542330742]
2026-01-17 13:19:53,622 : worker.worker : DEBUG : Step 47192, finished rewards -46.03, envs finished 1
2026-01-17 13:19:53,630 : worker.worker : DEBUG : Step 47194, finished rewards -100.62, envs finished 1
2026-01-17 13:19:53,721 : agent.on_policy : DEBUG : Mean Losses: [10.139691539108753]
2026-01-17 13:19:53,770 : worker.worker : DEBUG : Step 47212, finished rewards -16.92, envs finished 1
2026-01-17 13:19:53,821 : worker.worker : DEBUG : Step 47223, finished rewards -28.50, envs finished 1
2026-01-17 13:19:53,905 : agent.on_policy : DEBUG : Mean Losses: [7.672198448330164]
2026-01-17 13:19:54,071 : agent.on_policy : DEBUG : Mean Losses: [1.0517852948978543]
2026-01-17 13:19:54,209 : agent.on_policy : DEBUG : Mean Losses: [1.8733925595879555]
2026-01-17 13:19:54,246 : worker.worker : DEBUG : Step 47303, finished rewards -26.61, envs finished 2
2026-01-17 13:19:54,264 : worker.worker : DEBUG : Step 47307, finished rewards -115.24, envs finished 1
2026-01-17 13:19:54,393 : agent.on_policy : DEBUG : Mean Losses: [8.92503446340561]
2026-01-17 13:19:54,551 : agent.on_policy : DEBUG : Mean Losses: [2.39061326533556]
2026-01-17 13:19:54,583 : worker.worker : DEBUG : Step 47368, finished rewards -25.17, envs finished 1
2026-01-17 13:19:54,632 : worker.worker : DEBUG : Step 47381, finished rewards -57.47, envs finished 1
2026-01-17 13:19:54,671 : worker.worker : DEBUG : Step 47389, finished rewards -65.20, envs finished 1
2026-01-17 13:19:54,752 : agent.on_policy : DEBUG : Mean Losses: [13.634052716195583]
2026-01-17 13:19:54,813 : worker.worker : DEBUG : Step 47408, finished rewards -55.29, envs finished 1
2026-01-17 13:19:54,937 : agent.on_policy : DEBUG : Mean Losses: [4.23485704138875]
2026-01-17 13:19:55,127 : agent.on_policy : DEBUG : Mean Losses: [1.1171124838292599]
2026-01-17 13:19:55,129 : worker.worker : DEBUG : Step 47456, finished rewards -27.96, envs finished 1
2026-01-17 13:19:55,136 : worker.worker : DEBUG : Step 47458, finished rewards -35.08, envs finished 1
2026-01-17 13:19:55,184 : worker.worker : DEBUG : Step 47470, finished rewards -42.20, envs finished 1
2026-01-17 13:19:55,295 : agent.on_policy : DEBUG : Mean Losses: [5.324180543422699]
2026-01-17 13:19:55,309 : worker.worker : DEBUG : Step 47492, finished rewards -114.81, envs finished 1
2026-01-17 13:19:55,402 : worker.worker : DEBUG : Step 47513, finished rewards -24.11, envs finished 1
2026-01-17 13:19:55,504 : agent.on_policy : DEBUG : Mean Losses: [5.709527220577002]
2026-01-17 13:19:55,564 : worker.worker : DEBUG : Step 47536, finished rewards -31.45, envs finished 1
2026-01-17 13:19:55,584 : worker.worker : DEBUG : Step 47540, finished rewards -27.13, envs finished 1
2026-01-17 13:19:55,694 : agent.on_policy : DEBUG : Mean Losses: [9.382775366306305]
2026-01-17 13:19:55,864 : agent.on_policy : DEBUG : Mean Losses: [1.0989507222548127]
2026-01-17 13:19:55,871 : worker.worker : DEBUG : Step 47586, finished rewards -11.49, envs finished 1
2026-01-17 13:19:55,888 : worker.worker : DEBUG : Step 47590, finished rewards -54.14, envs finished 1
2026-01-17 13:19:56,030 : agent.on_policy : DEBUG : Mean Losses: [4.573405783623457]
2026-01-17 13:19:56,116 : worker.worker : DEBUG : Step 47636, finished rewards -41.78, envs finished 1
2026-01-17 13:19:56,139 : worker.worker : DEBUG : Step 47641, finished rewards -24.92, envs finished 1
2026-01-17 13:19:56,236 : agent.on_policy : DEBUG : Mean Losses: [9.54867060482502]
2026-01-17 13:19:56,243 : worker.worker : DEBUG : Step 47649, finished rewards -54.39, envs finished 1
2026-01-17 13:19:56,359 : worker.worker : DEBUG : Step 47677, finished rewards -36.39, envs finished 1
2026-01-17 13:19:56,439 : agent.on_policy : DEBUG : Mean Losses: [5.254036020487547]
2026-01-17 13:19:56,477 : worker.worker : DEBUG : Step 47691, finished rewards -27.99, envs finished 1
2026-01-17 13:19:56,504 : worker.worker : DEBUG : Step 47696, finished rewards -34.48, envs finished 1
2026-01-17 13:19:56,632 : agent.on_policy : DEBUG : Mean Losses: [8.206953763961792]
2026-01-17 13:19:56,901 : agent.on_policy : DEBUG : Mean Losses: [1.2972410833463073]
2026-01-17 13:19:56,903 : worker.worker : DEBUG : Step 47744, finished rewards -35.89, envs finished 1
2026-01-17 13:19:57,002 : worker.worker : DEBUG : Step 47766, finished rewards -53.00, envs finished 1
2026-01-17 13:19:57,111 : agent.on_policy : DEBUG : Mean Losses: [5.587828628718853]
2026-01-17 13:19:57,149 : worker.worker : DEBUG : Step 47785, finished rewards -21.71, envs finished 1
2026-01-17 13:19:57,168 : worker.worker : DEBUG : Step 47788, finished rewards -16.90, envs finished 1
2026-01-17 13:19:57,278 : agent.on_policy : DEBUG : Mean Losses: [7.339211720973253]
2026-01-17 13:19:57,445 : agent.on_policy : DEBUG : Mean Losses: [1.9197503607720137]
2026-01-17 13:19:57,479 : worker.worker : DEBUG : Step 47851, finished rewards -37.81, envs finished 1
2026-01-17 13:19:57,489 : worker.worker : DEBUG : Step 47854, finished rewards -35.35, envs finished 1
2026-01-17 13:19:57,550 : worker.worker : DEBUG : Step 47870, finished rewards -42.40, envs finished 1
2026-01-17 13:19:57,607 : agent.on_policy : DEBUG : Mean Losses: [10.060329973697662]
2026-01-17 13:19:57,612 : worker.worker : DEBUG : Step 47873, finished rewards -52.36, envs finished 1
2026-01-17 13:19:57,788 : agent.on_policy : DEBUG : Mean Losses: [1.5376188829541206]
2026-01-17 13:19:57,831 : worker.worker : DEBUG : Step 47918, finished rewards -15.19, envs finished 1
2026-01-17 13:19:57,941 : agent.on_policy : DEBUG : Mean Losses: [5.531984139233828]
2026-01-17 13:19:57,996 : worker.worker : DEBUG : Step 47949, finished rewards -38.73, envs finished 1
2026-01-17 13:19:58,034 : worker.worker : DEBUG : Step 47957, finished rewards -51.64, envs finished 1
2026-01-17 13:19:58,157 : agent.on_policy : DEBUG : Mean Losses: [7.1187879256904125]
2026-01-17 13:19:58,172 : worker.worker : DEBUG : Step 47970, finished rewards -103.61, envs finished 1
2026-01-17 13:19:58,290 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.0852575903343082
2026-01-17 13:19:58,357 : agent.on_policy : DEBUG : Mean Losses: [2.262633889913559]
2026-01-17 13:19:58,416 : worker.worker : DEBUG : Step 48017, finished rewards -43.27, envs finished 1
2026-01-17 13:19:58,446 : worker.worker : DEBUG : Step 48021, finished rewards -25.96, envs finished 1
2026-01-17 13:19:58,468 : worker.worker : DEBUG : Step 48025, finished rewards -47.58, envs finished 1
2026-01-17 13:19:58,495 : worker.worker : DEBUG : Step 48031, finished rewards -32.92, envs finished 1
2026-01-17 13:19:58,564 : agent.on_policy : DEBUG : Mean Losses: [17.026095177978277]
2026-01-17 13:19:58,819 : agent.on_policy : DEBUG : Mean Losses: [1.5831847451627254]
2026-01-17 13:19:58,965 : worker.worker : DEBUG : Step 48084, finished rewards -43.05, envs finished 1
2026-01-17 13:19:59,066 : agent.on_policy : DEBUG : Mean Losses: [4.819124482572079]
2026-01-17 13:19:59,228 : worker.worker : DEBUG : Step 48123, finished rewards -29.17, envs finished 1
2026-01-17 13:19:59,292 : agent.on_policy : DEBUG : Mean Losses: [5.475332867354155]
2026-01-17 13:19:59,317 : worker.worker : DEBUG : Step 48134, finished rewards -49.88, envs finished 1
2026-01-17 13:19:59,471 : agent.on_policy : DEBUG : Mean Losses: [4.390973217785358]
2026-01-17 13:19:59,530 : worker.worker : DEBUG : Step 48178, finished rewards -35.71, envs finished 1
2026-01-17 13:19:59,554 : worker.worker : DEBUG : Step 48183, finished rewards -38.22, envs finished 1
2026-01-17 13:19:59,647 : agent.on_policy : DEBUG : Mean Losses: [9.109326358884573]
2026-01-17 13:19:59,706 : worker.worker : DEBUG : Step 48206, finished rewards -45.22, envs finished 1
2026-01-17 13:19:59,713 : worker.worker : DEBUG : Step 48207, finished rewards -48.85, envs finished 1
2026-01-17 13:19:59,842 : agent.on_policy : DEBUG : Mean Losses: [8.014074496924877]
2026-01-17 13:19:59,897 : worker.worker : DEBUG : Step 48239, finished rewards -36.36, envs finished 1
2026-01-17 13:20:00,016 : agent.on_policy : DEBUG : Mean Losses: [4.144386414438486]
2026-01-17 13:20:00,112 : worker.worker : DEBUG : Step 48282, finished rewards -53.48, envs finished 1
2026-01-17 13:20:00,224 : agent.on_policy : DEBUG : Mean Losses: [4.468033967539668]
2026-01-17 13:20:00,236 : worker.worker : DEBUG : Step 48290, finished rewards -30.75, envs finished 1
2026-01-17 13:20:00,445 : agent.on_policy : DEBUG : Mean Losses: [2.9305384568870068]
2026-01-17 13:20:00,489 : worker.worker : DEBUG : Step 48329, finished rewards -68.47, envs finished 1
2026-01-17 13:20:00,523 : worker.worker : DEBUG : Step 48335, finished rewards -28.13, envs finished 1
2026-01-17 13:20:00,685 : agent.on_policy : DEBUG : Mean Losses: [7.494099505245686]
2026-01-17 13:20:00,896 : agent.on_policy : DEBUG : Mean Losses: [4.6712675876915455]
2026-01-17 13:20:00,902 : worker.worker : DEBUG : Step 48385, finished rewards -58.42, envs finished 1
2026-01-17 13:20:00,919 : worker.worker : DEBUG : Step 48388, finished rewards -47.95, envs finished 1
2026-01-17 13:20:00,939 : worker.worker : DEBUG : Step 48392, finished rewards -31.34, envs finished 1
2026-01-17 13:20:00,951 : worker.worker : DEBUG : Step 48394, finished rewards -49.10, envs finished 1
2026-01-17 13:20:01,085 : agent.on_policy : DEBUG : Mean Losses: [7.9667537324130535]
2026-01-17 13:20:01,290 : agent.on_policy : DEBUG : Mean Losses: [2.0145919788628817]
2026-01-17 13:20:01,305 : worker.worker : DEBUG : Step 48452, finished rewards -45.56, envs finished 1
2026-01-17 13:20:01,357 : worker.worker : DEBUG : Step 48462, finished rewards -37.69, envs finished 1
2026-01-17 13:20:01,651 : agent.on_policy : DEBUG : Mean Losses: [5.936931688338518]
2026-01-17 13:20:01,665 : worker.worker : DEBUG : Step 48484, finished rewards -34.00, envs finished 1
2026-01-17 13:20:01,727 : worker.worker : DEBUG : Step 48500, finished rewards -41.60, envs finished 1
2026-01-17 13:20:01,859 : agent.on_policy : DEBUG : Mean Losses: [6.613072315230966]
2026-01-17 13:20:01,866 : worker.worker : DEBUG : Step 48513, finished rewards -0.81, envs finished 1
2026-01-17 13:20:01,970 : worker.worker : DEBUG : Step 48540, finished rewards -25.69, envs finished 1
2026-01-17 13:20:02,064 : agent.on_policy : DEBUG : Mean Losses: [5.965970422141254]
2026-01-17 13:20:02,101 : worker.worker : DEBUG : Step 48556, finished rewards -27.38, envs finished 1
2026-01-17 13:20:02,223 : agent.on_policy : DEBUG : Mean Losses: [4.040702350437641]
2026-01-17 13:20:02,282 : worker.worker : DEBUG : Step 48585, finished rewards -13.05, envs finished 1
2026-01-17 13:20:02,300 : worker.worker : DEBUG : Step 48587, finished rewards -63.02, envs finished 1
2026-01-17 13:20:02,478 : agent.on_policy : DEBUG : Mean Losses: [6.469742808490992]
2026-01-17 13:20:02,577 : worker.worker : DEBUG : Step 48633, finished rewards -42.39, envs finished 1
2026-01-17 13:20:02,670 : agent.on_policy : DEBUG : Mean Losses: [4.90637628454715]
2026-01-17 13:20:02,705 : worker.worker : DEBUG : Step 48652, finished rewards -31.22, envs finished 1
2026-01-17 13:20:02,826 : agent.on_policy : DEBUG : Mean Losses: [4.686307646334171]
2026-01-17 13:20:02,832 : worker.worker : DEBUG : Step 48673, finished rewards -34.37, envs finished 1
2026-01-17 13:20:02,903 : worker.worker : DEBUG : Step 48687, finished rewards -13.42, envs finished 1
2026-01-17 13:20:02,946 : worker.worker : DEBUG : Step 48699, finished rewards -34.99, envs finished 1
2026-01-17 13:20:03,031 : agent.on_policy : DEBUG : Mean Losses: [9.343501418828964]
2026-01-17 13:20:03,200 : agent.on_policy : DEBUG : Mean Losses: [1.7313184347003698]
2026-01-17 13:20:03,268 : worker.worker : DEBUG : Step 48755, finished rewards -108.47, envs finished 1
2026-01-17 13:20:03,276 : worker.worker : DEBUG : Step 48756, finished rewards -42.57, envs finished 1
2026-01-17 13:20:03,386 : agent.on_policy : DEBUG : Mean Losses: [8.564683869481087]
2026-01-17 13:20:03,553 : agent.on_policy : DEBUG : Mean Losses: [2.223256140947342]
2026-01-17 13:20:03,561 : worker.worker : DEBUG : Step 48802, finished rewards -80.85, envs finished 1
2026-01-17 13:20:03,571 : worker.worker : DEBUG : Step 48804, finished rewards -36.75, envs finished 1
2026-01-17 13:20:03,657 : worker.worker : DEBUG : Step 48827, finished rewards -30.79, envs finished 1
2026-01-17 13:20:03,736 : agent.on_policy : DEBUG : Mean Losses: [10.354416653513908]
2026-01-17 13:20:03,750 : worker.worker : DEBUG : Step 48834, finished rewards -53.72, envs finished 1
2026-01-17 13:20:03,941 : agent.on_policy : DEBUG : Mean Losses: [2.838129784911871]
2026-01-17 13:20:03,954 : worker.worker : DEBUG : Step 48868, finished rewards -38.58, envs finished 1
2026-01-17 13:20:04,023 : worker.worker : DEBUG : Step 48887, finished rewards -58.32, envs finished 1
2026-01-17 13:20:04,134 : agent.on_policy : DEBUG : Mean Losses: [6.131444048136473]
2026-01-17 13:20:04,168 : worker.worker : DEBUG : Step 48904, finished rewards -26.71, envs finished 1
2026-01-17 13:20:04,364 : agent.on_policy : DEBUG : Mean Losses: [4.021205436438322]
2026-01-17 13:20:04,403 : worker.worker : DEBUG : Step 48936, finished rewards -46.51, envs finished 1
2026-01-17 13:20:04,593 : agent.on_policy : DEBUG : Mean Losses: [3.9473532494157553]
2026-01-17 13:20:04,616 : worker.worker : DEBUG : Step 48965, finished rewards -33.92, envs finished 1
2026-01-17 13:20:04,648 : worker.worker : DEBUG : Step 48971, finished rewards -44.72, envs finished 1
2026-01-17 13:20:04,696 : worker.worker : DEBUG : Step 48979, finished rewards -26.02, envs finished 1
2026-01-17 13:20:04,788 : agent.on_policy : DEBUG : Mean Losses: [10.318683926016092]
2026-01-17 13:20:04,809 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.08099471081759278
2026-01-17 13:20:04,958 : agent.on_policy : DEBUG : Mean Losses: [2.171540640760213]
2026-01-17 13:20:05,001 : worker.worker : DEBUG : Step 49039, finished rewards -27.17, envs finished 1
2026-01-17 13:20:05,035 : worker.worker : DEBUG : Step 49047, finished rewards -24.03, envs finished 1
2026-01-17 13:20:05,111 : agent.on_policy : DEBUG : Mean Losses: [8.432933874428272]
2026-01-17 13:20:05,295 : agent.on_policy : DEBUG : Mean Losses: [2.066825434565544]
2026-01-17 13:20:05,301 : worker.worker : DEBUG : Step 49089, finished rewards -52.83, envs finished 1
2026-01-17 13:20:05,331 : worker.worker : DEBUG : Step 49095, finished rewards -33.23, envs finished 1
2026-01-17 13:20:05,361 : worker.worker : DEBUG : Step 49102, finished rewards -13.06, envs finished 1
2026-01-17 13:20:05,394 : worker.worker : DEBUG : Step 49109, finished rewards -100.38, envs finished 1
2026-01-17 13:20:05,407 : worker.worker : DEBUG : Step 49112, finished rewards -15.26, envs finished 1
2026-01-17 13:20:05,436 : worker.worker : DEBUG : Step 49118, finished rewards -25.15, envs finished 1
2026-01-17 13:20:05,489 : agent.on_policy : DEBUG : Mean Losses: [20.259824186563492]
2026-01-17 13:20:05,655 : agent.on_policy : DEBUG : Mean Losses: [0.4600351098924875]
2026-01-17 13:20:05,798 : agent.on_policy : DEBUG : Mean Losses: [1.1425438951700926]
2026-01-17 13:20:05,848 : worker.worker : DEBUG : Step 49194, finished rewards -28.49, envs finished 1
2026-01-17 13:20:05,958 : agent.on_policy : DEBUG : Mean Losses: [4.2432741820812225]
2026-01-17 13:20:05,998 : worker.worker : DEBUG : Step 49223, finished rewards -51.13, envs finished 1
2026-01-17 13:20:06,117 : worker.worker : DEBUG : Step 49246, finished rewards -20.49, envs finished 1
2026-01-17 13:20:06,200 : agent.on_policy : DEBUG : Mean Losses: [7.319045811891556]
2026-01-17 13:20:06,243 : worker.worker : DEBUG : Step 49259, finished rewards -38.61, envs finished 1
2026-01-17 13:20:06,251 : worker.worker : DEBUG : Step 49260, finished rewards -28.23, envs finished 1
2026-01-17 13:20:06,330 : worker.worker : DEBUG : Step 49266, finished rewards -49.20, envs finished 1
2026-01-17 13:20:06,516 : agent.on_policy : DEBUG : Mean Losses: [11.19646193832159]
2026-01-17 13:20:06,536 : worker.worker : DEBUG : Step 49285, finished rewards -41.33, envs finished 1
2026-01-17 13:20:06,587 : worker.worker : DEBUG : Step 49297, finished rewards -56.25, envs finished 1
2026-01-17 13:20:06,687 : agent.on_policy : DEBUG : Mean Losses: [7.7165192775428295]
2026-01-17 13:20:06,866 : agent.on_policy : DEBUG : Mean Losses: [1.4481423608958721]
2026-01-17 13:20:06,883 : worker.worker : DEBUG : Step 49349, finished rewards -29.99, envs finished 1
2026-01-17 13:20:07,061 : agent.on_policy : DEBUG : Mean Losses: [3.0376791208982468]
2026-01-17 13:20:07,160 : worker.worker : DEBUG : Step 49400, finished rewards -49.58, envs finished 1
2026-01-17 13:20:07,166 : worker.worker : DEBUG : Step 49401, finished rewards -20.06, envs finished 1
2026-01-17 13:20:07,228 : worker.worker : DEBUG : Step 49407, finished rewards -6.04, envs finished 1
2026-01-17 13:20:07,365 : agent.on_policy : DEBUG : Mean Losses: [13.804876908659935]
2026-01-17 13:20:07,403 : worker.worker : DEBUG : Step 49414, finished rewards -34.55, envs finished 1
2026-01-17 13:20:07,570 : agent.on_policy : DEBUG : Mean Losses: [4.248626025393605]
2026-01-17 13:20:07,635 : worker.worker : DEBUG : Step 49457, finished rewards -36.65, envs finished 1
2026-01-17 13:20:07,647 : worker.worker : DEBUG : Step 49460, finished rewards -58.11, envs finished 1
2026-01-17 13:20:07,682 : worker.worker : DEBUG : Step 49468, finished rewards -2.40, envs finished 1
2026-01-17 13:20:07,776 : agent.on_policy : DEBUG : Mean Losses: [13.918733935803175]
2026-01-17 13:20:07,807 : worker.worker : DEBUG : Step 49480, finished rewards -81.23, envs finished 1
2026-01-17 13:20:07,956 : agent.on_policy : DEBUG : Mean Losses: [3.0637347362935543]
2026-01-17 13:20:08,094 : agent.on_policy : DEBUG : Mean Losses: [0.998372245579958]
2026-01-17 13:20:08,206 : worker.worker : DEBUG : Step 49563, finished rewards -33.21, envs finished 1
2026-01-17 13:20:08,329 : agent.on_policy : DEBUG : Mean Losses: [6.1968500800430775]
2026-01-17 13:20:08,332 : worker.worker : DEBUG : Step 49568, finished rewards -38.63, envs finished 1
2026-01-17 13:20:08,403 : worker.worker : DEBUG : Step 49579, finished rewards -36.64, envs finished 1
2026-01-17 13:20:08,420 : worker.worker : DEBUG : Step 49582, finished rewards -40.16, envs finished 1
2026-01-17 13:20:08,559 : agent.on_policy : DEBUG : Mean Losses: [8.077358733862638]
2026-01-17 13:20:08,617 : worker.worker : DEBUG : Step 49617, finished rewards -33.59, envs finished 1
2026-01-17 13:20:08,734 : agent.on_policy : DEBUG : Mean Losses: [6.31017505005002]
2026-01-17 13:20:08,740 : worker.worker : DEBUG : Step 49633, finished rewards -30.61, envs finished 1
2026-01-17 13:20:08,780 : worker.worker : DEBUG : Step 49644, finished rewards -34.66, envs finished 1
2026-01-17 13:20:08,900 : agent.on_policy : DEBUG : Mean Losses: [4.07530153170228]
2026-01-17 13:20:09,212 : agent.on_policy : DEBUG : Mean Losses: [2.9988154768943787]
2026-01-17 13:20:09,256 : worker.worker : DEBUG : Step 49707, finished rewards -21.03, envs finished 1
2026-01-17 13:20:09,329 : worker.worker : DEBUG : Step 49726, finished rewards -32.90, envs finished 1
2026-01-17 13:20:09,383 : agent.on_policy : DEBUG : Mean Losses: [8.750722356140614]
2026-01-17 13:20:09,402 : worker.worker : DEBUG : Step 49731, finished rewards -26.64, envs finished 1
2026-01-17 13:20:09,517 : worker.worker : DEBUG : Step 49756, finished rewards -17.55, envs finished 1
2026-01-17 13:20:09,530 : worker.worker : DEBUG : Step 49759, finished rewards -49.02, envs finished 1
2026-01-17 13:20:09,606 : agent.on_policy : DEBUG : Mean Losses: [10.144659347832203]
2026-01-17 13:20:09,659 : worker.worker : DEBUG : Step 49776, finished rewards -12.32, envs finished 1
2026-01-17 13:20:09,787 : agent.on_policy : DEBUG : Mean Losses: [5.272563029080629]
2026-01-17 13:20:09,851 : worker.worker : DEBUG : Step 49806, finished rewards -41.66, envs finished 1
2026-01-17 13:20:09,974 : agent.on_policy : DEBUG : Mean Losses: [3.4163977932184935]
2026-01-17 13:20:10,104 : agent.on_policy : DEBUG : Mean Losses: [0.9620136544108391]
2026-01-17 13:20:10,207 : worker.worker : DEBUG : Step 49882, finished rewards -32.95, envs finished 1
2026-01-17 13:20:10,297 : agent.on_policy : DEBUG : Mean Losses: [5.8636424243450165]
2026-01-17 13:20:10,302 : worker.worker : DEBUG : Step 49889, finished rewards -61.81, envs finished 2
2026-01-17 13:20:10,482 : agent.on_policy : DEBUG : Mean Losses: [4.3468164363875985]
2026-01-17 13:20:10,532 : worker.worker : DEBUG : Step 49931, finished rewards -69.96, envs finished 1
2026-01-17 13:20:10,613 : worker.worker : DEBUG : Step 49949, finished rewards -20.98, envs finished 1
2026-01-17 13:20:10,705 : agent.on_policy : DEBUG : Mean Losses: [9.49503180757165]
2026-01-17 13:20:10,724 : worker.worker : DEBUG : Step 49958, finished rewards -115.92, envs finished 1
2026-01-17 13:20:10,729 : worker.worker : DEBUG : Step 49959, finished rewards -58.04, envs finished 1
2026-01-17 13:20:10,787 : worker.worker : DEBUG : Step 49970, finished rewards -50.20, envs finished 1
2026-01-17 13:20:10,898 : agent.on_policy : DEBUG : Mean Losses: [8.649267420172691]
2026-01-17 13:20:10,957 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.07694497527671314
2026-01-17 13:20:10,968 : worker.worker : INFO : Step 50000, Avg Reward -41.6649, Max Reward 12.2671, Loss [5.86154115]
2026-01-17 13:20:10,971 : network.model : INFO : Saved model to logs/Acrobot-Sarsa/model.pt
2026-01-17 13:20:14,825 : evaluate.evaluate : INFO : Evaluation results: mean = -500.00, std = 0.00, min = -500.00, max = -500.00, count = 1
2026-01-17 13:20:16,732 : agent.on_policy : DEBUG : Mean Losses: [0.8211970049887896]
2026-01-17 13:20:16,784 : worker.worker : DEBUG : Step 50033, finished rewards -21.94, envs finished 1
2026-01-17 13:20:16,814 : worker.worker : DEBUG : Step 50041, finished rewards -30.94, envs finished 1
2026-01-17 13:20:16,896 : agent.on_policy : DEBUG : Mean Losses: [10.154346970841289]
2026-01-17 13:20:16,938 : worker.worker : DEBUG : Step 50060, finished rewards -44.95, envs finished 1
2026-01-17 13:20:17,070 : agent.on_policy : DEBUG : Mean Losses: [4.4911207892000675]
2026-01-17 13:20:17,159 : worker.worker : DEBUG : Step 50100, finished rewards -31.35, envs finished 1
2026-01-17 13:20:17,325 : agent.on_policy : DEBUG : Mean Losses: [4.328365501016378]
2026-01-17 13:20:17,326 : worker.worker : DEBUG : Step 50112, finished rewards -28.16, envs finished 1
2026-01-17 13:20:17,406 : worker.worker : DEBUG : Step 50130, finished rewards -43.10, envs finished 1
2026-01-17 13:20:17,522 : agent.on_policy : DEBUG : Mean Losses: [5.31082952581346]
2026-01-17 13:20:17,641 : worker.worker : DEBUG : Step 50168, finished rewards -52.87, envs finished 1
2026-01-17 13:20:17,679 : worker.worker : DEBUG : Step 50174, finished rewards -85.96, envs finished 1
2026-01-17 13:20:17,758 : agent.on_policy : DEBUG : Mean Losses: [7.965442801825702]
2026-01-17 13:20:17,893 : worker.worker : DEBUG : Step 50207, finished rewards -41.66, envs finished 1
2026-01-17 13:20:17,990 : agent.on_policy : DEBUG : Mean Losses: [5.845069609582424]
2026-01-17 13:20:17,994 : worker.worker : DEBUG : Step 50209, finished rewards -23.83, envs finished 1
2026-01-17 13:20:18,115 : worker.worker : DEBUG : Step 50239, finished rewards -70.81, envs finished 1
2026-01-17 13:20:18,220 : agent.on_policy : DEBUG : Mean Losses: [4.960252734832466]
2026-01-17 13:20:18,292 : worker.worker : DEBUG : Step 50247, finished rewards -21.98, envs finished 1
2026-01-17 13:20:17,698 : agent.on_policy : DEBUG : Mean Losses: [3.4774637185037136]
2026-01-17 13:20:17,754 : worker.worker : DEBUG : Step 50292, finished rewards -44.19, envs finished 1
2026-01-17 13:20:17,852 : agent.on_policy : DEBUG : Mean Losses: [4.624588161706924]
2026-01-17 13:20:17,909 : worker.worker : DEBUG : Step 50320, finished rewards -23.58, envs finished 1
2026-01-17 13:20:17,955 : worker.worker : DEBUG : Step 50333, finished rewards -29.32, envs finished 1
2026-01-17 13:20:18,028 : agent.on_policy : DEBUG : Mean Losses: [7.423489592969418]
2026-01-17 13:20:18,057 : worker.worker : DEBUG : Step 50345, finished rewards -37.61, envs finished 2
2026-01-17 13:20:18,183 : agent.on_policy : DEBUG : Mean Losses: [7.3824405036866665]
2026-01-17 13:20:18,228 : worker.worker : DEBUG : Step 50378, finished rewards -43.67, envs finished 1
2026-01-17 13:20:18,292 : worker.worker : DEBUG : Step 50397, finished rewards -27.20, envs finished 1
2026-01-17 13:20:18,350 : agent.on_policy : DEBUG : Mean Losses: [7.13408659119159]
2026-01-17 13:20:18,552 : agent.on_policy : DEBUG : Mean Losses: [1.2338649686425924]
2026-01-17 13:20:18,734 : worker.worker : DEBUG : Step 50451, finished rewards -43.55, envs finished 1
2026-01-17 13:20:18,858 : agent.on_policy : DEBUG : Mean Losses: [4.315955109894276]
2026-01-17 13:20:18,915 : worker.worker : DEBUG : Step 50474, finished rewards -18.72, envs finished 1
2026-01-17 13:20:18,963 : worker.worker : DEBUG : Step 50486, finished rewards -39.11, envs finished 1
2026-01-17 13:20:18,978 : worker.worker : DEBUG : Step 50489, finished rewards -65.28, envs finished 1
2026-01-17 13:20:19,069 : agent.on_policy : DEBUG : Mean Losses: [11.2740318775177]
2026-01-17 13:20:19,121 : worker.worker : DEBUG : Step 50513, finished rewards -39.44, envs finished 1
2026-01-17 13:20:19,140 : worker.worker : DEBUG : Step 50516, finished rewards -43.71, envs finished 1
2026-01-17 13:20:19,238 : agent.on_policy : DEBUG : Mean Losses: [8.44531849399209]
2026-01-17 13:20:19,313 : worker.worker : DEBUG : Step 50553, finished rewards -32.92, envs finished 1
2026-01-17 13:20:19,398 : agent.on_policy : DEBUG : Mean Losses: [5.147905798628926]
2026-01-17 13:20:19,500 : worker.worker : DEBUG : Step 50589, finished rewards -71.52, envs finished 1
2026-01-17 13:20:19,580 : agent.on_policy : DEBUG : Mean Losses: [5.502952229231596]
2026-01-17 13:20:19,767 : agent.on_policy : DEBUG : Mean Losses: [2.893385972827673]
2026-01-17 13:20:19,791 : worker.worker : DEBUG : Step 50631, finished rewards -33.18, envs finished 1
2026-01-17 13:20:19,823 : worker.worker : DEBUG : Step 50638, finished rewards -51.88, envs finished 1
2026-01-17 13:20:19,880 : worker.worker : DEBUG : Step 50653, finished rewards -20.06, envs finished 1
2026-01-17 13:20:19,943 : agent.on_policy : DEBUG : Mean Losses: [13.67200668156147]
2026-01-17 13:20:20,031 : worker.worker : DEBUG : Step 50672, finished rewards -51.49, envs finished 1
2026-01-17 13:20:20,064 : worker.worker : DEBUG : Step 50681, finished rewards -58.40, envs finished 1
2026-01-17 13:20:20,156 : agent.on_policy : DEBUG : Mean Losses: [8.05310958251357]
2026-01-17 13:20:20,166 : worker.worker : DEBUG : Step 50691, finished rewards -33.77, envs finished 2
2026-01-17 13:20:20,334 : agent.on_policy : DEBUG : Mean Losses: [3.5095610842108727]
2026-01-17 13:20:20,427 : worker.worker : DEBUG : Step 50749, finished rewards -35.85, envs finished 1
2026-01-17 13:20:20,506 : agent.on_policy : DEBUG : Mean Losses: [4.669805131852627]
2026-01-17 13:20:20,690 : agent.on_policy : DEBUG : Mean Losses: [2.3750337958335876]
2026-01-17 13:20:20,694 : worker.worker : DEBUG : Step 50785, finished rewards -26.91, envs finished 1
2026-01-17 13:20:20,853 : agent.on_policy : DEBUG : Mean Losses: [2.482108011841774]
2026-01-17 13:20:20,901 : worker.worker : DEBUG : Step 50827, finished rewards -44.00, envs finished 1
2026-01-17 13:20:20,925 : worker.worker : DEBUG : Step 50832, finished rewards -35.68, envs finished 1
2026-01-17 13:20:20,957 : worker.worker : DEBUG : Step 50837, finished rewards -26.18, envs finished 1
2026-01-17 13:20:21,075 : agent.on_policy : DEBUG : Mean Losses: [12.835524499416351]
2026-01-17 13:20:21,097 : worker.worker : DEBUG : Step 50853, finished rewards -36.84, envs finished 1
2026-01-17 13:20:21,174 : worker.worker : DEBUG : Step 50874, finished rewards -59.86, envs finished 1
2026-01-17 13:20:21,290 : agent.on_policy : DEBUG : Mean Losses: [6.411036893725395]
2026-01-17 13:20:21,611 : agent.on_policy : DEBUG : Mean Losses: [1.4325061300769448]
2026-01-17 13:20:21,829 : agent.on_policy : DEBUG : Mean Losses: [2.2263250313699245]
2026-01-17 13:20:21,856 : worker.worker : DEBUG : Step 50949, finished rewards -59.89, envs finished 1
2026-01-17 13:20:21,902 : worker.worker : DEBUG : Step 50959, finished rewards -49.59, envs finished 1
2026-01-17 13:20:21,942 : worker.worker : DEBUG : Step 50969, finished rewards -0.59, envs finished 1
2026-01-17 13:20:22,042 : agent.on_policy : DEBUG : Mean Losses: [11.626051485538483]
2026-01-17 13:20:22,086 : worker.worker : DEBUG : Step 50985, finished rewards -29.39, envs finished 1
2026-01-17 13:20:22,164 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.07309772651287748
2026-01-17 13:20:22,204 : worker.worker : DEBUG : Step 51007, finished rewards -49.05, envs finished 1
2026-01-17 13:20:22,294 : agent.on_policy : DEBUG : Mean Losses: [7.291114030405879]
2026-01-17 13:20:22,468 : agent.on_policy : DEBUG : Mean Losses: [0.9988186061382294]
2026-01-17 13:20:22,495 : worker.worker : DEBUG : Step 51048, finished rewards -46.69, envs finished 1
2026-01-17 13:20:22,547 : worker.worker : DEBUG : Step 51064, finished rewards -97.95, envs finished 1
2026-01-17 13:20:22,624 : agent.on_policy : DEBUG : Mean Losses: [8.242852553725243]
2026-01-17 13:20:22,805 : agent.on_policy : DEBUG : Mean Losses: [1.1903634816408157]
2026-01-17 13:20:22,810 : worker.worker : DEBUG : Step 51105, finished rewards -22.99, envs finished 1
2026-01-17 13:20:22,858 : worker.worker : DEBUG : Step 51116, finished rewards -35.87, envs finished 1
2026-01-17 13:20:22,923 : worker.worker : DEBUG : Step 51130, finished rewards -23.16, envs finished 1
2026-01-17 13:20:23,018 : agent.on_policy : DEBUG : Mean Losses: [8.725906863808632]
2026-01-17 13:20:23,021 : worker.worker : DEBUG : Step 51136, finished rewards -28.26, envs finished 1
2026-01-17 13:20:23,100 : worker.worker : DEBUG : Step 51153, finished rewards -37.41, envs finished 1
2026-01-17 13:20:23,131 : worker.worker : DEBUG : Step 51160, finished rewards -32.43, envs finished 1
2026-01-17 13:20:23,245 : agent.on_policy : DEBUG : Mean Losses: [7.760490737855434]
2026-01-17 13:20:23,429 : agent.on_policy : DEBUG : Mean Losses: [1.0129164829850197]
2026-01-17 13:20:23,487 : worker.worker : DEBUG : Step 51218, finished rewards -37.30, envs finished 1
2026-01-17 13:20:23,498 : worker.worker : DEBUG : Step 51221, finished rewards -31.84, envs finished 1
2026-01-17 13:20:23,596 : agent.on_policy : DEBUG : Mean Losses: [8.64237264636904]
2026-01-17 13:20:23,666 : worker.worker : DEBUG : Step 51252, finished rewards -23.93, envs finished 1
2026-01-17 13:20:23,688 : worker.worker : DEBUG : Step 51257, finished rewards -4.35, envs finished 1
2026-01-17 13:20:23,793 : agent.on_policy : DEBUG : Mean Losses: [8.835460089147091]
2026-01-17 13:20:23,851 : worker.worker : DEBUG : Step 51277, finished rewards -38.13, envs finished 1
2026-01-17 13:20:23,869 : worker.worker : DEBUG : Step 51281, finished rewards -27.69, envs finished 1
2026-01-17 13:20:23,990 : agent.on_policy : DEBUG : Mean Losses: [7.807261560112238]
2026-01-17 13:20:24,125 : worker.worker : DEBUG : Step 51325, finished rewards -34.81, envs finished 1
2026-01-17 13:20:24,185 : agent.on_policy : DEBUG : Mean Losses: [4.456637930124998]
2026-01-17 13:20:24,238 : worker.worker : DEBUG : Step 51343, finished rewards -59.03, envs finished 1
2026-01-17 13:20:24,246 : worker.worker : DEBUG : Step 51345, finished rewards -7.75, envs finished 1
2026-01-17 13:20:24,375 : agent.on_policy : DEBUG : Mean Losses: [9.57887520082295]
2026-01-17 13:20:24,413 : worker.worker : DEBUG : Step 51368, finished rewards -27.01, envs finished 1
2026-01-17 13:20:24,488 : worker.worker : DEBUG : Step 51386, finished rewards -15.48, envs finished 1
2026-01-17 13:20:24,593 : agent.on_policy : DEBUG : Mean Losses: [7.183340843766928]
2026-01-17 13:20:24,618 : worker.worker : DEBUG : Step 51397, finished rewards -18.76, envs finished 1
2026-01-17 13:20:24,674 : worker.worker : DEBUG : Step 51412, finished rewards -13.88, envs finished 1
2026-01-17 13:20:24,792 : agent.on_policy : DEBUG : Mean Losses: [6.69095029681921]
2026-01-17 13:20:24,945 : agent.on_policy : DEBUG : Mean Losses: [1.6112793302163482]
2026-01-17 13:20:24,952 : worker.worker : DEBUG : Step 51457, finished rewards -39.14, envs finished 1
2026-01-17 13:20:25,144 : agent.on_policy : DEBUG : Mean Losses: [2.328189268708229]
2026-01-17 13:20:25,151 : worker.worker : DEBUG : Step 51490, finished rewards -23.03, envs finished 1
2026-01-17 13:20:25,226 : worker.worker : DEBUG : Step 51511, finished rewards -42.67, envs finished 1
2026-01-17 13:20:25,322 : agent.on_policy : DEBUG : Mean Losses: [6.278371050953865]
2026-01-17 13:20:25,342 : worker.worker : DEBUG : Step 51524, finished rewards -36.22, envs finished 1
2026-01-17 13:20:25,360 : worker.worker : DEBUG : Step 51527, finished rewards -33.07, envs finished 1
2026-01-17 13:20:25,418 : worker.worker : DEBUG : Step 51541, finished rewards -23.18, envs finished 1
2026-01-17 13:20:25,463 : worker.worker : DEBUG : Step 51548, finished rewards -31.54, envs finished 1
2026-01-17 13:20:25,569 : agent.on_policy : DEBUG : Mean Losses: [11.828034102916718]
2026-01-17 13:20:25,587 : worker.worker : DEBUG : Step 51557, finished rewards -24.08, envs finished 1
2026-01-17 13:20:25,744 : agent.on_policy : DEBUG : Mean Losses: [2.467493586242199]
2026-01-17 13:20:25,800 : worker.worker : DEBUG : Step 51600, finished rewards -24.05, envs finished 1
2026-01-17 13:20:26,000 : agent.on_policy : DEBUG : Mean Losses: [4.1378592271357775]
2026-01-17 13:20:26,145 : worker.worker : DEBUG : Step 51641, finished rewards -0.66, envs finished 1
2026-01-17 13:20:26,180 : worker.worker : DEBUG : Step 51645, finished rewards -29.61, envs finished 1
2026-01-17 13:20:26,257 : agent.on_policy : DEBUG : Mean Losses: [10.54783944785595]
2026-01-17 13:20:26,432 : agent.on_policy : DEBUG : Mean Losses: [1.9226963687688112]
2026-01-17 13:20:26,440 : worker.worker : DEBUG : Step 51682, finished rewards -35.33, envs finished 1
2026-01-17 13:20:26,475 : worker.worker : DEBUG : Step 51692, finished rewards -24.53, envs finished 1
2026-01-17 13:20:26,494 : worker.worker : DEBUG : Step 51697, finished rewards -44.86, envs finished 1
2026-01-17 13:20:26,607 : agent.on_policy : DEBUG : Mean Losses: [9.532402881421149]
2026-01-17 13:20:26,613 : worker.worker : DEBUG : Step 51713, finished rewards -43.01, envs finished 1
2026-01-17 13:20:26,795 : agent.on_policy : DEBUG : Mean Losses: [2.189937842078507]
2026-01-17 13:20:26,886 : worker.worker : DEBUG : Step 51775, finished rewards -24.84, envs finished 1
2026-01-17 13:20:26,948 : agent.on_policy : DEBUG : Mean Losses: [3.534877348691225]
2026-01-17 13:20:26,982 : worker.worker : DEBUG : Step 51782, finished rewards -19.39, envs finished 1
2026-01-17 13:20:27,082 : worker.worker : DEBUG : Step 51803, finished rewards -31.48, envs finished 1
2026-01-17 13:20:27,181 : agent.on_policy : DEBUG : Mean Losses: [8.311224311590195]
2026-01-17 13:20:27,221 : worker.worker : DEBUG : Step 51819, finished rewards -80.77, envs finished 1
2026-01-17 13:20:27,293 : worker.worker : DEBUG : Step 51835, finished rewards -16.56, envs finished 1
2026-01-17 13:20:27,360 : agent.on_policy : DEBUG : Mean Losses: [8.582763379439712]
2026-01-17 13:20:27,429 : worker.worker : DEBUG : Step 51858, finished rewards -46.19, envs finished 1
2026-01-17 13:20:27,530 : agent.on_policy : DEBUG : Mean Losses: [4.560505822300911]
2026-01-17 13:20:27,578 : worker.worker : DEBUG : Step 51883, finished rewards -41.85, envs finished 1
2026-01-17 13:20:27,616 : worker.worker : DEBUG : Step 51893, finished rewards -38.92, envs finished 1
2026-01-17 13:20:27,734 : agent.on_policy : DEBUG : Mean Losses: [6.1419606655836105]
2026-01-17 13:20:27,839 : worker.worker : DEBUG : Step 51925, finished rewards -26.52, envs finished 1
2026-01-17 13:20:27,870 : worker.worker : DEBUG : Step 51932, finished rewards -11.27, envs finished 1
2026-01-17 13:20:27,949 : agent.on_policy : DEBUG : Mean Losses: [10.94437312707305]
2026-01-17 13:20:28,052 : worker.worker : DEBUG : Step 51961, finished rewards -6.35, envs finished 1
2026-01-17 13:20:28,144 : agent.on_policy : DEBUG : Mean Losses: [5.364290967583656]
2026-01-17 13:20:28,181 : worker.worker : DEBUG : Step 51978, finished rewards -35.03, envs finished 1
2026-01-17 13:20:28,279 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.0694428401872336
2026-01-17 13:20:28,340 : agent.on_policy : DEBUG : Mean Losses: [3.9468801245093346]
2026-01-17 13:20:28,506 : agent.on_policy : DEBUG : Mean Losses: [2.2261983789503574]
2026-01-17 13:20:28,533 : worker.worker : DEBUG : Step 52040, finished rewards -39.98, envs finished 1
2026-01-17 13:20:28,581 : worker.worker : DEBUG : Step 52054, finished rewards -6.90, envs finished 1
2026-01-17 13:20:28,597 : worker.worker : DEBUG : Step 52058, finished rewards -60.27, envs finished 1
2026-01-17 13:20:28,663 : agent.on_policy : DEBUG : Mean Losses: [14.396417438983917]
2026-01-17 13:20:28,683 : worker.worker : DEBUG : Step 52068, finished rewards -130.06, envs finished 1
2026-01-17 13:20:28,727 : worker.worker : DEBUG : Step 52079, finished rewards -46.29, envs finished 1
2026-01-17 13:20:29,057 : agent.on_policy : DEBUG : Mean Losses: [5.299760643392801]
2026-01-17 13:20:29,140 : worker.worker : DEBUG : Step 52113, finished rewards -27.92, envs finished 1
2026-01-17 13:20:29,205 : worker.worker : DEBUG : Step 52126, finished rewards -26.96, envs finished 1
2026-01-17 13:20:29,351 : agent.on_policy : DEBUG : Mean Losses: [8.430269656702876]
2026-01-17 13:20:29,529 : agent.on_policy : DEBUG : Mean Losses: [1.5098213702440262]
2026-01-17 13:20:29,699 : agent.on_policy : DEBUG : Mean Losses: [2.9729629904031754]
2026-01-17 13:20:29,727 : worker.worker : DEBUG : Step 52200, finished rewards -35.26, envs finished 1
2026-01-17 13:20:29,829 : worker.worker : DEBUG : Step 52211, finished rewards -12.61, envs finished 1
2026-01-17 13:20:29,988 : agent.on_policy : DEBUG : Mean Losses: [9.047966554760933]
2026-01-17 13:20:30,001 : worker.worker : DEBUG : Step 52227, finished rewards -37.44, envs finished 1
2026-01-17 13:20:30,040 : worker.worker : DEBUG : Step 52233, finished rewards -45.18, envs finished 1
2026-01-17 13:20:30,160 : agent.on_policy : DEBUG : Mean Losses: [6.7533778846263885]
2026-01-17 13:20:30,192 : worker.worker : DEBUG : Step 52263, finished rewards -27.29, envs finished 1
2026-01-17 13:20:30,232 : worker.worker : DEBUG : Step 52269, finished rewards -187.34, envs finished 1
2026-01-17 13:20:30,345 : agent.on_policy : DEBUG : Mean Losses: [6.871721075847745]
2026-01-17 13:20:30,399 : worker.worker : DEBUG : Step 52299, finished rewards -35.11, envs finished 1
2026-01-17 13:20:30,550 : agent.on_policy : DEBUG : Mean Losses: [3.129684366285801]
2026-01-17 13:20:30,693 : agent.on_policy : DEBUG : Mean Losses: [1.4584660958498716]
2026-01-17 13:20:30,712 : worker.worker : DEBUG : Step 52355, finished rewards -30.78, envs finished 1
2026-01-17 13:20:30,803 : worker.worker : DEBUG : Step 52381, finished rewards -25.30, envs finished 1
2026-01-17 13:20:30,884 : agent.on_policy : DEBUG : Mean Losses: [7.306035354733467]
2026-01-17 13:20:30,900 : worker.worker : DEBUG : Step 52388, finished rewards -20.65, envs finished 1
2026-01-17 13:20:30,980 : worker.worker : DEBUG : Step 52405, finished rewards -59.37, envs finished 1
2026-01-17 13:20:31,089 : agent.on_policy : DEBUG : Mean Losses: [6.2072697058320045]
2026-01-17 13:20:31,142 : worker.worker : DEBUG : Step 52428, finished rewards -35.08, envs finished 1
2026-01-17 13:20:31,302 : agent.on_policy : DEBUG : Mean Losses: [4.299965512007475]
2026-01-17 13:20:31,336 : worker.worker : DEBUG : Step 52458, finished rewards -33.46, envs finished 1
2026-01-17 13:20:31,451 : agent.on_policy : DEBUG : Mean Losses: [5.2562636360526085]
2026-01-17 13:20:31,540 : worker.worker : DEBUG : Step 52501, finished rewards -84.53, envs finished 1
2026-01-17 13:20:31,673 : agent.on_policy : DEBUG : Mean Losses: [5.706444334238768]
2026-01-17 13:20:31,686 : worker.worker : DEBUG : Step 52514, finished rewards -34.11, envs finished 1
2026-01-17 13:20:31,752 : worker.worker : DEBUG : Step 52527, finished rewards -17.44, envs finished 1
2026-01-17 13:20:31,930 : agent.on_policy : DEBUG : Mean Losses: [5.794912099838257]
2026-01-17 13:20:31,938 : worker.worker : DEBUG : Step 52545, finished rewards -18.29, envs finished 1
2026-01-17 13:20:32,184 : agent.on_policy : DEBUG : Mean Losses: [1.921508975327015]
2026-01-17 13:20:32,201 : worker.worker : DEBUG : Step 52578, finished rewards -44.03, envs finished 2
2026-01-17 13:20:32,462 : agent.on_policy : DEBUG : Mean Losses: [3.53405624255538]
2026-01-17 13:20:32,699 : agent.on_policy : DEBUG : Mean Losses: [1.6888046003878117]
2026-01-17 13:20:32,712 : worker.worker : DEBUG : Step 52643, finished rewards -27.63, envs finished 1
2026-01-17 13:20:32,801 : worker.worker : DEBUG : Step 52662, finished rewards -22.59, envs finished 1
2026-01-17 13:20:32,812 : worker.worker : DEBUG : Step 52664, finished rewards -27.92, envs finished 1
2026-01-17 13:20:32,922 : agent.on_policy : DEBUG : Mean Losses: [9.617806285619736]
2026-01-17 13:20:32,956 : worker.worker : DEBUG : Step 52681, finished rewards -8.63, envs finished 1
2026-01-17 13:20:32,976 : worker.worker : DEBUG : Step 52684, finished rewards -33.37, envs finished 1
2026-01-17 13:20:33,087 : agent.on_policy : DEBUG : Mean Losses: [6.098603727295995]
2026-01-17 13:20:33,103 : worker.worker : DEBUG : Step 52708, finished rewards -32.42, envs finished 1
2026-01-17 13:20:33,272 : agent.on_policy : DEBUG : Mean Losses: [2.856198253110051]
2026-01-17 13:20:33,373 : worker.worker : DEBUG : Step 52764, finished rewards -58.58, envs finished 1
2026-01-17 13:20:33,454 : agent.on_policy : DEBUG : Mean Losses: [5.281049683690071]
2026-01-17 13:20:33,455 : worker.worker : DEBUG : Step 52768, finished rewards -58.88, envs finished 1
2026-01-17 13:20:33,720 : agent.on_policy : DEBUG : Mean Losses: [2.156377326697111]
2026-01-17 13:20:33,722 : worker.worker : DEBUG : Step 52800, finished rewards -26.09, envs finished 1
2026-01-17 13:20:33,756 : worker.worker : DEBUG : Step 52810, finished rewards -25.32, envs finished 1
2026-01-17 13:20:33,763 : worker.worker : DEBUG : Step 52811, finished rewards -10.83, envs finished 1
2026-01-17 13:20:33,877 : agent.on_policy : DEBUG : Mean Losses: [8.261382214725018]
2026-01-17 13:20:33,990 : worker.worker : DEBUG : Step 52861, finished rewards -28.56, envs finished 1
2026-01-17 13:20:34,070 : agent.on_policy : DEBUG : Mean Losses: [5.477944187819958]
2026-01-17 13:20:34,107 : worker.worker : DEBUG : Step 52877, finished rewards -74.79, envs finished 1
2026-01-17 13:20:34,127 : worker.worker : DEBUG : Step 52882, finished rewards -1.51, envs finished 1
2026-01-17 13:20:34,241 : agent.on_policy : DEBUG : Mean Losses: [7.9046032736077905]
2026-01-17 13:20:34,321 : worker.worker : DEBUG : Step 52913, finished rewards -87.22, envs finished 1
2026-01-17 13:20:34,445 : agent.on_policy : DEBUG : Mean Losses: [5.511147126555443]
2026-01-17 13:20:34,543 : worker.worker : DEBUG : Step 52952, finished rewards -23.50, envs finished 1
2026-01-17 13:20:34,552 : worker.worker : DEBUG : Step 52954, finished rewards -21.89, envs finished 1
2026-01-17 13:20:34,646 : agent.on_policy : DEBUG : Mean Losses: [10.224351808428764]
2026-01-17 13:20:34,817 : agent.on_policy : DEBUG : Mean Losses: [2.7508437000215054]
2026-01-17 13:20:34,836 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.0659706981778719
2026-01-17 13:20:34,850 : worker.worker : DEBUG : Step 53003, finished rewards -48.72, envs finished 1
2026-01-17 13:20:34,882 : worker.worker : DEBUG : Step 53011, finished rewards -24.17, envs finished 1
2026-01-17 13:20:34,914 : worker.worker : DEBUG : Step 53019, finished rewards -32.39, envs finished 1
2026-01-17 13:20:34,986 : agent.on_policy : DEBUG : Mean Losses: [11.22072520852089]
2026-01-17 13:20:34,998 : worker.worker : DEBUG : Step 53025, finished rewards -24.38, envs finished 1
2026-01-17 13:20:35,188 : agent.on_policy : DEBUG : Mean Losses: [2.659992733038962]
2026-01-17 13:20:35,195 : worker.worker : DEBUG : Step 53058, finished rewards -42.76, envs finished 1
2026-01-17 13:20:35,256 : worker.worker : DEBUG : Step 53071, finished rewards -29.35, envs finished 1
2026-01-17 13:20:35,387 : agent.on_policy : DEBUG : Mean Losses: [4.076674055308104]
2026-01-17 13:20:35,550 : agent.on_policy : DEBUG : Mean Losses: [1.4433788042515516]
2026-01-17 13:20:35,552 : worker.worker : DEBUG : Step 53120, finished rewards -46.27, envs finished 1
2026-01-17 13:20:35,597 : worker.worker : DEBUG : Step 53130, finished rewards -50.43, envs finished 1
2026-01-17 13:20:35,658 : worker.worker : DEBUG : Step 53145, finished rewards -14.08, envs finished 1
2026-01-17 13:20:35,751 : agent.on_policy : DEBUG : Mean Losses: [8.242316697724164]
2026-01-17 13:20:35,796 : worker.worker : DEBUG : Step 53165, finished rewards -32.85, envs finished 1
2026-01-17 13:20:35,845 : worker.worker : DEBUG : Step 53179, finished rewards -34.46, envs finished 1
2026-01-17 13:20:35,900 : agent.on_policy : DEBUG : Mean Losses: [7.419042836874723]
2026-01-17 13:20:35,988 : worker.worker : DEBUG : Step 53212, finished rewards -54.28, envs finished 1
2026-01-17 13:20:36,060 : agent.on_policy : DEBUG : Mean Losses: [4.74598627910018]
2026-01-17 13:20:36,219 : agent.on_policy : DEBUG : Mean Losses: [2.2289040498435497]
2026-01-17 13:20:36,313 : worker.worker : DEBUG : Step 53277, finished rewards -73.45, envs finished 1
2026-01-17 13:20:36,396 : agent.on_policy : DEBUG : Mean Losses: [6.535015741363168]
2026-01-17 13:20:36,420 : worker.worker : DEBUG : Step 53284, finished rewards -35.26, envs finished 1
2026-01-17 13:20:36,473 : worker.worker : DEBUG : Step 53294, finished rewards -38.99, envs finished 1
2026-01-17 13:20:36,537 : worker.worker : DEBUG : Step 53309, finished rewards -38.12, envs finished 1
2026-01-17 13:20:36,623 : agent.on_policy : DEBUG : Mean Losses: [9.561770424246788]
2026-01-17 13:20:36,801 : agent.on_policy : DEBUG : Mean Losses: [2.1044853813946247]
2026-01-17 13:20:36,806 : worker.worker : DEBUG : Step 53345, finished rewards -52.65, envs finished 1
2026-01-17 13:20:36,972 : agent.on_policy : DEBUG : Mean Losses: [2.031158545985818]
2026-01-17 13:20:36,983 : worker.worker : DEBUG : Step 53378, finished rewards -40.52, envs finished 1
2026-01-17 13:20:37,059 : worker.worker : DEBUG : Step 53401, finished rewards -133.38, envs finished 1
2026-01-17 13:20:37,154 : agent.on_policy : DEBUG : Mean Losses: [6.193760395050049]
2026-01-17 13:20:37,179 : worker.worker : DEBUG : Step 53414, finished rewards -26.48, envs finished 1
2026-01-17 13:20:37,289 : worker.worker : DEBUG : Step 53433, finished rewards -21.55, envs finished 1
2026-01-17 13:20:37,399 : agent.on_policy : DEBUG : Mean Losses: [7.855914197862148]
2026-01-17 13:20:37,410 : worker.worker : DEBUG : Step 53442, finished rewards -38.02, envs finished 1
2026-01-17 13:20:37,529 : worker.worker : DEBUG : Step 53455, finished rewards -46.32, envs finished 1
2026-01-17 13:20:37,611 : worker.worker : DEBUG : Step 53466, finished rewards -29.47, envs finished 1
2026-01-17 13:20:37,715 : agent.on_policy : DEBUG : Mean Losses: [9.072643518447876]
2026-01-17 13:20:37,839 : worker.worker : DEBUG : Step 53501, finished rewards -31.28, envs finished 1
2026-01-17 13:20:37,915 : agent.on_policy : DEBUG : Mean Losses: [4.3439615946263075]
2026-01-17 13:20:38,084 : agent.on_policy : DEBUG : Mean Losses: [1.688112262636423]
2026-01-17 13:20:38,152 : worker.worker : DEBUG : Step 53557, finished rewards -41.60, envs finished 1
2026-01-17 13:20:38,166 : worker.worker : DEBUG : Step 53560, finished rewards -1.50, envs finished 1
2026-01-17 13:20:38,271 : agent.on_policy : DEBUG : Mean Losses: [9.038253866136074]
2026-01-17 13:20:38,306 : worker.worker : DEBUG : Step 53578, finished rewards -41.70, envs finished 1
2026-01-17 13:20:38,334 : worker.worker : DEBUG : Step 53583, finished rewards -50.99, envs finished 1
2026-01-17 13:20:38,401 : worker.worker : DEBUG : Step 53597, finished rewards -19.66, envs finished 1
2026-01-17 13:20:38,471 : agent.on_policy : DEBUG : Mean Losses: [12.141715086996555]
2026-01-17 13:20:38,503 : worker.worker : DEBUG : Step 53605, finished rewards -43.59, envs finished 1
2026-01-17 13:20:38,630 : agent.on_policy : DEBUG : Mean Losses: [3.791590429842472]
2026-01-17 13:20:38,659 : worker.worker : DEBUG : Step 53636, finished rewards -41.05, envs finished 1
2026-01-17 13:20:38,734 : worker.worker : DEBUG : Step 53656, finished rewards -23.24, envs finished 1
2026-01-17 13:20:38,840 : agent.on_policy : DEBUG : Mean Losses: [4.728512790054083]
2026-01-17 13:20:39,004 : agent.on_policy : DEBUG : Mean Losses: [1.478907499462366]
2026-01-17 13:20:39,033 : worker.worker : DEBUG : Step 53702, finished rewards -21.46, envs finished 1
2026-01-17 13:20:39,324 : agent.on_policy : DEBUG : Mean Losses: [4.487269081175327]
2026-01-17 13:20:39,327 : worker.worker : DEBUG : Step 53728, finished rewards -36.82, envs finished 1
2026-01-17 13:20:39,384 : worker.worker : DEBUG : Step 53744, finished rewards -22.19, envs finished 1
2026-01-17 13:20:39,419 : worker.worker : DEBUG : Step 53754, finished rewards -35.74, envs finished 1
2026-01-17 13:20:39,556 : agent.on_policy : DEBUG : Mean Losses: [9.29880042374134]
2026-01-17 13:20:39,585 : worker.worker : DEBUG : Step 53765, finished rewards -32.52, envs finished 1
2026-01-17 13:20:39,735 : agent.on_policy : DEBUG : Mean Losses: [4.058948390185833]
2026-01-17 13:20:39,772 : worker.worker : DEBUG : Step 53799, finished rewards -81.85, envs finished 1
2026-01-17 13:20:39,823 : worker.worker : DEBUG : Step 53813, finished rewards -35.71, envs finished 1
2026-01-17 13:20:39,861 : worker.worker : DEBUG : Step 53823, finished rewards -43.73, envs finished 1
2026-01-17 13:20:39,936 : agent.on_policy : DEBUG : Mean Losses: [8.286172017455101]
2026-01-17 13:20:40,118 : agent.on_policy : DEBUG : Mean Losses: [1.0512869786471128]
2026-01-17 13:20:40,180 : worker.worker : DEBUG : Step 53874, finished rewards -2.46, envs finished 1
2026-01-17 13:20:40,300 : agent.on_policy : DEBUG : Mean Losses: [6.439363334327936]
2026-01-17 13:20:40,302 : worker.worker : DEBUG : Step 53888, finished rewards -57.30, envs finished 1
2026-01-17 13:20:40,363 : worker.worker : DEBUG : Step 53906, finished rewards -35.19, envs finished 1
2026-01-17 13:20:40,487 : agent.on_policy : DEBUG : Mean Losses: [5.905777541920543]
2026-01-17 13:20:40,504 : worker.worker : DEBUG : Step 53924, finished rewards -34.38, envs finished 1
2026-01-17 13:20:40,658 : agent.on_policy : DEBUG : Mean Losses: [3.402773343026638]
2026-01-17 13:20:40,683 : worker.worker : DEBUG : Step 53957, finished rewards -34.73, envs finished 1
2026-01-17 13:20:40,714 : worker.worker : DEBUG : Step 53965, finished rewards -29.12, envs finished 1
2026-01-17 13:20:40,832 : agent.on_policy : DEBUG : Mean Losses: [5.82595444843173]
2026-01-17 13:20:40,842 : worker.worker : DEBUG : Step 53986, finished rewards -119.74, envs finished 1
2026-01-17 13:20:40,903 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.0626721632689783
2026-01-17 13:20:41,036 : agent.on_policy : DEBUG : Mean Losses: [2.276060327887535]
2026-01-17 13:20:41,115 : worker.worker : DEBUG : Step 54039, finished rewards -39.21, envs finished 1
2026-01-17 13:20:41,135 : worker.worker : DEBUG : Step 54045, finished rewards -32.31, envs finished 1
2026-01-17 13:20:41,219 : agent.on_policy : DEBUG : Mean Losses: [8.278356539085507]
2026-01-17 13:20:41,325 : worker.worker : DEBUG : Step 54075, finished rewards -31.08, envs finished 1
2026-01-17 13:20:41,411 : agent.on_policy : DEBUG : Mean Losses: [6.122211555019021]
2026-01-17 13:20:41,526 : worker.worker : DEBUG : Step 54108, finished rewards -20.02, envs finished 1
2026-01-17 13:20:41,532 : worker.worker : DEBUG : Step 54109, finished rewards -68.89, envs finished 1
2026-01-17 13:20:41,613 : agent.on_policy : DEBUG : Mean Losses: [9.806991796940565]
2026-01-17 13:20:41,736 : worker.worker : DEBUG : Step 54143, finished rewards -49.74, envs finished 1
2026-01-17 13:20:41,851 : agent.on_policy : DEBUG : Mean Losses: [4.008920742198825]
2026-01-17 13:20:41,875 : worker.worker : DEBUG : Step 54148, finished rewards -21.74, envs finished 1
2026-01-17 13:20:42,043 : worker.worker : DEBUG : Step 54174, finished rewards -47.86, envs finished 1
2026-01-17 13:20:42,224 : agent.on_policy : DEBUG : Mean Losses: [5.4040536899119616]
2026-01-17 13:20:42,458 : agent.on_policy : DEBUG : Mean Losses: [2.018402148038149]
2026-01-17 13:20:42,479 : worker.worker : DEBUG : Step 54214, finished rewards -39.45, envs finished 1
2026-01-17 13:20:42,511 : worker.worker : DEBUG : Step 54220, finished rewards -52.11, envs finished 1
2026-01-17 13:20:42,588 : worker.worker : DEBUG : Step 54237, finished rewards -39.04, envs finished 1
2026-01-17 13:20:42,679 : agent.on_policy : DEBUG : Mean Losses: [9.107611127197742]
2026-01-17 13:20:42,795 : worker.worker : DEBUG : Step 54261, finished rewards -27.94, envs finished 1
2026-01-17 13:20:42,808 : worker.worker : DEBUG : Step 54262, finished rewards -28.66, envs finished 1
2026-01-17 13:20:42,955 : agent.on_policy : DEBUG : Mean Losses: [9.06109599582851]
2026-01-17 13:20:43,068 : worker.worker : DEBUG : Step 54303, finished rewards -10.91, envs finished 1
2026-01-17 13:20:43,141 : agent.on_policy : DEBUG : Mean Losses: [4.910591892898083]
2026-01-17 13:20:43,179 : worker.worker : DEBUG : Step 54314, finished rewards -33.15, envs finished 1
2026-01-17 13:20:43,280 : worker.worker : DEBUG : Step 54334, finished rewards -40.22, envs finished 1
2026-01-17 13:20:43,360 : agent.on_policy : DEBUG : Mean Losses: [5.463239278644323]
2026-01-17 13:20:43,544 : agent.on_policy : DEBUG : Mean Losses: [2.4713874459266663]
2026-01-17 13:20:43,546 : worker.worker : DEBUG : Step 54368, finished rewards -29.57, envs finished 1
2026-01-17 13:20:43,626 : worker.worker : DEBUG : Step 54389, finished rewards -41.43, envs finished 1
2026-01-17 13:20:43,739 : agent.on_policy : DEBUG : Mean Losses: [5.669335181824863]
2026-01-17 13:20:43,808 : worker.worker : DEBUG : Step 54412, finished rewards -42.91, envs finished 1
2026-01-17 13:20:43,827 : worker.worker : DEBUG : Step 54414, finished rewards -30.14, envs finished 1
2026-01-17 13:20:43,848 : worker.worker : DEBUG : Step 54418, finished rewards -31.53, envs finished 1
2026-01-17 13:20:44,003 : agent.on_policy : DEBUG : Mean Losses: [11.065179243683815]
2026-01-17 13:20:44,099 : worker.worker : DEBUG : Step 54448, finished rewards -24.96, envs finished 1
2026-01-17 13:20:44,265 : agent.on_policy : DEBUG : Mean Losses: [4.657430339604616]
2026-01-17 13:20:44,304 : worker.worker : DEBUG : Step 54474, finished rewards -33.50, envs finished 1
2026-01-17 13:20:44,310 : worker.worker : DEBUG : Step 54475, finished rewards -19.56, envs finished 1
2026-01-17 13:20:44,500 : agent.on_policy : DEBUG : Mean Losses: [5.97457829862833]
2026-01-17 13:20:44,566 : worker.worker : DEBUG : Step 54511, finished rewards -19.19, envs finished 1
2026-01-17 13:20:44,745 : agent.on_policy : DEBUG : Mean Losses: [4.110342677682638]
2026-01-17 13:20:44,829 : worker.worker : DEBUG : Step 54550, finished rewards -34.72, envs finished 1
2026-01-17 13:20:44,841 : worker.worker : DEBUG : Step 54553, finished rewards -21.35, envs finished 1
2026-01-17 13:20:44,959 : agent.on_policy : DEBUG : Mean Losses: [8.792693922296166]
2026-01-17 13:20:44,999 : worker.worker : DEBUG : Step 54564, finished rewards -1.06, envs finished 1
2026-01-17 13:20:45,200 : agent.on_policy : DEBUG : Mean Losses: [3.155765116214752]
2026-01-17 13:20:45,435 : agent.on_policy : DEBUG : Mean Losses: [2.592104334384203]
2026-01-17 13:20:45,492 : worker.worker : DEBUG : Step 54638, finished rewards -35.69, envs finished 1
2026-01-17 13:20:45,500 : worker.worker : DEBUG : Step 54639, finished rewards -64.00, envs finished 1
2026-01-17 13:20:45,559 : worker.worker : DEBUG : Step 54652, finished rewards -41.45, envs finished 2
2026-01-17 13:20:45,664 : agent.on_policy : DEBUG : Mean Losses: [12.703537330031395]
2026-01-17 13:20:45,757 : worker.worker : DEBUG : Step 54676, finished rewards -28.58, envs finished 1
2026-01-17 13:20:45,877 : agent.on_policy : DEBUG : Mean Losses: [4.601467397063971]
2026-01-17 13:20:46,017 : worker.worker : DEBUG : Step 54714, finished rewards -27.38, envs finished 1
2026-01-17 13:20:46,104 : agent.on_policy : DEBUG : Mean Losses: [4.777800505980849]
2026-01-17 13:20:46,131 : worker.worker : DEBUG : Step 54726, finished rewards -48.82, envs finished 1
2026-01-17 13:20:46,412 : agent.on_policy : DEBUG : Mean Losses: [3.1600939445197582]
2026-01-17 13:20:46,430 : worker.worker : DEBUG : Step 54755, finished rewards -70.97, envs finished 1
2026-01-17 13:20:46,550 : worker.worker : DEBUG : Step 54781, finished rewards -9.99, envs finished 1
2026-01-17 13:20:46,671 : agent.on_policy : DEBUG : Mean Losses: [8.076065212488174]
2026-01-17 13:20:46,691 : worker.worker : DEBUG : Step 54787, finished rewards -15.39, envs finished 1
2026-01-17 13:20:46,740 : worker.worker : DEBUG : Step 54792, finished rewards -29.09, envs finished 1
2026-01-17 13:20:46,755 : worker.worker : DEBUG : Step 54794, finished rewards -31.52, envs finished 1
2026-01-17 13:20:46,925 : agent.on_policy : DEBUG : Mean Losses: [6.938991256058216]
2026-01-17 13:20:47,133 : agent.on_policy : DEBUG : Mean Losses: [1.171710403636098]
2026-01-17 13:20:47,248 : worker.worker : DEBUG : Step 54877, finished rewards -62.76, envs finished 1
2026-01-17 13:20:47,354 : agent.on_policy : DEBUG : Mean Losses: [4.959509149193764]
2026-01-17 13:20:47,466 : worker.worker : DEBUG : Step 54904, finished rewards -51.95, envs finished 1
2026-01-17 13:20:46,799 : agent.on_policy : DEBUG : Mean Losses: [6.696278776973486]
2026-01-17 13:20:46,824 : worker.worker : DEBUG : Step 54916, finished rewards -38.05, envs finished 1
2026-01-17 13:20:46,863 : worker.worker : DEBUG : Step 54921, finished rewards -45.96, envs finished 2
2026-01-17 13:20:46,887 : worker.worker : DEBUG : Step 54925, finished rewards -12.64, envs finished 1
2026-01-17 13:20:47,076 : agent.on_policy : DEBUG : Mean Losses: [11.009225010871887]
2026-01-17 13:20:47,097 : worker.worker : DEBUG : Step 54950, finished rewards -33.41, envs finished 1
2026-01-17 13:20:47,112 : worker.worker : DEBUG : Step 54953, finished rewards -40.49, envs finished 1
2026-01-17 13:20:47,251 : agent.on_policy : DEBUG : Mean Losses: [4.81078358925879]
2026-01-17 13:20:47,354 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.059538555105529384
2026-01-17 13:20:47,363 : worker.worker : INFO : Step 55000, Avg Reward -37.1779, Max Reward -0.5911, Loss [5.76818406]
2026-01-17 13:20:47,468 : agent.on_policy : DEBUG : Mean Losses: [0.7753042448312044]
2026-01-17 13:20:47,575 : worker.worker : DEBUG : Step 55032, finished rewards -28.47, envs finished 1
2026-01-17 13:20:47,735 : agent.on_policy : DEBUG : Mean Losses: [4.79610313475132]
2026-01-17 13:20:47,767 : worker.worker : DEBUG : Step 55048, finished rewards -12.70, envs finished 1
2026-01-17 13:20:47,841 : worker.worker : DEBUG : Step 55063, finished rewards -20.85, envs finished 1
2026-01-17 13:20:47,982 : agent.on_policy : DEBUG : Mean Losses: [9.621723897755146]
2026-01-17 13:20:47,990 : worker.worker : DEBUG : Step 55074, finished rewards -27.73, envs finished 1
2026-01-17 13:20:47,998 : worker.worker : DEBUG : Step 55076, finished rewards -39.88, envs finished 1
2026-01-17 13:20:48,049 : worker.worker : DEBUG : Step 55084, finished rewards -13.74, envs finished 1
2026-01-17 13:20:48,087 : worker.worker : DEBUG : Step 55092, finished rewards -39.98, envs finished 1
2026-01-17 13:20:48,223 : agent.on_policy : DEBUG : Mean Losses: [9.01176805049181]
2026-01-17 13:20:48,315 : worker.worker : DEBUG : Step 55127, finished rewards -44.16, envs finished 1
2026-01-17 13:20:48,446 : agent.on_policy : DEBUG : Mean Losses: [3.729953393340111]
2026-01-17 13:20:48,741 : agent.on_policy : DEBUG : Mean Losses: [1.2946775406599045]
2026-01-17 13:20:48,812 : worker.worker : DEBUG : Step 55190, finished rewards -18.87, envs finished 1
2026-01-17 13:20:48,819 : worker.worker : DEBUG : Step 55192, finished rewards -34.72, envs finished 1
2026-01-17 13:20:48,930 : agent.on_policy : DEBUG : Mean Losses: [7.960618861019611]
2026-01-17 13:20:49,050 : worker.worker : DEBUG : Step 55228, finished rewards -21.39, envs finished 1
2026-01-17 13:20:49,062 : worker.worker : DEBUG : Step 55230, finished rewards -16.80, envs finished 1
2026-01-17 13:20:49,169 : agent.on_policy : DEBUG : Mean Losses: [9.85637366399169]
2026-01-17 13:20:49,189 : worker.worker : DEBUG : Step 55238, finished rewards -32.35, envs finished 1
2026-01-17 13:20:49,240 : worker.worker : DEBUG : Step 55246, finished rewards -37.38, envs finished 1
2026-01-17 13:20:49,392 : agent.on_policy : DEBUG : Mean Losses: [7.032154276967049]
2026-01-17 13:20:49,472 : worker.worker : DEBUG : Step 55285, finished rewards -23.67, envs finished 1
2026-01-17 13:20:49,599 : agent.on_policy : DEBUG : Mean Losses: [3.8230844642966986]
2026-01-17 13:20:49,632 : worker.worker : DEBUG : Step 55302, finished rewards -64.91, envs finished 1
2026-01-17 13:20:49,822 : agent.on_policy : DEBUG : Mean Losses: [2.657746087759733]
2026-01-17 13:20:50,085 : agent.on_policy : DEBUG : Mean Losses: [2.8138906694948673]
2026-01-17 13:20:50,116 : worker.worker : DEBUG : Step 55366, finished rewards -33.20, envs finished 1
2026-01-17 13:20:50,132 : worker.worker : DEBUG : Step 55368, finished rewards -47.49, envs finished 1
2026-01-17 13:20:50,208 : worker.worker : DEBUG : Step 55382, finished rewards -20.90, envs finished 1
2026-01-17 13:20:50,230 : worker.worker : DEBUG : Step 55385, finished rewards -29.82, envs finished 1
2026-01-17 13:20:50,377 : agent.on_policy : DEBUG : Mean Losses: [12.371208652853966]
2026-01-17 13:20:50,463 : worker.worker : DEBUG : Step 55409, finished rewards -49.75, envs finished 1
2026-01-17 13:20:50,498 : worker.worker : DEBUG : Step 55414, finished rewards -40.25, envs finished 1
2026-01-17 13:20:50,627 : agent.on_policy : DEBUG : Mean Losses: [7.2599371038377285]
2026-01-17 13:20:50,916 : agent.on_policy : DEBUG : Mean Losses: [2.12472752854228]
2026-01-17 13:20:50,941 : worker.worker : DEBUG : Step 55463, finished rewards -35.98, envs finished 1
2026-01-17 13:20:50,984 : worker.worker : DEBUG : Step 55474, finished rewards -54.89, envs finished 1
2026-01-17 13:20:51,155 : agent.on_policy : DEBUG : Mean Losses: [6.0599794909358025]
2026-01-17 13:20:51,251 : worker.worker : DEBUG : Step 55509, finished rewards -20.49, envs finished 1
2026-01-17 13:20:51,408 : agent.on_policy : DEBUG : Mean Losses: [5.736791852861643]
2026-01-17 13:20:51,463 : worker.worker : DEBUG : Step 55533, finished rewards -26.81, envs finished 1
2026-01-17 13:20:51,499 : worker.worker : DEBUG : Step 55540, finished rewards -39.33, envs finished 1
2026-01-17 13:20:51,524 : worker.worker : DEBUG : Step 55544, finished rewards -12.44, envs finished 1
2026-01-17 13:20:51,693 : agent.on_policy : DEBUG : Mean Losses: [12.335638627409935]
2026-01-17 13:20:51,728 : worker.worker : DEBUG : Step 55559, finished rewards -51.84, envs finished 1
2026-01-17 13:20:51,985 : agent.on_policy : DEBUG : Mean Losses: [3.718707114458084]
2026-01-17 13:20:52,046 : worker.worker : DEBUG : Step 55595, finished rewards -37.29, envs finished 1
2026-01-17 13:20:52,271 : agent.on_policy : DEBUG : Mean Losses: [3.2828126940876245]
2026-01-17 13:20:52,536 : agent.on_policy : DEBUG : Mean Losses: [1.3249347880482674]
2026-01-17 13:20:52,772 : agent.on_policy : DEBUG : Mean Losses: [2.163719452917576]
2026-01-17 13:20:52,793 : worker.worker : DEBUG : Step 55684, finished rewards -83.01, envs finished 1
2026-01-17 13:20:52,798 : worker.worker : DEBUG : Step 55685, finished rewards -31.64, envs finished 1
2026-01-17 13:20:52,827 : worker.worker : DEBUG : Step 55691, finished rewards -59.23, envs finished 1
2026-01-17 13:20:52,919 : worker.worker : DEBUG : Step 55709, finished rewards -49.33, envs finished 1
2026-01-17 13:20:53,014 : agent.on_policy : DEBUG : Mean Losses: [11.65549635887146]
2026-01-17 13:20:53,144 : worker.worker : DEBUG : Step 55734, finished rewards -62.57, envs finished 1
2026-01-17 13:20:53,156 : worker.worker : DEBUG : Step 55736, finished rewards -129.15, envs finished 1
2026-01-17 13:20:53,187 : worker.worker : DEBUG : Step 55740, finished rewards -53.45, envs finished 1
2026-01-17 13:20:53,276 : agent.on_policy : DEBUG : Mean Losses: [11.574492290616035]
2026-01-17 13:20:53,282 : worker.worker : DEBUG : Step 55745, finished rewards -22.12, envs finished 1
2026-01-17 13:20:53,479 : agent.on_policy : DEBUG : Mean Losses: [1.1435509100556374]
2026-01-17 13:20:53,687 : agent.on_policy : DEBUG : Mean Losses: [1.2760470509529114]
2026-01-17 13:20:53,736 : worker.worker : DEBUG : Step 55822, finished rewards -11.95, envs finished 1
2026-01-17 13:20:53,799 : worker.worker : DEBUG : Step 55838, finished rewards -30.18, envs finished 1
2026-01-17 13:20:53,879 : agent.on_policy : DEBUG : Mean Losses: [7.5203016474843025]
2026-01-17 13:20:53,976 : worker.worker : DEBUG : Step 55855, finished rewards -41.88, envs finished 1
2026-01-17 13:20:54,013 : worker.worker : DEBUG : Step 55861, finished rewards -25.44, envs finished 1
2026-01-17 13:20:54,149 : agent.on_policy : DEBUG : Mean Losses: [7.747734546661377]
2026-01-17 13:20:54,190 : worker.worker : DEBUG : Step 55883, finished rewards -15.73, envs finished 1
2026-01-17 13:20:54,238 : worker.worker : DEBUG : Step 55896, finished rewards -33.15, envs finished 1
2026-01-17 13:20:54,318 : agent.on_policy : DEBUG : Mean Losses: [7.244091866537929]
2026-01-17 13:20:54,347 : worker.worker : DEBUG : Step 55913, finished rewards -47.96, envs finished 1
2026-01-17 13:20:54,422 : worker.worker : DEBUG : Step 55928, finished rewards -60.50, envs finished 1
2026-01-17 13:20:54,525 : agent.on_policy : DEBUG : Mean Losses: [5.8883472084999084]
2026-01-17 13:20:54,665 : agent.on_policy : DEBUG : Mean Losses: [1.2898954525589943]
2026-01-17 13:20:54,717 : worker.worker : DEBUG : Step 55978, finished rewards -31.97, envs finished 1
2026-01-17 13:20:54,745 : worker.worker : DEBUG : Step 55984, finished rewards -23.53, envs finished 1
2026-01-17 13:20:54,834 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.05656162735025291
2026-01-17 13:20:54,949 : agent.on_policy : DEBUG : Mean Losses: [6.914422735571861]
2026-01-17 13:20:55,134 : worker.worker : DEBUG : Step 56027, finished rewards -12.33, envs finished 1
2026-01-17 13:20:55,141 : worker.worker : DEBUG : Step 56029, finished rewards -25.93, envs finished 1
2026-01-17 13:20:55,220 : agent.on_policy : DEBUG : Mean Losses: [9.13085924088955]
2026-01-17 13:20:55,222 : worker.worker : DEBUG : Step 56032, finished rewards -36.79, envs finished 1
2026-01-17 13:20:55,291 : worker.worker : DEBUG : Step 56046, finished rewards -60.31, envs finished 1
2026-01-17 13:20:55,448 : agent.on_policy : DEBUG : Mean Losses: [4.554095156490803]
2026-01-17 13:20:55,453 : worker.worker : DEBUG : Step 56065, finished rewards -30.10, envs finished 1
2026-01-17 13:20:55,497 : worker.worker : DEBUG : Step 56077, finished rewards -25.41, envs finished 1
2026-01-17 13:20:55,603 : agent.on_policy : DEBUG : Mean Losses: [4.094500252045691]
2026-01-17 13:20:55,671 : worker.worker : DEBUG : Step 56109, finished rewards -9.46, envs finished 1
2026-01-17 13:20:55,816 : agent.on_policy : DEBUG : Mean Losses: [4.292412292212248]
2026-01-17 13:20:55,913 : worker.worker : DEBUG : Step 56157, finished rewards -48.49, envs finished 1
2026-01-17 13:20:55,992 : agent.on_policy : DEBUG : Mean Losses: [5.0163560919463634]
2026-01-17 13:20:56,053 : worker.worker : DEBUG : Step 56175, finished rewards -23.49, envs finished 1
2026-01-17 13:20:56,081 : worker.worker : DEBUG : Step 56180, finished rewards -14.02, envs finished 1
2026-01-17 13:20:56,205 : agent.on_policy : DEBUG : Mean Losses: [9.226087555289268]
2026-01-17 13:20:56,240 : worker.worker : DEBUG : Step 56199, finished rewards -38.15, envs finished 1
2026-01-17 13:20:56,256 : worker.worker : DEBUG : Step 56202, finished rewards -37.46, envs finished 1
2026-01-17 13:20:56,271 : worker.worker : DEBUG : Step 56205, finished rewards -20.47, envs finished 1
2026-01-17 13:20:56,378 : agent.on_policy : DEBUG : Mean Losses: [9.55840258859098]
2026-01-17 13:20:56,451 : worker.worker : DEBUG : Step 56237, finished rewards -31.18, envs finished 1
2026-01-17 13:20:56,592 : agent.on_policy : DEBUG : Mean Losses: [3.0302526727318764]
2026-01-17 13:20:56,600 : worker.worker : DEBUG : Step 56258, finished rewards -26.07, envs finished 1
2026-01-17 13:20:56,735 : agent.on_policy : DEBUG : Mean Losses: [1.9677962884306908]
2026-01-17 13:20:56,790 : worker.worker : DEBUG : Step 56298, finished rewards -20.19, envs finished 1
2026-01-17 13:20:56,938 : agent.on_policy : DEBUG : Mean Losses: [3.9298793394118547]
2026-01-17 13:20:56,978 : worker.worker : DEBUG : Step 56332, finished rewards -29.67, envs finished 1
2026-01-17 13:20:56,984 : worker.worker : DEBUG : Step 56333, finished rewards -33.04, envs finished 1
2026-01-17 13:20:57,016 : worker.worker : DEBUG : Step 56339, finished rewards -15.43, envs finished 1
2026-01-17 13:20:57,130 : agent.on_policy : DEBUG : Mean Losses: [12.220101341605186]
2026-01-17 13:20:57,197 : worker.worker : DEBUG : Step 56361, finished rewards -34.65, envs finished 1
2026-01-17 13:20:57,286 : worker.worker : DEBUG : Step 56375, finished rewards -45.42, envs finished 1
2026-01-17 13:20:57,306 : worker.worker : DEBUG : Step 56378, finished rewards -17.94, envs finished 1
2026-01-17 13:20:57,383 : agent.on_policy : DEBUG : Mean Losses: [9.65792373381555]
2026-01-17 13:20:57,564 : agent.on_policy : DEBUG : Mean Losses: [1.0520128905773163]
2026-01-17 13:20:57,591 : worker.worker : DEBUG : Step 56424, finished rewards -38.09, envs finished 1
2026-01-17 13:20:57,707 : agent.on_policy : DEBUG : Mean Losses: [3.407217960804701]
2026-01-17 13:20:57,813 : worker.worker : DEBUG : Step 56473, finished rewards -20.79, envs finished 1
2026-01-17 13:20:57,899 : agent.on_policy : DEBUG : Mean Losses: [4.843939432874322]
2026-01-17 13:20:57,907 : worker.worker : DEBUG : Step 56482, finished rewards -20.81, envs finished 1
2026-01-17 13:20:57,944 : worker.worker : DEBUG : Step 56491, finished rewards -33.35, envs finished 1
2026-01-17 13:20:57,993 : worker.worker : DEBUG : Step 56499, finished rewards -47.62, envs finished 1
2026-01-17 13:20:58,004 : worker.worker : DEBUG : Step 56501, finished rewards -18.76, envs finished 1
2026-01-17 13:20:58,096 : agent.on_policy : DEBUG : Mean Losses: [10.531230041757226]
2026-01-17 13:20:58,156 : worker.worker : DEBUG : Step 56527, finished rewards -22.78, envs finished 1
2026-01-17 13:20:58,238 : worker.worker : DEBUG : Step 56543, finished rewards -36.18, envs finished 1
2026-01-17 13:20:58,305 : agent.on_policy : DEBUG : Mean Losses: [6.351979058235884]
2026-01-17 13:20:58,571 : agent.on_policy : DEBUG : Mean Losses: [1.0109866596758366]
2026-01-17 13:20:58,584 : worker.worker : DEBUG : Step 56580, finished rewards -28.30, envs finished 1
2026-01-17 13:20:58,739 : agent.on_policy : DEBUG : Mean Losses: [2.671963032335043]
2026-01-17 13:20:58,809 : worker.worker : DEBUG : Step 56626, finished rewards -29.15, envs finished 1
2026-01-17 13:20:59,069 : agent.on_policy : DEBUG : Mean Losses: [5.73974060639739]
2026-01-17 13:20:59,091 : worker.worker : DEBUG : Step 56646, finished rewards -37.58, envs finished 1
2026-01-17 13:20:59,132 : worker.worker : DEBUG : Step 56656, finished rewards -31.44, envs finished 1
2026-01-17 13:20:59,159 : worker.worker : DEBUG : Step 56663, finished rewards -44.69, envs finished 1
2026-01-17 13:20:59,246 : agent.on_policy : DEBUG : Mean Losses: [8.694734588265419]
2026-01-17 13:20:59,285 : worker.worker : DEBUG : Step 56682, finished rewards -19.52, envs finished 1
2026-01-17 13:20:59,297 : worker.worker : DEBUG : Step 56684, finished rewards -32.03, envs finished 1
2026-01-17 13:20:59,497 : agent.on_policy : DEBUG : Mean Losses: [7.255216337740421]
2026-01-17 13:20:59,656 : agent.on_policy : DEBUG : Mean Losses: [2.0152983255684376]
2026-01-17 13:20:59,737 : worker.worker : DEBUG : Step 56757, finished rewards -49.11, envs finished 1
2026-01-17 13:20:59,765 : worker.worker : DEBUG : Step 56764, finished rewards -51.94, envs finished 1
2026-01-17 13:20:59,846 : agent.on_policy : DEBUG : Mean Losses: [8.098047595471144]
2026-01-17 13:20:59,886 : worker.worker : DEBUG : Step 56782, finished rewards -23.41, envs finished 1
2026-01-17 13:21:00,008 : agent.on_policy : DEBUG : Mean Losses: [4.462991412729025]
2026-01-17 13:21:00,083 : worker.worker : DEBUG : Step 56811, finished rewards -41.98, envs finished 1
2026-01-17 13:21:00,096 : worker.worker : DEBUG : Step 56814, finished rewards -33.51, envs finished 1
2026-01-17 13:21:00,231 : agent.on_policy : DEBUG : Mean Losses: [8.507117535918951]
2026-01-17 13:21:00,252 : worker.worker : DEBUG : Step 56836, finished rewards -31.25, envs finished 1
2026-01-17 13:21:00,309 : worker.worker : DEBUG : Step 56850, finished rewards -33.58, envs finished 1
2026-01-17 13:21:00,428 : agent.on_policy : DEBUG : Mean Losses: [5.166727250441909]
2026-01-17 13:21:00,444 : worker.worker : DEBUG : Step 56867, finished rewards -55.21, envs finished 1
2026-01-17 13:21:00,673 : agent.on_policy : DEBUG : Mean Losses: [3.065802313387394]
2026-01-17 13:21:00,741 : worker.worker : DEBUG : Step 56911, finished rewards -24.55, envs finished 1
2026-01-17 13:21:00,894 : agent.on_policy : DEBUG : Mean Losses: [4.78395064547658]
2026-01-17 13:21:00,919 : worker.worker : DEBUG : Step 56935, finished rewards -28.21, envs finished 1
2026-01-17 13:21:01,096 : agent.on_policy : DEBUG : Mean Losses: [4.960245184600353]
2026-01-17 13:21:01,118 : worker.worker : DEBUG : Step 56966, finished rewards -28.90, envs finished 1
2026-01-17 13:21:01,122 : worker.worker : DEBUG : Step 56967, finished rewards -11.62, envs finished 1
2026-01-17 13:21:01,169 : worker.worker : DEBUG : Step 56979, finished rewards -36.42, envs finished 1
2026-01-17 13:21:01,209 : worker.worker : DEBUG : Step 56989, finished rewards -60.39, envs finished 1
2026-01-17 13:21:01,274 : agent.on_policy : DEBUG : Mean Losses: [12.148271266371012]
2026-01-17 13:21:01,309 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.053733545982740265
2026-01-17 13:21:01,335 : worker.worker : DEBUG : Step 57006, finished rewards -27.57, envs finished 1
2026-01-17 13:21:01,468 : agent.on_policy : DEBUG : Mean Losses: [3.124298430979252]
2026-01-17 13:21:01,688 : agent.on_policy : DEBUG : Mean Losses: [1.5740093812346458]
2026-01-17 13:21:01,731 : worker.worker : DEBUG : Step 57067, finished rewards -70.54, envs finished 1
2026-01-17 13:21:01,780 : worker.worker : DEBUG : Step 57079, finished rewards -37.40, envs finished 1
2026-01-17 13:21:01,854 : agent.on_policy : DEBUG : Mean Losses: [7.48765380308032]
2026-01-17 13:21:02,069 : agent.on_policy : DEBUG : Mean Losses: [2.4725256934762]
2026-01-17 13:21:02,070 : worker.worker : DEBUG : Step 57120, finished rewards -13.07, envs finished 1
2026-01-17 13:21:02,111 : worker.worker : DEBUG : Step 57130, finished rewards -59.88, envs finished 1
2026-01-17 13:21:02,134 : worker.worker : DEBUG : Step 57135, finished rewards -40.76, envs finished 1
2026-01-17 13:21:02,236 : agent.on_policy : DEBUG : Mean Losses: [8.146665126085281]
2026-01-17 13:21:02,244 : worker.worker : DEBUG : Step 57154, finished rewards -47.76, envs finished 1
2026-01-17 13:21:02,262 : worker.worker : DEBUG : Step 57158, finished rewards -59.42, envs finished 1
2026-01-17 13:21:02,410 : worker.worker : DEBUG : Step 57182, finished rewards -47.48, envs finished 1
2026-01-17 13:21:02,483 : agent.on_policy : DEBUG : Mean Losses: [7.249099589884281]
2026-01-17 13:21:02,617 : worker.worker : DEBUG : Step 57209, finished rewards -19.12, envs finished 1
2026-01-17 13:21:02,724 : agent.on_policy : DEBUG : Mean Losses: [4.23005997762084]
2026-01-17 13:21:02,760 : worker.worker : DEBUG : Step 57225, finished rewards -22.02, envs finished 1
2026-01-17 13:21:02,903 : agent.on_policy : DEBUG : Mean Losses: [3.3436035811901093]
2026-01-17 13:21:02,978 : worker.worker : DEBUG : Step 57267, finished rewards -26.27, envs finished 1
2026-01-17 13:21:03,185 : agent.on_policy : DEBUG : Mean Losses: [5.227510996162891]
2026-01-17 13:21:03,206 : worker.worker : DEBUG : Step 57284, finished rewards -30.45, envs finished 1
2026-01-17 13:21:03,278 : worker.worker : DEBUG : Step 57300, finished rewards -24.52, envs finished 1
2026-01-17 13:21:03,401 : agent.on_policy : DEBUG : Mean Losses: [7.153783604502678]
2026-01-17 13:21:03,415 : worker.worker : DEBUG : Step 57316, finished rewards -49.57, envs finished 1
2026-01-17 13:21:03,419 : worker.worker : DEBUG : Step 57317, finished rewards -26.50, envs finished 1
2026-01-17 13:21:03,552 : agent.on_policy : DEBUG : Mean Losses: [4.483496899716556]
2026-01-17 13:21:03,624 : worker.worker : DEBUG : Step 57354, finished rewards -44.04, envs finished 1
2026-01-17 13:21:03,772 : agent.on_policy : DEBUG : Mean Losses: [4.379359934478998]
2026-01-17 13:21:03,773 : worker.worker : DEBUG : Step 57376, finished rewards -27.63, envs finished 1
2026-01-17 13:21:03,987 : agent.on_policy : DEBUG : Mean Losses: [2.1692673452198505]
2026-01-17 13:21:04,003 : worker.worker : DEBUG : Step 57413, finished rewards -23.22, envs finished 1
2026-01-17 13:21:04,029 : worker.worker : DEBUG : Step 57420, finished rewards -71.42, envs finished 1
2026-01-17 13:21:04,081 : worker.worker : DEBUG : Step 57434, finished rewards -26.38, envs finished 1
2026-01-17 13:21:04,155 : agent.on_policy : DEBUG : Mean Losses: [9.427136562764645]
2026-01-17 13:21:04,261 : worker.worker : DEBUG : Step 57463, finished rewards -22.52, envs finished 1
2026-01-17 13:21:04,360 : agent.on_policy : DEBUG : Mean Losses: [6.85816440731287]
2026-01-17 13:21:04,441 : worker.worker : DEBUG : Step 57490, finished rewards -59.38, envs finished 1
2026-01-17 13:21:04,467 : worker.worker : DEBUG : Step 57495, finished rewards -43.29, envs finished 1
2026-01-17 13:21:04,565 : agent.on_policy : DEBUG : Mean Losses: [7.118758335709572]
2026-01-17 13:21:04,669 : worker.worker : DEBUG : Step 57529, finished rewards -50.73, envs finished 1
2026-01-17 13:21:04,765 : agent.on_policy : DEBUG : Mean Losses: [4.678960099816322]
2026-01-17 13:21:04,777 : worker.worker : DEBUG : Step 57539, finished rewards -27.94, envs finished 1
2026-01-17 13:21:04,952 : agent.on_policy : DEBUG : Mean Losses: [1.872814692556858]
2026-01-17 13:21:05,007 : worker.worker : DEBUG : Step 57585, finished rewards -39.15, envs finished 1
2026-01-17 13:21:05,091 : agent.on_policy : DEBUG : Mean Losses: [4.092134709935635]
2026-01-17 13:21:05,112 : worker.worker : DEBUG : Step 57603, finished rewards -66.50, envs finished 1
2026-01-17 13:21:05,133 : worker.worker : DEBUG : Step 57607, finished rewards -46.03, envs finished 1
2026-01-17 13:21:05,275 : agent.on_policy : DEBUG : Mean Losses: [4.623363733291626]
2026-01-17 13:21:05,320 : worker.worker : DEBUG : Step 57643, finished rewards -56.04, envs finished 1
2026-01-17 13:21:05,342 : worker.worker : DEBUG : Step 57649, finished rewards -27.64, envs finished 1
2026-01-17 13:21:05,447 : agent.on_policy : DEBUG : Mean Losses: [8.147694028913975]
2026-01-17 13:21:05,449 : worker.worker : DEBUG : Step 57664, finished rewards -42.20, envs finished 1
2026-01-17 13:21:05,633 : agent.on_policy : DEBUG : Mean Losses: [2.160385688766837]
2026-01-17 13:21:05,726 : worker.worker : DEBUG : Step 57723, finished rewards -42.37, envs finished 1
2026-01-17 13:21:05,820 : agent.on_policy : DEBUG : Mean Losses: [4.658777300268412]
2026-01-17 13:21:05,903 : worker.worker : DEBUG : Step 57744, finished rewards -25.15, envs finished 1
2026-01-17 13:21:05,929 : worker.worker : DEBUG : Step 57750, finished rewards -22.04, envs finished 1
2026-01-17 13:21:05,944 : worker.worker : DEBUG : Step 57753, finished rewards -24.51, envs finished 1
2026-01-17 13:21:05,961 : worker.worker : DEBUG : Step 57755, finished rewards -81.09, envs finished 1
2026-01-17 13:21:06,056 : agent.on_policy : DEBUG : Mean Losses: [13.1344352401793]
2026-01-17 13:21:06,160 : worker.worker : DEBUG : Step 57777, finished rewards -10.72, envs finished 1
2026-01-17 13:21:06,252 : worker.worker : DEBUG : Step 57789, finished rewards -24.53, envs finished 1
2026-01-17 13:21:06,339 : agent.on_policy : DEBUG : Mean Losses: [9.207502577453852]
2026-01-17 13:21:06,506 : agent.on_policy : DEBUG : Mean Losses: [0.8074639514088631]
2026-01-17 13:21:06,508 : worker.worker : DEBUG : Step 57824, finished rewards -35.13, envs finished 1
2026-01-17 13:21:06,637 : agent.on_policy : DEBUG : Mean Losses: [1.278456650674343]
2026-01-17 13:21:06,832 : agent.on_policy : DEBUG : Mean Losses: [2.458105906844139]
2026-01-17 13:21:06,855 : worker.worker : DEBUG : Step 57894, finished rewards -18.69, envs finished 1
2026-01-17 13:21:06,875 : worker.worker : DEBUG : Step 57899, finished rewards -25.60, envs finished 1
2026-01-17 13:21:06,994 : agent.on_policy : DEBUG : Mean Losses: [7.8166855573654175]
2026-01-17 13:21:07,139 : worker.worker : DEBUG : Step 57938, finished rewards -32.04, envs finished 1
2026-01-17 13:21:07,183 : worker.worker : DEBUG : Step 57944, finished rewards -63.23, envs finished 1
2026-01-17 13:21:07,346 : agent.on_policy : DEBUG : Mean Losses: [7.815311659127474]
2026-01-17 13:21:07,362 : worker.worker : DEBUG : Step 57954, finished rewards -53.63, envs finished 1
2026-01-17 13:21:07,578 : agent.on_policy : DEBUG : Mean Losses: [2.980006664991379]
2026-01-17 13:21:07,586 : worker.worker : DEBUG : Step 57986, finished rewards -6.48, envs finished 1
2026-01-17 13:21:07,629 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.05104686868360325
2026-01-17 13:21:07,714 : agent.on_policy : DEBUG : Mean Losses: [2.8965593250468373]
2026-01-17 13:21:07,749 : worker.worker : DEBUG : Step 58025, finished rewards -43.05, envs finished 1
2026-01-17 13:21:07,754 : worker.worker : DEBUG : Step 58026, finished rewards -94.57, envs finished 1
2026-01-17 13:21:07,837 : worker.worker : DEBUG : Step 58039, finished rewards -17.96, envs finished 1
2026-01-17 13:21:07,940 : agent.on_policy : DEBUG : Mean Losses: [9.545743454247713]
2026-01-17 13:21:08,062 : worker.worker : DEBUG : Step 58078, finished rewards -49.88, envs finished 1
2026-01-17 13:21:08,137 : agent.on_policy : DEBUG : Mean Losses: [4.787646800279617]
2026-01-17 13:21:08,266 : worker.worker : DEBUG : Step 58109, finished rewards -44.68, envs finished 1
2026-01-17 13:21:08,352 : agent.on_policy : DEBUG : Mean Losses: [4.74057084415108]
2026-01-17 13:21:08,510 : worker.worker : DEBUG : Step 58141, finished rewards -39.12, envs finished 2
2026-01-17 13:21:08,566 : agent.on_policy : DEBUG : Mean Losses: [6.668302945792675]
2026-01-17 13:21:08,611 : worker.worker : DEBUG : Step 58156, finished rewards -12.25, envs finished 1
2026-01-17 13:21:08,640 : worker.worker : DEBUG : Step 58164, finished rewards -22.48, envs finished 1
2026-01-17 13:21:08,753 : agent.on_policy : DEBUG : Mean Losses: [6.871065836399794]
2026-01-17 13:21:08,778 : worker.worker : DEBUG : Step 58182, finished rewards -35.08, envs finished 1
2026-01-17 13:21:08,958 : agent.on_policy : DEBUG : Mean Losses: [4.063434019684792]
2026-01-17 13:21:09,029 : worker.worker : DEBUG : Step 58229, finished rewards -50.88, envs finished 1
2026-01-17 13:21:09,169 : agent.on_policy : DEBUG : Mean Losses: [4.681599365547299]
2026-01-17 13:21:09,223 : worker.worker : DEBUG : Step 58249, finished rewards -18.10, envs finished 1
2026-01-17 13:21:09,349 : worker.worker : DEBUG : Step 58258, finished rewards -40.92, envs finished 1
2026-01-17 13:21:09,456 : agent.on_policy : DEBUG : Mean Losses: [5.452732242643833]
2026-01-17 13:21:09,599 : worker.worker : DEBUG : Step 58301, finished rewards -35.88, envs finished 1
2026-01-17 13:21:09,657 : agent.on_policy : DEBUG : Mean Losses: [5.142255911137909]
2026-01-17 13:21:09,703 : worker.worker : DEBUG : Step 58316, finished rewards -37.95, envs finished 1
2026-01-17 13:21:09,719 : worker.worker : DEBUG : Step 58320, finished rewards -19.00, envs finished 1
2026-01-17 13:21:09,848 : agent.on_policy : DEBUG : Mean Losses: [8.672550525516272]
2026-01-17 13:21:09,874 : worker.worker : DEBUG : Step 58340, finished rewards -56.10, envs finished 1
2026-01-17 13:21:09,922 : worker.worker : DEBUG : Step 58349, finished rewards -55.87, envs finished 1
2026-01-17 13:21:10,040 : agent.on_policy : DEBUG : Mean Losses: [6.333690669387579]
2026-01-17 13:21:10,060 : worker.worker : DEBUG : Step 58372, finished rewards -20.70, envs finished 1
2026-01-17 13:21:10,123 : worker.worker : DEBUG : Step 58383, finished rewards -5.67, envs finished 1
2026-01-17 13:21:10,271 : agent.on_policy : DEBUG : Mean Losses: [5.506554999388754]
2026-01-17 13:21:10,327 : worker.worker : DEBUG : Step 58415, finished rewards -36.21, envs finished 1
2026-01-17 13:21:10,444 : agent.on_policy : DEBUG : Mean Losses: [3.247779224999249]
2026-01-17 13:21:10,635 : agent.on_policy : DEBUG : Mean Losses: [2.1054687574505806]
2026-01-17 13:21:10,647 : worker.worker : DEBUG : Step 58466, finished rewards -39.57, envs finished 1
2026-01-17 13:21:10,730 : worker.worker : DEBUG : Step 58484, finished rewards -45.59, envs finished 1
2026-01-17 13:21:10,852 : agent.on_policy : DEBUG : Mean Losses: [7.953995745629072]
2026-01-17 13:21:10,929 : worker.worker : DEBUG : Step 58508, finished rewards -48.12, envs finished 1
2026-01-17 13:21:11,025 : worker.worker : DEBUG : Step 58516, finished rewards -46.69, envs finished 1
2026-01-17 13:21:11,176 : agent.on_policy : DEBUG : Mean Losses: [8.633264858275652]
2026-01-17 13:21:11,217 : worker.worker : DEBUG : Step 58540, finished rewards -35.07, envs finished 1
2026-01-17 13:21:11,341 : agent.on_policy : DEBUG : Mean Losses: [4.361785273998976]
2026-01-17 13:21:11,348 : worker.worker : DEBUG : Step 58561, finished rewards -63.75, envs finished 1
2026-01-17 13:21:11,460 : worker.worker : DEBUG : Step 58587, finished rewards -45.33, envs finished 1
2026-01-17 13:21:11,578 : agent.on_policy : DEBUG : Mean Losses: [5.132588539272547]
2026-01-17 13:21:11,666 : worker.worker : DEBUG : Step 58611, finished rewards -111.09, envs finished 1
2026-01-17 13:21:11,783 : agent.on_policy : DEBUG : Mean Losses: [4.632187128067017]
2026-01-17 13:21:11,850 : worker.worker : DEBUG : Step 58635, finished rewards -25.10, envs finished 1
2026-01-17 13:21:11,872 : worker.worker : DEBUG : Step 58639, finished rewards -10.01, envs finished 1
2026-01-17 13:21:12,049 : agent.on_policy : DEBUG : Mean Losses: [9.087426990270615]
2026-01-17 13:21:12,181 : worker.worker : DEBUG : Step 58687, finished rewards -43.57, envs finished 1
2026-01-17 13:21:12,291 : agent.on_policy : DEBUG : Mean Losses: [5.266332700848579]
2026-01-17 13:21:12,372 : worker.worker : DEBUG : Step 58699, finished rewards -16.26, envs finished 1
2026-01-17 13:21:12,489 : worker.worker : DEBUG : Step 58718, finished rewards -38.73, envs finished 1
2026-01-17 13:21:12,582 : agent.on_policy : DEBUG : Mean Losses: [7.649824392050505]
2026-01-17 13:21:12,667 : worker.worker : DEBUG : Step 58741, finished rewards -102.44, envs finished 1
2026-01-17 13:21:12,806 : agent.on_policy : DEBUG : Mean Losses: [3.6829042434692383]
2026-01-17 13:21:12,906 : worker.worker : DEBUG : Step 58776, finished rewards -41.79, envs finished 1
2026-01-17 13:21:13,023 : agent.on_policy : DEBUG : Mean Losses: [5.800979800522327]
2026-01-17 13:21:13,182 : worker.worker : DEBUG : Step 58810, finished rewards -46.21, envs finished 1
2026-01-17 13:21:13,276 : agent.on_policy : DEBUG : Mean Losses: [6.413652101531625]
2026-01-17 13:21:13,368 : worker.worker : DEBUG : Step 58837, finished rewards -95.50, envs finished 1
2026-01-17 13:21:13,487 : agent.on_policy : DEBUG : Mean Losses: [5.858831437304616]
2026-01-17 13:21:13,495 : worker.worker : DEBUG : Step 58849, finished rewards -13.30, envs finished 1
2026-01-17 13:21:13,556 : worker.worker : DEBUG : Step 58857, finished rewards -40.44, envs finished 1
2026-01-17 13:21:13,742 : agent.on_policy : DEBUG : Mean Losses: [4.871026215143502]
2026-01-17 13:21:13,913 : agent.on_policy : DEBUG : Mean Losses: [2.7816345766186714]
2026-01-17 13:21:13,966 : worker.worker : DEBUG : Step 58926, finished rewards -22.61, envs finished 1
2026-01-17 13:21:14,032 : worker.worker : DEBUG : Step 58943, finished rewards -95.75, envs finished 1
2026-01-17 13:21:14,114 : agent.on_policy : DEBUG : Mean Losses: [5.6157001703977585]
2026-01-17 13:21:14,168 : worker.worker : DEBUG : Step 58961, finished rewards -22.97, envs finished 1
2026-01-17 13:21:14,219 : worker.worker : DEBUG : Step 58970, finished rewards -77.14, envs finished 1
2026-01-17 13:21:14,373 : agent.on_policy : DEBUG : Mean Losses: [7.13457702472806]
2026-01-17 13:21:14,528 : worker.worker : DEBUG : Step 58998, finished rewards -36.19, envs finished 1
2026-01-17 13:21:14,529 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.04849452524942309
2026-01-17 13:21:14,628 : agent.on_policy : DEBUG : Mean Losses: [4.6532851457595825]
2026-01-17 13:21:14,636 : worker.worker : DEBUG : Step 59009, finished rewards -28.96, envs finished 1
2026-01-17 13:21:14,643 : worker.worker : DEBUG : Step 59010, finished rewards -35.86, envs finished 1
2026-01-17 13:21:14,743 : worker.worker : DEBUG : Step 59030, finished rewards -53.64, envs finished 1
2026-01-17 13:21:14,844 : agent.on_policy : DEBUG : Mean Losses: [5.043213959783316]
2026-01-17 13:21:14,934 : worker.worker : DEBUG : Step 59061, finished rewards -15.28, envs finished 1
2026-01-17 13:21:15,042 : agent.on_policy : DEBUG : Mean Losses: [3.691555032506585]
2026-01-17 13:21:15,150 : worker.worker : DEBUG : Step 59100, finished rewards -34.06, envs finished 1
2026-01-17 13:21:15,233 : agent.on_policy : DEBUG : Mean Losses: [4.318967945873737]
2026-01-17 13:21:15,296 : worker.worker : DEBUG : Step 59118, finished rewards -34.84, envs finished 1
2026-01-17 13:21:15,484 : agent.on_policy : DEBUG : Mean Losses: [5.00552337244153]
2026-01-17 13:21:15,506 : worker.worker : DEBUG : Step 59141, finished rewards -46.50, envs finished 1
2026-01-17 13:21:15,565 : worker.worker : DEBUG : Step 59151, finished rewards -17.58, envs finished 1
2026-01-17 13:21:15,609 : worker.worker : DEBUG : Step 59162, finished rewards -33.37, envs finished 1
2026-01-17 13:21:15,725 : agent.on_policy : DEBUG : Mean Losses: [8.053939057514071]
2026-01-17 13:21:15,846 : worker.worker : DEBUG : Step 59197, finished rewards -40.45, envs finished 1
2026-01-17 13:21:15,927 : agent.on_policy : DEBUG : Mean Losses: [4.780758259817958]
2026-01-17 13:21:15,944 : worker.worker : DEBUG : Step 59204, finished rewards -59.38, envs finished 1
2026-01-17 13:21:15,988 : worker.worker : DEBUG : Step 59214, finished rewards -30.80, envs finished 1
2026-01-17 13:21:16,162 : agent.on_policy : DEBUG : Mean Losses: [5.397296965122223]
2026-01-17 13:21:16,332 : agent.on_policy : DEBUG : Mean Losses: [2.067859809845686]
2026-01-17 13:21:16,366 : worker.worker : DEBUG : Step 59269, finished rewards -39.54, envs finished 1
2026-01-17 13:21:16,438 : worker.worker : DEBUG : Step 59289, finished rewards -25.36, envs finished 1
2026-01-17 13:21:16,454 : worker.worker : DEBUG : Step 59293, finished rewards -39.81, envs finished 1
2026-01-17 13:21:16,542 : agent.on_policy : DEBUG : Mean Losses: [10.04033175855875]
2026-01-17 13:21:16,549 : worker.worker : DEBUG : Step 59297, finished rewards -14.57, envs finished 1
2026-01-17 13:21:16,662 : worker.worker : DEBUG : Step 59322, finished rewards -34.95, envs finished 1
2026-01-17 13:21:16,757 : agent.on_policy : DEBUG : Mean Losses: [4.600883182138205]
2026-01-17 13:21:16,108 : worker.worker : DEBUG : Step 59356, finished rewards -30.20, envs finished 1
2026-01-17 13:21:16,164 : agent.on_policy : DEBUG : Mean Losses: [5.053743006661534]
2026-01-17 13:21:16,188 : worker.worker : DEBUG : Step 59367, finished rewards -32.58, envs finished 1
2026-01-17 13:21:16,345 : agent.on_policy : DEBUG : Mean Losses: [3.1301919147372246]
2026-01-17 13:21:16,399 : worker.worker : DEBUG : Step 59407, finished rewards -2.04, envs finished 1
2026-01-17 13:21:16,431 : worker.worker : DEBUG : Step 59416, finished rewards -64.25, envs finished 1
2026-01-17 13:21:16,542 : agent.on_policy : DEBUG : Mean Losses: [6.935567390173674]
2026-01-17 13:21:16,635 : worker.worker : DEBUG : Step 59433, finished rewards -14.91, envs finished 1
2026-01-17 13:21:16,701 : worker.worker : DEBUG : Step 59443, finished rewards -43.16, envs finished 1
2026-01-17 13:21:16,763 : worker.worker : DEBUG : Step 59454, finished rewards -36.57, envs finished 1
2026-01-17 13:21:16,856 : agent.on_policy : DEBUG : Mean Losses: [9.320987801998854]
2026-01-17 13:21:17,040 : agent.on_policy : DEBUG : Mean Losses: [1.9883951917290688]
2026-01-17 13:21:17,052 : worker.worker : DEBUG : Step 59491, finished rewards -44.28, envs finished 1
2026-01-17 13:21:17,087 : worker.worker : DEBUG : Step 59500, finished rewards -24.76, envs finished 1
2026-01-17 13:21:17,205 : agent.on_policy : DEBUG : Mean Losses: [5.542568761855364]
2026-01-17 13:21:17,310 : worker.worker : DEBUG : Step 59549, finished rewards -14.00, envs finished 1
2026-01-17 13:21:17,420 : agent.on_policy : DEBUG : Mean Losses: [5.53893019631505]
2026-01-17 13:21:17,424 : worker.worker : DEBUG : Step 59552, finished rewards -21.32, envs finished 1
2026-01-17 13:21:17,482 : worker.worker : DEBUG : Step 59560, finished rewards -58.31, envs finished 1
2026-01-17 13:21:17,642 : agent.on_policy : DEBUG : Mean Losses: [3.7973784767091274]
2026-01-17 13:21:17,645 : worker.worker : DEBUG : Step 59584, finished rewards -11.13, envs finished 1
2026-01-17 13:21:17,683 : worker.worker : DEBUG : Step 59594, finished rewards -34.55, envs finished 1
2026-01-17 13:21:17,801 : agent.on_policy : DEBUG : Mean Losses: [4.374665234237909]
2026-01-17 13:21:17,854 : worker.worker : DEBUG : Step 59627, finished rewards -53.65, envs finished 1
2026-01-17 13:21:17,899 : worker.worker : DEBUG : Step 59637, finished rewards -21.96, envs finished 1
2026-01-17 13:21:18,024 : agent.on_policy : DEBUG : Mean Losses: [6.4804751724004745]
2026-01-17 13:21:18,103 : worker.worker : DEBUG : Step 59665, finished rewards -36.97, envs finished 1
2026-01-17 13:21:18,218 : agent.on_policy : DEBUG : Mean Losses: [3.3701509926468134]
2026-01-17 13:21:18,223 : worker.worker : DEBUG : Step 59681, finished rewards -11.30, envs finished 1
2026-01-17 13:21:18,392 : agent.on_policy : DEBUG : Mean Losses: [3.3467662185430527]
2026-01-17 13:21:18,402 : worker.worker : DEBUG : Step 59714, finished rewards -28.08, envs finished 1
2026-01-17 13:21:18,453 : worker.worker : DEBUG : Step 59729, finished rewards -50.89, envs finished 1
2026-01-17 13:21:18,486 : worker.worker : DEBUG : Step 59736, finished rewards -27.78, envs finished 1
2026-01-17 13:21:18,581 : agent.on_policy : DEBUG : Mean Losses: [9.124098712578416]
2026-01-17 13:21:18,624 : worker.worker : DEBUG : Step 59749, finished rewards -30.06, envs finished 1
2026-01-17 13:21:18,854 : worker.worker : DEBUG : Step 59770, finished rewards -22.12, envs finished 1
2026-01-17 13:21:18,918 : agent.on_policy : DEBUG : Mean Losses: [6.1639333395287395]
2026-01-17 13:21:18,999 : worker.worker : DEBUG : Step 59795, finished rewards -12.37, envs finished 1
2026-01-17 13:21:19,022 : worker.worker : DEBUG : Step 59798, finished rewards -26.41, envs finished 1
2026-01-17 13:21:19,072 : worker.worker : DEBUG : Step 59806, finished rewards -6.91, envs finished 1
2026-01-17 13:21:19,164 : agent.on_policy : DEBUG : Mean Losses: [9.415428703650832]
2026-01-17 13:21:19,357 : agent.on_policy : DEBUG : Mean Losses: [0.9595538377761841]
2026-01-17 13:21:19,525 : agent.on_policy : DEBUG : Mean Losses: [2.4243789613246918]
2026-01-17 13:21:19,546 : worker.worker : DEBUG : Step 59877, finished rewards -38.91, envs finished 1
2026-01-17 13:21:19,586 : worker.worker : DEBUG : Step 59888, finished rewards -19.65, envs finished 1
2026-01-17 13:21:19,632 : worker.worker : DEBUG : Step 59900, finished rewards -32.54, envs finished 1
2026-01-17 13:21:19,690 : agent.on_policy : DEBUG : Mean Losses: [11.72569677233696]
2026-01-17 13:21:19,696 : worker.worker : DEBUG : Step 59905, finished rewards -43.65, envs finished 1
2026-01-17 13:21:19,797 : worker.worker : DEBUG : Step 59927, finished rewards -5.57, envs finished 1
2026-01-17 13:21:19,839 : worker.worker : DEBUG : Step 59935, finished rewards -17.48, envs finished 1
2026-01-17 13:21:19,898 : agent.on_policy : DEBUG : Mean Losses: [8.633545394986868]
2026-01-17 13:21:19,921 : worker.worker : DEBUG : Step 59942, finished rewards -37.96, envs finished 1
2026-01-17 13:21:19,953 : worker.worker : DEBUG : Step 59951, finished rewards -30.19, envs finished 1
2026-01-17 13:21:20,085 : agent.on_policy : DEBUG : Mean Losses: [4.839490973390639]
2026-01-17 13:21:20,297 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.04606979898695193
2026-01-17 13:21:20,350 : agent.on_policy : DEBUG : Mean Losses: [0.7083519659936428]
2026-01-17 13:21:20,364 : worker.worker : INFO : Step 60000, Avg Reward -35.8778, Max Reward -2.0411, Loss [5.53981176]
2026-01-17 13:21:20,467 : worker.worker : DEBUG : Step 60018, finished rewards -18.28, envs finished 1
2026-01-17 13:21:20,587 : agent.on_policy : DEBUG : Mean Losses: [4.412705764174461]
2026-01-17 13:21:20,812 : agent.on_policy : DEBUG : Mean Losses: [4.560890465974808]
2026-01-17 13:21:20,857 : worker.worker : DEBUG : Step 60074, finished rewards -23.33, envs finished 1
2026-01-17 13:21:20,874 : worker.worker : DEBUG : Step 60077, finished rewards -44.55, envs finished 1
2026-01-17 13:21:20,937 : worker.worker : DEBUG : Step 60091, finished rewards -59.47, envs finished 1
2026-01-17 13:21:20,943 : worker.worker : DEBUG : Step 60092, finished rewards -66.03, envs finished 1
2026-01-17 13:21:21,033 : agent.on_policy : DEBUG : Mean Losses: [14.961297169327736]
2026-01-17 13:21:21,044 : worker.worker : DEBUG : Step 60098, finished rewards -32.94, envs finished 1
2026-01-17 13:21:21,069 : worker.worker : DEBUG : Step 60102, finished rewards -28.66, envs finished 1
2026-01-17 13:21:21,151 : worker.worker : DEBUG : Step 60126, finished rewards -60.46, envs finished 1
2026-01-17 13:21:21,219 : agent.on_policy : DEBUG : Mean Losses: [6.806594781577587]
2026-01-17 13:21:21,435 : agent.on_policy : DEBUG : Mean Losses: [1.2398723922669888]
2026-01-17 13:21:21,513 : worker.worker : DEBUG : Step 60180, finished rewards -27.81, envs finished 1
2026-01-17 13:21:21,640 : agent.on_policy : DEBUG : Mean Losses: [3.637098725885153]
2026-01-17 13:21:21,839 : agent.on_policy : DEBUG : Mean Losses: [2.362229399383068]
2026-01-17 13:21:21,860 : worker.worker : DEBUG : Step 60230, finished rewards -28.87, envs finished 1
2026-01-17 13:21:21,864 : worker.worker : DEBUG : Step 60231, finished rewards -33.22, envs finished 1
2026-01-17 13:21:21,882 : worker.worker : DEBUG : Step 60235, finished rewards -21.89, envs finished 1
2026-01-17 13:21:21,943 : worker.worker : DEBUG : Step 60249, finished rewards -23.66, envs finished 1
2026-01-17 13:21:22,050 : agent.on_policy : DEBUG : Mean Losses: [11.9984689950943]
2026-01-17 13:21:22,092 : worker.worker : DEBUG : Step 60265, finished rewards -41.08, envs finished 1
2026-01-17 13:21:22,187 : worker.worker : DEBUG : Step 60285, finished rewards -56.11, envs finished 1
2026-01-17 13:21:22,289 : agent.on_policy : DEBUG : Mean Losses: [6.241731967777014]
2026-01-17 13:21:22,493 : agent.on_policy : DEBUG : Mean Losses: [1.451297277584672]
2026-01-17 13:21:22,564 : worker.worker : DEBUG : Step 60340, finished rewards -65.21, envs finished 1
2026-01-17 13:21:22,597 : worker.worker : DEBUG : Step 60348, finished rewards -40.63, envs finished 1
2026-01-17 13:21:22,687 : agent.on_policy : DEBUG : Mean Losses: [7.282390050590038]
2026-01-17 13:21:22,871 : agent.on_policy : DEBUG : Mean Losses: [2.4931616745889187]
2026-01-17 13:21:22,887 : worker.worker : DEBUG : Step 60389, finished rewards -34.00, envs finished 1
2026-01-17 13:21:22,931 : worker.worker : DEBUG : Step 60400, finished rewards -40.07, envs finished 1
2026-01-17 13:21:23,030 : agent.on_policy : DEBUG : Mean Losses: [7.196342125535011]
2026-01-17 13:21:23,093 : worker.worker : DEBUG : Step 60429, finished rewards -49.32, envs finished 1
2026-01-17 13:21:23,139 : worker.worker : DEBUG : Step 60438, finished rewards -29.06, envs finished 1
2026-01-17 13:21:23,242 : agent.on_policy : DEBUG : Mean Losses: [7.371087782084942]
2026-01-17 13:21:23,426 : agent.on_policy : DEBUG : Mean Losses: [1.7744775116443634]
2026-01-17 13:21:23,434 : worker.worker : DEBUG : Step 60482, finished rewards -105.69, envs finished 1
2026-01-17 13:21:23,484 : worker.worker : DEBUG : Step 60496, finished rewards -31.92, envs finished 1
2026-01-17 13:21:23,625 : agent.on_policy : DEBUG : Mean Losses: [5.330524608492851]
2026-01-17 13:21:23,685 : worker.worker : DEBUG : Step 60525, finished rewards -36.23, envs finished 1
2026-01-17 13:21:23,819 : agent.on_policy : DEBUG : Mean Losses: [4.072113221511245]
2026-01-17 13:21:23,820 : worker.worker : DEBUG : Step 60544, finished rewards -32.27, envs finished 1
2026-01-17 13:21:23,877 : worker.worker : DEBUG : Step 60561, finished rewards -1.00, envs finished 1
2026-01-17 13:21:23,920 : worker.worker : DEBUG : Step 60575, finished rewards -43.15, envs finished 1
2026-01-17 13:21:23,998 : agent.on_policy : DEBUG : Mean Losses: [8.822807997465134]
2026-01-17 13:21:24,014 : worker.worker : DEBUG : Step 60580, finished rewards -19.10, envs finished 1
2026-01-17 13:21:24,187 : agent.on_policy : DEBUG : Mean Losses: [2.7448820769786835]
2026-01-17 13:21:24,257 : worker.worker : DEBUG : Step 60631, finished rewards -26.12, envs finished 1
2026-01-17 13:21:24,350 : agent.on_policy : DEBUG : Mean Losses: [5.625748809427023]
2026-01-17 13:21:24,410 : worker.worker : DEBUG : Step 60656, finished rewards -89.62, envs finished 1
2026-01-17 13:21:24,532 : agent.on_policy : DEBUG : Mean Losses: [5.065122649073601]
2026-01-17 13:21:24,562 : worker.worker : DEBUG : Step 60679, finished rewards -29.89, envs finished 1
2026-01-17 13:21:24,705 : agent.on_policy : DEBUG : Mean Losses: [3.60409564524889]
2026-01-17 13:21:24,793 : worker.worker : DEBUG : Step 60725, finished rewards -22.29, envs finished 1
2026-01-17 13:21:24,806 : worker.worker : DEBUG : Step 60728, finished rewards -52.02, envs finished 1
2026-01-17 13:21:24,915 : agent.on_policy : DEBUG : Mean Losses: [8.01681336760521]
2026-01-17 13:21:24,933 : worker.worker : DEBUG : Step 60741, finished rewards -39.31, envs finished 2
2026-01-17 13:21:24,950 : worker.worker : DEBUG : Step 60744, finished rewards -28.36, envs finished 1
2026-01-17 13:21:25,237 : agent.on_policy : DEBUG : Mean Losses: [5.709777520503849]
2026-01-17 13:21:25,385 : agent.on_policy : DEBUG : Mean Losses: [1.5272478461265564]
2026-01-17 13:21:25,435 : worker.worker : DEBUG : Step 60811, finished rewards -53.68, envs finished 1
2026-01-17 13:21:25,454 : worker.worker : DEBUG : Step 60816, finished rewards -29.85, envs finished 1
2026-01-17 13:21:25,517 : worker.worker : DEBUG : Step 60831, finished rewards -27.56, envs finished 1
2026-01-17 13:21:25,571 : agent.on_policy : DEBUG : Mean Losses: [8.3336251527071]
2026-01-17 13:21:25,744 : agent.on_policy : DEBUG : Mean Losses: [1.118478287011385]
2026-01-17 13:21:25,833 : worker.worker : DEBUG : Step 60885, finished rewards -34.33, envs finished 1
2026-01-17 13:21:25,961 : agent.on_policy : DEBUG : Mean Losses: [6.400139287114143]
2026-01-17 13:21:26,041 : worker.worker : DEBUG : Step 60915, finished rewards -40.15, envs finished 1
2026-01-17 13:21:26,059 : worker.worker : DEBUG : Step 60919, finished rewards -42.79, envs finished 1
2026-01-17 13:21:26,069 : worker.worker : DEBUG : Step 60921, finished rewards -49.12, envs finished 1
2026-01-17 13:21:26,075 : worker.worker : DEBUG : Step 60922, finished rewards -50.42, envs finished 1
2026-01-17 13:21:26,175 : agent.on_policy : DEBUG : Mean Losses: [15.096344269812107]
2026-01-17 13:21:26,383 : agent.on_policy : DEBUG : Mean Losses: [1.0649625724181533]
2026-01-17 13:21:26,429 : worker.worker : DEBUG : Step 60973, finished rewards -31.94, envs finished 1
2026-01-17 13:21:26,534 : agent.on_policy : DEBUG : Mean Losses: [5.006841249763966]
2026-01-17 13:21:26,559 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.04376630903760433
2026-01-17 13:21:26,652 : worker.worker : DEBUG : Step 61018, finished rewards -57.74, envs finished 1
2026-01-17 13:21:26,751 : agent.on_policy : DEBUG : Mean Losses: [4.964043125510216]
2026-01-17 13:21:26,753 : worker.worker : DEBUG : Step 61024, finished rewards -69.78, envs finished 1
2026-01-17 13:21:26,850 : worker.worker : DEBUG : Step 61044, finished rewards -34.69, envs finished 1
2026-01-17 13:21:26,964 : agent.on_policy : DEBUG : Mean Losses: [5.467118851840496]
2026-01-17 13:21:27,014 : worker.worker : DEBUG : Step 61067, finished rewards -28.96, envs finished 1
2026-01-17 13:21:27,047 : worker.worker : DEBUG : Step 61074, finished rewards -29.09, envs finished 1
2026-01-17 13:21:27,064 : worker.worker : DEBUG : Step 61078, finished rewards -25.98, envs finished 1
2026-01-17 13:21:27,145 : agent.on_policy : DEBUG : Mean Losses: [10.829104840755463]
2026-01-17 13:21:27,327 : agent.on_policy : DEBUG : Mean Losses: [1.2734003085643053]
2026-01-17 13:21:27,367 : worker.worker : DEBUG : Step 61133, finished rewards -60.45, envs finished 1
2026-01-17 13:21:27,472 : agent.on_policy : DEBUG : Mean Losses: [3.765523750334978]
2026-01-17 13:21:27,504 : worker.worker : DEBUG : Step 61159, finished rewards -12.18, envs finished 1
2026-01-17 13:21:27,587 : worker.worker : DEBUG : Step 61176, finished rewards -10.36, envs finished 1
2026-01-17 13:21:27,699 : agent.on_policy : DEBUG : Mean Losses: [7.70143885910511]
2026-01-17 13:21:27,703 : worker.worker : DEBUG : Step 61185, finished rewards -42.25, envs finished 1
2026-01-17 13:21:27,790 : worker.worker : DEBUG : Step 61203, finished rewards -12.09, envs finished 1
2026-01-17 13:21:27,829 : worker.worker : DEBUG : Step 61214, finished rewards -29.06, envs finished 1
2026-01-17 13:21:27,924 : agent.on_policy : DEBUG : Mean Losses: [8.402999296784401]
2026-01-17 13:21:27,945 : worker.worker : DEBUG : Step 61223, finished rewards -22.79, envs finished 1
2026-01-17 13:21:28,029 : worker.worker : DEBUG : Step 61242, finished rewards -25.53, envs finished 1
2026-01-17 13:21:28,141 : agent.on_policy : DEBUG : Mean Losses: [6.109188638627529]
2026-01-17 13:21:28,251 : worker.worker : DEBUG : Step 61269, finished rewards -8.66, envs finished 1
2026-01-17 13:21:28,368 : agent.on_policy : DEBUG : Mean Losses: [4.299795608967543]
2026-01-17 13:21:28,395 : worker.worker : DEBUG : Step 61286, finished rewards -2.86, envs finished 1
2026-01-17 13:21:28,598 : agent.on_policy : DEBUG : Mean Losses: [3.4678660854697227]
2026-01-17 13:21:28,599 : worker.worker : DEBUG : Step 61312, finished rewards -11.89, envs finished 1
2026-01-17 13:21:28,632 : worker.worker : DEBUG : Step 61319, finished rewards -7.60, envs finished 1
2026-01-17 13:21:28,737 : worker.worker : DEBUG : Step 61336, finished rewards -9.73, envs finished 1
2026-01-17 13:21:28,750 : worker.worker : DEBUG : Step 61338, finished rewards 5.54, envs finished 1
2026-01-17 13:21:29,034 : agent.on_policy : DEBUG : Mean Losses: [10.575534366071224]
2026-01-17 13:21:29,174 : worker.worker : DEBUG : Step 61362, finished rewards 22.36, envs finished 1
2026-01-17 13:21:29,303 : agent.on_policy : DEBUG : Mean Losses: [5.009687628597021]
2026-01-17 13:21:29,359 : worker.worker : DEBUG : Step 61387, finished rewards -14.60, envs finished 1
2026-01-17 13:21:29,439 : worker.worker : DEBUG : Step 61406, finished rewards 8.85, envs finished 1
2026-01-17 13:21:29,534 : agent.on_policy : DEBUG : Mean Losses: [5.509050644934177]
2026-01-17 13:21:29,633 : worker.worker : DEBUG : Step 61431, finished rewards 21.14, envs finished 1
2026-01-17 13:21:29,650 : worker.worker : DEBUG : Step 61436, finished rewards -0.43, envs finished 1
2026-01-17 13:21:29,745 : agent.on_policy : DEBUG : Mean Losses: [9.30006693303585]
2026-01-17 13:21:29,757 : worker.worker : DEBUG : Step 61443, finished rewards -20.57, envs finished 1
2026-01-17 13:21:29,864 : worker.worker : DEBUG : Step 61468, finished rewards -7.33, envs finished 1
2026-01-17 13:21:29,950 : agent.on_policy : DEBUG : Mean Losses: [5.3086885288357735]
2026-01-17 13:21:30,017 : worker.worker : DEBUG : Step 61488, finished rewards 4.09, envs finished 1
2026-01-17 13:21:30,052 : worker.worker : DEBUG : Step 61493, finished rewards 14.51, envs finished 1
2026-01-17 13:21:30,169 : agent.on_policy : DEBUG : Mean Losses: [6.53629308193922]
2026-01-17 13:21:30,230 : worker.worker : DEBUG : Step 61516, finished rewards 28.94, envs finished 1
2026-01-17 13:21:30,246 : worker.worker : DEBUG : Step 61519, finished rewards 8.57, envs finished 1
2026-01-17 13:21:30,314 : worker.worker : DEBUG : Step 61530, finished rewards 23.54, envs finished 1
2026-01-17 13:21:30,440 : agent.on_policy : DEBUG : Mean Losses: [10.547307848930359]
2026-01-17 13:21:30,460 : worker.worker : DEBUG : Step 61540, finished rewards -9.40, envs finished 1
2026-01-17 13:21:30,501 : worker.worker : DEBUG : Step 61550, finished rewards 15.93, envs finished 1
2026-01-17 13:21:30,603 : agent.on_policy : DEBUG : Mean Losses: [7.226602278649807]
2026-01-17 13:21:30,625 : worker.worker : DEBUG : Step 61573, finished rewards 34.01, envs finished 1
2026-01-17 13:21:30,710 : worker.worker : DEBUG : Step 61587, finished rewards 11.23, envs finished 1
2026-01-17 13:21:30,821 : agent.on_policy : DEBUG : Mean Losses: [5.1022077947855]
2026-01-17 13:21:30,903 : worker.worker : DEBUG : Step 61614, finished rewards 10.37, envs finished 1
2026-01-17 13:21:30,967 : worker.worker : DEBUG : Step 61630, finished rewards 7.11, envs finished 1
2026-01-17 13:21:31,044 : agent.on_policy : DEBUG : Mean Losses: [8.17263438552618]
2026-01-17 13:21:31,072 : worker.worker : DEBUG : Step 61636, finished rewards 4.95, envs finished 1
2026-01-17 13:21:31,086 : worker.worker : DEBUG : Step 61639, finished rewards 18.38, envs finished 1
2026-01-17 13:21:31,094 : worker.worker : DEBUG : Step 61640, finished rewards 11.07, envs finished 1
2026-01-17 13:21:31,263 : agent.on_policy : DEBUG : Mean Losses: [7.092429682612419]
2026-01-17 13:21:31,294 : worker.worker : DEBUG : Step 61671, finished rewards -1.53, envs finished 1
2026-01-17 13:21:31,332 : worker.worker : DEBUG : Step 61680, finished rewards 12.41, envs finished 1
2026-01-17 13:21:31,340 : worker.worker : DEBUG : Step 61682, finished rewards 20.50, envs finished 1
2026-01-17 13:21:31,432 : agent.on_policy : DEBUG : Mean Losses: [8.584322195500135]
2026-01-17 13:21:31,626 : agent.on_policy : DEBUG : Mean Losses: [2.54607255756855]
2026-01-17 13:21:31,641 : worker.worker : DEBUG : Step 61733, finished rewards 23.75, envs finished 1
2026-01-17 13:21:31,705 : worker.worker : DEBUG : Step 61748, finished rewards 3.34, envs finished 1
2026-01-17 13:21:31,742 : worker.worker : DEBUG : Step 61756, finished rewards 4.78, envs finished 1
2026-01-17 13:21:31,898 : agent.on_policy : DEBUG : Mean Losses: [10.582864731550217]
2026-01-17 13:21:31,941 : worker.worker : DEBUG : Step 61768, finished rewards 27.10, envs finished 1
2026-01-17 13:21:32,044 : worker.worker : DEBUG : Step 61784, finished rewards -43.25, envs finished 1
2026-01-17 13:21:32,221 : agent.on_policy : DEBUG : Mean Losses: [6.84618853032589]
2026-01-17 13:21:32,237 : worker.worker : DEBUG : Step 61794, finished rewards 7.07, envs finished 1
2026-01-17 13:21:32,251 : worker.worker : DEBUG : Step 61796, finished rewards 20.26, envs finished 1
2026-01-17 13:21:32,369 : worker.worker : DEBUG : Step 61819, finished rewards -4.97, envs finished 1
2026-01-17 13:21:32,558 : agent.on_policy : DEBUG : Mean Losses: [6.723148368299007]
2026-01-17 13:21:32,790 : agent.on_policy : DEBUG : Mean Losses: [2.889716163277626]
2026-01-17 13:21:32,819 : worker.worker : DEBUG : Step 61863, finished rewards -5.29, envs finished 1
2026-01-17 13:21:32,852 : worker.worker : DEBUG : Step 61870, finished rewards 6.13, envs finished 1
2026-01-17 13:21:32,871 : worker.worker : DEBUG : Step 61874, finished rewards 0.41, envs finished 1
2026-01-17 13:21:32,924 : worker.worker : DEBUG : Step 61882, finished rewards 10.19, envs finished 1
2026-01-17 13:21:33,044 : agent.on_policy : DEBUG : Mean Losses: [12.616988718509674]
2026-01-17 13:21:33,047 : worker.worker : DEBUG : Step 61888, finished rewards 17.51, envs finished 1
2026-01-17 13:21:33,055 : worker.worker : DEBUG : Step 61889, finished rewards 21.41, envs finished 1
2026-01-17 13:21:33,172 : worker.worker : DEBUG : Step 61919, finished rewards 6.64, envs finished 1
2026-01-17 13:21:33,250 : agent.on_policy : DEBUG : Mean Losses: [3.8560734018683434]
2026-01-17 13:21:33,269 : worker.worker : DEBUG : Step 61924, finished rewards 11.55, envs finished 1
2026-01-17 13:21:33,451 : agent.on_policy : DEBUG : Mean Losses: [3.012712001800537]
2026-01-17 13:21:33,533 : worker.worker : DEBUG : Step 61977, finished rewards 8.32, envs finished 1
2026-01-17 13:21:33,635 : agent.on_policy : DEBUG : Mean Losses: [4.857291340827942]
2026-01-17 13:21:33,657 : worker.worker : DEBUG : Step 61988, finished rewards 7.25, envs finished 1
2026-01-17 13:21:33,670 : worker.worker : DEBUG : Step 61990, finished rewards 14.75, envs finished 1
2026-01-17 13:21:33,679 : worker.worker : DEBUG : Step 61991, finished rewards 18.00, envs finished 1
2026-01-17 13:21:33,730 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.041577993585724116
2026-01-17 13:21:33,788 : worker.worker : DEBUG : Step 62011, finished rewards 9.16, envs finished 1
2026-01-17 13:21:33,884 : agent.on_policy : DEBUG : Mean Losses: [7.899189569056034]
2026-01-17 13:21:34,022 : worker.worker : DEBUG : Step 62046, finished rewards 7.30, envs finished 1
2026-01-17 13:21:34,078 : agent.on_policy : DEBUG : Mean Losses: [4.692523829638958]
2026-01-17 13:21:34,242 : agent.on_policy : DEBUG : Mean Losses: [2.4320607110857964]
2026-01-17 13:21:34,255 : worker.worker : DEBUG : Step 62083, finished rewards 24.80, envs finished 1
2026-01-17 13:21:34,266 : worker.worker : DEBUG : Step 62085, finished rewards 11.60, envs finished 1
2026-01-17 13:21:34,280 : worker.worker : DEBUG : Step 62087, finished rewards 12.36, envs finished 2
2026-01-17 13:21:34,321 : worker.worker : DEBUG : Step 62097, finished rewards 9.08, envs finished 1
2026-01-17 13:21:34,352 : worker.worker : DEBUG : Step 62105, finished rewards 4.93, envs finished 1
2026-01-17 13:21:34,384 : worker.worker : DEBUG : Step 62110, finished rewards 9.01, envs finished 1
2026-01-17 13:21:34,447 : agent.on_policy : DEBUG : Mean Losses: [13.878205493092537]
2026-01-17 13:21:34,528 : worker.worker : DEBUG : Step 62135, finished rewards 26.10, envs finished 1
2026-01-17 13:21:34,619 : agent.on_policy : DEBUG : Mean Losses: [4.531831115484238]
2026-01-17 13:21:34,820 : agent.on_policy : DEBUG : Mean Losses: [2.685490131378174]
2026-01-17 13:21:34,822 : worker.worker : DEBUG : Step 62176, finished rewards 25.62, envs finished 1
2026-01-17 13:21:34,854 : worker.worker : DEBUG : Step 62184, finished rewards 17.42, envs finished 1
2026-01-17 13:21:34,864 : worker.worker : DEBUG : Step 62186, finished rewards 18.70, envs finished 1
2026-01-17 13:21:34,922 : worker.worker : DEBUG : Step 62201, finished rewards 21.45, envs finished 1
2026-01-17 13:21:34,926 : worker.worker : DEBUG : Step 62202, finished rewards 15.16, envs finished 1
2026-01-17 13:21:34,932 : worker.worker : DEBUG : Step 62203, finished rewards 13.38, envs finished 1
2026-01-17 13:21:35,052 : agent.on_policy : DEBUG : Mean Losses: [13.439554661512375]
2026-01-17 13:21:35,102 : worker.worker : DEBUG : Step 62222, finished rewards 28.82, envs finished 1
2026-01-17 13:21:35,110 : worker.worker : DEBUG : Step 62224, finished rewards 7.57, envs finished 1
2026-01-17 13:21:35,255 : agent.on_policy : DEBUG : Mean Losses: [5.914860766381025]
2026-01-17 13:21:35,346 : worker.worker : DEBUG : Step 62264, finished rewards 26.94, envs finished 1
2026-01-17 13:21:35,453 : agent.on_policy : DEBUG : Mean Losses: [5.568317964673042]
2026-01-17 13:21:35,455 : worker.worker : DEBUG : Step 62272, finished rewards 29.67, envs finished 1
2026-01-17 13:21:35,575 : worker.worker : DEBUG : Step 62299, finished rewards 6.35, envs finished 1
2026-01-17 13:21:35,588 : worker.worker : DEBUG : Step 62302, finished rewards 25.34, envs finished 2
2026-01-17 13:21:35,670 : agent.on_policy : DEBUG : Mean Losses: [11.965307876467705]
2026-01-17 13:21:35,704 : worker.worker : DEBUG : Step 62312, finished rewards 12.15, envs finished 1
2026-01-17 13:21:35,711 : worker.worker : DEBUG : Step 62314, finished rewards 28.31, envs finished 1
2026-01-17 13:21:35,865 : agent.on_policy : DEBUG : Mean Losses: [5.57683502137661]
2026-01-17 13:21:35,893 : worker.worker : DEBUG : Step 62345, finished rewards 37.24, envs finished 1
2026-01-17 13:21:35,900 : worker.worker : DEBUG : Step 62346, finished rewards -8.69, envs finished 1
2026-01-17 13:21:36,013 : agent.on_policy : DEBUG : Mean Losses: [6.606326147913933]
2026-01-17 13:21:36,097 : worker.worker : DEBUG : Step 62386, finished rewards 40.79, envs finished 1
2026-01-17 13:21:36,141 : worker.worker : DEBUG : Step 62397, finished rewards 5.16, envs finished 1
2026-01-17 13:21:36,156 : worker.worker : DEBUG : Step 62399, finished rewards 27.73, envs finished 1
2026-01-17 13:21:36,238 : agent.on_policy : DEBUG : Mean Losses: [11.673587799072266]
2026-01-17 13:21:36,275 : worker.worker : DEBUG : Step 62410, finished rewards 19.48, envs finished 1
2026-01-17 13:21:36,282 : worker.worker : DEBUG : Step 62412, finished rewards 12.50, envs finished 1
2026-01-17 13:21:36,326 : worker.worker : DEBUG : Step 62416, finished rewards 10.52, envs finished 1
2026-01-17 13:21:36,446 : agent.on_policy : DEBUG : Mean Losses: [7.7310513108968735]
2026-01-17 13:21:36,448 : worker.worker : DEBUG : Step 62432, finished rewards 26.53, envs finished 1
2026-01-17 13:21:36,582 : worker.worker : DEBUG : Step 62454, finished rewards 15.06, envs finished 1
2026-01-17 13:21:36,768 : agent.on_policy : DEBUG : Mean Losses: [3.22908878326416]
2026-01-17 13:21:36,852 : worker.worker : DEBUG : Step 62485, finished rewards 39.97, envs finished 1
2026-01-17 13:21:36,864 : worker.worker : DEBUG : Step 62488, finished rewards 17.36, envs finished 1
2026-01-17 13:21:36,963 : agent.on_policy : DEBUG : Mean Losses: [8.151815384626389]
2026-01-17 13:21:36,982 : worker.worker : DEBUG : Step 62501, finished rewards 17.07, envs finished 1
2026-01-17 13:21:36,989 : worker.worker : DEBUG : Step 62502, finished rewards 24.31, envs finished 1
2026-01-17 13:21:37,158 : agent.on_policy : DEBUG : Mean Losses: [5.421113669872284]
2026-01-17 13:21:37,163 : worker.worker : DEBUG : Step 62529, finished rewards 12.07, envs finished 1
2026-01-17 13:21:37,182 : worker.worker : DEBUG : Step 62534, finished rewards -11.59, envs finished 1
2026-01-17 13:21:37,200 : worker.worker : DEBUG : Step 62538, finished rewards 12.56, envs finished 1
2026-01-17 13:21:37,206 : worker.worker : DEBUG : Step 62539, finished rewards 29.82, envs finished 1
2026-01-17 13:21:37,332 : agent.on_policy : DEBUG : Mean Losses: [7.421937935054302]
2026-01-17 13:21:37,532 : agent.on_policy : DEBUG : Mean Losses: [2.859990745782852]
2026-01-17 13:21:37,540 : worker.worker : DEBUG : Step 62594, finished rewards 15.63, envs finished 1
2026-01-17 13:21:37,577 : worker.worker : DEBUG : Step 62602, finished rewards 18.08, envs finished 1
2026-01-17 13:21:37,626 : worker.worker : DEBUG : Step 62615, finished rewards 9.29, envs finished 1
2026-01-17 13:21:37,648 : worker.worker : DEBUG : Step 62620, finished rewards 28.41, envs finished 2
2026-01-17 13:21:37,659 : worker.worker : DEBUG : Step 62622, finished rewards -2.36, envs finished 1
2026-01-17 13:21:37,719 : agent.on_policy : DEBUG : Mean Losses: [16.26826924085617]
2026-01-17 13:21:37,789 : worker.worker : DEBUG : Step 62645, finished rewards 13.10, envs finished 1
2026-01-17 13:21:37,940 : agent.on_policy : DEBUG : Mean Losses: [3.9307585284113884]
2026-01-17 13:21:37,965 : worker.worker : DEBUG : Step 62664, finished rewards 2.09, envs finished 1
2026-01-17 13:21:38,140 : agent.on_policy : DEBUG : Mean Losses: [3.8881152644753456]
2026-01-17 13:21:38,156 : worker.worker : DEBUG : Step 62690, finished rewards 22.49, envs finished 1
2026-01-17 13:21:38,187 : worker.worker : DEBUG : Step 62697, finished rewards 24.30, envs finished 1
2026-01-17 13:21:38,217 : worker.worker : DEBUG : Step 62705, finished rewards 28.99, envs finished 1
2026-01-17 13:21:38,253 : worker.worker : DEBUG : Step 62714, finished rewards 23.99, envs finished 2
2026-01-17 13:21:38,323 : agent.on_policy : DEBUG : Mean Losses: [13.551081702113152]
2026-01-17 13:21:38,365 : worker.worker : DEBUG : Step 62733, finished rewards 26.56, envs finished 1
2026-01-17 13:21:38,400 : worker.worker : DEBUG : Step 62740, finished rewards 36.80, envs finished 1
2026-01-17 13:21:38,517 : agent.on_policy : DEBUG : Mean Losses: [6.966709166765213]
2026-01-17 13:21:38,598 : worker.worker : DEBUG : Step 62772, finished rewards -5.56, envs finished 1
2026-01-17 13:21:38,620 : worker.worker : DEBUG : Step 62776, finished rewards 29.19, envs finished 1
2026-01-17 13:21:38,647 : worker.worker : DEBUG : Step 62782, finished rewards 29.30, envs finished 1
2026-01-17 13:21:38,730 : agent.on_policy : DEBUG : Mean Losses: [9.909262016415596]
2026-01-17 13:21:38,778 : worker.worker : DEBUG : Step 62798, finished rewards 45.04, envs finished 1
2026-01-17 13:21:38,793 : worker.worker : DEBUG : Step 62800, finished rewards 29.52, envs finished 1
2026-01-17 13:21:38,823 : worker.worker : DEBUG : Step 62805, finished rewards 19.91, envs finished 1
2026-01-17 13:21:38,852 : worker.worker : DEBUG : Step 62810, finished rewards 23.54, envs finished 1
2026-01-17 13:21:38,918 : agent.on_policy : DEBUG : Mean Losses: [12.38084390759468]
2026-01-17 13:21:38,976 : worker.worker : DEBUG : Step 62834, finished rewards 23.95, envs finished 1
2026-01-17 13:21:39,090 : agent.on_policy : DEBUG : Mean Losses: [3.992007005959749]
2026-01-17 13:21:39,118 : worker.worker : DEBUG : Step 62855, finished rewards 31.72, envs finished 1
2026-01-17 13:21:39,244 : worker.worker : DEBUG : Step 62868, finished rewards 22.03, envs finished 1
2026-01-17 13:21:39,446 : agent.on_policy : DEBUG : Mean Losses: [6.218848370015621]
2026-01-17 13:21:39,472 : worker.worker : DEBUG : Step 62887, finished rewards 35.48, envs finished 1
2026-01-17 13:21:39,483 : worker.worker : DEBUG : Step 62889, finished rewards 21.11, envs finished 1
2026-01-17 13:21:39,488 : worker.worker : DEBUG : Step 62890, finished rewards 29.22, envs finished 1
2026-01-17 13:21:39,528 : worker.worker : DEBUG : Step 62898, finished rewards 20.67, envs finished 1
2026-01-17 13:21:39,572 : worker.worker : DEBUG : Step 62909, finished rewards 12.67, envs finished 1
2026-01-17 13:21:39,651 : agent.on_policy : DEBUG : Mean Losses: [11.994102537631989]
2026-01-17 13:21:39,718 : worker.worker : DEBUG : Step 62927, finished rewards 23.85, envs finished 1
2026-01-17 13:21:39,867 : agent.on_policy : DEBUG : Mean Losses: [3.70975960791111]
2026-01-17 13:21:39,892 : worker.worker : DEBUG : Step 62952, finished rewards 22.31, envs finished 1
2026-01-17 13:21:39,949 : worker.worker : DEBUG : Step 62968, finished rewards 17.63, envs finished 1
2026-01-17 13:21:40,015 : agent.on_policy : DEBUG : Mean Losses: [6.469304651021957]
2026-01-17 13:21:40,083 : worker.worker : DEBUG : Step 62988, finished rewards 19.53, envs finished 1
2026-01-17 13:21:40,093 : worker.worker : DEBUG : Step 62990, finished rewards 16.96, envs finished 1
2026-01-17 13:21:40,127 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.03949909390643791
2026-01-17 13:21:40,240 : agent.on_policy : DEBUG : Mean Losses: [7.682468235492706]
2026-01-17 13:21:40,246 : worker.worker : DEBUG : Step 63009, finished rewards 21.42, envs finished 1
2026-01-17 13:21:40,270 : worker.worker : DEBUG : Step 63014, finished rewards 7.19, envs finished 1
2026-01-17 13:21:40,287 : worker.worker : DEBUG : Step 63015, finished rewards 4.29, envs finished 1
2026-01-17 13:21:40,366 : worker.worker : DEBUG : Step 63034, finished rewards 11.03, envs finished 1
2026-01-17 13:21:40,459 : agent.on_policy : DEBUG : Mean Losses: [8.352967016398907]
2026-01-17 13:21:40,485 : worker.worker : DEBUG : Step 63047, finished rewards 24.11, envs finished 1
2026-01-17 13:21:40,580 : worker.worker : DEBUG : Step 63062, finished rewards 40.02, envs finished 1
2026-01-17 13:21:40,594 : worker.worker : DEBUG : Step 63064, finished rewards 22.10, envs finished 1
2026-01-17 13:21:40,788 : agent.on_policy : DEBUG : Mean Losses: [8.601770386099815]
2026-01-17 13:21:40,798 : worker.worker : DEBUG : Step 63074, finished rewards 28.33, envs finished 1
2026-01-17 13:21:40,895 : worker.worker : DEBUG : Step 63090, finished rewards 37.15, envs finished 1
2026-01-17 13:21:40,966 : worker.worker : DEBUG : Step 63103, finished rewards 29.07, envs finished 1
2026-01-17 13:21:41,026 : agent.on_policy : DEBUG : Mean Losses: [7.353841509670019]
2026-01-17 13:21:41,065 : worker.worker : DEBUG : Step 63107, finished rewards 20.89, envs finished 1
2026-01-17 13:21:41,163 : worker.worker : DEBUG : Step 63130, finished rewards 26.93, envs finished 1
2026-01-17 13:21:41,188 : worker.worker : DEBUG : Step 63135, finished rewards 40.24, envs finished 1
2026-01-17 13:21:41,284 : agent.on_policy : DEBUG : Mean Losses: [7.550583820790052]
2026-01-17 13:21:41,319 : worker.worker : DEBUG : Step 63145, finished rewards 31.68, envs finished 1
2026-01-17 13:21:41,361 : worker.worker : DEBUG : Step 63149, finished rewards 18.57, envs finished 1
2026-01-17 13:21:41,446 : worker.worker : DEBUG : Step 63167, finished rewards 24.42, envs finished 1
2026-01-17 13:21:41,496 : agent.on_policy : DEBUG : Mean Losses: [7.276207022368908]
2026-01-17 13:21:41,607 : worker.worker : DEBUG : Step 63189, finished rewards 32.06, envs finished 1
2026-01-17 13:21:41,614 : worker.worker : DEBUG : Step 63190, finished rewards 17.60, envs finished 1
2026-01-17 13:21:41,691 : agent.on_policy : DEBUG : Mean Losses: [7.15785539150238]
2026-01-17 13:21:41,752 : worker.worker : DEBUG : Step 63216, finished rewards 19.37, envs finished 1
2026-01-17 13:21:41,760 : worker.worker : DEBUG : Step 63217, finished rewards 31.87, envs finished 1
2026-01-17 13:21:41,804 : worker.worker : DEBUG : Step 63225, finished rewards 22.78, envs finished 1
2026-01-17 13:21:41,828 : worker.worker : DEBUG : Step 63229, finished rewards 29.95, envs finished 1
2026-01-17 13:21:41,949 : agent.on_policy : DEBUG : Mean Losses: [10.609639286994934]
2026-01-17 13:21:42,065 : worker.worker : DEBUG : Step 63254, finished rewards 27.39, envs finished 1
2026-01-17 13:21:42,091 : worker.worker : DEBUG : Step 63258, finished rewards 13.97, envs finished 1
2026-01-17 13:21:42,141 : worker.worker : DEBUG : Step 63263, finished rewards 38.67, envs finished 1
2026-01-17 13:21:42,236 : agent.on_policy : DEBUG : Mean Losses: [8.611765034496784]
2026-01-17 13:21:42,382 : worker.worker : DEBUG : Step 63285, finished rewards 24.68, envs finished 1
2026-01-17 13:21:42,508 : agent.on_policy : DEBUG : Mean Losses: [4.511197239160538]
2026-01-17 13:21:42,591 : worker.worker : DEBUG : Step 63315, finished rewards 26.25, envs finished 1
2026-01-17 13:21:42,604 : worker.worker : DEBUG : Step 63317, finished rewards 28.41, envs finished 1
2026-01-17 13:21:42,623 : worker.worker : DEBUG : Step 63321, finished rewards 21.26, envs finished 1
2026-01-17 13:21:42,774 : agent.on_policy : DEBUG : Mean Losses: [9.647492840886116]
2026-01-17 13:21:42,799 : worker.worker : DEBUG : Step 63334, finished rewards 40.29, envs finished 1
2026-01-17 13:21:42,827 : worker.worker : DEBUG : Step 63339, finished rewards 30.07, envs finished 1
2026-01-17 13:21:42,841 : worker.worker : DEBUG : Step 63341, finished rewards 31.94, envs finished 1
2026-01-17 13:21:42,964 : agent.on_policy : DEBUG : Mean Losses: [7.783785814419389]
2026-01-17 13:21:43,100 : worker.worker : DEBUG : Step 63386, finished rewards 20.99, envs finished 1
2026-01-17 13:21:43,195 : agent.on_policy : DEBUG : Mean Losses: [4.680508889257908]
2026-01-17 13:21:43,220 : worker.worker : DEBUG : Step 63398, finished rewards 31.58, envs finished 1
2026-01-17 13:21:43,327 : worker.worker : DEBUG : Step 63419, finished rewards 23.82, envs finished 1
2026-01-17 13:21:43,336 : worker.worker : DEBUG : Step 63421, finished rewards 16.64, envs finished 1
2026-01-17 13:21:43,343 : worker.worker : DEBUG : Step 63422, finished rewards 28.72, envs finished 1
2026-01-17 13:21:43,430 : agent.on_policy : DEBUG : Mean Losses: [11.585597898811102]
2026-01-17 13:21:43,432 : worker.worker : DEBUG : Step 63424, finished rewards 30.61, envs finished 1
2026-01-17 13:21:43,520 : worker.worker : DEBUG : Step 63443, finished rewards 42.53, envs finished 1
2026-01-17 13:21:43,660 : agent.on_policy : DEBUG : Mean Losses: [4.418410357087851]
2026-01-17 13:21:43,709 : worker.worker : DEBUG : Step 63471, finished rewards 29.89, envs finished 1
2026-01-17 13:21:43,807 : agent.on_policy : DEBUG : Mean Losses: [4.35374141484499]
2026-01-17 13:21:43,946 : worker.worker : DEBUG : Step 63516, finished rewards 23.06, envs finished 1
2026-01-17 13:21:43,958 : worker.worker : DEBUG : Step 63518, finished rewards 19.25, envs finished 1
2026-01-17 13:21:43,966 : worker.worker : DEBUG : Step 63519, finished rewards 14.73, envs finished 1
2026-01-17 13:21:44,031 : agent.on_policy : DEBUG : Mean Losses: [8.775918185710907]
2026-01-17 13:21:44,075 : worker.worker : DEBUG : Step 63528, finished rewards 12.74, envs finished 1
2026-01-17 13:21:44,150 : worker.worker : DEBUG : Step 63535, finished rewards 8.04, envs finished 1
2026-01-17 13:21:44,434 : agent.on_policy : DEBUG : Mean Losses: [6.140033591538668]
2026-01-17 13:21:44,484 : worker.worker : DEBUG : Step 63562, finished rewards 4.66, envs finished 1
2026-01-17 13:21:44,533 : worker.worker : DEBUG : Step 63573, finished rewards 17.57, envs finished 1
2026-01-17 13:21:44,652 : agent.on_policy : DEBUG : Mean Losses: [7.383309122174978]
2026-01-17 13:21:44,820 : worker.worker : DEBUG : Step 63614, finished rewards 23.71, envs finished 1
2026-01-17 13:21:44,892 : agent.on_policy : DEBUG : Mean Losses: [5.510047882795334]
2026-01-17 13:21:44,908 : worker.worker : DEBUG : Step 63618, finished rewards 20.09, envs finished 2
2026-01-17 13:21:44,952 : worker.worker : DEBUG : Step 63627, finished rewards 19.98, envs finished 1
2026-01-17 13:21:45,141 : agent.on_policy : DEBUG : Mean Losses: [5.291371390223503]
2026-01-17 13:21:45,164 : worker.worker : DEBUG : Step 63654, finished rewards 5.02, envs finished 1
2026-01-17 13:21:45,184 : worker.worker : DEBUG : Step 63658, finished rewards 30.39, envs finished 1
2026-01-17 13:21:45,224 : worker.worker : DEBUG : Step 63665, finished rewards 16.22, envs finished 1
2026-01-17 13:21:45,270 : worker.worker : DEBUG : Step 63674, finished rewards 79.31, envs finished 1
2026-01-17 13:21:45,365 : agent.on_policy : DEBUG : Mean Losses: [9.053375206887722]
2026-01-17 13:21:45,470 : worker.worker : DEBUG : Step 63699, finished rewards 32.49, envs finished 1
2026-01-17 13:21:45,593 : agent.on_policy : DEBUG : Mean Losses: [5.3632423132658005]
2026-01-17 13:21:45,601 : worker.worker : DEBUG : Step 63713, finished rewards 30.70, envs finished 1
2026-01-17 13:21:45,665 : worker.worker : DEBUG : Step 63718, finished rewards 22.33, envs finished 1
2026-01-17 13:21:45,817 : worker.worker : DEBUG : Step 63740, finished rewards 5.27, envs finished 1
2026-01-17 13:21:45,824 : worker.worker : DEBUG : Step 63741, finished rewards 31.03, envs finished 1
2026-01-17 13:21:45,893 : agent.on_policy : DEBUG : Mean Losses: [10.133111380040646]
2026-01-17 13:21:45,655 : worker.worker : DEBUG : Step 63769, finished rewards 40.62, envs finished 1
2026-01-17 13:21:45,256 : worker.worker : DEBUG : Step 63773, finished rewards 20.03, envs finished 1
2026-01-17 13:21:45,336 : agent.on_policy : DEBUG : Mean Losses: [7.395263290032744]
2026-01-17 13:21:45,345 : worker.worker : DEBUG : Step 63778, finished rewards 11.05, envs finished 2
2026-01-17 13:21:45,567 : agent.on_policy : DEBUG : Mean Losses: [3.3837556149810553]
2026-01-17 13:21:45,605 : worker.worker : DEBUG : Step 63819, finished rewards 35.10, envs finished 1
2026-01-17 13:21:45,610 : worker.worker : DEBUG : Step 63820, finished rewards 18.06, envs finished 1
2026-01-17 13:21:45,623 : worker.worker : DEBUG : Step 63822, finished rewards 11.64, envs finished 1
2026-01-17 13:21:45,658 : worker.worker : DEBUG : Step 63829, finished rewards 27.52, envs finished 1
2026-01-17 13:21:45,765 : agent.on_policy : DEBUG : Mean Losses: [11.779282987117767]
2026-01-17 13:21:45,842 : worker.worker : DEBUG : Step 63852, finished rewards 30.90, envs finished 1
2026-01-17 13:21:46,033 : agent.on_policy : DEBUG : Mean Losses: [4.0019466653466225]
2026-01-17 13:21:46,035 : worker.worker : DEBUG : Step 63872, finished rewards 21.56, envs finished 1
2026-01-17 13:21:46,061 : worker.worker : DEBUG : Step 63877, finished rewards 18.92, envs finished 1
2026-01-17 13:21:46,114 : worker.worker : DEBUG : Step 63889, finished rewards 11.54, envs finished 1
2026-01-17 13:21:46,146 : worker.worker : DEBUG : Step 63893, finished rewards 39.00, envs finished 1
2026-01-17 13:21:46,267 : agent.on_policy : DEBUG : Mean Losses: [7.896072223782539]
2026-01-17 13:21:46,332 : worker.worker : DEBUG : Step 63913, finished rewards 31.40, envs finished 1
2026-01-17 13:21:46,353 : worker.worker : DEBUG : Step 63916, finished rewards 21.29, envs finished 1
2026-01-17 13:21:46,409 : worker.worker : DEBUG : Step 63927, finished rewards 13.15, envs finished 1
2026-01-17 13:21:46,547 : agent.on_policy : DEBUG : Mean Losses: [7.285542547702789]
2026-01-17 13:21:46,770 : agent.on_policy : DEBUG : Mean Losses: [2.585191674530506]
2026-01-17 13:21:46,826 : worker.worker : DEBUG : Step 63977, finished rewards 13.60, envs finished 1
2026-01-17 13:21:46,876 : worker.worker : DEBUG : Step 63989, finished rewards 19.32, envs finished 1
2026-01-17 13:21:46,884 : worker.worker : DEBUG : Step 63990, finished rewards 15.81, envs finished 1
2026-01-17 13:21:46,900 : worker.worker : DEBUG : Step 63992, finished rewards 12.10, envs finished 1
2026-01-17 13:21:46,951 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.03752413921111601
2026-01-17 13:21:47,013 : agent.on_policy : DEBUG : Mean Losses: [10.718699008226395]
2026-01-17 13:21:47,056 : worker.worker : DEBUG : Step 64007, finished rewards 24.40, envs finished 1
2026-01-17 13:21:47,115 : worker.worker : DEBUG : Step 64013, finished rewards 22.02, envs finished 1
2026-01-17 13:21:47,248 : worker.worker : DEBUG : Step 64026, finished rewards 18.42, envs finished 1
2026-01-17 13:21:47,344 : agent.on_policy : DEBUG : Mean Losses: [7.849244859069586]
2026-01-17 13:21:47,461 : worker.worker : DEBUG : Step 64048, finished rewards -24.18, envs finished 1
2026-01-17 13:21:47,618 : agent.on_policy : DEBUG : Mean Losses: [4.0564156994223595]
2026-01-17 13:21:47,621 : worker.worker : DEBUG : Step 64064, finished rewards 29.34, envs finished 1
2026-01-17 13:21:47,679 : worker.worker : DEBUG : Step 64076, finished rewards 29.96, envs finished 2
2026-01-17 13:21:47,754 : worker.worker : DEBUG : Step 64093, finished rewards 30.19, envs finished 1
2026-01-17 13:21:47,856 : agent.on_policy : DEBUG : Mean Losses: [9.906143203377724]
2026-01-17 13:21:47,869 : worker.worker : DEBUG : Step 64098, finished rewards 30.96, envs finished 1
2026-01-17 13:21:47,984 : worker.worker : DEBUG : Step 64119, finished rewards 23.99, envs finished 1
2026-01-17 13:21:48,133 : agent.on_policy : DEBUG : Mean Losses: [4.985841311514378]
2026-01-17 13:21:48,215 : worker.worker : DEBUG : Step 64143, finished rewards 20.87, envs finished 1
2026-01-17 13:21:48,249 : worker.worker : DEBUG : Step 64147, finished rewards -5.69, envs finished 1
2026-01-17 13:21:48,385 : agent.on_policy : DEBUG : Mean Losses: [5.600777260959148]
2026-01-17 13:21:48,397 : worker.worker : DEBUG : Step 64162, finished rewards 29.39, envs finished 1
2026-01-17 13:21:48,409 : worker.worker : DEBUG : Step 64164, finished rewards 26.50, envs finished 1
2026-01-17 13:21:48,508 : worker.worker : DEBUG : Step 64185, finished rewards 11.20, envs finished 1
2026-01-17 13:21:48,520 : worker.worker : DEBUG : Step 64186, finished rewards 23.23, envs finished 1
2026-01-17 13:21:48,662 : agent.on_policy : DEBUG : Mean Losses: [7.8978037759661674]
2026-01-17 13:21:48,776 : worker.worker : DEBUG : Step 64207, finished rewards 26.25, envs finished 1
2026-01-17 13:21:49,010 : agent.on_policy : DEBUG : Mean Losses: [4.275219604372978]
2026-01-17 13:21:49,067 : worker.worker : DEBUG : Step 64236, finished rewards 39.89, envs finished 1
2026-01-17 13:21:49,094 : worker.worker : DEBUG : Step 64242, finished rewards -13.41, envs finished 1
2026-01-17 13:21:49,113 : worker.worker : DEBUG : Step 64245, finished rewards 18.51, envs finished 1
2026-01-17 13:21:49,249 : agent.on_policy : DEBUG : Mean Losses: [10.273608565330505]
2026-01-17 13:21:49,276 : worker.worker : DEBUG : Step 64264, finished rewards 14.09, envs finished 2
2026-01-17 13:21:49,309 : worker.worker : DEBUG : Step 64273, finished rewards 28.56, envs finished 1
2026-01-17 13:21:49,330 : worker.worker : DEBUG : Step 64278, finished rewards 25.17, envs finished 1
2026-01-17 13:21:49,413 : agent.on_policy : DEBUG : Mean Losses: [8.67907564342022]
2026-01-17 13:21:49,601 : agent.on_policy : DEBUG : Mean Losses: [3.0182271525263786]
2026-01-17 13:21:49,604 : worker.worker : DEBUG : Step 64320, finished rewards 13.62, envs finished 1
2026-01-17 13:21:49,683 : worker.worker : DEBUG : Step 64337, finished rewards 21.60, envs finished 1
2026-01-17 13:21:49,689 : worker.worker : DEBUG : Step 64338, finished rewards 17.92, envs finished 1
2026-01-17 13:21:49,854 : agent.on_policy : DEBUG : Mean Losses: [7.843146279454231]
2026-01-17 13:21:49,875 : worker.worker : DEBUG : Step 64356, finished rewards 10.81, envs finished 1
2026-01-17 13:21:49,924 : worker.worker : DEBUG : Step 64365, finished rewards 17.54, envs finished 1
2026-01-17 13:21:49,967 : worker.worker : DEBUG : Step 64373, finished rewards 17.49, envs finished 1
2026-01-17 13:21:50,082 : agent.on_policy : DEBUG : Mean Losses: [7.06724226474762]
2026-01-17 13:21:50,206 : worker.worker : DEBUG : Step 64404, finished rewards -2.85, envs finished 1
2026-01-17 13:21:50,397 : agent.on_policy : DEBUG : Mean Losses: [4.397630035877228]
2026-01-17 13:21:50,433 : worker.worker : DEBUG : Step 64419, finished rewards 32.03, envs finished 1
2026-01-17 13:21:50,466 : worker.worker : DEBUG : Step 64422, finished rewards 20.10, envs finished 1
2026-01-17 13:21:50,567 : worker.worker : DEBUG : Step 64441, finished rewards 29.71, envs finished 1
2026-01-17 13:21:50,609 : worker.worker : DEBUG : Step 64446, finished rewards 38.43, envs finished 1
2026-01-17 13:21:50,634 : worker.worker : DEBUG : Step 64447, finished rewards 17.59, envs finished 1
2026-01-17 13:21:50,720 : agent.on_policy : DEBUG : Mean Losses: [12.593948356807232]
2026-01-17 13:21:50,735 : worker.worker : DEBUG : Step 64450, finished rewards 29.56, envs finished 1
2026-01-17 13:21:51,030 : agent.on_policy : DEBUG : Mean Losses: [2.3573686853051186]
2026-01-17 13:21:51,100 : worker.worker : DEBUG : Step 64494, finished rewards 39.77, envs finished 1
2026-01-17 13:21:51,152 : worker.worker : DEBUG : Step 64505, finished rewards 84.97, envs finished 1
2026-01-17 13:21:51,167 : worker.worker : DEBUG : Step 64507, finished rewards 13.73, envs finished 1
2026-01-17 13:21:51,280 : agent.on_policy : DEBUG : Mean Losses: [9.39588563889265]
2026-01-17 13:21:51,311 : worker.worker : DEBUG : Step 64520, finished rewards 16.89, envs finished 1
2026-01-17 13:21:51,422 : worker.worker : DEBUG : Step 64531, finished rewards 29.92, envs finished 1
2026-01-17 13:21:51,590 : agent.on_policy : DEBUG : Mean Losses: [6.226688958704472]
2026-01-17 13:21:51,595 : worker.worker : DEBUG : Step 64545, finished rewards 20.59, envs finished 1
2026-01-17 13:21:51,622 : worker.worker : DEBUG : Step 64549, finished rewards 21.36, envs finished 1
2026-01-17 13:21:51,843 : agent.on_policy : DEBUG : Mean Losses: [3.5545762069523335]
2026-01-17 13:21:51,889 : worker.worker : DEBUG : Step 64587, finished rewards 1.61, envs finished 1
2026-01-17 13:21:51,912 : worker.worker : DEBUG : Step 64592, finished rewards 30.71, envs finished 1
2026-01-17 13:21:51,919 : worker.worker : DEBUG : Step 64593, finished rewards 20.74, envs finished 1
2026-01-17 13:21:51,967 : worker.worker : DEBUG : Step 64604, finished rewards 21.12, envs finished 1
2026-01-17 13:21:52,034 : agent.on_policy : DEBUG : Mean Losses: [10.370486572384834]
2026-01-17 13:21:52,082 : worker.worker : DEBUG : Step 64621, finished rewards 39.78, envs finished 1
2026-01-17 13:21:52,154 : worker.worker : DEBUG : Step 64634, finished rewards 17.70, envs finished 1
2026-01-17 13:21:52,168 : worker.worker : DEBUG : Step 64636, finished rewards 8.10, envs finished 1
2026-01-17 13:21:52,280 : agent.on_policy : DEBUG : Mean Losses: [9.09167841821909]
2026-01-17 13:21:52,506 : agent.on_policy : DEBUG : Mean Losses: [3.541246708482504]
2026-01-17 13:21:52,540 : worker.worker : DEBUG : Step 64678, finished rewards 30.51, envs finished 1
2026-01-17 13:21:52,547 : worker.worker : DEBUG : Step 64679, finished rewards 26.83, envs finished 1
2026-01-17 13:21:52,577 : worker.worker : DEBUG : Step 64683, finished rewards 10.63, envs finished 1
2026-01-17 13:21:52,600 : worker.worker : DEBUG : Step 64687, finished rewards 17.25, envs finished 1
2026-01-17 13:21:52,754 : agent.on_policy : DEBUG : Mean Losses: [10.11228159070015]
2026-01-17 13:21:52,780 : worker.worker : DEBUG : Step 64708, finished rewards 14.98, envs finished 1
2026-01-17 13:21:52,843 : worker.worker : DEBUG : Step 64724, finished rewards 24.90, envs finished 1
2026-01-17 13:21:52,852 : worker.worker : DEBUG : Step 64726, finished rewards 24.99, envs finished 1
2026-01-17 13:21:52,969 : agent.on_policy : DEBUG : Mean Losses: [9.337326630949974]
2026-01-17 13:21:53,046 : worker.worker : DEBUG : Step 64757, finished rewards -10.23, envs finished 1
2026-01-17 13:21:53,209 : agent.on_policy : DEBUG : Mean Losses: [3.9989735931158066]
2026-01-17 13:21:53,252 : worker.worker : DEBUG : Step 64783, finished rewards 15.09, envs finished 1
2026-01-17 13:21:53,267 : worker.worker : DEBUG : Step 64786, finished rewards 15.89, envs finished 1
2026-01-17 13:21:53,280 : worker.worker : DEBUG : Step 64788, finished rewards 11.03, envs finished 1
2026-01-17 13:21:53,369 : agent.on_policy : DEBUG : Mean Losses: [10.115143731236458]
2026-01-17 13:21:53,406 : worker.worker : DEBUG : Step 64811, finished rewards 16.32, envs finished 1
2026-01-17 13:21:53,417 : worker.worker : DEBUG : Step 64812, finished rewards 29.10, envs finished 1
2026-01-17 13:21:53,475 : worker.worker : DEBUG : Step 64821, finished rewards 20.30, envs finished 2
2026-01-17 13:21:53,558 : agent.on_policy : DEBUG : Mean Losses: [13.293173730373383]
2026-01-17 13:21:53,631 : worker.worker : DEBUG : Step 64844, finished rewards 12.37, envs finished 1
2026-01-17 13:21:53,767 : agent.on_policy : DEBUG : Mean Losses: [3.4268373996019363]
2026-01-17 13:21:53,820 : worker.worker : DEBUG : Step 64877, finished rewards 24.64, envs finished 1
2026-01-17 13:21:53,956 : agent.on_policy : DEBUG : Mean Losses: [5.851445198059082]
2026-01-17 13:21:53,966 : worker.worker : DEBUG : Step 64898, finished rewards 26.47, envs finished 1
2026-01-17 13:21:53,977 : worker.worker : DEBUG : Step 64900, finished rewards 21.56, envs finished 1
2026-01-17 13:21:54,032 : worker.worker : DEBUG : Step 64915, finished rewards 40.39, envs finished 1
2026-01-17 13:21:54,071 : worker.worker : DEBUG : Step 64926, finished rewards 16.61, envs finished 1
2026-01-17 13:21:54,160 : agent.on_policy : DEBUG : Mean Losses: [10.94897112250328]
2026-01-17 13:21:54,196 : worker.worker : DEBUG : Step 64935, finished rewards 5.87, envs finished 1
2026-01-17 13:21:54,250 : worker.worker : DEBUG : Step 64942, finished rewards 3.34, envs finished 1
2026-01-17 13:21:54,294 : worker.worker : DEBUG : Step 64949, finished rewards 3.19, envs finished 1
2026-01-17 13:21:54,445 : agent.on_policy : DEBUG : Mean Losses: [8.593898475170135]
2026-01-17 13:21:54,566 : worker.worker : DEBUG : Step 64990, finished rewards 9.78, envs finished 1
2026-01-17 13:21:54,659 : agent.on_policy : DEBUG : Mean Losses: [4.273134991526604]
2026-01-17 13:21:54,683 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.03564793225056021
2026-01-17 13:21:54,690 : worker.worker : DEBUG : Step 64999, finished rewards 19.03, envs finished 1
2026-01-17 13:21:54,706 : worker.worker : INFO : Step 65000, Avg Reward 8.8173, Max Reward 84.9735, Loss [6.77737897]
2026-01-17 13:21:54,724 : worker.worker : DEBUG : Step 65001, finished rewards 18.81, envs finished 1
2026-01-17 13:21:54,958 : agent.on_policy : DEBUG : Mean Losses: [5.872415691614151]
2026-01-17 13:21:54,959 : worker.worker : DEBUG : Step 65024, finished rewards 19.90, envs finished 1
2026-01-17 13:21:55,008 : worker.worker : DEBUG : Step 65035, finished rewards 8.04, envs finished 1
2026-01-17 13:21:55,088 : worker.worker : DEBUG : Step 65054, finished rewards 2.32, envs finished 1
2026-01-17 13:21:55,193 : agent.on_policy : DEBUG : Mean Losses: [6.975889779627323]
2026-01-17 13:21:55,260 : worker.worker : DEBUG : Step 65068, finished rewards 16.17, envs finished 1
2026-01-17 13:21:55,368 : worker.worker : DEBUG : Step 65077, finished rewards 26.73, envs finished 1
2026-01-17 13:21:55,551 : agent.on_policy : DEBUG : Mean Losses: [5.827812638133764]
2026-01-17 13:21:55,644 : worker.worker : DEBUG : Step 65111, finished rewards 10.92, envs finished 1
2026-01-17 13:21:55,776 : agent.on_policy : DEBUG : Mean Losses: [4.753739058971405]
2026-01-17 13:21:55,798 : worker.worker : DEBUG : Step 65123, finished rewards 9.30, envs finished 1
2026-01-17 13:21:55,824 : worker.worker : DEBUG : Step 65127, finished rewards 11.34, envs finished 1
2026-01-17 13:21:55,858 : worker.worker : DEBUG : Step 65133, finished rewards 16.73, envs finished 1
2026-01-17 13:21:55,870 : worker.worker : DEBUG : Step 65135, finished rewards 32.33, envs finished 1
2026-01-17 13:21:55,904 : worker.worker : DEBUG : Step 65141, finished rewards 40.38, envs finished 1
2026-01-17 13:21:55,947 : worker.worker : DEBUG : Step 65150, finished rewards 7.93, envs finished 1
2026-01-17 13:21:56,017 : agent.on_policy : DEBUG : Mean Losses: [15.281960785388947]
2026-01-17 13:21:56,064 : worker.worker : DEBUG : Step 65164, finished rewards 28.96, envs finished 1
2026-01-17 13:21:56,244 : agent.on_policy : DEBUG : Mean Losses: [2.9763657450675964]
2026-01-17 13:21:56,335 : worker.worker : DEBUG : Step 65205, finished rewards 24.33, envs finished 1
2026-01-17 13:21:56,499 : agent.on_policy : DEBUG : Mean Losses: [5.45505665242672]
2026-01-17 13:21:56,525 : worker.worker : DEBUG : Step 65223, finished rewards 24.53, envs finished 2
2026-01-17 13:21:56,552 : worker.worker : DEBUG : Step 65229, finished rewards 20.77, envs finished 1
2026-01-17 13:21:56,593 : worker.worker : DEBUG : Step 65237, finished rewards 26.43, envs finished 1
2026-01-17 13:21:56,640 : worker.worker : DEBUG : Step 65246, finished rewards 15.96, envs finished 1
2026-01-17 13:21:56,716 : agent.on_policy : DEBUG : Mean Losses: [12.872676283121109]
2026-01-17 13:21:56,722 : worker.worker : DEBUG : Step 65249, finished rewards 29.66, envs finished 1
2026-01-17 13:21:56,854 : worker.worker : DEBUG : Step 65273, finished rewards -11.97, envs finished 1
2026-01-17 13:21:56,892 : worker.worker : DEBUG : Step 65277, finished rewards 39.77, envs finished 1
2026-01-17 13:21:56,972 : agent.on_policy : DEBUG : Mean Losses: [6.47408189624548]
2026-01-17 13:21:57,129 : worker.worker : DEBUG : Step 65309, finished rewards 39.75, envs finished 1
2026-01-17 13:21:57,226 : agent.on_policy : DEBUG : Mean Losses: [5.172898426651955]
2026-01-17 13:21:57,308 : worker.worker : DEBUG : Step 65327, finished rewards 12.32, envs finished 1
2026-01-17 13:21:57,319 : worker.worker : DEBUG : Step 65329, finished rewards 15.25, envs finished 1
2026-01-17 13:21:57,368 : worker.worker : DEBUG : Step 65339, finished rewards 15.21, envs finished 1
2026-01-17 13:21:57,384 : worker.worker : DEBUG : Step 65341, finished rewards 21.13, envs finished 1
2026-01-17 13:21:57,455 : agent.on_policy : DEBUG : Mean Losses: [13.116294786334038]
2026-01-17 13:21:57,528 : worker.worker : DEBUG : Step 65364, finished rewards 7.55, envs finished 1
2026-01-17 13:21:57,635 : agent.on_policy : DEBUG : Mean Losses: [4.079525258392096]
2026-01-17 13:21:57,724 : worker.worker : DEBUG : Step 65397, finished rewards 3.37, envs finished 1
2026-01-17 13:21:57,738 : worker.worker : DEBUG : Step 65401, finished rewards 24.02, envs finished 1
2026-01-17 13:21:57,848 : agent.on_policy : DEBUG : Mean Losses: [7.5739913284778595]
2026-01-17 13:21:57,906 : worker.worker : DEBUG : Step 65421, finished rewards 21.75, envs finished 1
2026-01-17 13:21:57,910 : worker.worker : DEBUG : Step 65422, finished rewards 31.91, envs finished 1
2026-01-17 13:21:57,958 : worker.worker : DEBUG : Step 65432, finished rewards 24.95, envs finished 1
2026-01-17 13:21:58,055 : agent.on_policy : DEBUG : Mean Losses: [9.826615020632744]
2026-01-17 13:21:58,066 : worker.worker : DEBUG : Step 65443, finished rewards 12.70, envs finished 1
2026-01-17 13:21:58,248 : agent.on_policy : DEBUG : Mean Losses: [3.415762446820736]
2026-01-17 13:21:58,265 : worker.worker : DEBUG : Step 65477, finished rewards 9.81, envs finished 1
2026-01-17 13:21:58,281 : worker.worker : DEBUG : Step 65481, finished rewards 31.05, envs finished 1
2026-01-17 13:21:58,322 : worker.worker : DEBUG : Step 65490, finished rewards 26.86, envs finished 1
2026-01-17 13:21:58,333 : worker.worker : DEBUG : Step 65493, finished rewards 39.79, envs finished 1
2026-01-17 13:21:58,369 : worker.worker : DEBUG : Step 65502, finished rewards 80.36, envs finished 1
2026-01-17 13:21:58,426 : agent.on_policy : DEBUG : Mean Losses: [14.560601592063904]
2026-01-17 13:21:58,464 : worker.worker : DEBUG : Step 65515, finished rewards 31.65, envs finished 1
2026-01-17 13:21:58,477 : worker.worker : DEBUG : Step 65519, finished rewards 21.73, envs finished 1
2026-01-17 13:21:58,604 : agent.on_policy : DEBUG : Mean Losses: [6.701525317505002]
2026-01-17 13:21:58,618 : worker.worker : DEBUG : Step 65539, finished rewards 25.49, envs finished 1
2026-01-17 13:21:58,806 : agent.on_policy : DEBUG : Mean Losses: [3.3832127042114735]
2026-01-17 13:21:58,821 : worker.worker : DEBUG : Step 65572, finished rewards 31.97, envs finished 1
2026-01-17 13:21:58,841 : worker.worker : DEBUG : Step 65577, finished rewards 21.25, envs finished 1
2026-01-17 13:21:59,091 : agent.on_policy : DEBUG : Mean Losses: [6.149226188659668]
2026-01-17 13:21:59,097 : worker.worker : DEBUG : Step 65600, finished rewards 21.86, envs finished 1
2026-01-17 13:21:59,156 : worker.worker : DEBUG : Step 65605, finished rewards 27.72, envs finished 1
2026-01-17 13:21:59,174 : worker.worker : DEBUG : Step 65609, finished rewards 16.20, envs finished 2
2026-01-17 13:21:59,179 : worker.worker : DEBUG : Step 65610, finished rewards 40.23, envs finished 1
2026-01-17 13:21:59,200 : worker.worker : DEBUG : Step 65614, finished rewards 0.94, envs finished 1
2026-01-17 13:21:59,465 : agent.on_policy : DEBUG : Mean Losses: [10.582516349852085]
2026-01-17 13:21:59,552 : worker.worker : DEBUG : Step 65649, finished rewards 39.78, envs finished 1
2026-01-17 13:21:59,574 : worker.worker : DEBUG : Step 65653, finished rewards 32.86, envs finished 1
2026-01-17 13:21:59,693 : agent.on_policy : DEBUG : Mean Losses: [6.3757778108119965]
2026-01-17 13:21:59,787 : worker.worker : DEBUG : Step 65686, finished rewards 34.51, envs finished 1
2026-01-17 13:21:59,806 : worker.worker : DEBUG : Step 65691, finished rewards 34.53, envs finished 1
2026-01-17 13:21:59,902 : agent.on_policy : DEBUG : Mean Losses: [7.336601674556732]
2026-01-17 13:21:59,941 : worker.worker : DEBUG : Step 65706, finished rewards 24.49, envs finished 1
2026-01-17 13:21:59,947 : worker.worker : DEBUG : Step 65707, finished rewards 23.30, envs finished 1
2026-01-17 13:21:59,954 : worker.worker : DEBUG : Step 65708, finished rewards 11.26, envs finished 1
2026-01-17 13:22:00,052 : worker.worker : DEBUG : Step 65723, finished rewards 40.81, envs finished 1
2026-01-17 13:22:00,151 : agent.on_policy : DEBUG : Mean Losses: [11.211064115166664]
2026-01-17 13:22:00,271 : worker.worker : DEBUG : Step 65758, finished rewards 39.99, envs finished 1
2026-01-17 13:22:00,377 : agent.on_policy : DEBUG : Mean Losses: [5.289393976330757]
2026-01-17 13:22:00,464 : worker.worker : DEBUG : Step 65779, finished rewards 26.74, envs finished 1
2026-01-17 13:22:00,514 : worker.worker : DEBUG : Step 65791, finished rewards 30.81, envs finished 1
2026-01-17 13:22:00,596 : agent.on_policy : DEBUG : Mean Losses: [8.209270440042019]
2026-01-17 13:22:00,682 : worker.worker : DEBUG : Step 65809, finished rewards 24.41, envs finished 1
2026-01-17 13:22:00,691 : worker.worker : DEBUG : Step 65811, finished rewards 17.05, envs finished 1
2026-01-17 13:22:00,709 : worker.worker : DEBUG : Step 65814, finished rewards -19.08, envs finished 1
2026-01-17 13:22:00,819 : agent.on_policy : DEBUG : Mean Losses: [8.775154560804367]
2026-01-17 13:22:00,823 : worker.worker : DEBUG : Step 65825, finished rewards 15.63, envs finished 1
2026-01-17 13:22:00,827 : worker.worker : DEBUG : Step 65826, finished rewards 57.88, envs finished 1
2026-01-17 13:22:00,997 : agent.on_policy : DEBUG : Mean Losses: [2.637911692261696]
2026-01-17 13:22:01,017 : worker.worker : DEBUG : Step 65862, finished rewards 18.11, envs finished 1
2026-01-17 13:22:01,087 : worker.worker : DEBUG : Step 65879, finished rewards 27.10, envs finished 1
2026-01-17 13:22:01,197 : agent.on_policy : DEBUG : Mean Losses: [6.300135180354118]
2026-01-17 13:22:01,224 : worker.worker : DEBUG : Step 65894, finished rewards 7.79, envs finished 1
2026-01-17 13:22:01,258 : worker.worker : DEBUG : Step 65902, finished rewards 23.72, envs finished 1
2026-01-17 13:22:01,379 : agent.on_policy : DEBUG : Mean Losses: [5.3975991904735565]
2026-01-17 13:22:01,426 : worker.worker : DEBUG : Step 65929, finished rewards 17.22, envs finished 1
2026-01-17 13:22:01,468 : worker.worker : DEBUG : Step 65938, finished rewards 3.69, envs finished 1
2026-01-17 13:22:01,473 : worker.worker : DEBUG : Step 65939, finished rewards 20.33, envs finished 1
2026-01-17 13:22:01,561 : agent.on_policy : DEBUG : Mean Losses: [9.475050494074821]
2026-01-17 13:22:01,573 : worker.worker : DEBUG : Step 65955, finished rewards 23.26, envs finished 1
2026-01-17 13:22:01,766 : worker.worker : DEBUG : Step 65981, finished rewards 19.11, envs finished 1
2026-01-17 13:22:01,850 : agent.on_policy : DEBUG : Mean Losses: [5.139127969741821]
2026-01-17 13:22:01,937 : worker.worker : DEBUG : Step 65996, finished rewards 23.20, envs finished 1
2026-01-17 13:22:01,954 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.0338655356380322
2026-01-17 13:22:02,163 : agent.on_policy : DEBUG : Mean Losses: [4.559029690921307]
2026-01-17 13:22:02,172 : worker.worker : DEBUG : Step 66018, finished rewards 33.93, envs finished 1
2026-01-17 13:22:02,254 : worker.worker : DEBUG : Step 66035, finished rewards 17.08, envs finished 2
2026-01-17 13:22:02,378 : agent.on_policy : DEBUG : Mean Losses: [8.105248775333166]
2026-01-17 13:22:02,417 : worker.worker : DEBUG : Step 66054, finished rewards 49.14, envs finished 1
2026-01-17 13:22:02,479 : worker.worker : DEBUG : Step 66070, finished rewards 28.55, envs finished 1
2026-01-17 13:22:02,518 : worker.worker : DEBUG : Step 66078, finished rewards -32.86, envs finished 1
2026-01-17 13:22:02,644 : agent.on_policy : DEBUG : Mean Losses: [7.7528530433773994]
2026-01-17 13:22:02,709 : worker.worker : DEBUG : Step 66086, finished rewards 26.34, envs finished 1
2026-01-17 13:22:02,740 : worker.worker : DEBUG : Step 66090, finished rewards -12.80, envs finished 1
2026-01-17 13:22:02,960 : agent.on_policy : DEBUG : Mean Losses: [5.195771314203739]
2026-01-17 13:22:03,053 : worker.worker : DEBUG : Step 66135, finished rewards 19.67, envs finished 1
2026-01-17 13:22:03,057 : worker.worker : DEBUG : Step 66136, finished rewards 14.05, envs finished 1
2026-01-17 13:22:03,072 : worker.worker : DEBUG : Step 66140, finished rewards 29.33, envs finished 1
2026-01-17 13:22:03,173 : agent.on_policy : DEBUG : Mean Losses: [8.320565529167652]
2026-01-17 13:22:03,239 : worker.worker : DEBUG : Step 66158, finished rewards 28.45, envs finished 1
2026-01-17 13:22:03,294 : worker.worker : DEBUG : Step 66171, finished rewards 26.41, envs finished 1
2026-01-17 13:22:03,308 : worker.worker : DEBUG : Step 66174, finished rewards -8.89, envs finished 1
2026-01-17 13:22:03,406 : agent.on_policy : DEBUG : Mean Losses: [9.200957644730806]
2026-01-17 13:22:03,422 : worker.worker : DEBUG : Step 66180, finished rewards 25.34, envs finished 1
2026-01-17 13:22:03,485 : worker.worker : DEBUG : Step 66192, finished rewards 16.16, envs finished 1
2026-01-17 13:22:03,620 : agent.on_policy : DEBUG : Mean Losses: [3.918602267280221]
2026-01-17 13:22:03,673 : worker.worker : DEBUG : Step 66225, finished rewards 30.09, envs finished 1
2026-01-17 13:22:03,680 : worker.worker : DEBUG : Step 66227, finished rewards 26.72, envs finished 1
2026-01-17 13:22:03,800 : agent.on_policy : DEBUG : Mean Losses: [6.4255476370453835]
2026-01-17 13:22:03,835 : worker.worker : DEBUG : Step 66250, finished rewards 27.86, envs finished 1
2026-01-17 13:22:03,877 : worker.worker : DEBUG : Step 66261, finished rewards 13.63, envs finished 1
2026-01-17 13:22:03,883 : worker.worker : DEBUG : Step 66262, finished rewards 33.44, envs finished 1
2026-01-17 13:22:03,896 : worker.worker : DEBUG : Step 66264, finished rewards 33.30, envs finished 2
2026-01-17 13:22:03,996 : agent.on_policy : DEBUG : Mean Losses: [14.67011470720172]
2026-01-17 13:22:04,004 : worker.worker : DEBUG : Step 66274, finished rewards 16.43, envs finished 1
2026-01-17 13:22:04,202 : agent.on_policy : DEBUG : Mean Losses: [1.6107468716800213]
2026-01-17 13:22:04,381 : agent.on_policy : DEBUG : Mean Losses: [3.2166983410716057]
2026-01-17 13:22:04,414 : worker.worker : DEBUG : Step 66342, finished rewards 34.21, envs finished 1
2026-01-17 13:22:04,420 : worker.worker : DEBUG : Step 66343, finished rewards 10.91, envs finished 1
2026-01-17 13:22:04,428 : worker.worker : DEBUG : Step 66344, finished rewards 9.37, envs finished 1
2026-01-17 13:22:04,439 : worker.worker : DEBUG : Step 66346, finished rewards 35.61, envs finished 2
2026-01-17 13:22:04,450 : worker.worker : DEBUG : Step 66348, finished rewards 32.10, envs finished 1
2026-01-17 13:22:04,494 : worker.worker : DEBUG : Step 66358, finished rewards 12.89, envs finished 1
2026-01-17 13:22:04,574 : agent.on_policy : DEBUG : Mean Losses: [15.045474350452423]
2026-01-17 13:22:04,748 : agent.on_policy : DEBUG : Mean Losses: [0.6048401817679405]
2026-01-17 13:22:04,810 : worker.worker : DEBUG : Step 66421, finished rewards 33.95, envs finished 1
2026-01-17 13:22:04,842 : worker.worker : DEBUG : Step 66428, finished rewards 30.72, envs finished 1
2026-01-17 13:22:04,937 : agent.on_policy : DEBUG : Mean Losses: [8.07274143397808]
2026-01-17 13:22:04,945 : worker.worker : DEBUG : Step 66434, finished rewards 37.55, envs finished 1
2026-01-17 13:22:04,950 : worker.worker : DEBUG : Step 66435, finished rewards 24.01, envs finished 1
2026-01-17 13:22:05,014 : worker.worker : DEBUG : Step 66447, finished rewards 17.76, envs finished 1
2026-01-17 13:22:05,146 : agent.on_policy : DEBUG : Mean Losses: [7.595549039542675]
2026-01-17 13:22:05,195 : worker.worker : DEBUG : Step 66479, finished rewards 5.91, envs finished 1
2026-01-17 13:22:05,299 : agent.on_policy : DEBUG : Mean Losses: [5.588606372475624]
2026-01-17 13:22:05,339 : worker.worker : DEBUG : Step 66507, finished rewards 27.85, envs finished 1
2026-01-17 13:22:05,450 : worker.worker : DEBUG : Step 66526, finished rewards 23.59, envs finished 2
2026-01-17 13:22:05,529 : agent.on_policy : DEBUG : Mean Losses: [9.126734755933285]
2026-01-17 13:22:05,537 : worker.worker : DEBUG : Step 66530, finished rewards 16.48, envs finished 1
2026-01-17 13:22:05,564 : worker.worker : DEBUG : Step 66537, finished rewards 53.18, envs finished 1
2026-01-17 13:22:05,648 : worker.worker : DEBUG : Step 66557, finished rewards 10.61, envs finished 1
2026-01-17 13:22:05,753 : agent.on_policy : DEBUG : Mean Losses: [5.50973666831851]
2026-01-17 13:22:05,776 : worker.worker : DEBUG : Step 66567, finished rewards 27.03, envs finished 1
2026-01-17 13:22:05,863 : worker.worker : DEBUG : Step 66583, finished rewards 36.88, envs finished 1
2026-01-17 13:22:06,067 : agent.on_policy : DEBUG : Mean Losses: [5.755687236785889]
2026-01-17 13:22:06,181 : worker.worker : DEBUG : Step 66613, finished rewards 37.42, envs finished 1
2026-01-17 13:22:06,216 : worker.worker : DEBUG : Step 66619, finished rewards 24.88, envs finished 1
2026-01-17 13:22:06,323 : agent.on_policy : DEBUG : Mean Losses: [7.239250661805272]
2026-01-17 13:22:06,333 : worker.worker : DEBUG : Step 66626, finished rewards 18.01, envs finished 1
2026-01-17 13:22:06,354 : worker.worker : DEBUG : Step 66630, finished rewards 39.33, envs finished 1
2026-01-17 13:22:06,439 : worker.worker : DEBUG : Step 66647, finished rewards 6.69, envs finished 1
2026-01-17 13:22:06,546 : agent.on_policy : DEBUG : Mean Losses: [5.951453074812889]
2026-01-17 13:22:06,603 : worker.worker : DEBUG : Step 66668, finished rewards 29.37, envs finished 1
2026-01-17 13:22:06,675 : worker.worker : DEBUG : Step 66683, finished rewards 8.33, envs finished 1
2026-01-17 13:22:06,767 : agent.on_policy : DEBUG : Mean Losses: [6.664949834346771]
2026-01-17 13:22:06,834 : worker.worker : DEBUG : Step 66705, finished rewards 25.21, envs finished 1
2026-01-17 13:22:06,879 : worker.worker : DEBUG : Step 66712, finished rewards 26.83, envs finished 1
2026-01-17 13:22:06,987 : agent.on_policy : DEBUG : Mean Losses: [7.695365194231272]
2026-01-17 13:22:06,995 : worker.worker : DEBUG : Step 66722, finished rewards 137.41, envs finished 1
2026-01-17 13:22:07,026 : worker.worker : DEBUG : Step 66729, finished rewards 9.84, envs finished 1
2026-01-17 13:22:07,080 : worker.worker : DEBUG : Step 66737, finished rewards 25.48, envs finished 1
2026-01-17 13:22:07,191 : agent.on_policy : DEBUG : Mean Losses: [7.086416885256767]
2026-01-17 13:22:07,241 : worker.worker : DEBUG : Step 66762, finished rewards 4.12, envs finished 1
2026-01-17 13:22:07,264 : worker.worker : DEBUG : Step 66765, finished rewards 20.67, envs finished 1
2026-01-17 13:22:07,356 : worker.worker : DEBUG : Step 66777, finished rewards 44.70, envs finished 1
2026-01-17 13:22:07,369 : worker.worker : DEBUG : Step 66778, finished rewards 22.73, envs finished 1
2026-01-17 13:22:07,492 : agent.on_policy : DEBUG : Mean Losses: [11.540548361837864]
2026-01-17 13:22:07,545 : worker.worker : DEBUG : Step 66790, finished rewards 28.88, envs finished 1
2026-01-17 13:22:07,719 : agent.on_policy : DEBUG : Mean Losses: [3.1099010091274977]
2026-01-17 13:22:07,740 : worker.worker : DEBUG : Step 66822, finished rewards 26.53, envs finished 2
2026-01-17 13:22:07,759 : worker.worker : DEBUG : Step 66825, finished rewards 24.81, envs finished 1
2026-01-17 13:22:07,878 : agent.on_policy : DEBUG : Mean Losses: [6.431359201669693]
2026-01-17 13:22:07,934 : worker.worker : DEBUG : Step 66857, finished rewards 24.79, envs finished 1
2026-01-17 13:22:07,965 : worker.worker : DEBUG : Step 66863, finished rewards 13.59, envs finished 1
2026-01-17 13:22:08,109 : agent.on_policy : DEBUG : Mean Losses: [6.485669523477554]
2026-01-17 13:22:08,123 : worker.worker : DEBUG : Step 66884, finished rewards 12.54, envs finished 1
2026-01-17 13:22:08,138 : worker.worker : DEBUG : Step 66888, finished rewards 8.92, envs finished 1
2026-01-17 13:22:08,192 : worker.worker : DEBUG : Step 66903, finished rewards 20.10, envs finished 1
2026-01-17 13:22:08,268 : agent.on_policy : DEBUG : Mean Losses: [6.259834356606007]
2026-01-17 13:22:08,290 : worker.worker : DEBUG : Step 66915, finished rewards 23.69, envs finished 1
2026-01-17 13:22:08,319 : worker.worker : DEBUG : Step 66918, finished rewards 24.21, envs finished 1
2026-01-17 13:22:08,370 : worker.worker : DEBUG : Step 66928, finished rewards 12.27, envs finished 1
2026-01-17 13:22:08,521 : agent.on_policy : DEBUG : Mean Losses: [6.16239476762712]
2026-01-17 13:22:08,622 : worker.worker : DEBUG : Step 66972, finished rewards 30.27, envs finished 1
2026-01-17 13:22:08,705 : agent.on_policy : DEBUG : Mean Losses: [5.992751434445381]
2026-01-17 13:22:08,707 : worker.worker : DEBUG : Step 66976, finished rewards 10.34, envs finished 2
2026-01-17 13:22:08,763 : worker.worker : DEBUG : Step 66990, finished rewards 13.79, envs finished 1
2026-01-17 13:22:08,810 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.032172258856130585
2026-01-17 13:22:08,915 : agent.on_policy : DEBUG : Mean Losses: [4.684595603495836]
2026-01-17 13:22:08,975 : worker.worker : DEBUG : Step 67021, finished rewards 13.74, envs finished 1
2026-01-17 13:22:09,078 : worker.worker : DEBUG : Step 67030, finished rewards 9.82, envs finished 1
2026-01-17 13:22:09,222 : agent.on_policy : DEBUG : Mean Losses: [5.344600901007652]
2026-01-17 13:22:09,310 : worker.worker : DEBUG : Step 67048, finished rewards 39.77, envs finished 1
2026-01-17 13:22:09,333 : worker.worker : DEBUG : Step 67050, finished rewards 17.50, envs finished 1
2026-01-17 13:22:09,515 : worker.worker : DEBUG : Step 67064, finished rewards 16.13, envs finished 1
2026-01-17 13:22:09,597 : agent.on_policy : DEBUG : Mean Losses: [6.942377332597971]
2026-01-17 13:22:09,636 : worker.worker : DEBUG : Step 67084, finished rewards 13.67, envs finished 1
2026-01-17 13:22:09,645 : worker.worker : DEBUG : Step 67086, finished rewards 10.60, envs finished 1
2026-01-17 13:22:09,684 : worker.worker : DEBUG : Step 67091, finished rewards 18.35, envs finished 1
2026-01-17 13:22:09,790 : agent.on_policy : DEBUG : Mean Losses: [7.665522966533899]
2026-01-17 13:22:09,868 : worker.worker : DEBUG : Step 67122, finished rewards 21.01, envs finished 1
2026-01-17 13:22:09,916 : worker.worker : DEBUG : Step 67134, finished rewards 29.36, envs finished 1
2026-01-17 13:22:10,022 : agent.on_policy : DEBUG : Mean Losses: [6.41681782156229]
2026-01-17 13:22:10,092 : worker.worker : DEBUG : Step 67153, finished rewards 16.80, envs finished 1
2026-01-17 13:22:10,214 : agent.on_policy : DEBUG : Mean Losses: [4.385222941637039]
2026-01-17 13:22:10,223 : worker.worker : DEBUG : Step 67170, finished rewards 13.10, envs finished 1
2026-01-17 13:22:10,230 : worker.worker : DEBUG : Step 67171, finished rewards 12.70, envs finished 1
2026-01-17 13:22:10,265 : worker.worker : DEBUG : Step 67178, finished rewards 23.90, envs finished 1
2026-01-17 13:22:10,293 : worker.worker : DEBUG : Step 67185, finished rewards 23.05, envs finished 1
2026-01-17 13:22:10,403 : agent.on_policy : DEBUG : Mean Losses: [8.317788541316986]
2026-01-17 13:22:10,433 : worker.worker : DEBUG : Step 67206, finished rewards 0.43, envs finished 1
2026-01-17 13:22:10,532 : worker.worker : DEBUG : Step 67228, finished rewards 16.02, envs finished 1
2026-01-17 13:22:10,647 : agent.on_policy : DEBUG : Mean Losses: [5.210073828697205]
2026-01-17 13:22:10,656 : worker.worker : DEBUG : Step 67234, finished rewards 18.58, envs finished 1
2026-01-17 13:22:10,742 : worker.worker : DEBUG : Step 67248, finished rewards 22.24, envs finished 1
2026-01-17 13:22:10,753 : worker.worker : DEBUG : Step 67250, finished rewards 36.17, envs finished 2
2026-01-17 13:22:10,882 : agent.on_policy : DEBUG : Mean Losses: [10.29037994146347]
2026-01-17 13:22:10,931 : worker.worker : DEBUG : Step 67270, finished rewards 30.29, envs finished 1
2026-01-17 13:22:11,022 : worker.worker : DEBUG : Step 67290, finished rewards 31.14, envs finished 1
2026-01-17 13:22:11,123 : agent.on_policy : DEBUG : Mean Losses: [5.261236272752285]
2026-01-17 13:22:11,309 : agent.on_policy : DEBUG : Mean Losses: [2.5198507346212864]
2026-01-17 13:22:11,338 : worker.worker : DEBUG : Step 67337, finished rewards 16.48, envs finished 1
2026-01-17 13:22:11,357 : worker.worker : DEBUG : Step 67342, finished rewards 9.00, envs finished 1
2026-01-17 13:22:11,385 : worker.worker : DEBUG : Step 67347, finished rewards 63.88, envs finished 1
2026-01-17 13:22:11,392 : worker.worker : DEBUG : Step 67348, finished rewards 19.89, envs finished 1
2026-01-17 13:22:11,417 : worker.worker : DEBUG : Step 67352, finished rewards 18.13, envs finished 2
2026-01-17 13:22:11,500 : agent.on_policy : DEBUG : Mean Losses: [14.216708272695541]
2026-01-17 13:22:11,694 : agent.on_policy : DEBUG : Mean Losses: [1.1515235118567944]
2026-01-17 13:22:11,722 : worker.worker : DEBUG : Step 67402, finished rewards 18.71, envs finished 1
2026-01-17 13:22:11,827 : agent.on_policy : DEBUG : Mean Losses: [3.457300215959549]
2026-01-17 13:22:11,852 : worker.worker : DEBUG : Step 67430, finished rewards 24.07, envs finished 1
2026-01-17 13:22:11,963 : worker.worker : DEBUG : Step 67452, finished rewards 17.62, envs finished 1
2026-01-17 13:22:12,150 : agent.on_policy : DEBUG : Mean Losses: [6.0203337371349335]
2026-01-17 13:22:12,156 : worker.worker : DEBUG : Step 67457, finished rewards 13.96, envs finished 1
2026-01-17 13:22:12,164 : worker.worker : DEBUG : Step 67458, finished rewards 16.29, envs finished 1
2026-01-17 13:22:12,178 : worker.worker : DEBUG : Step 67459, finished rewards 12.85, envs finished 1
2026-01-17 13:22:12,234 : worker.worker : DEBUG : Step 67465, finished rewards 7.83, envs finished 1
2026-01-17 13:22:12,392 : worker.worker : DEBUG : Step 67485, finished rewards 60.99, envs finished 1
2026-01-17 13:22:12,492 : agent.on_policy : DEBUG : Mean Losses: [6.746756121516228]
2026-01-17 13:22:12,713 : agent.on_policy : DEBUG : Mean Losses: [1.8510722890496254]
2026-01-17 13:22:12,734 : worker.worker : DEBUG : Step 67527, finished rewards 1.39, envs finished 1
2026-01-17 13:22:12,801 : worker.worker : DEBUG : Step 67545, finished rewards 23.43, envs finished 1
2026-01-17 13:22:12,830 : worker.worker : DEBUG : Step 67550, finished rewards 7.23, envs finished 1
2026-01-17 13:22:12,838 : worker.worker : DEBUG : Step 67551, finished rewards 22.53, envs finished 1
2026-01-17 13:22:12,952 : agent.on_policy : DEBUG : Mean Losses: [12.162108302116394]
2026-01-17 13:22:12,958 : worker.worker : DEBUG : Step 67553, finished rewards 23.23, envs finished 1
2026-01-17 13:22:13,054 : worker.worker : DEBUG : Step 67563, finished rewards 14.73, envs finished 1
2026-01-17 13:22:13,099 : worker.worker : DEBUG : Step 67570, finished rewards 27.40, envs finished 1
2026-01-17 13:22:13,298 : agent.on_policy : DEBUG : Mean Losses: [6.753672324120998]
2026-01-17 13:22:13,343 : worker.worker : DEBUG : Step 67594, finished rewards 1.58, envs finished 1
2026-01-17 13:22:13,477 : agent.on_policy : DEBUG : Mean Losses: [3.5093699991703033]
2026-01-17 13:22:13,569 : worker.worker : DEBUG : Step 67633, finished rewards 17.01, envs finished 1
2026-01-17 13:22:13,785 : agent.on_policy : DEBUG : Mean Losses: [5.320839889347553]
2026-01-17 13:22:13,819 : worker.worker : DEBUG : Step 67652, finished rewards 15.58, envs finished 2
2026-01-17 13:22:13,998 : agent.on_policy : DEBUG : Mean Losses: [4.887565195560455]
2026-01-17 13:22:14,012 : worker.worker : DEBUG : Step 67682, finished rewards 6.99, envs finished 1
2026-01-17 13:22:14,098 : worker.worker : DEBUG : Step 67704, finished rewards -8.37, envs finished 1
2026-01-17 13:22:14,114 : worker.worker : DEBUG : Step 67708, finished rewards 9.77, envs finished 1
2026-01-17 13:22:14,218 : agent.on_policy : DEBUG : Mean Losses: [7.842337112873793]
2026-01-17 13:22:14,229 : worker.worker : DEBUG : Step 67714, finished rewards -46.83, envs finished 1
2026-01-17 13:22:14,326 : worker.worker : DEBUG : Step 67732, finished rewards 19.57, envs finished 1
2026-01-17 13:22:14,353 : worker.worker : DEBUG : Step 67738, finished rewards 28.16, envs finished 1
2026-01-17 13:22:14,448 : agent.on_policy : DEBUG : Mean Losses: [7.617189582437277]
2026-01-17 13:22:14,564 : worker.worker : DEBUG : Step 67767, finished rewards 21.54, envs finished 1
2026-01-17 13:22:14,684 : agent.on_policy : DEBUG : Mean Losses: [4.265555005520582]
2026-01-17 13:22:14,694 : worker.worker : DEBUG : Step 67778, finished rewards 22.32, envs finished 1
2026-01-17 13:22:14,885 : agent.on_policy : DEBUG : Mean Losses: [3.607921276241541]
2026-01-17 13:22:14,895 : worker.worker : DEBUG : Step 67810, finished rewards 17.26, envs finished 1
2026-01-17 13:22:14,987 : worker.worker : DEBUG : Step 67829, finished rewards -22.68, envs finished 1
2026-01-17 13:22:15,015 : worker.worker : DEBUG : Step 67834, finished rewards 3.10, envs finished 1
2026-01-17 13:22:15,105 : agent.on_policy : DEBUG : Mean Losses: [7.507786609232426]
2026-01-17 13:22:15,107 : worker.worker : DEBUG : Step 67840, finished rewards -1.93, envs finished 1
2026-01-17 13:22:15,156 : worker.worker : DEBUG : Step 67851, finished rewards 7.38, envs finished 1
2026-01-17 13:22:15,168 : worker.worker : DEBUG : Step 67852, finished rewards 13.09, envs finished 1
2026-01-17 13:22:14,521 : agent.on_policy : DEBUG : Mean Losses: [6.172706067562103]
2026-01-17 13:22:14,548 : worker.worker : DEBUG : Step 67881, finished rewards 11.75, envs finished 1
2026-01-17 13:22:14,584 : worker.worker : DEBUG : Step 67891, finished rewards 18.09, envs finished 1
2026-01-17 13:22:14,613 : worker.worker : DEBUG : Step 67898, finished rewards 27.63, envs finished 1
2026-01-17 13:22:14,706 : agent.on_policy : DEBUG : Mean Losses: [8.380479933694005]
2026-01-17 13:22:14,736 : worker.worker : DEBUG : Step 67911, finished rewards 40.61, envs finished 1
2026-01-17 13:22:14,836 : worker.worker : DEBUG : Step 67923, finished rewards 22.83, envs finished 1
2026-01-17 13:22:14,985 : agent.on_policy : DEBUG : Mean Losses: [6.136906713247299]
2026-01-17 13:22:15,026 : worker.worker : DEBUG : Step 67942, finished rewards 10.86, envs finished 1
2026-01-17 13:22:15,067 : worker.worker : DEBUG : Step 67951, finished rewards 19.02, envs finished 1
2026-01-17 13:22:15,205 : worker.worker : DEBUG : Step 67967, finished rewards 29.21, envs finished 1
2026-01-17 13:22:15,295 : agent.on_policy : DEBUG : Mean Losses: [8.671490088105202]
2026-01-17 13:22:15,322 : worker.worker : DEBUG : Step 67971, finished rewards 4.23, envs finished 1
2026-01-17 13:22:15,453 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.030563645913324056
2026-01-17 13:22:15,520 : agent.on_policy : DEBUG : Mean Losses: [2.859694831073284]
2026-01-17 13:22:15,536 : worker.worker : DEBUG : Step 68005, finished rewards 23.28, envs finished 1
2026-01-17 13:22:15,550 : worker.worker : DEBUG : Step 68008, finished rewards 9.57, envs finished 1
2026-01-17 13:22:15,656 : worker.worker : DEBUG : Step 68031, finished rewards 26.64, envs finished 1
2026-01-17 13:22:15,730 : agent.on_policy : DEBUG : Mean Losses: [8.137354329228401]
2026-01-17 13:22:15,744 : worker.worker : DEBUG : Step 68034, finished rewards 11.30, envs finished 1
2026-01-17 13:22:15,870 : worker.worker : DEBUG : Step 68062, finished rewards 9.98, envs finished 1
2026-01-17 13:22:15,954 : agent.on_policy : DEBUG : Mean Losses: [4.854018431156874]
2026-01-17 13:22:15,966 : worker.worker : DEBUG : Step 68067, finished rewards 20.98, envs finished 1
2026-01-17 13:22:16,057 : worker.worker : DEBUG : Step 68083, finished rewards 8.03, envs finished 1
2026-01-17 13:22:16,182 : agent.on_policy : DEBUG : Mean Losses: [4.781665667891502]
2026-01-17 13:22:16,196 : worker.worker : DEBUG : Step 68099, finished rewards 22.24, envs finished 1
2026-01-17 13:22:16,232 : worker.worker : DEBUG : Step 68102, finished rewards -59.28, envs finished 1
2026-01-17 13:22:16,319 : worker.worker : DEBUG : Step 68125, finished rewards 8.92, envs finished 1
2026-01-17 13:22:16,407 : agent.on_policy : DEBUG : Mean Losses: [7.267886653542519]
2026-01-17 13:22:16,423 : worker.worker : DEBUG : Step 68131, finished rewards 46.14, envs finished 1
2026-01-17 13:22:16,443 : worker.worker : DEBUG : Step 68135, finished rewards 19.29, envs finished 1
2026-01-17 13:22:16,493 : worker.worker : DEBUG : Step 68141, finished rewards 11.45, envs finished 1
2026-01-17 13:22:16,611 : agent.on_policy : DEBUG : Mean Losses: [6.189485881477594]
2026-01-17 13:22:16,697 : worker.worker : DEBUG : Step 68177, finished rewards 9.19, envs finished 1
2026-01-17 13:22:16,819 : agent.on_policy : DEBUG : Mean Losses: [4.586523987352848]
2026-01-17 13:22:16,868 : worker.worker : DEBUG : Step 68199, finished rewards 7.47, envs finished 1
2026-01-17 13:22:16,879 : worker.worker : DEBUG : Step 68200, finished rewards 19.83, envs finished 1
2026-01-17 13:22:16,926 : worker.worker : DEBUG : Step 68209, finished rewards 12.89, envs finished 1
2026-01-17 13:22:17,033 : worker.worker : DEBUG : Step 68223, finished rewards 25.40, envs finished 1
2026-01-17 13:22:17,131 : agent.on_policy : DEBUG : Mean Losses: [9.409340433776379]
2026-01-17 13:22:17,201 : worker.worker : DEBUG : Step 68237, finished rewards 13.85, envs finished 2
2026-01-17 13:22:17,346 : agent.on_policy : DEBUG : Mean Losses: [5.490575805306435]
2026-01-17 13:22:17,383 : worker.worker : DEBUG : Step 68264, finished rewards 5.86, envs finished 1
2026-01-17 13:22:17,570 : worker.worker : DEBUG : Step 68287, finished rewards 28.08, envs finished 1
2026-01-17 13:22:17,636 : agent.on_policy : DEBUG : Mean Losses: [6.471937671303749]
2026-01-17 13:22:17,671 : worker.worker : DEBUG : Step 68296, finished rewards 27.70, envs finished 1
2026-01-17 13:22:17,759 : worker.worker : DEBUG : Step 68313, finished rewards -10.54, envs finished 1
2026-01-17 13:22:17,767 : worker.worker : DEBUG : Step 68314, finished rewards 5.41, envs finished 1
2026-01-17 13:22:17,869 : agent.on_policy : DEBUG : Mean Losses: [8.605000361800194]
2026-01-17 13:22:17,895 : worker.worker : DEBUG : Step 68327, finished rewards 18.31, envs finished 1
2026-01-17 13:22:18,072 : agent.on_policy : DEBUG : Mean Losses: [4.587383089587092]
2026-01-17 13:22:18,122 : worker.worker : DEBUG : Step 68366, finished rewards 17.72, envs finished 1
2026-01-17 13:22:18,152 : worker.worker : DEBUG : Step 68373, finished rewards -5.05, envs finished 1
2026-01-17 13:22:18,175 : worker.worker : DEBUG : Step 68377, finished rewards 24.54, envs finished 1
2026-01-17 13:22:18,186 : worker.worker : DEBUG : Step 68378, finished rewards -7.47, envs finished 1
2026-01-17 13:22:18,293 : agent.on_policy : DEBUG : Mean Losses: [12.258989058434963]
2026-01-17 13:22:18,357 : worker.worker : DEBUG : Step 68399, finished rewards 19.34, envs finished 1
2026-01-17 13:22:18,486 : agent.on_policy : DEBUG : Mean Losses: [3.745898298919201]
2026-01-17 13:22:18,563 : worker.worker : DEBUG : Step 68438, finished rewards 11.04, envs finished 2
2026-01-17 13:22:18,690 : agent.on_policy : DEBUG : Mean Losses: [7.004952594637871]
2026-01-17 13:22:18,778 : worker.worker : DEBUG : Step 68457, finished rewards 0.08, envs finished 1
2026-01-17 13:22:19,017 : agent.on_policy : DEBUG : Mean Losses: [4.779515773057938]
2026-01-17 13:22:19,047 : worker.worker : DEBUG : Step 68488, finished rewards 12.79, envs finished 1
2026-01-17 13:22:19,065 : worker.worker : DEBUG : Step 68492, finished rewards 15.17, envs finished 2
2026-01-17 13:22:19,129 : worker.worker : DEBUG : Step 68510, finished rewards -0.83, envs finished 1
2026-01-17 13:22:19,192 : agent.on_policy : DEBUG : Mean Losses: [9.763318732380867]
2026-01-17 13:22:19,210 : worker.worker : DEBUG : Step 68515, finished rewards 4.37, envs finished 1
2026-01-17 13:22:19,420 : agent.on_policy : DEBUG : Mean Losses: [2.4330241978168488]
2026-01-17 13:22:19,446 : worker.worker : DEBUG : Step 68550, finished rewards 13.31, envs finished 1
2026-01-17 13:22:19,489 : worker.worker : DEBUG : Step 68561, finished rewards 16.97, envs finished 1
2026-01-17 13:22:19,589 : agent.on_policy : DEBUG : Mean Losses: [5.529612630605698]
2026-01-17 13:22:19,626 : worker.worker : DEBUG : Step 68585, finished rewards 20.68, envs finished 1
2026-01-17 13:22:19,653 : worker.worker : DEBUG : Step 68588, finished rewards 21.99, envs finished 1
2026-01-17 13:22:19,722 : worker.worker : DEBUG : Step 68602, finished rewards 25.96, envs finished 1
2026-01-17 13:22:19,795 : agent.on_policy : DEBUG : Mean Losses: [8.035064667463303]
2026-01-17 13:22:19,869 : worker.worker : DEBUG : Step 68618, finished rewards 30.75, envs finished 1
2026-01-17 13:22:20,036 : agent.on_policy : DEBUG : Mean Losses: [2.9404725283384323]
2026-01-17 13:22:20,107 : worker.worker : DEBUG : Step 68658, finished rewards 26.08, envs finished 2
2026-01-17 13:22:20,152 : worker.worker : DEBUG : Step 68670, finished rewards 64.65, envs finished 1
2026-01-17 13:22:20,256 : agent.on_policy : DEBUG : Mean Losses: [9.600430198013783]
2026-01-17 13:22:20,279 : worker.worker : DEBUG : Step 68678, finished rewards 21.19, envs finished 1
2026-01-17 13:22:20,337 : worker.worker : DEBUG : Step 68689, finished rewards -1.02, envs finished 1
2026-01-17 13:22:20,471 : agent.on_policy : DEBUG : Mean Losses: [6.3340794891119]
2026-01-17 13:22:20,478 : worker.worker : DEBUG : Step 68705, finished rewards 17.71, envs finished 1
2026-01-17 13:22:20,539 : worker.worker : DEBUG : Step 68722, finished rewards 12.90, envs finished 1
2026-01-17 13:22:20,572 : worker.worker : DEBUG : Step 68730, finished rewards 40.98, envs finished 1
2026-01-17 13:22:20,665 : agent.on_policy : DEBUG : Mean Losses: [7.80383226275444]
2026-01-17 13:22:20,703 : worker.worker : DEBUG : Step 68747, finished rewards -24.88, envs finished 1
2026-01-17 13:22:20,782 : worker.worker : DEBUG : Step 68760, finished rewards 25.68, envs finished 1
2026-01-17 13:22:20,872 : agent.on_policy : DEBUG : Mean Losses: [6.9622099213302135]
2026-01-17 13:22:20,977 : worker.worker : DEBUG : Step 68788, finished rewards 0.08, envs finished 1
2026-01-17 13:22:21,067 : worker.worker : DEBUG : Step 68796, finished rewards 2.62, envs finished 1
2026-01-17 13:22:21,205 : agent.on_policy : DEBUG : Mean Losses: [7.627368159592152]
2026-01-17 13:22:21,274 : worker.worker : DEBUG : Step 68821, finished rewards 22.88, envs finished 1
2026-01-17 13:22:21,308 : worker.worker : DEBUG : Step 68829, finished rewards 5.26, envs finished 1
2026-01-17 13:22:21,403 : agent.on_policy : DEBUG : Mean Losses: [8.629444118589163]
2026-01-17 13:22:21,407 : worker.worker : DEBUG : Step 68832, finished rewards -11.79, envs finished 1
2026-01-17 13:22:21,414 : worker.worker : DEBUG : Step 68833, finished rewards 30.20, envs finished 1
2026-01-17 13:22:21,627 : worker.worker : DEBUG : Step 68860, finished rewards 20.79, envs finished 1
2026-01-17 13:22:21,726 : agent.on_policy : DEBUG : Mean Losses: [4.880992140620947]
2026-01-17 13:22:21,737 : worker.worker : DEBUG : Step 68866, finished rewards -6.61, envs finished 1
2026-01-17 13:22:21,848 : worker.worker : DEBUG : Step 68881, finished rewards 23.46, envs finished 1
2026-01-17 13:22:22,024 : agent.on_policy : DEBUG : Mean Losses: [4.573228670284152]
2026-01-17 13:22:22,030 : worker.worker : DEBUG : Step 68897, finished rewards 18.29, envs finished 1
2026-01-17 13:22:22,064 : worker.worker : DEBUG : Step 68905, finished rewards 30.95, envs finished 1
2026-01-17 13:22:22,129 : worker.worker : DEBUG : Step 68920, finished rewards 23.83, envs finished 1
2026-01-17 13:22:22,229 : agent.on_policy : DEBUG : Mean Losses: [7.40889448300004]
2026-01-17 13:22:22,300 : worker.worker : DEBUG : Step 68947, finished rewards 4.97, envs finished 1
2026-01-17 13:22:22,310 : worker.worker : DEBUG : Step 68949, finished rewards 26.52, envs finished 1
2026-01-17 13:22:22,331 : worker.worker : DEBUG : Step 68952, finished rewards 14.33, envs finished 1
2026-01-17 13:22:22,478 : agent.on_policy : DEBUG : Mean Losses: [8.380470350384712]
2026-01-17 13:22:22,507 : worker.worker : DEBUG : Step 68967, finished rewards 18.85, envs finished 1
2026-01-17 13:22:22,556 : worker.worker : DEBUG : Step 68978, finished rewards 31.76, envs finished 1
2026-01-17 13:22:22,668 : agent.on_policy : DEBUG : Mean Losses: [6.779823783785105]
2026-01-17 13:22:22,680 : worker.worker : DEBUG : Step 68995, finished rewards 17.96, envs finished 1
2026-01-17 13:22:22,698 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.029035463617657853
2026-01-17 13:22:22,727 : worker.worker : DEBUG : Step 69001, finished rewards 22.22, envs finished 1
2026-01-17 13:22:22,751 : worker.worker : DEBUG : Step 69005, finished rewards 29.35, envs finished 1
2026-01-17 13:22:22,819 : worker.worker : DEBUG : Step 69021, finished rewards 39.49, envs finished 1
2026-01-17 13:22:22,873 : agent.on_policy : DEBUG : Mean Losses: [9.024254389107227]
2026-01-17 13:22:23,074 : agent.on_policy : DEBUG : Mean Losses: [1.951525829732418]
2026-01-17 13:22:23,088 : worker.worker : DEBUG : Step 69060, finished rewards 22.07, envs finished 1
2026-01-17 13:22:23,157 : worker.worker : DEBUG : Step 69076, finished rewards 9.85, envs finished 1
2026-01-17 13:22:23,190 : worker.worker : DEBUG : Step 69082, finished rewards 27.17, envs finished 1
2026-01-17 13:22:23,285 : agent.on_policy : DEBUG : Mean Losses: [10.827063873410225]
2026-01-17 13:22:23,386 : worker.worker : DEBUG : Step 69111, finished rewards 12.53, envs finished 1
2026-01-17 13:22:23,499 : agent.on_policy : DEBUG : Mean Losses: [4.759989522397518]
2026-01-17 13:22:23,503 : worker.worker : DEBUG : Step 69120, finished rewards 3.06, envs finished 1
2026-01-17 13:22:23,603 : worker.worker : DEBUG : Step 69142, finished rewards 2.93, envs finished 1
2026-01-17 13:22:23,611 : worker.worker : DEBUG : Step 69144, finished rewards 5.84, envs finished 1
2026-01-17 13:22:23,710 : agent.on_policy : DEBUG : Mean Losses: [7.71860034763813]
2026-01-17 13:22:23,813 : worker.worker : DEBUG : Step 69171, finished rewards 14.19, envs finished 1
2026-01-17 13:22:23,966 : agent.on_policy : DEBUG : Mean Losses: [3.5420685298740864]
2026-01-17 13:22:24,027 : worker.worker : DEBUG : Step 69203, finished rewards 23.84, envs finished 1
2026-01-17 13:22:24,143 : agent.on_policy : DEBUG : Mean Losses: [5.127420544624329]
2026-01-17 13:22:24,210 : worker.worker : DEBUG : Step 69229, finished rewards 19.54, envs finished 1
2026-01-17 13:22:24,221 : worker.worker : DEBUG : Step 69231, finished rewards -15.40, envs finished 1
2026-01-17 13:22:24,288 : worker.worker : DEBUG : Step 69247, finished rewards 16.40, envs finished 1
2026-01-17 13:22:24,376 : agent.on_policy : DEBUG : Mean Losses: [7.576996356248856]
2026-01-17 13:22:24,462 : worker.worker : DEBUG : Step 69254, finished rewards 10.60, envs finished 1
2026-01-17 13:22:24,554 : worker.worker : DEBUG : Step 69266, finished rewards 0.91, envs finished 1
2026-01-17 13:22:24,740 : agent.on_policy : DEBUG : Mean Losses: [4.622410958632827]
2026-01-17 13:22:24,766 : worker.worker : DEBUG : Step 69288, finished rewards 7.19, envs finished 1
2026-01-17 13:22:24,820 : worker.worker : DEBUG : Step 69304, finished rewards 17.97, envs finished 1
2026-01-17 13:22:24,896 : agent.on_policy : DEBUG : Mean Losses: [5.244056444615126]
2026-01-17 13:22:25,007 : worker.worker : DEBUG : Step 69338, finished rewards 52.66, envs finished 2
2026-01-17 13:22:25,024 : worker.worker : DEBUG : Step 69341, finished rewards 28.00, envs finished 1
2026-01-17 13:22:25,121 : agent.on_policy : DEBUG : Mean Losses: [10.083391308784485]
2026-01-17 13:22:25,140 : worker.worker : DEBUG : Step 69350, finished rewards 18.02, envs finished 1
2026-01-17 13:22:25,182 : worker.worker : DEBUG : Step 69356, finished rewards 26.45, envs finished 1
2026-01-17 13:22:25,270 : worker.worker : DEBUG : Step 69375, finished rewards -14.75, envs finished 1
2026-01-17 13:22:25,334 : agent.on_policy : DEBUG : Mean Losses: [7.0547704473137856]
2026-01-17 13:22:25,447 : worker.worker : DEBUG : Step 69398, finished rewards 21.22, envs finished 1
2026-01-17 13:22:25,524 : agent.on_policy : DEBUG : Mean Losses: [4.7708435729146]
2026-01-17 13:22:25,548 : worker.worker : DEBUG : Step 69413, finished rewards 1.90, envs finished 1
2026-01-17 13:22:25,632 : worker.worker : DEBUG : Step 69427, finished rewards 28.90, envs finished 1
2026-01-17 13:22:25,746 : agent.on_policy : DEBUG : Mean Losses: [6.864190820604563]
2026-01-17 13:22:25,802 : worker.worker : DEBUG : Step 69450, finished rewards 8.92, envs finished 1
2026-01-17 13:22:25,833 : worker.worker : DEBUG : Step 69457, finished rewards 5.42, envs finished 1
2026-01-17 13:22:25,843 : worker.worker : DEBUG : Step 69459, finished rewards 15.49, envs finished 1
2026-01-17 13:22:25,937 : worker.worker : DEBUG : Step 69471, finished rewards 20.62, envs finished 1
2026-01-17 13:22:25,990 : agent.on_policy : DEBUG : Mean Losses: [10.888541840016842]
2026-01-17 13:22:26,022 : worker.worker : DEBUG : Step 69476, finished rewards 7.53, envs finished 1
2026-01-17 13:22:26,106 : worker.worker : DEBUG : Step 69492, finished rewards 23.88, envs finished 1
2026-01-17 13:22:26,149 : worker.worker : DEBUG : Step 69500, finished rewards 27.42, envs finished 1
2026-01-17 13:22:26,257 : agent.on_policy : DEBUG : Mean Losses: [7.945788152515888]
2026-01-17 13:22:26,305 : worker.worker : DEBUG : Step 69515, finished rewards 25.01, envs finished 1
2026-01-17 13:22:26,419 : agent.on_policy : DEBUG : Mean Losses: [3.9378612861037254]
2026-01-17 13:22:26,486 : worker.worker : DEBUG : Step 69548, finished rewards 19.11, envs finished 1
2026-01-17 13:22:26,629 : agent.on_policy : DEBUG : Mean Losses: [4.8435054533183575]
2026-01-17 13:22:26,645 : worker.worker : DEBUG : Step 69571, finished rewards 10.00, envs finished 1
2026-01-17 13:22:26,713 : worker.worker : DEBUG : Step 69587, finished rewards 5.96, envs finished 2
2026-01-17 13:22:26,730 : worker.worker : DEBUG : Step 69590, finished rewards 5.46, envs finished 1
2026-01-17 13:22:26,867 : agent.on_policy : DEBUG : Mean Losses: [10.806808657944202]
2026-01-17 13:22:26,912 : worker.worker : DEBUG : Step 69614, finished rewards 2.40, envs finished 1
2026-01-17 13:22:26,929 : worker.worker : DEBUG : Step 69617, finished rewards 6.59, envs finished 1
2026-01-17 13:22:27,016 : agent.on_policy : DEBUG : Mean Losses: [5.255772825330496]
2026-01-17 13:22:27,153 : worker.worker : DEBUG : Step 69663, finished rewards 22.74, envs finished 2
2026-01-17 13:22:27,209 : agent.on_policy : DEBUG : Mean Losses: [6.8601288869977]
2026-01-17 13:22:27,244 : worker.worker : DEBUG : Step 69671, finished rewards -23.31, envs finished 1
2026-01-17 13:22:27,254 : worker.worker : DEBUG : Step 69673, finished rewards 28.44, envs finished 1
2026-01-17 13:22:27,523 : agent.on_policy : DEBUG : Mean Losses: [5.39946636557579]
2026-01-17 13:22:27,536 : worker.worker : DEBUG : Step 69699, finished rewards 6.74, envs finished 1
2026-01-17 13:22:27,574 : worker.worker : DEBUG : Step 69710, finished rewards 24.22, envs finished 1
2026-01-17 13:22:27,629 : worker.worker : DEBUG : Step 69724, finished rewards -5.77, envs finished 1
2026-01-17 13:22:27,697 : agent.on_policy : DEBUG : Mean Losses: [6.3728746101260185]
2026-01-17 13:22:27,853 : worker.worker : DEBUG : Step 69759, finished rewards 22.61, envs finished 1
2026-01-17 13:22:27,913 : agent.on_policy : DEBUG : Mean Losses: [5.562329735606909]
2026-01-17 13:22:27,943 : worker.worker : DEBUG : Step 69767, finished rewards 20.12, envs finished 1
2026-01-17 13:22:27,968 : worker.worker : DEBUG : Step 69773, finished rewards 18.62, envs finished 1
2026-01-17 13:22:27,986 : worker.worker : DEBUG : Step 69776, finished rewards -30.80, envs finished 1
2026-01-17 13:22:28,121 : agent.on_policy : DEBUG : Mean Losses: [8.97139222547412]
2026-01-17 13:22:28,130 : worker.worker : DEBUG : Step 69793, finished rewards -4.21, envs finished 1
2026-01-17 13:22:28,213 : worker.worker : DEBUG : Step 69811, finished rewards 18.22, envs finished 1
2026-01-17 13:22:28,354 : agent.on_policy : DEBUG : Mean Losses: [6.072528354823589]
2026-01-17 13:22:28,527 : worker.worker : DEBUG : Step 69851, finished rewards 34.51, envs finished 1
2026-01-17 13:22:28,617 : agent.on_policy : DEBUG : Mean Losses: [5.362166672945023]
2026-01-17 13:22:28,626 : worker.worker : DEBUG : Step 69857, finished rewards 0.48, envs finished 1
2026-01-17 13:22:28,739 : worker.worker : DEBUG : Step 69876, finished rewards 5.00, envs finished 1
2026-01-17 13:22:28,824 : worker.worker : DEBUG : Step 69886, finished rewards 11.95, envs finished 1
2026-01-17 13:22:28,886 : agent.on_policy : DEBUG : Mean Losses: [7.578243553638458]
2026-01-17 13:22:28,902 : worker.worker : DEBUG : Step 69888, finished rewards 11.11, envs finished 1
2026-01-17 13:22:29,055 : worker.worker : DEBUG : Step 69910, finished rewards 8.85, envs finished 1
2026-01-17 13:22:29,277 : agent.on_policy : DEBUG : Mean Losses: [4.012655822560191]
2026-01-17 13:22:29,314 : worker.worker : DEBUG : Step 69928, finished rewards -8.06, envs finished 1
2026-01-17 13:22:29,443 : agent.on_policy : DEBUG : Mean Losses: [3.945958137512207]
2026-01-17 13:22:29,524 : worker.worker : DEBUG : Step 69968, finished rewards 2.39, envs finished 1
2026-01-17 13:22:29,546 : worker.worker : DEBUG : Step 69973, finished rewards 13.18, envs finished 1
2026-01-17 13:22:29,588 : worker.worker : DEBUG : Step 69982, finished rewards 23.98, envs finished 1
2026-01-17 13:22:29,684 : agent.on_policy : DEBUG : Mean Losses: [9.194417506456375]
2026-01-17 13:22:29,712 : worker.worker : DEBUG : Step 69991, finished rewards 7.64, envs finished 1
2026-01-17 13:22:29,734 : worker.worker : DEBUG : Step 69996, finished rewards 28.57, envs finished 1
2026-01-17 13:22:29,757 : worker.worker : DEBUG : Step 69997, finished rewards 17.73, envs finished 1
2026-01-17 13:22:29,763 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.027583690436774957
2026-01-17 13:22:29,793 : worker.worker : INFO : Step 70000, Avg Reward 18.2981, Max Reward 137.4129, Loss [6.68143113]
2026-01-17 13:22:29,983 : agent.on_policy : DEBUG : Mean Losses: [7.217440582811832]
2026-01-17 13:22:29,999 : worker.worker : DEBUG : Step 70018, finished rewards -7.50, envs finished 1
2026-01-17 13:22:30,081 : worker.worker : DEBUG : Step 70039, finished rewards 9.89, envs finished 1
2026-01-17 13:22:30,174 : agent.on_policy : DEBUG : Mean Losses: [3.3374462500214577]
2026-01-17 13:22:30,259 : worker.worker : DEBUG : Step 70062, finished rewards 23.67, envs finished 1
2026-01-17 13:22:30,331 : worker.worker : DEBUG : Step 70076, finished rewards 23.40, envs finished 1
2026-01-17 13:22:30,451 : agent.on_policy : DEBUG : Mean Losses: [7.9221274852752686]
2026-01-17 13:22:30,483 : worker.worker : DEBUG : Step 70091, finished rewards 19.76, envs finished 1
2026-01-17 13:22:30,504 : worker.worker : DEBUG : Step 70096, finished rewards 19.16, envs finished 1
2026-01-17 13:22:30,579 : worker.worker : DEBUG : Step 70102, finished rewards 2.46, envs finished 1
2026-01-17 13:22:30,586 : worker.worker : DEBUG : Step 70103, finished rewards 12.32, envs finished 1
2026-01-17 13:22:30,764 : agent.on_policy : DEBUG : Mean Losses: [9.90412213653326]
2026-01-17 13:22:30,920 : worker.worker : DEBUG : Step 70141, finished rewards 17.55, envs finished 1
2026-01-17 13:22:31,003 : agent.on_policy : DEBUG : Mean Losses: [4.393367860466242]
2026-01-17 13:22:31,088 : worker.worker : DEBUG : Step 70160, finished rewards -11.91, envs finished 1
2026-01-17 13:22:31,290 : agent.on_policy : DEBUG : Mean Losses: [5.455363214015961]
2026-01-17 13:22:31,291 : worker.worker : DEBUG : Step 70176, finished rewards 18.43, envs finished 1
2026-01-17 13:22:31,352 : worker.worker : DEBUG : Step 70188, finished rewards -0.17, envs finished 1
2026-01-17 13:22:31,417 : worker.worker : DEBUG : Step 70205, finished rewards 5.12, envs finished 1
2026-01-17 13:22:31,517 : agent.on_policy : DEBUG : Mean Losses: [7.927294552326202]
2026-01-17 13:22:31,537 : worker.worker : DEBUG : Step 70213, finished rewards 9.32, envs finished 2
2026-01-17 13:22:31,633 : worker.worker : DEBUG : Step 70228, finished rewards -1.55, envs finished 1
2026-01-17 13:22:31,648 : worker.worker : DEBUG : Step 70231, finished rewards 26.23, envs finished 1
2026-01-17 13:22:31,785 : agent.on_policy : DEBUG : Mean Losses: [8.234113872051239]
2026-01-17 13:22:32,005 : agent.on_policy : DEBUG : Mean Losses: [2.0079696476459503]
2026-01-17 13:22:32,058 : worker.worker : DEBUG : Step 70278, finished rewards 18.01, envs finished 1
2026-01-17 13:22:32,130 : worker.worker : DEBUG : Step 70287, finished rewards 0.26, envs finished 1
2026-01-17 13:22:32,322 : agent.on_policy : DEBUG : Mean Losses: [5.563591111451387]
2026-01-17 13:22:32,348 : worker.worker : DEBUG : Step 70311, finished rewards 19.97, envs finished 1
2026-01-17 13:22:32,369 : worker.worker : DEBUG : Step 70315, finished rewards 16.92, envs finished 1
2026-01-17 13:22:32,423 : worker.worker : DEBUG : Step 70325, finished rewards -9.55, envs finished 1
2026-01-17 13:22:32,581 : agent.on_policy : DEBUG : Mean Losses: [8.300326600670815]
2026-01-17 13:22:32,618 : worker.worker : DEBUG : Step 70344, finished rewards 7.32, envs finished 1
2026-01-17 13:22:32,665 : worker.worker : DEBUG : Step 70351, finished rewards 4.95, envs finished 1
2026-01-17 13:22:32,876 : agent.on_policy : DEBUG : Mean Losses: [5.216626457870007]
2026-01-17 13:22:32,886 : worker.worker : DEBUG : Step 70370, finished rewards 3.03, envs finished 1
2026-01-17 13:22:32,907 : worker.worker : DEBUG : Step 70374, finished rewards 27.85, envs finished 1
2026-01-17 13:22:32,942 : worker.worker : DEBUG : Step 70380, finished rewards 18.19, envs finished 1
2026-01-17 13:22:33,153 : agent.on_policy : DEBUG : Mean Losses: [6.585549898445606]
2026-01-17 13:22:33,176 : worker.worker : DEBUG : Step 70405, finished rewards 24.12, envs finished 1
2026-01-17 13:22:33,216 : worker.worker : DEBUG : Step 70414, finished rewards 15.26, envs finished 1
2026-01-17 13:22:33,273 : worker.worker : DEBUG : Step 70431, finished rewards 13.00, envs finished 1
2026-01-17 13:22:33,326 : agent.on_policy : DEBUG : Mean Losses: [7.361445918679237]
2026-01-17 13:22:33,426 : worker.worker : DEBUG : Step 70448, finished rewards 15.17, envs finished 1
2026-01-17 13:22:33,563 : agent.on_policy : DEBUG : Mean Losses: [4.01005120575428]
2026-01-17 13:22:33,589 : worker.worker : DEBUG : Step 70470, finished rewards 5.68, envs finished 1
2026-01-17 13:22:33,609 : worker.worker : DEBUG : Step 70475, finished rewards 13.64, envs finished 1
2026-01-17 13:22:33,641 : worker.worker : DEBUG : Step 70482, finished rewards 17.24, envs finished 1
2026-01-17 13:22:33,745 : agent.on_policy : DEBUG : Mean Losses: [8.591707423329353]
2026-01-17 13:22:33,749 : worker.worker : DEBUG : Step 70497, finished rewards 8.56, envs finished 1
2026-01-17 13:22:33,822 : worker.worker : DEBUG : Step 70512, finished rewards 19.86, envs finished 1
2026-01-17 13:22:33,878 : worker.worker : DEBUG : Step 70526, finished rewards 9.15, envs finished 1
2026-01-17 13:22:33,965 : agent.on_policy : DEBUG : Mean Losses: [6.162965661846101]
2026-01-17 13:22:34,000 : worker.worker : DEBUG : Step 70539, finished rewards 25.70, envs finished 1
2026-01-17 13:22:34,052 : worker.worker : DEBUG : Step 70549, finished rewards 7.65, envs finished 1
2026-01-17 13:22:34,081 : worker.worker : DEBUG : Step 70556, finished rewards 28.61, envs finished 1
2026-01-17 13:22:34,294 : agent.on_policy : DEBUG : Mean Losses: [7.918399365618825]
2026-01-17 13:22:34,336 : worker.worker : DEBUG : Step 70569, finished rewards 22.18, envs finished 1
2026-01-17 13:22:34,480 : agent.on_policy : DEBUG : Mean Losses: [4.3053782396018505]
2026-01-17 13:22:34,551 : worker.worker : DEBUG : Step 70609, finished rewards 14.19, envs finished 1
2026-01-17 13:22:34,581 : worker.worker : DEBUG : Step 70616, finished rewards 14.08, envs finished 1
2026-01-17 13:22:34,699 : agent.on_policy : DEBUG : Mean Losses: [6.641857028007507]
2026-01-17 13:22:34,715 : worker.worker : DEBUG : Step 70628, finished rewards 17.26, envs finished 1
2026-01-17 13:22:34,785 : worker.worker : DEBUG : Step 70639, finished rewards 17.52, envs finished 1
2026-01-17 13:22:34,833 : worker.worker : DEBUG : Step 70650, finished rewards 23.96, envs finished 1
2026-01-17 13:22:34,931 : agent.on_policy : DEBUG : Mean Losses: [10.138033423572779]
2026-01-17 13:22:34,947 : worker.worker : DEBUG : Step 70661, finished rewards -8.24, envs finished 1
2026-01-17 13:22:34,983 : worker.worker : DEBUG : Step 70668, finished rewards 5.47, envs finished 1
2026-01-17 13:22:35,139 : agent.on_policy : DEBUG : Mean Losses: [4.42036491073668]
2026-01-17 13:22:35,185 : worker.worker : DEBUG : Step 70698, finished rewards -2.26, envs finished 1
2026-01-17 13:22:35,322 : agent.on_policy : DEBUG : Mean Losses: [3.8384416550397873]
2026-01-17 13:22:35,408 : worker.worker : DEBUG : Step 70735, finished rewards -1.54, envs finished 1
2026-01-17 13:22:35,461 : worker.worker : DEBUG : Step 70744, finished rewards 2.18, envs finished 1
2026-01-17 13:22:35,510 : worker.worker : DEBUG : Step 70750, finished rewards 15.91, envs finished 2
2026-01-17 13:22:35,608 : agent.on_policy : DEBUG : Mean Losses: [11.647498071193695]
2026-01-17 13:22:35,642 : worker.worker : DEBUG : Step 70762, finished rewards 24.25, envs finished 1
2026-01-17 13:22:35,676 : worker.worker : DEBUG : Step 70765, finished rewards 13.73, envs finished 1
2026-01-17 13:22:35,804 : agent.on_policy : DEBUG : Mean Losses: [4.916736517101526]
2026-01-17 13:22:35,811 : worker.worker : DEBUG : Step 70785, finished rewards -16.16, envs finished 1
2026-01-17 13:22:35,888 : worker.worker : DEBUG : Step 70796, finished rewards 20.19, envs finished 1
2026-01-17 13:22:36,037 : agent.on_policy : DEBUG : Mean Losses: [4.047361612319946]
2026-01-17 13:22:36,143 : worker.worker : DEBUG : Step 70845, finished rewards 16.46, envs finished 1
2026-01-17 13:22:36,253 : agent.on_policy : DEBUG : Mean Losses: [6.460755102336407]
2026-01-17 13:22:36,274 : worker.worker : DEBUG : Step 70853, finished rewards 16.71, envs finished 1
2026-01-17 13:22:36,355 : worker.worker : DEBUG : Step 70863, finished rewards 12.25, envs finished 2
2026-01-17 13:22:36,410 : worker.worker : DEBUG : Step 70878, finished rewards -16.49, envs finished 1
2026-01-17 13:22:36,531 : agent.on_policy : DEBUG : Mean Losses: [9.86410466209054]
2026-01-17 13:22:36,578 : worker.worker : DEBUG : Step 70892, finished rewards -1.28, envs finished 1
2026-01-17 13:22:36,594 : worker.worker : DEBUG : Step 70896, finished rewards 10.94, envs finished 1
2026-01-17 13:22:36,697 : agent.on_policy : DEBUG : Mean Losses: [5.4238023310899734]
2026-01-17 13:22:36,972 : agent.on_policy : DEBUG : Mean Losses: [3.0576003789901733]
2026-01-17 13:22:36,985 : worker.worker : DEBUG : Step 70945, finished rewards 16.90, envs finished 1
2026-01-17 13:22:37,011 : worker.worker : DEBUG : Step 70950, finished rewards -17.97, envs finished 1
2026-01-17 13:22:37,139 : agent.on_policy : DEBUG : Mean Losses: [5.770828932523727]
2026-01-17 13:22:37,165 : worker.worker : DEBUG : Step 70980, finished rewards -1.38, envs finished 1
2026-01-17 13:22:37,270 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02620450591493621
2026-01-17 13:22:37,310 : worker.worker : DEBUG : Step 71007, finished rewards -0.13, envs finished 2
2026-01-17 13:22:37,401 : agent.on_policy : DEBUG : Mean Losses: [7.183164030313492]
2026-01-17 13:22:37,402 : worker.worker : DEBUG : Step 71008, finished rewards 10.09, envs finished 1
2026-01-17 13:22:37,413 : worker.worker : DEBUG : Step 71010, finished rewards 7.59, envs finished 1
2026-01-17 13:22:37,649 : agent.on_policy : DEBUG : Mean Losses: [3.1976586934179068]
2026-01-17 13:22:37,713 : worker.worker : DEBUG : Step 71057, finished rewards -10.58, envs finished 1
2026-01-17 13:22:37,726 : worker.worker : DEBUG : Step 71060, finished rewards 8.36, envs finished 1
2026-01-17 13:22:37,852 : agent.on_policy : DEBUG : Mean Losses: [5.568883128464222]
2026-01-17 13:22:37,863 : worker.worker : DEBUG : Step 71074, finished rewards -1.27, envs finished 1
2026-01-17 13:22:37,976 : worker.worker : DEBUG : Step 71093, finished rewards 8.59, envs finished 1
2026-01-17 13:22:38,147 : agent.on_policy : DEBUG : Mean Losses: [6.059364885091782]
2026-01-17 13:22:38,154 : worker.worker : DEBUG : Step 71105, finished rewards 19.70, envs finished 1
2026-01-17 13:22:38,363 : agent.on_policy : DEBUG : Mean Losses: [3.254738338291645]
2026-01-17 13:22:38,393 : worker.worker : DEBUG : Step 71141, finished rewards 1.45, envs finished 1
2026-01-17 13:22:38,436 : worker.worker : DEBUG : Step 71148, finished rewards -10.73, envs finished 1
2026-01-17 13:22:38,461 : worker.worker : DEBUG : Step 71152, finished rewards 4.20, envs finished 2
2026-01-17 13:22:38,609 : agent.on_policy : DEBUG : Mean Losses: [9.489766791462898]
2026-01-17 13:22:38,698 : worker.worker : DEBUG : Step 71185, finished rewards 9.05, envs finished 1
2026-01-17 13:22:38,726 : worker.worker : DEBUG : Step 71192, finished rewards 27.20, envs finished 1
2026-01-17 13:22:38,736 : worker.worker : DEBUG : Step 71194, finished rewards 15.69, envs finished 1
2026-01-17 13:22:38,838 : agent.on_policy : DEBUG : Mean Losses: [11.034182794392109]
2026-01-17 13:22:38,925 : worker.worker : DEBUG : Step 71219, finished rewards -21.18, envs finished 1
2026-01-17 13:22:39,045 : agent.on_policy : DEBUG : Mean Losses: [2.7939870208501816]
2026-01-17 13:22:39,138 : worker.worker : DEBUG : Step 71253, finished rewards 8.94, envs finished 1
2026-01-17 13:22:39,146 : worker.worker : DEBUG : Step 71255, finished rewards 15.39, envs finished 2
2026-01-17 13:22:39,298 : agent.on_policy : DEBUG : Mean Losses: [7.788660190999508]
2026-01-17 13:22:39,308 : worker.worker : DEBUG : Step 71265, finished rewards 11.86, envs finished 1
2026-01-17 13:22:39,611 : agent.on_policy : DEBUG : Mean Losses: [2.559503484517336]
2026-01-17 13:22:39,613 : worker.worker : DEBUG : Step 71296, finished rewards 17.40, envs finished 1
2026-01-17 13:22:39,695 : worker.worker : DEBUG : Step 71315, finished rewards 1.03, envs finished 1
2026-01-17 13:22:39,705 : worker.worker : DEBUG : Step 71317, finished rewards 20.30, envs finished 1
2026-01-17 13:22:39,854 : agent.on_policy : DEBUG : Mean Losses: [6.3045466132462025]
2026-01-17 13:22:39,933 : worker.worker : DEBUG : Step 71350, finished rewards 22.84, envs finished 1
2026-01-17 13:22:40,049 : agent.on_policy : DEBUG : Mean Losses: [4.732134468853474]
2026-01-17 13:22:40,122 : worker.worker : DEBUG : Step 71374, finished rewards 10.57, envs finished 1
2026-01-17 13:22:40,157 : worker.worker : DEBUG : Step 71382, finished rewards 28.34, envs finished 1
2026-01-17 13:22:40,173 : worker.worker : DEBUG : Step 71385, finished rewards -5.01, envs finished 1
2026-01-17 13:22:40,274 : agent.on_policy : DEBUG : Mean Losses: [9.331089481711388]
2026-01-17 13:22:40,295 : worker.worker : DEBUG : Step 71398, finished rewards -8.21, envs finished 1
2026-01-17 13:22:40,355 : worker.worker : DEBUG : Step 71409, finished rewards 23.62, envs finished 1
2026-01-17 13:22:40,397 : worker.worker : DEBUG : Step 71420, finished rewards -12.86, envs finished 1
2026-01-17 13:22:40,562 : agent.on_policy : DEBUG : Mean Losses: [6.357208751142025]
2026-01-17 13:22:40,725 : worker.worker : DEBUG : Step 71446, finished rewards 6.81, envs finished 1
2026-01-17 13:22:40,820 : agent.on_policy : DEBUG : Mean Losses: [3.1552531979978085]
2026-01-17 13:22:40,853 : worker.worker : DEBUG : Step 71467, finished rewards 21.95, envs finished 1
2026-01-17 13:22:40,922 : worker.worker : DEBUG : Step 71479, finished rewards 0.15, envs finished 1
2026-01-17 13:22:40,945 : worker.worker : DEBUG : Step 71484, finished rewards 15.76, envs finished 1
2026-01-17 13:22:41,056 : agent.on_policy : DEBUG : Mean Losses: [10.277028732001781]
2026-01-17 13:22:41,089 : worker.worker : DEBUG : Step 71493, finished rewards 12.64, envs finished 1
2026-01-17 13:22:41,195 : worker.worker : DEBUG : Step 71513, finished rewards 6.28, envs finished 1
2026-01-17 13:22:41,231 : worker.worker : DEBUG : Step 71519, finished rewards 19.34, envs finished 1
2026-01-17 13:22:41,313 : agent.on_policy : DEBUG : Mean Losses: [7.1062899604439735]
2026-01-17 13:22:41,353 : worker.worker : DEBUG : Step 71529, finished rewards 1.87, envs finished 1
2026-01-17 13:22:41,534 : agent.on_policy : DEBUG : Mean Losses: [3.0961561389267445]
2026-01-17 13:22:41,663 : worker.worker : DEBUG : Step 71581, finished rewards 17.93, envs finished 1
2026-01-17 13:22:41,757 : agent.on_policy : DEBUG : Mean Losses: [6.244742423295975]
2026-01-17 13:22:41,767 : worker.worker : DEBUG : Step 71587, finished rewards 2.55, envs finished 1
2026-01-17 13:22:41,833 : worker.worker : DEBUG : Step 71599, finished rewards 28.47, envs finished 1
2026-01-17 13:22:41,841 : worker.worker : DEBUG : Step 71600, finished rewards -18.12, envs finished 1
2026-01-17 13:22:41,858 : worker.worker : DEBUG : Step 71602, finished rewards 10.26, envs finished 1
2026-01-17 13:22:41,898 : worker.worker : DEBUG : Step 71609, finished rewards 4.74, envs finished 1
2026-01-17 13:22:42,046 : agent.on_policy : DEBUG : Mean Losses: [12.33928107097745]
2026-01-17 13:22:42,092 : worker.worker : DEBUG : Step 71627, finished rewards 10.79, envs finished 1
2026-01-17 13:22:42,108 : worker.worker : DEBUG : Step 71629, finished rewards 18.96, envs finished 1
2026-01-17 13:22:42,229 : agent.on_policy : DEBUG : Mean Losses: [4.8177223317325115]
2026-01-17 13:22:42,432 : agent.on_policy : DEBUG : Mean Losses: [3.155796006321907]
2026-01-17 13:22:42,437 : worker.worker : DEBUG : Step 71681, finished rewards 21.50, envs finished 1
2026-01-17 13:22:42,481 : worker.worker : DEBUG : Step 71691, finished rewards 18.65, envs finished 2
2026-01-17 13:22:42,522 : worker.worker : DEBUG : Step 71702, finished rewards 17.82, envs finished 1
2026-01-17 13:22:42,531 : worker.worker : DEBUG : Step 71704, finished rewards 23.16, envs finished 1
2026-01-17 13:22:42,561 : worker.worker : DEBUG : Step 71710, finished rewards 10.33, envs finished 1
2026-01-17 13:22:42,614 : agent.on_policy : DEBUG : Mean Losses: [13.145266830921173]
2026-01-17 13:22:42,625 : worker.worker : DEBUG : Step 71713, finished rewards 28.62, envs finished 1
2026-01-17 13:22:42,851 : agent.on_policy : DEBUG : Mean Losses: [1.9526921957731247]
2026-01-17 13:22:42,877 : worker.worker : DEBUG : Step 71751, finished rewards 0.14, envs finished 1
2026-01-17 13:22:43,083 : agent.on_policy : DEBUG : Mean Losses: [3.4703799821436405]
2026-01-17 13:22:43,151 : worker.worker : DEBUG : Step 71793, finished rewards 16.52, envs finished 1
2026-01-17 13:22:43,285 : agent.on_policy : DEBUG : Mean Losses: [6.264514058828354]
2026-01-17 13:22:43,307 : worker.worker : DEBUG : Step 71815, finished rewards 16.01, envs finished 1
2026-01-17 13:22:43,326 : worker.worker : DEBUG : Step 71820, finished rewards 5.01, envs finished 1
2026-01-17 13:22:43,341 : worker.worker : DEBUG : Step 71823, finished rewards 8.57, envs finished 1
2026-01-17 13:22:43,384 : worker.worker : DEBUG : Step 71834, finished rewards -5.05, envs finished 1
2026-01-17 13:22:43,455 : agent.on_policy : DEBUG : Mean Losses: [12.056145787239075]
2026-01-17 13:22:43,462 : worker.worker : DEBUG : Step 71841, finished rewards -18.27, envs finished 1
2026-01-17 13:22:43,555 : worker.worker : DEBUG : Step 71859, finished rewards 12.85, envs finished 1
2026-01-17 13:22:43,576 : worker.worker : DEBUG : Step 71863, finished rewards -41.16, envs finished 1
2026-01-17 13:22:43,718 : agent.on_policy : DEBUG : Mean Losses: [7.00271300598979]
2026-01-17 13:22:43,899 : agent.on_policy : DEBUG : Mean Losses: [1.6756137274205685]
2026-01-17 13:22:43,943 : worker.worker : DEBUG : Step 71913, finished rewards 3.33, envs finished 1
2026-01-17 13:22:44,061 : agent.on_policy : DEBUG : Mean Losses: [5.09499292075634]
2026-01-17 13:22:44,063 : worker.worker : DEBUG : Step 71936, finished rewards 8.76, envs finished 2
2026-01-17 13:22:44,113 : worker.worker : DEBUG : Step 71945, finished rewards -1.83, envs finished 1
2026-01-17 13:22:44,126 : worker.worker : DEBUG : Step 71947, finished rewards 26.84, envs finished 1
2026-01-17 13:22:44,198 : worker.worker : DEBUG : Step 71963, finished rewards 2.43, envs finished 1
2026-01-17 13:22:44,232 : worker.worker : DEBUG : Step 71966, finished rewards 3.42, envs finished 1
2026-01-17 13:22:44,321 : agent.on_policy : DEBUG : Mean Losses: [10.925769038498402]
2026-01-17 13:22:44,329 : worker.worker : DEBUG : Step 71969, finished rewards 13.38, envs finished 1
2026-01-17 13:22:43,700 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.0248942806191894
2026-01-17 13:22:43,749 : agent.on_policy : DEBUG : Mean Losses: [1.179778770543635]
2026-01-17 13:22:43,787 : worker.worker : DEBUG : Step 72014, finished rewards 18.07, envs finished 1
2026-01-17 13:22:43,895 : agent.on_policy : DEBUG : Mean Losses: [4.514239624142647]
2026-01-17 13:22:43,897 : worker.worker : DEBUG : Step 72032, finished rewards 29.06, envs finished 1
2026-01-17 13:22:44,044 : worker.worker : DEBUG : Step 72051, finished rewards 9.30, envs finished 1
2026-01-17 13:22:44,103 : worker.worker : DEBUG : Step 72058, finished rewards 23.25, envs finished 1
2026-01-17 13:22:44,149 : worker.worker : DEBUG : Step 72062, finished rewards 12.49, envs finished 1
2026-01-17 13:22:44,249 : agent.on_policy : DEBUG : Mean Losses: [9.692637175321579]
2026-01-17 13:22:44,365 : worker.worker : DEBUG : Step 72091, finished rewards 7.96, envs finished 1
2026-01-17 13:22:44,383 : worker.worker : DEBUG : Step 72095, finished rewards -24.29, envs finished 1
2026-01-17 13:22:44,468 : agent.on_policy : DEBUG : Mean Losses: [6.245851289480925]
2026-01-17 13:22:44,547 : worker.worker : DEBUG : Step 72118, finished rewards -6.03, envs finished 1
2026-01-17 13:22:44,656 : agent.on_policy : DEBUG : Mean Losses: [3.355124868452549]
2026-01-17 13:22:44,719 : worker.worker : DEBUG : Step 72142, finished rewards -2.76, envs finished 1
2026-01-17 13:22:44,741 : worker.worker : DEBUG : Step 72146, finished rewards 6.54, envs finished 1
2026-01-17 13:22:44,861 : agent.on_policy : DEBUG : Mean Losses: [7.249635249376297]
2026-01-17 13:22:44,921 : worker.worker : DEBUG : Step 72170, finished rewards 13.96, envs finished 1
2026-01-17 13:22:44,951 : worker.worker : DEBUG : Step 72176, finished rewards 28.30, envs finished 1
2026-01-17 13:22:45,006 : worker.worker : DEBUG : Step 72188, finished rewards 1.82, envs finished 1
2026-01-17 13:22:45,034 : worker.worker : DEBUG : Step 72191, finished rewards -8.45, envs finished 1
2026-01-17 13:22:45,095 : agent.on_policy : DEBUG : Mean Losses: [10.764154948294163]
2026-01-17 13:22:45,299 : agent.on_policy : DEBUG : Mean Losses: [1.6734862588346004]
2026-01-17 13:22:45,329 : worker.worker : DEBUG : Step 72234, finished rewards -4.52, envs finished 1
2026-01-17 13:22:45,385 : worker.worker : DEBUG : Step 72249, finished rewards 18.28, envs finished 1
2026-01-17 13:22:45,464 : agent.on_policy : DEBUG : Mean Losses: [7.048744708299637]
2026-01-17 13:22:45,476 : worker.worker : DEBUG : Step 72258, finished rewards 1.70, envs finished 1
2026-01-17 13:22:45,554 : worker.worker : DEBUG : Step 72274, finished rewards -4.07, envs finished 1
2026-01-17 13:22:45,564 : worker.worker : DEBUG : Step 72276, finished rewards 21.22, envs finished 1
2026-01-17 13:22:45,711 : agent.on_policy : DEBUG : Mean Losses: [6.751936420798302]
2026-01-17 13:22:45,727 : worker.worker : DEBUG : Step 72292, finished rewards 18.60, envs finished 1
2026-01-17 13:22:45,751 : worker.worker : DEBUG : Step 72297, finished rewards 13.26, envs finished 1
2026-01-17 13:22:45,788 : worker.worker : DEBUG : Step 72303, finished rewards 5.65, envs finished 1
2026-01-17 13:22:45,913 : agent.on_policy : DEBUG : Mean Losses: [5.437896333634853]
2026-01-17 13:22:46,102 : agent.on_policy : DEBUG : Mean Losses: [1.7789215259253979]
2026-01-17 13:22:46,130 : worker.worker : DEBUG : Step 72359, finished rewards 0.91, envs finished 1
2026-01-17 13:22:46,215 : worker.worker : DEBUG : Step 72382, finished rewards 10.87, envs finished 1
2026-01-17 13:22:46,313 : agent.on_policy : DEBUG : Mean Losses: [7.421384260058403]
2026-01-17 13:22:46,316 : worker.worker : DEBUG : Step 72384, finished rewards 10.33, envs finished 1
2026-01-17 13:22:46,437 : worker.worker : DEBUG : Step 72403, finished rewards 12.80, envs finished 1
2026-01-17 13:22:46,511 : worker.worker : DEBUG : Step 72415, finished rewards -20.52, envs finished 1
2026-01-17 13:22:46,682 : agent.on_policy : DEBUG : Mean Losses: [8.392248027026653]
2026-01-17 13:22:46,705 : worker.worker : DEBUG : Step 72421, finished rewards -1.57, envs finished 1
2026-01-17 13:22:46,752 : worker.worker : DEBUG : Step 72433, finished rewards -41.49, envs finished 1
2026-01-17 13:22:46,795 : worker.worker : DEBUG : Step 72445, finished rewards -14.90, envs finished 1
2026-01-17 13:22:46,864 : agent.on_policy : DEBUG : Mean Losses: [7.7018043380230665]
2026-01-17 13:22:47,038 : agent.on_policy : DEBUG : Mean Losses: [2.795324987731874]
2026-01-17 13:22:47,094 : worker.worker : DEBUG : Step 72497, finished rewards 14.52, envs finished 1
2026-01-17 13:22:47,116 : worker.worker : DEBUG : Step 72502, finished rewards -8.97, envs finished 1
2026-01-17 13:22:47,235 : agent.on_policy : DEBUG : Mean Losses: [6.520764142274857]
2026-01-17 13:22:47,287 : worker.worker : DEBUG : Step 72521, finished rewards 19.45, envs finished 1
2026-01-17 13:22:47,320 : worker.worker : DEBUG : Step 72528, finished rewards -14.31, envs finished 1
2026-01-17 13:22:47,335 : worker.worker : DEBUG : Step 72531, finished rewards 3.17, envs finished 1
2026-01-17 13:22:47,464 : agent.on_policy : DEBUG : Mean Losses: [7.890594901517034]
2026-01-17 13:22:47,473 : worker.worker : DEBUG : Step 72545, finished rewards 17.94, envs finished 1
2026-01-17 13:22:47,519 : worker.worker : DEBUG : Step 72551, finished rewards 5.55, envs finished 1
2026-01-17 13:22:47,655 : agent.on_policy : DEBUG : Mean Losses: [3.954126674681902]
2026-01-17 13:22:47,740 : worker.worker : DEBUG : Step 72594, finished rewards 25.22, envs finished 1
2026-01-17 13:22:47,752 : worker.worker : DEBUG : Step 72597, finished rewards 19.35, envs finished 1
2026-01-17 13:22:47,777 : worker.worker : DEBUG : Step 72603, finished rewards -32.84, envs finished 1
2026-01-17 13:22:47,871 : agent.on_policy : DEBUG : Mean Losses: [10.239924415946007]
2026-01-17 13:22:47,947 : worker.worker : DEBUG : Step 72623, finished rewards 20.93, envs finished 1
2026-01-17 13:22:47,954 : worker.worker : DEBUG : Step 72624, finished rewards 17.36, envs finished 1
2026-01-17 13:22:47,976 : worker.worker : DEBUG : Step 72627, finished rewards 21.34, envs finished 1
2026-01-17 13:22:48,156 : agent.on_policy : DEBUG : Mean Losses: [9.659672915935516]
2026-01-17 13:22:48,228 : worker.worker : DEBUG : Step 72660, finished rewards 7.38, envs finished 1
2026-01-17 13:22:48,235 : worker.worker : DEBUG : Step 72662, finished rewards 15.83, envs finished 1
2026-01-17 13:22:48,363 : agent.on_policy : DEBUG : Mean Losses: [4.9335278533399105]
2026-01-17 13:22:48,437 : worker.worker : DEBUG : Step 72688, finished rewards 29.12, envs finished 1
2026-01-17 13:22:48,454 : worker.worker : DEBUG : Step 72692, finished rewards 23.66, envs finished 1
2026-01-17 13:22:48,579 : agent.on_policy : DEBUG : Mean Losses: [7.092031344771385]
2026-01-17 13:22:48,638 : worker.worker : DEBUG : Step 72714, finished rewards 7.20, envs finished 1
2026-01-17 13:22:48,678 : worker.worker : DEBUG : Step 72722, finished rewards 23.00, envs finished 1
2026-01-17 13:22:48,754 : worker.worker : DEBUG : Step 72734, finished rewards 11.07, envs finished 1
2026-01-17 13:22:48,989 : agent.on_policy : DEBUG : Mean Losses: [8.560525454580784]
2026-01-17 13:22:49,040 : worker.worker : DEBUG : Step 72747, finished rewards 0.63, envs finished 1
2026-01-17 13:22:49,082 : worker.worker : DEBUG : Step 72757, finished rewards 23.02, envs finished 1
2026-01-17 13:22:49,101 : worker.worker : DEBUG : Step 72761, finished rewards 19.14, envs finished 1
2026-01-17 13:22:49,201 : agent.on_policy : DEBUG : Mean Losses: [7.808602303266525]
2026-01-17 13:22:49,392 : agent.on_policy : DEBUG : Mean Losses: [2.285031583160162]
2026-01-17 13:22:49,449 : worker.worker : DEBUG : Step 72815, finished rewards -0.83, envs finished 1
2026-01-17 13:22:49,486 : worker.worker : DEBUG : Step 72824, finished rewards -2.53, envs finished 1
2026-01-17 13:22:49,591 : agent.on_policy : DEBUG : Mean Losses: [5.685395583510399]
2026-01-17 13:22:49,604 : worker.worker : DEBUG : Step 72835, finished rewards 4.93, envs finished 1
2026-01-17 13:22:49,696 : worker.worker : DEBUG : Step 72842, finished rewards 11.11, envs finished 1
2026-01-17 13:22:49,815 : worker.worker : DEBUG : Step 72860, finished rewards 7.59, envs finished 1
2026-01-17 13:22:49,910 : agent.on_policy : DEBUG : Mean Losses: [7.799351651221514]
2026-01-17 13:22:49,937 : worker.worker : DEBUG : Step 72870, finished rewards -12.41, envs finished 1
2026-01-17 13:22:49,961 : worker.worker : DEBUG : Step 72874, finished rewards 4.15, envs finished 1
2026-01-17 13:22:50,134 : agent.on_policy : DEBUG : Mean Losses: [4.653347315266728]
2026-01-17 13:22:50,193 : worker.worker : DEBUG : Step 72912, finished rewards -20.91, envs finished 1
2026-01-17 13:22:50,198 : worker.worker : DEBUG : Step 72913, finished rewards 19.29, envs finished 1
2026-01-17 13:22:50,354 : agent.on_policy : DEBUG : Mean Losses: [6.508197221904993]
2026-01-17 13:22:50,420 : worker.worker : DEBUG : Step 72946, finished rewards 9.90, envs finished 1
2026-01-17 13:22:50,457 : worker.worker : DEBUG : Step 72955, finished rewards -5.49, envs finished 1
2026-01-17 13:22:50,569 : agent.on_policy : DEBUG : Mean Losses: [7.078853230923414]
2026-01-17 13:22:50,624 : worker.worker : DEBUG : Step 72968, finished rewards 23.77, envs finished 1
2026-01-17 13:22:50,641 : worker.worker : DEBUG : Step 72971, finished rewards 17.03, envs finished 1
2026-01-17 13:22:50,677 : worker.worker : DEBUG : Step 72980, finished rewards 2.63, envs finished 1
2026-01-17 13:22:50,688 : worker.worker : DEBUG : Step 72982, finished rewards -12.58, envs finished 1
2026-01-17 13:22:50,797 : agent.on_policy : DEBUG : Mean Losses: [9.279801607131958]
2026-01-17 13:22:50,817 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.023649566588229927
2026-01-17 13:22:50,925 : worker.worker : DEBUG : Step 73022, finished rewards 11.34, envs finished 1
2026-01-17 13:22:51,035 : agent.on_policy : DEBUG : Mean Losses: [3.7211672887206078]
2026-01-17 13:22:51,138 : worker.worker : DEBUG : Step 73043, finished rewards 20.07, envs finished 1
2026-01-17 13:22:51,174 : worker.worker : DEBUG : Step 73050, finished rewards -10.04, envs finished 1
2026-01-17 13:22:51,185 : worker.worker : DEBUG : Step 73051, finished rewards 21.11, envs finished 1
2026-01-17 13:22:51,284 : agent.on_policy : DEBUG : Mean Losses: [8.421617321670055]
2026-01-17 13:22:51,327 : worker.worker : DEBUG : Step 73066, finished rewards 23.22, envs finished 1
2026-01-17 13:22:51,528 : agent.on_policy : DEBUG : Mean Losses: [4.562869302928448]
2026-01-17 13:22:51,542 : worker.worker : DEBUG : Step 73090, finished rewards 13.60, envs finished 1
2026-01-17 13:22:51,624 : worker.worker : DEBUG : Step 73110, finished rewards -13.03, envs finished 1
2026-01-17 13:22:51,757 : agent.on_policy : DEBUG : Mean Losses: [5.033824037760496]
2026-01-17 13:22:51,801 : worker.worker : DEBUG : Step 73125, finished rewards -11.84, envs finished 1
2026-01-17 13:22:51,839 : worker.worker : DEBUG : Step 73130, finished rewards 11.22, envs finished 1
2026-01-17 13:22:52,083 : agent.on_policy : DEBUG : Mean Losses: [5.171809453517199]
2026-01-17 13:22:52,085 : worker.worker : DEBUG : Step 73152, finished rewards 16.65, envs finished 1
2026-01-17 13:22:52,214 : worker.worker : DEBUG : Step 73182, finished rewards 7.07, envs finished 1
2026-01-17 13:22:52,408 : agent.on_policy : DEBUG : Mean Losses: [4.731014158576727]
2026-01-17 13:22:52,449 : worker.worker : DEBUG : Step 73188, finished rewards -6.41, envs finished 1
2026-01-17 13:22:52,497 : worker.worker : DEBUG : Step 73196, finished rewards 28.67, envs finished 1
2026-01-17 13:22:52,558 : worker.worker : DEBUG : Step 73206, finished rewards 3.27, envs finished 1
2026-01-17 13:22:52,703 : agent.on_policy : DEBUG : Mean Losses: [7.308091402053833]
2026-01-17 13:22:52,731 : worker.worker : DEBUG : Step 73220, finished rewards 1.13, envs finished 1
2026-01-17 13:22:52,760 : worker.worker : DEBUG : Step 73224, finished rewards 17.89, envs finished 1
2026-01-17 13:22:52,966 : agent.on_policy : DEBUG : Mean Losses: [4.792428473010659]
2026-01-17 13:22:53,032 : worker.worker : DEBUG : Step 73266, finished rewards 7.58, envs finished 1
2026-01-17 13:22:53,179 : agent.on_policy : DEBUG : Mean Losses: [4.562205024063587]
2026-01-17 13:22:53,184 : worker.worker : DEBUG : Step 73280, finished rewards 18.22, envs finished 1
2026-01-17 13:22:53,200 : worker.worker : DEBUG : Step 73283, finished rewards -13.55, envs finished 1
2026-01-17 13:22:53,244 : worker.worker : DEBUG : Step 73292, finished rewards 28.80, envs finished 1
2026-01-17 13:22:53,298 : worker.worker : DEBUG : Step 73306, finished rewards 4.57, envs finished 1
2026-01-17 13:22:53,320 : worker.worker : DEBUG : Step 73311, finished rewards 6.85, envs finished 1
2026-01-17 13:22:53,380 : agent.on_policy : DEBUG : Mean Losses: [9.517526626586914]
2026-01-17 13:22:53,538 : worker.worker : DEBUG : Step 73341, finished rewards 3.89, envs finished 1
2026-01-17 13:22:53,591 : agent.on_policy : DEBUG : Mean Losses: [4.026672158390284]
2026-01-17 13:22:53,649 : worker.worker : DEBUG : Step 73361, finished rewards 22.69, envs finished 1
2026-01-17 13:22:53,685 : worker.worker : DEBUG : Step 73369, finished rewards 28.04, envs finished 1
2026-01-17 13:22:53,783 : agent.on_policy : DEBUG : Mean Losses: [7.2204515263438225]
2026-01-17 13:22:53,793 : worker.worker : DEBUG : Step 73378, finished rewards 19.79, envs finished 1
2026-01-17 13:22:53,808 : worker.worker : DEBUG : Step 73381, finished rewards -7.14, envs finished 1
2026-01-17 13:22:53,859 : worker.worker : DEBUG : Step 73388, finished rewards 20.78, envs finished 1
2026-01-17 13:22:53,924 : worker.worker : DEBUG : Step 73402, finished rewards 21.06, envs finished 1
2026-01-17 13:22:54,024 : agent.on_policy : DEBUG : Mean Losses: [8.373865470290184]
2026-01-17 13:22:54,217 : agent.on_policy : DEBUG : Mean Losses: [2.1365235708653927]
2026-01-17 13:22:54,220 : worker.worker : DEBUG : Step 73440, finished rewards 19.87, envs finished 1
2026-01-17 13:22:54,274 : worker.worker : DEBUG : Step 73454, finished rewards -11.71, envs finished 1
2026-01-17 13:22:54,307 : worker.worker : DEBUG : Step 73461, finished rewards 19.47, envs finished 1
2026-01-17 13:22:54,325 : worker.worker : DEBUG : Step 73465, finished rewards 22.49, envs finished 1
2026-01-17 13:22:54,440 : agent.on_policy : DEBUG : Mean Losses: [8.21017824858427]
2026-01-17 13:22:54,495 : worker.worker : DEBUG : Step 73480, finished rewards 20.27, envs finished 1
2026-01-17 13:22:54,564 : worker.worker : DEBUG : Step 73495, finished rewards 7.28, envs finished 1
2026-01-17 13:22:54,671 : agent.on_policy : DEBUG : Mean Losses: [5.073210544884205]
2026-01-17 13:22:54,730 : worker.worker : DEBUG : Step 73514, finished rewards -2.10, envs finished 1
2026-01-17 13:22:54,887 : agent.on_policy : DEBUG : Mean Losses: [3.832135945558548]
2026-01-17 13:22:54,899 : worker.worker : DEBUG : Step 73539, finished rewards 19.92, envs finished 1
2026-01-17 13:22:54,911 : worker.worker : DEBUG : Step 73541, finished rewards -12.65, envs finished 1
2026-01-17 13:22:54,967 : worker.worker : DEBUG : Step 73557, finished rewards 21.42, envs finished 1
2026-01-17 13:22:54,996 : worker.worker : DEBUG : Step 73564, finished rewards 19.72, envs finished 1
2026-01-17 13:22:55,114 : agent.on_policy : DEBUG : Mean Losses: [8.885802570730448]
2026-01-17 13:22:55,314 : agent.on_policy : DEBUG : Mean Losses: [2.8763379883021116]
2026-01-17 13:22:55,346 : worker.worker : DEBUG : Step 73608, finished rewards 2.75, envs finished 2
2026-01-17 13:22:55,411 : worker.worker : DEBUG : Step 73621, finished rewards 13.81, envs finished 1
2026-01-17 13:22:55,443 : worker.worker : DEBUG : Step 73627, finished rewards 28.85, envs finished 1
2026-01-17 13:22:55,556 : agent.on_policy : DEBUG : Mean Losses: [10.125805124640465]
2026-01-17 13:22:55,581 : worker.worker : DEBUG : Step 73638, finished rewards -46.41, envs finished 1
2026-01-17 13:22:55,610 : worker.worker : DEBUG : Step 73641, finished rewards 30.01, envs finished 1
2026-01-17 13:22:55,939 : agent.on_policy : DEBUG : Mean Losses: [5.432200899347663]
2026-01-17 13:22:55,980 : worker.worker : DEBUG : Step 73674, finished rewards 5.27, envs finished 1
2026-01-17 13:22:56,097 : agent.on_policy : DEBUG : Mean Losses: [4.1472975462675095]
2026-01-17 13:22:56,166 : worker.worker : DEBUG : Step 73709, finished rewards -3.02, envs finished 1
2026-01-17 13:22:56,318 : agent.on_policy : DEBUG : Mean Losses: [4.374754533171654]
2026-01-17 13:22:56,354 : worker.worker : DEBUG : Step 73737, finished rewards 11.26, envs finished 1
2026-01-17 13:22:56,371 : worker.worker : DEBUG : Step 73740, finished rewards 16.28, envs finished 1
2026-01-17 13:22:56,443 : worker.worker : DEBUG : Step 73758, finished rewards -9.22, envs finished 1
2026-01-17 13:22:56,492 : agent.on_policy : DEBUG : Mean Losses: [8.81193619966507]
2026-01-17 13:22:56,499 : worker.worker : DEBUG : Step 73761, finished rewards 27.73, envs finished 1
2026-01-17 13:22:56,596 : worker.worker : DEBUG : Step 73780, finished rewards -32.68, envs finished 1
2026-01-17 13:22:56,712 : agent.on_policy : DEBUG : Mean Losses: [5.229150716215372]
2026-01-17 13:22:56,766 : worker.worker : DEBUG : Step 73801, finished rewards -38.60, envs finished 1
2026-01-17 13:22:56,930 : agent.on_policy : DEBUG : Mean Losses: [4.422590330243111]
2026-01-17 13:22:56,953 : worker.worker : DEBUG : Step 73831, finished rewards 2.46, envs finished 1
2026-01-17 13:22:57,022 : worker.worker : DEBUG : Step 73854, finished rewards 3.66, envs finished 1
2026-01-17 13:22:57,072 : agent.on_policy : DEBUG : Mean Losses: [5.7848739847540855]
2026-01-17 13:22:57,164 : worker.worker : DEBUG : Step 73876, finished rewards 4.89, envs finished 1
2026-01-17 13:22:57,181 : worker.worker : DEBUG : Step 73880, finished rewards 18.95, envs finished 1
2026-01-17 13:22:57,198 : worker.worker : DEBUG : Step 73883, finished rewards 2.95, envs finished 1
2026-01-17 13:22:57,302 : agent.on_policy : DEBUG : Mean Losses: [10.860277451574802]
2026-01-17 13:22:57,344 : worker.worker : DEBUG : Step 73894, finished rewards -5.46, envs finished 1
2026-01-17 13:22:57,387 : worker.worker : DEBUG : Step 73897, finished rewards 77.48, envs finished 1
2026-01-17 13:22:57,598 : agent.on_policy : DEBUG : Mean Losses: [5.110081050544977]
2026-01-17 13:22:57,639 : worker.worker : DEBUG : Step 73931, finished rewards 2.33, envs finished 1
2026-01-17 13:22:57,645 : worker.worker : DEBUG : Step 73932, finished rewards 17.66, envs finished 1
2026-01-17 13:22:57,791 : agent.on_policy : DEBUG : Mean Losses: [4.652844585478306]
2026-01-17 13:22:57,881 : worker.worker : DEBUG : Step 73968, finished rewards 23.41, envs finished 1
2026-01-17 13:22:58,042 : agent.on_policy : DEBUG : Mean Losses: [5.519357845187187]
2026-01-17 13:22:58,071 : worker.worker : DEBUG : Step 73991, finished rewards 13.77, envs finished 1
2026-01-17 13:22:58,096 : worker.worker : DEBUG : Step 73996, finished rewards 16.05, envs finished 1
2026-01-17 13:22:58,111 : worker.worker : DEBUG : Step 73998, finished rewards 4.92, envs finished 1
2026-01-17 13:22:58,112 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.022467088258818428
2026-01-17 13:22:58,150 : worker.worker : DEBUG : Step 74005, finished rewards -17.71, envs finished 1
2026-01-17 13:22:58,258 : agent.on_policy : DEBUG : Mean Losses: [9.160309687256813]
2026-01-17 13:22:58,269 : worker.worker : DEBUG : Step 74017, finished rewards 2.71, envs finished 1
2026-01-17 13:22:58,371 : worker.worker : DEBUG : Step 74032, finished rewards 19.53, envs finished 1
2026-01-17 13:22:58,462 : worker.worker : DEBUG : Step 74042, finished rewards 8.90, envs finished 1
2026-01-17 13:22:58,581 : agent.on_policy : DEBUG : Mean Losses: [6.058446452021599]
2026-01-17 13:22:58,624 : worker.worker : DEBUG : Step 74054, finished rewards 28.51, envs finished 1
2026-01-17 13:22:58,870 : agent.on_policy : DEBUG : Mean Losses: [3.0586010590195656]
2026-01-17 13:22:58,994 : worker.worker : DEBUG : Step 74094, finished rewards 21.23, envs finished 1
2026-01-17 13:22:59,050 : worker.worker : DEBUG : Step 74097, finished rewards 16.88, envs finished 1
2026-01-17 13:22:59,368 : agent.on_policy : DEBUG : Mean Losses: [8.372714653611183]
2026-01-17 13:22:59,374 : worker.worker : DEBUG : Step 74113, finished rewards 13.26, envs finished 2
2026-01-17 13:22:59,469 : worker.worker : DEBUG : Step 74133, finished rewards -2.07, envs finished 1
2026-01-17 13:22:59,490 : worker.worker : DEBUG : Step 74137, finished rewards 14.74, envs finished 1
2026-01-17 13:22:59,641 : agent.on_policy : DEBUG : Mean Losses: [6.671499088406563]
2026-01-17 13:22:59,753 : worker.worker : DEBUG : Step 74165, finished rewards 0.88, envs finished 1
2026-01-17 13:22:59,902 : agent.on_policy : DEBUG : Mean Losses: [3.2696856409311295]
2026-01-17 13:23:00,026 : worker.worker : DEBUG : Step 74205, finished rewards 9.27, envs finished 1
2026-01-17 13:23:00,041 : worker.worker : DEBUG : Step 74207, finished rewards 11.23, envs finished 1
2026-01-17 13:23:00,141 : agent.on_policy : DEBUG : Mean Losses: [5.902536880224943]
2026-01-17 13:23:00,267 : worker.worker : DEBUG : Step 74231, finished rewards -11.04, envs finished 1
2026-01-17 13:23:00,317 : worker.worker : DEBUG : Step 74236, finished rewards 0.41, envs finished 1
2026-01-17 13:23:00,421 : agent.on_policy : DEBUG : Mean Losses: [7.071051102131605]
2026-01-17 13:23:00,440 : worker.worker : DEBUG : Step 74241, finished rewards 14.94, envs finished 1
2026-01-17 13:23:00,522 : worker.worker : DEBUG : Step 74257, finished rewards -14.72, envs finished 1
2026-01-17 13:23:00,553 : worker.worker : DEBUG : Step 74263, finished rewards -2.75, envs finished 1
2026-01-17 13:23:00,692 : agent.on_policy : DEBUG : Mean Losses: [6.153516177088022]
2026-01-17 13:23:00,770 : worker.worker : DEBUG : Step 74296, finished rewards -4.73, envs finished 1
2026-01-17 13:23:00,870 : agent.on_policy : DEBUG : Mean Losses: [3.637692164629698]
2026-01-17 13:23:00,927 : worker.worker : DEBUG : Step 74313, finished rewards 11.77, envs finished 1
2026-01-17 13:23:01,107 : agent.on_policy : DEBUG : Mean Losses: [3.9561226069927216]
2026-01-17 13:23:01,134 : worker.worker : DEBUG : Step 74343, finished rewards 18.56, envs finished 3
2026-01-17 13:23:01,139 : worker.worker : DEBUG : Step 74344, finished rewards 13.10, envs finished 1
2026-01-17 13:23:01,151 : worker.worker : DEBUG : Step 74346, finished rewards -8.77, envs finished 1
2026-01-17 13:23:01,206 : worker.worker : DEBUG : Step 74357, finished rewards 23.56, envs finished 1
2026-01-17 13:23:01,292 : agent.on_policy : DEBUG : Mean Losses: [10.624128431081772]
2026-01-17 13:23:01,409 : worker.worker : DEBUG : Step 74391, finished rewards 22.66, envs finished 1
2026-01-17 13:23:01,523 : agent.on_policy : DEBUG : Mean Losses: [3.2749232798814774]
2026-01-17 13:23:01,652 : worker.worker : DEBUG : Step 74431, finished rewards 4.01, envs finished 1
2026-01-17 13:23:01,723 : agent.on_policy : DEBUG : Mean Losses: [3.7397147864103317]
2026-01-17 13:23:01,767 : worker.worker : DEBUG : Step 74443, finished rewards 18.36, envs finished 1
2026-01-17 13:23:01,773 : worker.worker : DEBUG : Step 74444, finished rewards 17.33, envs finished 1
2026-01-17 13:23:01,860 : worker.worker : DEBUG : Step 74454, finished rewards 16.28, envs finished 2
2026-01-17 13:23:02,145 : agent.on_policy : DEBUG : Mean Losses: [10.706914573907852]
2026-01-17 13:23:02,174 : worker.worker : DEBUG : Step 74468, finished rewards -0.59, envs finished 1
2026-01-17 13:23:02,197 : worker.worker : DEBUG : Step 74471, finished rewards -0.70, envs finished 1
2026-01-17 13:23:02,253 : worker.worker : DEBUG : Step 74482, finished rewards 24.43, envs finished 1
2026-01-17 13:23:02,430 : agent.on_policy : DEBUG : Mean Losses: [5.864849574863911]
2026-01-17 13:23:02,679 : agent.on_policy : DEBUG : Mean Losses: [1.684221513569355]
2026-01-17 13:23:02,752 : worker.worker : DEBUG : Step 74544, finished rewards 8.57, envs finished 1
2026-01-17 13:23:02,817 : worker.worker : DEBUG : Step 74556, finished rewards 16.04, envs finished 1
2026-01-17 13:23:02,923 : agent.on_policy : DEBUG : Mean Losses: [8.86006011068821]
2026-01-17 13:23:02,937 : worker.worker : DEBUG : Step 74562, finished rewards 23.44, envs finished 1
2026-01-17 13:23:02,989 : worker.worker : DEBUG : Step 74569, finished rewards 17.15, envs finished 1
2026-01-17 13:23:03,063 : worker.worker : DEBUG : Step 74584, finished rewards -4.24, envs finished 1
2026-01-17 13:23:03,177 : agent.on_policy : DEBUG : Mean Losses: [8.173812910914421]
2026-01-17 13:23:03,258 : worker.worker : DEBUG : Step 74606, finished rewards -26.30, envs finished 1
2026-01-17 13:23:03,312 : worker.worker : DEBUG : Step 74617, finished rewards -1.92, envs finished 1
2026-01-17 13:23:03,351 : worker.worker : DEBUG : Step 74621, finished rewards -33.96, envs finished 1
2026-01-17 13:23:03,463 : agent.on_policy : DEBUG : Mean Losses: [8.140470154583454]
2026-01-17 13:23:03,560 : worker.worker : DEBUG : Step 74644, finished rewards 17.92, envs finished 1
2026-01-17 13:23:03,673 : agent.on_policy : DEBUG : Mean Losses: [4.402211710810661]
2026-01-17 13:23:03,703 : worker.worker : DEBUG : Step 74664, finished rewards 16.16, envs finished 1
2026-01-17 13:23:03,848 : agent.on_policy : DEBUG : Mean Losses: [4.20785816013813]
2026-01-17 13:23:03,870 : worker.worker : DEBUG : Step 74689, finished rewards -7.76, envs finished 1
2026-01-17 13:23:03,893 : worker.worker : DEBUG : Step 74692, finished rewards 28.54, envs finished 1
2026-01-17 13:23:03,924 : worker.worker : DEBUG : Step 74698, finished rewards 6.94, envs finished 1
2026-01-17 13:23:04,048 : agent.on_policy : DEBUG : Mean Losses: [6.667113494127989]
2026-01-17 13:23:04,097 : worker.worker : DEBUG : Step 74728, finished rewards 11.99, envs finished 1
2026-01-17 13:23:04,144 : worker.worker : DEBUG : Step 74739, finished rewards -18.41, envs finished 1
2026-01-17 13:23:04,240 : agent.on_policy : DEBUG : Mean Losses: [5.419734507799149]
2026-01-17 13:23:04,259 : worker.worker : DEBUG : Step 74758, finished rewards 8.19, envs finished 1
2026-01-17 13:23:04,269 : worker.worker : DEBUG : Step 74760, finished rewards -15.61, envs finished 1
2026-01-17 13:23:04,437 : agent.on_policy : DEBUG : Mean Losses: [5.275303319096565]
2026-01-17 13:23:04,446 : worker.worker : DEBUG : Step 74785, finished rewards 6.75, envs finished 1
2026-01-17 13:23:04,543 : worker.worker : DEBUG : Step 74811, finished rewards 8.36, envs finished 1
2026-01-17 13:23:04,548 : worker.worker : DEBUG : Step 74812, finished rewards 2.72, envs finished 1
2026-01-17 13:23:04,647 : agent.on_policy : DEBUG : Mean Losses: [6.77894464880228]
2026-01-17 13:23:04,730 : worker.worker : DEBUG : Step 74830, finished rewards -10.22, envs finished 1
2026-01-17 13:23:04,740 : worker.worker : DEBUG : Step 74831, finished rewards 23.60, envs finished 1
2026-01-17 13:23:04,799 : worker.worker : DEBUG : Step 74842, finished rewards 6.99, envs finished 1
2026-01-17 13:23:04,978 : agent.on_policy : DEBUG : Mean Losses: [7.809007089585066]
2026-01-17 13:23:05,151 : worker.worker : DEBUG : Step 74878, finished rewards 22.71, envs finished 1
2026-01-17 13:23:05,230 : agent.on_policy : DEBUG : Mean Losses: [4.722367390990257]
2026-01-17 13:23:05,259 : worker.worker : DEBUG : Step 74888, finished rewards -0.93, envs finished 1
2026-01-17 13:23:05,407 : agent.on_policy : DEBUG : Mean Losses: [3.440473087131977]
2026-01-17 13:23:05,425 : worker.worker : DEBUG : Step 74916, finished rewards 29.11, envs finished 1
2026-01-17 13:23:05,432 : worker.worker : DEBUG : Step 74917, finished rewards -20.36, envs finished 1
2026-01-17 13:23:05,498 : worker.worker : DEBUG : Step 74931, finished rewards 16.12, envs finished 1
2026-01-17 13:23:05,634 : agent.on_policy : DEBUG : Mean Losses: [7.146143347024918]
2026-01-17 13:23:05,701 : worker.worker : DEBUG : Step 74960, finished rewards -6.92, envs finished 1
2026-01-17 13:23:05,721 : worker.worker : DEBUG : Step 74964, finished rewards 28.78, envs finished 1
2026-01-17 13:23:05,748 : worker.worker : DEBUG : Step 74970, finished rewards -3.71, envs finished 1
2026-01-17 13:23:05,870 : agent.on_policy : DEBUG : Mean Losses: [8.476806350052357]
2026-01-17 13:23:05,973 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.021343733845877507
2026-01-17 13:23:05,985 : worker.worker : INFO : Step 75000, Avg Reward 8.2179, Max Reward 77.4750, Loss [6.20312161]
2026-01-17 13:23:06,002 : worker.worker : DEBUG : Step 75004, finished rewards 3.61, envs finished 1
2026-01-17 13:23:06,106 : agent.on_policy : DEBUG : Mean Losses: [4.5361394584178925]
2026-01-17 13:23:06,131 : worker.worker : DEBUG : Step 75015, finished rewards 19.52, envs finished 1
2026-01-17 13:23:06,196 : worker.worker : DEBUG : Step 75025, finished rewards -39.03, envs finished 1
2026-01-17 13:23:06,327 : agent.on_policy : DEBUG : Mean Losses: [6.572996750473976]
2026-01-17 13:23:06,365 : worker.worker : DEBUG : Step 75051, finished rewards 27.90, envs finished 1
2026-01-17 13:23:06,375 : worker.worker : DEBUG : Step 75053, finished rewards 2.93, envs finished 1
2026-01-17 13:23:06,393 : worker.worker : DEBUG : Step 75057, finished rewards -9.92, envs finished 1
2026-01-17 13:23:06,504 : agent.on_policy : DEBUG : Mean Losses: [8.194428384304047]
2026-01-17 13:23:06,535 : worker.worker : DEBUG : Step 75079, finished rewards 11.44, envs finished 1
2026-01-17 13:23:06,598 : worker.worker : DEBUG : Step 75085, finished rewards -1.84, envs finished 1
2026-01-17 13:23:06,742 : agent.on_policy : DEBUG : Mean Losses: [4.642255172133446]
2026-01-17 13:23:06,750 : worker.worker : DEBUG : Step 75106, finished rewards 17.26, envs finished 1
2026-01-17 13:23:06,797 : worker.worker : DEBUG : Step 75119, finished rewards 21.98, envs finished 1
2026-01-17 13:23:06,901 : agent.on_policy : DEBUG : Mean Losses: [5.382339715957642]
2026-01-17 13:23:06,905 : worker.worker : DEBUG : Step 75137, finished rewards 1.45, envs finished 1
2026-01-17 13:23:06,933 : worker.worker : DEBUG : Step 75143, finished rewards 23.35, envs finished 1
2026-01-17 13:23:06,982 : worker.worker : DEBUG : Step 75150, finished rewards 23.27, envs finished 1
2026-01-17 13:23:07,090 : agent.on_policy : DEBUG : Mean Losses: [5.961218275129795]
2026-01-17 13:23:07,161 : worker.worker : DEBUG : Step 75183, finished rewards -0.04, envs finished 1
2026-01-17 13:23:07,312 : agent.on_policy : DEBUG : Mean Losses: [4.0300322920084]
2026-01-17 13:23:07,448 : worker.worker : DEBUG : Step 75220, finished rewards 18.24, envs finished 1
2026-01-17 13:23:07,560 : worker.worker : DEBUG : Step 75230, finished rewards 23.01, envs finished 1
2026-01-17 13:23:07,677 : agent.on_policy : DEBUG : Mean Losses: [8.484791718423367]
2026-01-17 13:23:07,686 : worker.worker : DEBUG : Step 75234, finished rewards -17.98, envs finished 1
2026-01-17 13:23:07,747 : worker.worker : DEBUG : Step 75243, finished rewards 22.66, envs finished 1
2026-01-17 13:23:07,773 : worker.worker : DEBUG : Step 75248, finished rewards -13.56, envs finished 1
2026-01-17 13:23:07,801 : worker.worker : DEBUG : Step 75255, finished rewards -27.81, envs finished 1
2026-01-17 13:23:07,901 : agent.on_policy : DEBUG : Mean Losses: [8.03698530420661]
2026-01-17 13:23:07,950 : worker.worker : DEBUG : Step 75274, finished rewards -6.40, envs finished 1
2026-01-17 13:23:07,969 : worker.worker : DEBUG : Step 75275, finished rewards 23.93, envs finished 1
2026-01-17 13:23:08,214 : agent.on_policy : DEBUG : Mean Losses: [4.519046489149332]
2026-01-17 13:23:08,272 : worker.worker : DEBUG : Step 75315, finished rewards 23.01, envs finished 1
2026-01-17 13:23:08,311 : worker.worker : DEBUG : Step 75325, finished rewards 21.86, envs finished 1
2026-01-17 13:23:08,405 : agent.on_policy : DEBUG : Mean Losses: [6.940767899155617]
2026-01-17 13:23:08,543 : worker.worker : DEBUG : Step 75359, finished rewards -0.12, envs finished 1
2026-01-17 13:23:08,603 : agent.on_policy : DEBUG : Mean Losses: [4.525308221578598]
2026-01-17 13:23:08,608 : worker.worker : DEBUG : Step 75361, finished rewards 3.18, envs finished 1
2026-01-17 13:23:08,624 : worker.worker : DEBUG : Step 75365, finished rewards 24.53, envs finished 1
2026-01-17 13:23:08,748 : worker.worker : DEBUG : Step 75387, finished rewards 9.12, envs finished 1
2026-01-17 13:23:08,857 : agent.on_policy : DEBUG : Mean Losses: [6.038298517465591]
2026-01-17 13:23:08,887 : worker.worker : DEBUG : Step 75399, finished rewards -14.51, envs finished 2
2026-01-17 13:23:08,987 : worker.worker : DEBUG : Step 75420, finished rewards 14.85, envs finished 1
2026-01-17 13:23:09,075 : agent.on_policy : DEBUG : Mean Losses: [7.342717623338103]
2026-01-17 13:23:09,076 : worker.worker : DEBUG : Step 75424, finished rewards 19.95, envs finished 1
2026-01-17 13:23:09,266 : agent.on_policy : DEBUG : Mean Losses: [1.8961695600301027]
2026-01-17 13:23:09,512 : worker.worker : DEBUG : Step 75483, finished rewards 0.40, envs finished 1
2026-01-17 13:23:09,556 : worker.worker : DEBUG : Step 75486, finished rewards 2.91, envs finished 1
2026-01-17 13:23:09,645 : agent.on_policy : DEBUG : Mean Losses: [6.407407529652119]
2026-01-17 13:23:09,777 : worker.worker : DEBUG : Step 75509, finished rewards 0.59, envs finished 1
2026-01-17 13:23:09,788 : worker.worker : DEBUG : Step 75510, finished rewards 8.75, envs finished 1
2026-01-17 13:23:09,932 : agent.on_policy : DEBUG : Mean Losses: [6.762708276510239]
2026-01-17 13:23:09,970 : worker.worker : DEBUG : Step 75524, finished rewards -21.91, envs finished 1
2026-01-17 13:23:09,975 : worker.worker : DEBUG : Step 75525, finished rewards -1.60, envs finished 1
2026-01-17 13:23:10,025 : worker.worker : DEBUG : Step 75538, finished rewards 7.44, envs finished 1
2026-01-17 13:23:10,030 : worker.worker : DEBUG : Step 75539, finished rewards 2.95, envs finished 1
2026-01-17 13:23:10,142 : agent.on_policy : DEBUG : Mean Losses: [7.97208022326231]
2026-01-17 13:23:10,303 : agent.on_policy : DEBUG : Mean Losses: [1.3276319950819016]
2026-01-17 13:23:10,310 : worker.worker : DEBUG : Step 75585, finished rewards 18.79, envs finished 1
2026-01-17 13:23:10,393 : worker.worker : DEBUG : Step 75609, finished rewards 29.42, envs finished 1
2026-01-17 13:23:10,397 : worker.worker : DEBUG : Step 75610, finished rewards 17.75, envs finished 1
2026-01-17 13:23:10,499 : agent.on_policy : DEBUG : Mean Losses: [8.805551297962666]
2026-01-17 13:23:10,537 : worker.worker : DEBUG : Step 75622, finished rewards 21.19, envs finished 1
2026-01-17 13:23:10,560 : worker.worker : DEBUG : Step 75624, finished rewards 29.14, envs finished 1
2026-01-17 13:23:10,604 : worker.worker : DEBUG : Step 75632, finished rewards 4.93, envs finished 1
2026-01-17 13:23:10,652 : worker.worker : DEBUG : Step 75641, finished rewards -9.20, envs finished 1
2026-01-17 13:23:10,725 : agent.on_policy : DEBUG : Mean Losses: [7.995314218103886]
2026-01-17 13:23:10,762 : worker.worker : DEBUG : Step 75659, finished rewards 2.70, envs finished 1
2026-01-17 13:23:11,015 : agent.on_policy : DEBUG : Mean Losses: [2.388538770377636]
2026-01-17 13:23:11,035 : worker.worker : DEBUG : Step 75686, finished rewards 17.16, envs finished 1
2026-01-17 13:23:11,208 : agent.on_policy : DEBUG : Mean Losses: [3.8537740781903267]
2026-01-17 13:23:11,254 : worker.worker : DEBUG : Step 75721, finished rewards 6.97, envs finished 1
2026-01-17 13:23:11,340 : worker.worker : DEBUG : Step 75739, finished rewards -3.06, envs finished 1
2026-01-17 13:23:11,445 : agent.on_policy : DEBUG : Mean Losses: [7.788961365818977]
2026-01-17 13:23:11,482 : worker.worker : DEBUG : Step 75753, finished rewards -5.69, envs finished 1
2026-01-17 13:23:11,582 : worker.worker : DEBUG : Step 75769, finished rewards -8.00, envs finished 1
2026-01-17 13:23:11,689 : agent.on_policy : DEBUG : Mean Losses: [7.988446913659573]
2026-01-17 13:23:11,768 : worker.worker : DEBUG : Step 75791, finished rewards 14.12, envs finished 1
2026-01-17 13:23:11,789 : worker.worker : DEBUG : Step 75795, finished rewards -25.74, envs finished 1
2026-01-17 13:23:11,826 : worker.worker : DEBUG : Step 75803, finished rewards -40.77, envs finished 1
2026-01-17 13:23:11,927 : agent.on_policy : DEBUG : Mean Losses: [7.894494883716106]
2026-01-17 13:23:11,949 : worker.worker : DEBUG : Step 75813, finished rewards -19.91, envs finished 1
2026-01-17 13:23:12,119 : worker.worker : DEBUG : Step 75835, finished rewards 7.92, envs finished 1
2026-01-17 13:23:12,186 : agent.on_policy : DEBUG : Mean Losses: [3.972691297531128]
2026-01-17 13:23:12,212 : worker.worker : DEBUG : Step 75847, finished rewards 23.74, envs finished 1
2026-01-17 13:23:12,298 : worker.worker : DEBUG : Step 75865, finished rewards 1.67, envs finished 1
2026-01-17 13:23:12,422 : agent.on_policy : DEBUG : Mean Losses: [4.658912882208824]
2026-01-17 13:23:12,564 : worker.worker : DEBUG : Step 75898, finished rewards 13.24, envs finished 1
2026-01-17 13:23:12,636 : agent.on_policy : DEBUG : Mean Losses: [4.165525004267693]
2026-01-17 13:23:12,668 : worker.worker : DEBUG : Step 75910, finished rewards 20.64, envs finished 1
2026-01-17 13:23:12,673 : worker.worker : DEBUG : Step 75911, finished rewards 7.21, envs finished 1
2026-01-17 13:23:12,876 : agent.on_policy : DEBUG : Mean Losses: [6.255344703793526]
2026-01-17 13:23:12,905 : worker.worker : DEBUG : Step 75943, finished rewards -4.79, envs finished 1
2026-01-17 13:23:12,926 : worker.worker : DEBUG : Step 75947, finished rewards 9.57, envs finished 1
2026-01-17 13:23:12,984 : worker.worker : DEBUG : Step 75959, finished rewards 23.61, envs finished 1
2026-01-17 13:23:13,108 : agent.on_policy : DEBUG : Mean Losses: [7.064255326986313]
2026-01-17 13:23:13,179 : worker.worker : DEBUG : Step 75984, finished rewards 28.69, envs finished 1
2026-01-17 13:23:13,210 : worker.worker : DEBUG : Step 75991, finished rewards -4.48, envs finished 1
2026-01-17 13:23:13,239 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02027654715358363
2026-01-17 13:23:13,326 : agent.on_policy : DEBUG : Mean Losses: [5.813004449009895]
2026-01-17 13:23:13,418 : worker.worker : DEBUG : Step 76024, finished rewards 6.90, envs finished 1
2026-01-17 13:23:13,449 : worker.worker : DEBUG : Step 76030, finished rewards -41.63, envs finished 1
2026-01-17 13:23:13,534 : agent.on_policy : DEBUG : Mean Losses: [6.062506143003702]
2026-01-17 13:23:13,562 : worker.worker : DEBUG : Step 76039, finished rewards 23.71, envs finished 1
2026-01-17 13:23:13,611 : worker.worker : DEBUG : Step 76046, finished rewards -8.98, envs finished 1
2026-01-17 13:23:12,951 : worker.worker : DEBUG : Step 76063, finished rewards 7.06, envs finished 1
2026-01-17 13:23:13,016 : agent.on_policy : DEBUG : Mean Losses: [5.960061598569155]
2026-01-17 13:23:13,068 : worker.worker : DEBUG : Step 76080, finished rewards 9.45, envs finished 1
2026-01-17 13:23:13,087 : worker.worker : DEBUG : Step 76084, finished rewards 23.12, envs finished 1
2026-01-17 13:23:13,233 : agent.on_policy : DEBUG : Mean Losses: [6.738714080303907]
2026-01-17 13:23:13,406 : worker.worker : DEBUG : Step 76115, finished rewards -8.38, envs finished 1
2026-01-17 13:23:13,533 : agent.on_policy : DEBUG : Mean Losses: [3.789964735507965]
2026-01-17 13:23:13,650 : worker.worker : DEBUG : Step 76157, finished rewards 6.32, envs finished 2
2026-01-17 13:23:13,657 : worker.worker : DEBUG : Step 76159, finished rewards -5.07, envs finished 1
2026-01-17 13:23:13,744 : agent.on_policy : DEBUG : Mean Losses: [7.460973657667637]
2026-01-17 13:23:13,752 : worker.worker : DEBUG : Step 76162, finished rewards 1.45, envs finished 1
2026-01-17 13:23:13,765 : worker.worker : DEBUG : Step 76165, finished rewards 17.59, envs finished 1
2026-01-17 13:23:13,928 : agent.on_policy : DEBUG : Mean Losses: [4.528599824756384]
2026-01-17 13:23:13,952 : worker.worker : DEBUG : Step 76200, finished rewards 5.39, envs finished 1
2026-01-17 13:23:13,989 : worker.worker : DEBUG : Step 76209, finished rewards 23.55, envs finished 1
2026-01-17 13:23:14,009 : worker.worker : DEBUG : Step 76214, finished rewards -2.66, envs finished 1
2026-01-17 13:23:14,097 : agent.on_policy : DEBUG : Mean Losses: [7.654329262673855]
2026-01-17 13:23:14,222 : worker.worker : DEBUG : Step 76253, finished rewards 21.32, envs finished 1
2026-01-17 13:23:14,309 : agent.on_policy : DEBUG : Mean Losses: [4.582426570355892]
2026-01-17 13:23:14,335 : worker.worker : DEBUG : Step 76265, finished rewards 13.12, envs finished 1
2026-01-17 13:23:14,387 : worker.worker : DEBUG : Step 76274, finished rewards 6.41, envs finished 1
2026-01-17 13:23:14,548 : agent.on_policy : DEBUG : Mean Losses: [5.135869398713112]
2026-01-17 13:23:14,550 : worker.worker : DEBUG : Step 76288, finished rewards 4.10, envs finished 1
2026-01-17 13:23:14,567 : worker.worker : DEBUG : Step 76292, finished rewards 24.70, envs finished 1
2026-01-17 13:23:14,623 : worker.worker : DEBUG : Step 76304, finished rewards -6.00, envs finished 1
2026-01-17 13:23:14,674 : worker.worker : DEBUG : Step 76319, finished rewards 13.99, envs finished 1
2026-01-17 13:23:14,782 : agent.on_policy : DEBUG : Mean Losses: [6.500056337565184]
2026-01-17 13:23:14,859 : worker.worker : DEBUG : Step 76331, finished rewards 3.96, envs finished 1
2026-01-17 13:23:15,031 : agent.on_policy : DEBUG : Mean Losses: [2.522972629405558]
2026-01-17 13:23:15,052 : worker.worker : DEBUG : Step 76359, finished rewards 23.80, envs finished 1
2026-01-17 13:23:15,090 : worker.worker : DEBUG : Step 76368, finished rewards 6.97, envs finished 1
2026-01-17 13:23:15,138 : worker.worker : DEBUG : Step 76381, finished rewards 23.24, envs finished 1
2026-01-17 13:23:15,195 : agent.on_policy : DEBUG : Mean Losses: [7.636073634028435]
2026-01-17 13:23:15,304 : worker.worker : DEBUG : Step 76411, finished rewards 23.08, envs finished 1
2026-01-17 13:23:15,378 : agent.on_policy : DEBUG : Mean Losses: [7.684430094435811]
2026-01-17 13:23:15,410 : worker.worker : DEBUG : Step 76425, finished rewards -7.91, envs finished 1
2026-01-17 13:23:15,562 : agent.on_policy : DEBUG : Mean Losses: [4.332944791764021]
2026-01-17 13:23:15,566 : worker.worker : DEBUG : Step 76449, finished rewards -9.73, envs finished 1
2026-01-17 13:23:15,610 : worker.worker : DEBUG : Step 76462, finished rewards -6.82, envs finished 1
2026-01-17 13:23:15,656 : worker.worker : DEBUG : Step 76476, finished rewards 6.80, envs finished 1
2026-01-17 13:23:15,739 : agent.on_policy : DEBUG : Mean Losses: [7.542168535292149]
2026-01-17 13:23:15,781 : worker.worker : DEBUG : Step 76489, finished rewards 13.68, envs finished 1
2026-01-17 13:23:15,952 : agent.on_policy : DEBUG : Mean Losses: [4.224143907427788]
2026-01-17 13:23:16,020 : worker.worker : DEBUG : Step 76529, finished rewards 4.22, envs finished 1
2026-01-17 13:23:16,028 : worker.worker : DEBUG : Step 76531, finished rewards 14.47, envs finished 1
2026-01-17 13:23:16,058 : worker.worker : DEBUG : Step 76536, finished rewards -92.97, envs finished 1
2026-01-17 13:23:16,177 : agent.on_policy : DEBUG : Mean Losses: [9.178944759070873]
2026-01-17 13:23:16,224 : worker.worker : DEBUG : Step 76553, finished rewards 13.23, envs finished 1
2026-01-17 13:23:16,355 : agent.on_policy : DEBUG : Mean Losses: [3.4669383205473423]
2026-01-17 13:23:16,366 : worker.worker : DEBUG : Step 76578, finished rewards 5.73, envs finished 1
2026-01-17 13:23:16,418 : worker.worker : DEBUG : Step 76585, finished rewards 51.06, envs finished 1
2026-01-17 13:23:16,658 : agent.on_policy : DEBUG : Mean Losses: [4.867370029911399]
2026-01-17 13:23:16,704 : worker.worker : DEBUG : Step 76621, finished rewards 23.17, envs finished 1
2026-01-17 13:23:16,730 : worker.worker : DEBUG : Step 76628, finished rewards 23.30, envs finished 1
2026-01-17 13:23:16,745 : worker.worker : DEBUG : Step 76631, finished rewards 18.93, envs finished 1
2026-01-17 13:23:16,830 : agent.on_policy : DEBUG : Mean Losses: [12.651241764426231]
2026-01-17 13:23:16,846 : worker.worker : DEBUG : Step 76644, finished rewards -11.17, envs finished 1
2026-01-17 13:23:17,022 : agent.on_policy : DEBUG : Mean Losses: [4.345012212172151]
2026-01-17 13:23:17,042 : worker.worker : DEBUG : Step 76677, finished rewards -55.16, envs finished 1
2026-01-17 13:23:17,071 : worker.worker : DEBUG : Step 76683, finished rewards 18.97, envs finished 1
2026-01-17 13:23:17,081 : worker.worker : DEBUG : Step 76686, finished rewards 5.16, envs finished 1
2026-01-17 13:23:17,196 : agent.on_policy : DEBUG : Mean Losses: [6.019903287291527]
2026-01-17 13:23:17,298 : worker.worker : DEBUG : Step 76726, finished rewards -20.62, envs finished 1
2026-01-17 13:23:17,416 : agent.on_policy : DEBUG : Mean Losses: [5.116283278912306]
2026-01-17 13:23:17,433 : worker.worker : DEBUG : Step 76739, finished rewards 3.94, envs finished 1
2026-01-17 13:23:17,502 : worker.worker : DEBUG : Step 76747, finished rewards 4.52, envs finished 1
2026-01-17 13:23:17,531 : worker.worker : DEBUG : Step 76753, finished rewards 11.13, envs finished 1
2026-01-17 13:23:17,570 : worker.worker : DEBUG : Step 76761, finished rewards -7.56, envs finished 1
2026-01-17 13:23:17,685 : agent.on_policy : DEBUG : Mean Losses: [8.36211122572422]
2026-01-17 13:23:17,788 : worker.worker : DEBUG : Step 76787, finished rewards 17.55, envs finished 1
2026-01-17 13:23:17,897 : agent.on_policy : DEBUG : Mean Losses: [3.860419485718012]
2026-01-17 13:23:17,995 : worker.worker : DEBUG : Step 76817, finished rewards -6.39, envs finished 1
2026-01-17 13:23:18,015 : worker.worker : DEBUG : Step 76820, finished rewards -11.61, envs finished 1
2026-01-17 13:23:18,172 : agent.on_policy : DEBUG : Mean Losses: [5.730204112827778]
2026-01-17 13:23:18,213 : worker.worker : DEBUG : Step 76844, finished rewards 30.55, envs finished 1
2026-01-17 13:23:18,223 : worker.worker : DEBUG : Step 76846, finished rewards 18.40, envs finished 1
2026-01-17 13:23:18,347 : agent.on_policy : DEBUG : Mean Losses: [7.314530521631241]
2026-01-17 13:23:18,446 : worker.worker : DEBUG : Step 76884, finished rewards -13.41, envs finished 2
2026-01-17 13:23:18,469 : worker.worker : DEBUG : Step 76889, finished rewards -13.73, envs finished 1
2026-01-17 13:23:18,565 : agent.on_policy : DEBUG : Mean Losses: [7.395040463656187]
2026-01-17 13:23:18,634 : worker.worker : DEBUG : Step 76910, finished rewards 1.12, envs finished 1
2026-01-17 13:23:18,644 : worker.worker : DEBUG : Step 76912, finished rewards 23.72, envs finished 1
2026-01-17 13:23:18,816 : agent.on_policy : DEBUG : Mean Losses: [6.030246455222368]
2026-01-17 13:23:18,841 : worker.worker : DEBUG : Step 76932, finished rewards 9.40, envs finished 1
2026-01-17 13:23:19,121 : agent.on_policy : DEBUG : Mean Losses: [2.705466203391552]
2026-01-17 13:23:19,125 : worker.worker : DEBUG : Step 76961, finished rewards 6.75, envs finished 1
2026-01-17 13:23:19,141 : worker.worker : DEBUG : Step 76964, finished rewards 5.28, envs finished 1
2026-01-17 13:23:19,193 : worker.worker : DEBUG : Step 76979, finished rewards 22.93, envs finished 1
2026-01-17 13:23:19,317 : agent.on_policy : DEBUG : Mean Losses: [4.715646345168352]
2026-01-17 13:23:19,340 : worker.worker : DEBUG : Step 76997, finished rewards 27.96, envs finished 1
2026-01-17 13:23:19,345 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:23:19,367 : worker.worker : DEBUG : Step 77003, finished rewards 3.90, envs finished 1
2026-01-17 13:23:19,476 : agent.on_policy : DEBUG : Mean Losses: [4.780395774170756]
2026-01-17 13:23:19,491 : worker.worker : DEBUG : Step 77028, finished rewards 20.37, envs finished 1
2026-01-17 13:23:19,508 : worker.worker : DEBUG : Step 77031, finished rewards -3.46, envs finished 1
2026-01-17 13:23:19,561 : worker.worker : DEBUG : Step 77039, finished rewards -3.29, envs finished 1
2026-01-17 13:23:19,731 : agent.on_policy : DEBUG : Mean Losses: [5.955532763153315]
2026-01-17 13:23:19,935 : worker.worker : DEBUG : Step 77085, finished rewards 3.57, envs finished 1
2026-01-17 13:23:19,995 : agent.on_policy : DEBUG : Mean Losses: [4.598907273262739]
2026-01-17 13:23:20,056 : worker.worker : DEBUG : Step 77104, finished rewards 3.20, envs finished 1
2026-01-17 13:23:20,074 : worker.worker : DEBUG : Step 77108, finished rewards -15.23, envs finished 1
2026-01-17 13:23:20,109 : worker.worker : DEBUG : Step 77110, finished rewards 9.66, envs finished 1
2026-01-17 13:23:20,141 : worker.worker : DEBUG : Step 77115, finished rewards 27.38, envs finished 1
2026-01-17 13:23:20,156 : worker.worker : DEBUG : Step 77117, finished rewards 28.97, envs finished 1
2026-01-17 13:23:20,221 : agent.on_policy : DEBUG : Mean Losses: [12.078100483864546]
2026-01-17 13:23:20,288 : worker.worker : DEBUG : Step 77135, finished rewards -3.48, envs finished 1
2026-01-17 13:23:20,382 : worker.worker : DEBUG : Step 77144, finished rewards 15.21, envs finished 1
2026-01-17 13:23:20,521 : agent.on_policy : DEBUG : Mean Losses: [4.290320932865143]
2026-01-17 13:23:20,665 : agent.on_policy : DEBUG : Mean Losses: [1.6804239302873611]
2026-01-17 13:23:20,726 : worker.worker : DEBUG : Step 77194, finished rewards 26.08, envs finished 1
2026-01-17 13:23:20,769 : worker.worker : DEBUG : Step 77204, finished rewards 22.63, envs finished 1
2026-01-17 13:23:20,900 : agent.on_policy : DEBUG : Mean Losses: [7.297698229551315]
2026-01-17 13:23:20,947 : worker.worker : DEBUG : Step 77223, finished rewards -1.35, envs finished 1
2026-01-17 13:23:20,977 : worker.worker : DEBUG : Step 77228, finished rewards 11.06, envs finished 1
2026-01-17 13:23:21,024 : worker.worker : DEBUG : Step 77238, finished rewards 1.07, envs finished 1
2026-01-17 13:23:21,126 : agent.on_policy : DEBUG : Mean Losses: [7.85343325138092]
2026-01-17 13:23:21,132 : worker.worker : DEBUG : Step 77249, finished rewards 12.87, envs finished 1
2026-01-17 13:23:21,232 : worker.worker : DEBUG : Step 77265, finished rewards -22.99, envs finished 1
2026-01-17 13:23:21,362 : agent.on_policy : DEBUG : Mean Losses: [3.5067813470959663]
2026-01-17 13:23:21,455 : worker.worker : DEBUG : Step 77301, finished rewards -26.34, envs finished 1
2026-01-17 13:23:21,600 : agent.on_policy : DEBUG : Mean Losses: [5.775774255394936]
2026-01-17 13:23:21,628 : worker.worker : DEBUG : Step 77318, finished rewards 7.31, envs finished 1
2026-01-17 13:23:21,643 : worker.worker : DEBUG : Step 77321, finished rewards -1.77, envs finished 1
2026-01-17 13:23:21,689 : worker.worker : DEBUG : Step 77331, finished rewards 24.29, envs finished 1
2026-01-17 13:23:21,748 : worker.worker : DEBUG : Step 77343, finished rewards 24.27, envs finished 1
2026-01-17 13:23:21,831 : agent.on_policy : DEBUG : Mean Losses: [9.644886136054993]
2026-01-17 13:23:21,920 : worker.worker : DEBUG : Step 77356, finished rewards 2.43, envs finished 1
2026-01-17 13:23:21,938 : worker.worker : DEBUG : Step 77359, finished rewards 23.94, envs finished 1
2026-01-17 13:23:21,968 : worker.worker : DEBUG : Step 77363, finished rewards -5.40, envs finished 1
2026-01-17 13:23:22,152 : agent.on_policy : DEBUG : Mean Losses: [6.744041740894318]
2026-01-17 13:23:22,321 : agent.on_policy : DEBUG : Mean Losses: [1.5627372562885284]
2026-01-17 13:23:22,365 : worker.worker : DEBUG : Step 77418, finished rewards 19.98, envs finished 1
2026-01-17 13:23:22,584 : agent.on_policy : DEBUG : Mean Losses: [4.686167895793915]
2026-01-17 13:23:22,619 : worker.worker : DEBUG : Step 77449, finished rewards 13.02, envs finished 1
2026-01-17 13:23:22,649 : worker.worker : DEBUG : Step 77455, finished rewards 2.98, envs finished 1
2026-01-17 13:23:22,675 : worker.worker : DEBUG : Step 77460, finished rewards -3.53, envs finished 1
2026-01-17 13:23:22,695 : worker.worker : DEBUG : Step 77464, finished rewards 9.54, envs finished 1
2026-01-17 13:23:22,802 : agent.on_policy : DEBUG : Mean Losses: [9.563557617366314]
2026-01-17 13:23:22,877 : worker.worker : DEBUG : Step 77485, finished rewards -1.97, envs finished 1
2026-01-17 13:23:22,928 : worker.worker : DEBUG : Step 77494, finished rewards -2.15, envs finished 1
2026-01-17 13:23:22,959 : worker.worker : DEBUG : Step 77498, finished rewards 7.21, envs finished 1
2026-01-17 13:23:23,051 : agent.on_policy : DEBUG : Mean Losses: [6.462846267968416]
2026-01-17 13:23:23,277 : worker.worker : DEBUG : Step 77532, finished rewards 5.14, envs finished 1
2026-01-17 13:23:23,378 : agent.on_policy : DEBUG : Mean Losses: [4.064184762537479]
2026-01-17 13:23:23,418 : worker.worker : DEBUG : Step 77548, finished rewards 22.65, envs finished 1
2026-01-17 13:23:23,467 : worker.worker : DEBUG : Step 77555, finished rewards 12.85, envs finished 1
2026-01-17 13:23:23,563 : agent.on_policy : DEBUG : Mean Losses: [6.132694207131863]
2026-01-17 13:23:23,570 : worker.worker : DEBUG : Step 77569, finished rewards 11.08, envs finished 1
2026-01-17 13:23:23,657 : worker.worker : DEBUG : Step 77585, finished rewards 23.84, envs finished 1
2026-01-17 13:23:23,665 : worker.worker : DEBUG : Step 77586, finished rewards 17.50, envs finished 1
2026-01-17 13:23:23,688 : worker.worker : DEBUG : Step 77589, finished rewards -0.47, envs finished 1
2026-01-17 13:23:23,743 : worker.worker : DEBUG : Step 77597, finished rewards 20.35, envs finished 1
2026-01-17 13:23:23,816 : agent.on_policy : DEBUG : Mean Losses: [10.226904399693012]
2026-01-17 13:23:24,019 : agent.on_policy : DEBUG : Mean Losses: [1.7333149127662182]
2026-01-17 13:23:24,035 : worker.worker : DEBUG : Step 77635, finished rewards 27.88, envs finished 1
2026-01-17 13:23:24,268 : agent.on_policy : DEBUG : Mean Losses: [3.4002987071871758]
2026-01-17 13:23:24,274 : worker.worker : DEBUG : Step 77665, finished rewards -0.03, envs finished 1
2026-01-17 13:23:24,295 : worker.worker : DEBUG : Step 77669, finished rewards 17.52, envs finished 1
2026-01-17 13:23:24,324 : worker.worker : DEBUG : Step 77674, finished rewards 6.02, envs finished 1
2026-01-17 13:23:24,360 : worker.worker : DEBUG : Step 77681, finished rewards 21.66, envs finished 1
2026-01-17 13:23:24,402 : worker.worker : DEBUG : Step 77690, finished rewards 23.51, envs finished 1
2026-01-17 13:23:24,492 : agent.on_policy : DEBUG : Mean Losses: [9.78889212757349]
2026-01-17 13:23:24,568 : worker.worker : DEBUG : Step 77711, finished rewards 4.43, envs finished 1
2026-01-17 13:23:24,607 : worker.worker : DEBUG : Step 77718, finished rewards -6.80, envs finished 1
2026-01-17 13:23:24,625 : worker.worker : DEBUG : Step 77721, finished rewards 28.48, envs finished 1
2026-01-17 13:23:24,771 : agent.on_policy : DEBUG : Mean Losses: [7.130157344043255]
2026-01-17 13:23:24,978 : agent.on_policy : DEBUG : Mean Losses: [1.779222495853901]
2026-01-17 13:23:25,095 : worker.worker : DEBUG : Step 77784, finished rewards 7.97, envs finished 1
2026-01-17 13:23:25,248 : agent.on_policy : DEBUG : Mean Losses: [5.433420814573765]
2026-01-17 13:23:25,258 : worker.worker : DEBUG : Step 77794, finished rewards 9.10, envs finished 1
2026-01-17 13:23:25,280 : worker.worker : DEBUG : Step 77798, finished rewards -7.74, envs finished 1
2026-01-17 13:23:25,336 : worker.worker : DEBUG : Step 77809, finished rewards 19.27, envs finished 1
2026-01-17 13:23:25,368 : worker.worker : DEBUG : Step 77815, finished rewards 6.90, envs finished 1
2026-01-17 13:23:25,505 : agent.on_policy : DEBUG : Mean Losses: [8.920066714286804]
2026-01-17 13:23:25,642 : worker.worker : DEBUG : Step 77855, finished rewards -40.61, envs finished 1
2026-01-17 13:23:25,731 : agent.on_policy : DEBUG : Mean Losses: [5.235879093408585]
2026-01-17 13:23:25,743 : worker.worker : DEBUG : Step 77858, finished rewards -14.13, envs finished 1
2026-01-17 13:23:25,809 : worker.worker : DEBUG : Step 77867, finished rewards -8.35, envs finished 1
2026-01-17 13:23:25,927 : worker.worker : DEBUG : Step 77886, finished rewards 14.69, envs finished 1
2026-01-17 13:23:26,001 : agent.on_policy : DEBUG : Mean Losses: [6.890928104519844]
2026-01-17 13:23:26,148 : worker.worker : DEBUG : Step 77916, finished rewards 3.21, envs finished 1
2026-01-17 13:23:26,163 : worker.worker : DEBUG : Step 77918, finished rewards 0.16, envs finished 1
2026-01-17 13:23:26,238 : agent.on_policy : DEBUG : Mean Losses: [6.740965023636818]
2026-01-17 13:23:26,462 : agent.on_policy : DEBUG : Mean Losses: [2.5250710770487785]
2026-01-17 13:23:26,506 : worker.worker : DEBUG : Step 77961, finished rewards 22.97, envs finished 1
2026-01-17 13:23:26,518 : worker.worker : DEBUG : Step 77963, finished rewards -9.19, envs finished 1
2026-01-17 13:23:26,557 : worker.worker : DEBUG : Step 77970, finished rewards 9.71, envs finished 1
2026-01-17 13:23:26,619 : worker.worker : DEBUG : Step 77982, finished rewards -16.81, envs finished 1
2026-01-17 13:23:26,774 : agent.on_policy : DEBUG : Mean Losses: [9.559671863913536]
2026-01-17 13:23:26,858 : worker.worker : DEBUG : Step 77996, finished rewards -10.15, envs finished 1
2026-01-17 13:23:26,873 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:23:26,898 : worker.worker : DEBUG : Step 78003, finished rewards 29.31, envs finished 1
2026-01-17 13:23:26,923 : worker.worker : DEBUG : Step 78006, finished rewards 3.74, envs finished 1
2026-01-17 13:23:27,068 : agent.on_policy : DEBUG : Mean Losses: [7.194952664896846]
2026-01-17 13:23:27,365 : agent.on_policy : DEBUG : Mean Losses: [1.3623283207416534]
2026-01-17 13:23:27,394 : worker.worker : DEBUG : Step 78054, finished rewards 29.52, envs finished 1
2026-01-17 13:23:27,467 : worker.worker : DEBUG : Step 78066, finished rewards 14.71, envs finished 1
2026-01-17 13:23:27,617 : agent.on_policy : DEBUG : Mean Losses: [5.885947480797768]
2026-01-17 13:23:27,644 : worker.worker : DEBUG : Step 78086, finished rewards -23.78, envs finished 1
2026-01-17 13:23:27,673 : worker.worker : DEBUG : Step 78091, finished rewards 23.29, envs finished 1
2026-01-17 13:23:27,739 : worker.worker : DEBUG : Step 78105, finished rewards 8.59, envs finished 1
2026-01-17 13:23:27,843 : agent.on_policy : DEBUG : Mean Losses: [7.978153586387634]
2026-01-17 13:23:27,849 : worker.worker : DEBUG : Step 78113, finished rewards -11.44, envs finished 1
2026-01-17 13:23:27,915 : worker.worker : DEBUG : Step 78127, finished rewards 2.55, envs finished 1
2026-01-17 13:23:27,966 : worker.worker : DEBUG : Step 78140, finished rewards -3.62, envs finished 1
2026-01-17 13:23:28,075 : agent.on_policy : DEBUG : Mean Losses: [5.3927608616650105]
2026-01-17 13:23:28,238 : worker.worker : DEBUG : Step 78173, finished rewards 12.68, envs finished 1
2026-01-17 13:23:28,335 : agent.on_policy : DEBUG : Mean Losses: [4.178964622318745]
2026-01-17 13:23:28,442 : worker.worker : DEBUG : Step 78190, finished rewards 15.84, envs finished 1
2026-01-17 13:23:28,478 : worker.worker : DEBUG : Step 78195, finished rewards 25.11, envs finished 1
2026-01-17 13:23:28,565 : worker.worker : DEBUG : Step 78206, finished rewards 23.02, envs finished 1
2026-01-17 13:23:28,671 : agent.on_policy : DEBUG : Mean Losses: [9.98959755152464]
2026-01-17 13:23:28,742 : worker.worker : DEBUG : Step 78220, finished rewards 0.62, envs finished 1
2026-01-17 13:23:28,903 : agent.on_policy : DEBUG : Mean Losses: [4.19016785081476]
2026-01-17 13:23:28,933 : worker.worker : DEBUG : Step 78247, finished rewards -51.41, envs finished 1
2026-01-17 13:23:29,009 : worker.worker : DEBUG : Step 78266, finished rewards -1.98, envs finished 1
2026-01-17 13:23:29,147 : agent.on_policy : DEBUG : Mean Losses: [5.962161675095558]
2026-01-17 13:23:29,184 : worker.worker : DEBUG : Step 78276, finished rewards 28.94, envs finished 1
2026-01-17 13:23:29,250 : worker.worker : DEBUG : Step 78283, finished rewards 4.00, envs finished 1
2026-01-17 13:23:29,369 : worker.worker : DEBUG : Step 78293, finished rewards 1.96, envs finished 1
2026-01-17 13:23:29,476 : agent.on_policy : DEBUG : Mean Losses: [6.542574293911457]
2026-01-17 13:23:29,589 : worker.worker : DEBUG : Step 78322, finished rewards 1.20, envs finished 1
2026-01-17 13:23:29,842 : agent.on_policy : DEBUG : Mean Losses: [6.079277858138084]
2026-01-17 13:23:29,844 : worker.worker : DEBUG : Step 78336, finished rewards -4.02, envs finished 1
2026-01-17 13:23:29,872 : worker.worker : DEBUG : Step 78339, finished rewards 9.40, envs finished 1
2026-01-17 13:23:29,890 : worker.worker : DEBUG : Step 78342, finished rewards 23.45, envs finished 1
2026-01-17 13:23:30,066 : agent.on_policy : DEBUG : Mean Losses: [3.43248469568789]
2026-01-17 13:23:30,104 : worker.worker : DEBUG : Step 78376, finished rewards 17.81, envs finished 1
2026-01-17 13:23:30,184 : worker.worker : DEBUG : Step 78395, finished rewards 7.90, envs finished 1
2026-01-17 13:23:30,299 : agent.on_policy : DEBUG : Mean Losses: [7.154957011342049]
2026-01-17 13:23:30,392 : worker.worker : DEBUG : Step 78414, finished rewards 2.51, envs finished 1
2026-01-17 13:23:30,435 : worker.worker : DEBUG : Step 78420, finished rewards 19.73, envs finished 1
2026-01-17 13:23:30,494 : worker.worker : DEBUG : Step 78426, finished rewards 24.52, envs finished 1
2026-01-17 13:23:30,530 : worker.worker : DEBUG : Step 78431, finished rewards 23.30, envs finished 1
2026-01-17 13:23:30,626 : agent.on_policy : DEBUG : Mean Losses: [12.974092524498701]
2026-01-17 13:23:30,651 : worker.worker : DEBUG : Step 78438, finished rewards -15.37, envs finished 1
2026-01-17 13:23:30,848 : agent.on_policy : DEBUG : Mean Losses: [1.9897898212075233]
2026-01-17 13:23:30,906 : worker.worker : DEBUG : Step 78476, finished rewards 18.20, envs finished 1
2026-01-17 13:23:31,069 : agent.on_policy : DEBUG : Mean Losses: [4.889046758413315]
2026-01-17 13:23:31,091 : worker.worker : DEBUG : Step 78502, finished rewards -11.25, envs finished 1
2026-01-17 13:23:31,172 : worker.worker : DEBUG : Step 78521, finished rewards 11.17, envs finished 1
2026-01-17 13:23:31,178 : worker.worker : DEBUG : Step 78522, finished rewards 21.93, envs finished 1
2026-01-17 13:23:31,191 : worker.worker : DEBUG : Step 78524, finished rewards -2.96, envs finished 1
2026-01-17 13:23:31,298 : agent.on_policy : DEBUG : Mean Losses: [10.57557663321495]
2026-01-17 13:23:31,378 : worker.worker : DEBUG : Step 78539, finished rewards 2.31, envs finished 1
2026-01-17 13:23:31,453 : worker.worker : DEBUG : Step 78549, finished rewards 7.93, envs finished 1
2026-01-17 13:23:31,505 : worker.worker : DEBUG : Step 78552, finished rewards 1.60, envs finished 1
2026-01-17 13:23:31,673 : agent.on_policy : DEBUG : Mean Losses: [7.3212343864142895]
2026-01-17 13:23:31,917 : agent.on_policy : DEBUG : Mean Losses: [1.4959487579762936]
2026-01-17 13:23:32,002 : worker.worker : DEBUG : Step 78608, finished rewards 12.24, envs finished 1
2026-01-17 13:23:32,148 : worker.worker : DEBUG : Step 78623, finished rewards 26.84, envs finished 1
2026-01-17 13:23:32,241 : agent.on_policy : DEBUG : Mean Losses: [6.230799615383148]
2026-01-17 13:23:32,262 : worker.worker : DEBUG : Step 78628, finished rewards 13.34, envs finished 1
2026-01-17 13:23:32,355 : worker.worker : DEBUG : Step 78641, finished rewards 3.29, envs finished 1
2026-01-17 13:23:32,372 : worker.worker : DEBUG : Step 78643, finished rewards 22.18, envs finished 1
2026-01-17 13:23:32,516 : agent.on_policy : DEBUG : Mean Losses: [7.184760075062513]
2026-01-17 13:23:32,560 : worker.worker : DEBUG : Step 78668, finished rewards 11.18, envs finished 1
2026-01-17 13:23:32,743 : agent.on_policy : DEBUG : Mean Losses: [3.6544566452503204]
2026-01-17 13:23:32,774 : worker.worker : DEBUG : Step 78692, finished rewards -13.52, envs finished 1
2026-01-17 13:23:32,790 : worker.worker : DEBUG : Step 78693, finished rewards 29.27, envs finished 1
2026-01-17 13:23:32,833 : worker.worker : DEBUG : Step 78698, finished rewards 71.98, envs finished 1
2026-01-17 13:23:32,936 : worker.worker : DEBUG : Step 78719, finished rewards 23.36, envs finished 1
2026-01-17 13:23:33,072 : agent.on_policy : DEBUG : Mean Losses: [7.925163883715868]
2026-01-17 13:23:33,191 : worker.worker : DEBUG : Step 78740, finished rewards 16.99, envs finished 1
2026-01-17 13:23:33,312 : agent.on_policy : DEBUG : Mean Losses: [4.112456016242504]
2026-01-17 13:23:33,322 : worker.worker : DEBUG : Step 78754, finished rewards 7.49, envs finished 1
2026-01-17 13:23:33,433 : worker.worker : DEBUG : Step 78763, finished rewards 21.84, envs finished 1
2026-01-17 13:23:33,514 : worker.worker : DEBUG : Step 78767, finished rewards -11.14, envs finished 1
2026-01-17 13:23:33,740 : agent.on_policy : DEBUG : Mean Losses: [5.81005621701479]
2026-01-17 13:23:33,775 : worker.worker : DEBUG : Step 78792, finished rewards 19.45, envs finished 1
2026-01-17 13:23:33,841 : worker.worker : DEBUG : Step 78806, finished rewards 8.04, envs finished 1
2026-01-17 13:23:33,882 : worker.worker : DEBUG : Step 78814, finished rewards 23.46, envs finished 1
2026-01-17 13:23:33,980 : agent.on_policy : DEBUG : Mean Losses: [7.536199644207954]
2026-01-17 13:23:33,983 : worker.worker : DEBUG : Step 78816, finished rewards 8.05, envs finished 1
2026-01-17 13:23:34,077 : worker.worker : DEBUG : Step 78832, finished rewards 24.65, envs finished 1
2026-01-17 13:23:34,239 : agent.on_policy : DEBUG : Mean Losses: [3.302899206057191]
2026-01-17 13:23:34,398 : worker.worker : DEBUG : Step 78875, finished rewards 3.46, envs finished 1
2026-01-17 13:23:34,519 : agent.on_policy : DEBUG : Mean Losses: [3.5308973491191864]
2026-01-17 13:23:34,523 : worker.worker : DEBUG : Step 78880, finished rewards 8.43, envs finished 1
2026-01-17 13:23:34,591 : worker.worker : DEBUG : Step 78887, finished rewards 23.24, envs finished 1
2026-01-17 13:23:34,672 : worker.worker : DEBUG : Step 78898, finished rewards 30.07, envs finished 1
2026-01-17 13:23:34,710 : worker.worker : DEBUG : Step 78901, finished rewards -3.95, envs finished 1
2026-01-17 13:23:34,767 : worker.worker : DEBUG : Step 78911, finished rewards 23.44, envs finished 1
2026-01-17 13:23:34,861 : agent.on_policy : DEBUG : Mean Losses: [10.546684682369232]
2026-01-17 13:23:35,115 : agent.on_policy : DEBUG : Mean Losses: [2.809345228597522]
2026-01-17 13:23:35,161 : worker.worker : DEBUG : Step 78955, finished rewards 3.63, envs finished 1
2026-01-17 13:23:35,253 : worker.worker : DEBUG : Step 78971, finished rewards 30.15, envs finished 1
2026-01-17 13:23:35,407 : agent.on_policy : DEBUG : Mean Losses: [8.552912779152393]
2026-01-17 13:23:35,421 : worker.worker : DEBUG : Step 78980, finished rewards 18.49, envs finished 1
2026-01-17 13:23:35,480 : worker.worker : DEBUG : Step 78993, finished rewards 0.86, envs finished 1
2026-01-17 13:23:35,505 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:23:35,526 : worker.worker : DEBUG : Step 79003, finished rewards 24.62, envs finished 1
2026-01-17 13:23:35,626 : agent.on_policy : DEBUG : Mean Losses: [7.9544669054448605]
2026-01-17 13:23:35,719 : worker.worker : DEBUG : Step 79020, finished rewards 4.38, envs finished 1
2026-01-17 13:23:35,746 : worker.worker : DEBUG : Step 79024, finished rewards -14.80, envs finished 1
2026-01-17 13:23:35,764 : worker.worker : DEBUG : Step 79026, finished rewards -0.62, envs finished 1
2026-01-17 13:23:35,923 : agent.on_policy : DEBUG : Mean Losses: [6.288282820954919]
2026-01-17 13:23:35,994 : worker.worker : DEBUG : Step 79061, finished rewards 24.78, envs finished 1
2026-01-17 13:23:36,109 : agent.on_policy : DEBUG : Mean Losses: [4.757384780794382]
2026-01-17 13:23:36,125 : worker.worker : DEBUG : Step 79074, finished rewards 3.01, envs finished 1
2026-01-17 13:23:36,167 : worker.worker : DEBUG : Step 79083, finished rewards 24.80, envs finished 1
2026-01-17 13:23:36,291 : agent.on_policy : DEBUG : Mean Losses: [4.496999256312847]
2026-01-17 13:23:36,298 : worker.worker : DEBUG : Step 79105, finished rewards 4.92, envs finished 1
2026-01-17 13:23:36,341 : worker.worker : DEBUG : Step 79109, finished rewards 28.81, envs finished 1
2026-01-17 13:23:36,394 : worker.worker : DEBUG : Step 79119, finished rewards 4.74, envs finished 1
2026-01-17 13:23:36,440 : worker.worker : DEBUG : Step 79130, finished rewards 15.54, envs finished 1
2026-01-17 13:23:36,608 : agent.on_policy : DEBUG : Mean Losses: [6.735797945410013]
2026-01-17 13:23:36,861 : agent.on_policy : DEBUG : Mean Losses: [3.537224158644676]
2026-01-17 13:23:36,909 : worker.worker : DEBUG : Step 79179, finished rewards -15.24, envs finished 1
2026-01-17 13:23:36,948 : worker.worker : DEBUG : Step 79187, finished rewards 5.21, envs finished 1
2026-01-17 13:23:37,050 : agent.on_policy : DEBUG : Mean Losses: [6.882994666695595]
2026-01-17 13:23:37,139 : worker.worker : DEBUG : Step 79219, finished rewards -16.67, envs finished 1
2026-01-17 13:23:37,147 : worker.worker : DEBUG : Step 79220, finished rewards -8.15, envs finished 1
2026-01-17 13:23:37,189 : worker.worker : DEBUG : Step 79228, finished rewards 11.67, envs finished 1
2026-01-17 13:23:37,297 : agent.on_policy : DEBUG : Mean Losses: [7.969489581882954]
2026-01-17 13:23:37,314 : worker.worker : DEBUG : Step 79237, finished rewards -6.85, envs finished 1
2026-01-17 13:23:37,375 : worker.worker : DEBUG : Step 79246, finished rewards -11.12, envs finished 1
2026-01-17 13:23:37,535 : agent.on_policy : DEBUG : Mean Losses: [4.521648965775967]
2026-01-17 13:23:37,577 : worker.worker : DEBUG : Step 79272, finished rewards 24.44, envs finished 1
2026-01-17 13:23:37,621 : worker.worker : DEBUG : Step 79280, finished rewards 22.48, envs finished 1
2026-01-17 13:23:37,734 : agent.on_policy : DEBUG : Mean Losses: [6.036725156009197]
2026-01-17 13:23:37,792 : worker.worker : DEBUG : Step 79305, finished rewards 29.40, envs finished 1
2026-01-17 13:23:37,840 : worker.worker : DEBUG : Step 79315, finished rewards -1.37, envs finished 1
2026-01-17 13:23:37,864 : worker.worker : DEBUG : Step 79319, finished rewards 20.40, envs finished 1
2026-01-17 13:23:37,887 : worker.worker : DEBUG : Step 79322, finished rewards 22.91, envs finished 1
2026-01-17 13:23:37,991 : agent.on_policy : DEBUG : Mean Losses: [9.26650569587946]
2026-01-17 13:23:38,014 : worker.worker : DEBUG : Step 79333, finished rewards 22.17, envs finished 1
2026-01-17 13:23:38,197 : agent.on_policy : DEBUG : Mean Losses: [3.31768336892128]
2026-01-17 13:23:38,220 : worker.worker : DEBUG : Step 79367, finished rewards 2.27, envs finished 1
2026-01-17 13:23:38,238 : worker.worker : DEBUG : Step 79370, finished rewards 20.79, envs finished 1
2026-01-17 13:23:38,272 : worker.worker : DEBUG : Step 79378, finished rewards 20.29, envs finished 1
2026-01-17 13:23:38,379 : agent.on_policy : DEBUG : Mean Losses: [7.432988479733467]
2026-01-17 13:23:38,455 : worker.worker : DEBUG : Step 79405, finished rewards 19.80, envs finished 1
2026-01-17 13:23:38,609 : agent.on_policy : DEBUG : Mean Losses: [4.025157101452351]
2026-01-17 13:23:38,662 : worker.worker : DEBUG : Step 79436, finished rewards 3.28, envs finished 1
2026-01-17 13:23:38,681 : worker.worker : DEBUG : Step 79440, finished rewards 5.44, envs finished 2
2026-01-17 13:23:38,698 : worker.worker : DEBUG : Step 79443, finished rewards -1.70, envs finished 1
2026-01-17 13:23:38,837 : agent.on_policy : DEBUG : Mean Losses: [9.856439903378487]
2026-01-17 13:23:38,861 : worker.worker : DEBUG : Step 79462, finished rewards 22.68, envs finished 1
2026-01-17 13:23:38,867 : worker.worker : DEBUG : Step 79463, finished rewards 28.95, envs finished 1
2026-01-17 13:23:38,901 : worker.worker : DEBUG : Step 79469, finished rewards 20.89, envs finished 1
2026-01-17 13:23:39,030 : agent.on_policy : DEBUG : Mean Losses: [5.270345404744148]
2026-01-17 13:23:39,045 : worker.worker : DEBUG : Step 79490, finished rewards 28.71, envs finished 1
2026-01-17 13:23:39,251 : agent.on_policy : DEBUG : Mean Losses: [2.1082236729562283]
2026-01-17 13:23:39,281 : worker.worker : DEBUG : Step 79526, finished rewards 28.81, envs finished 1
2026-01-17 13:23:39,385 : worker.worker : DEBUG : Step 79548, finished rewards 13.09, envs finished 1
2026-01-17 13:23:39,607 : agent.on_policy : DEBUG : Mean Losses: [5.53837725520134]
2026-01-17 13:23:39,620 : worker.worker : DEBUG : Step 79555, finished rewards 22.77, envs finished 1
2026-01-17 13:23:39,707 : worker.worker : DEBUG : Step 79577, finished rewards -9.56, envs finished 1
2026-01-17 13:23:39,838 : agent.on_policy : DEBUG : Mean Losses: [5.028061144053936]
2026-01-17 13:23:39,892 : worker.worker : DEBUG : Step 79589, finished rewards -11.30, envs finished 1
2026-01-17 13:23:39,907 : worker.worker : DEBUG : Step 79590, finished rewards 17.57, envs finished 1
2026-01-17 13:23:40,120 : worker.worker : DEBUG : Step 79608, finished rewards -12.16, envs finished 1
2026-01-17 13:23:40,156 : worker.worker : DEBUG : Step 79613, finished rewards -9.09, envs finished 1
2026-01-17 13:23:40,230 : agent.on_policy : DEBUG : Mean Losses: [7.312452852725983]
2026-01-17 13:23:40,241 : worker.worker : DEBUG : Step 79618, finished rewards 23.05, envs finished 1
2026-01-17 13:23:40,442 : agent.on_policy : DEBUG : Mean Losses: [2.24583388119936]
2026-01-17 13:23:40,451 : worker.worker : DEBUG : Step 79650, finished rewards 17.44, envs finished 1
2026-01-17 13:23:40,515 : worker.worker : DEBUG : Step 79666, finished rewards 24.76, envs finished 1
2026-01-17 13:23:40,677 : agent.on_policy : DEBUG : Mean Losses: [4.579223070293665]
2026-01-17 13:23:40,704 : worker.worker : DEBUG : Step 79687, finished rewards 19.78, envs finished 1
2026-01-17 13:23:40,714 : worker.worker : DEBUG : Step 79689, finished rewards -7.80, envs finished 1
2026-01-17 13:23:40,775 : worker.worker : DEBUG : Step 79702, finished rewards 7.98, envs finished 1
2026-01-17 13:23:40,870 : agent.on_policy : DEBUG : Mean Losses: [6.644859954714775]
2026-01-17 13:23:40,914 : worker.worker : DEBUG : Step 79718, finished rewards 10.03, envs finished 1
2026-01-17 13:23:41,081 : agent.on_policy : DEBUG : Mean Losses: [4.668444540351629]
2026-01-17 13:23:41,166 : worker.worker : DEBUG : Step 79762, finished rewards 9.93, envs finished 1
2026-01-17 13:23:41,297 : agent.on_policy : DEBUG : Mean Losses: [5.019196756184101]
2026-01-17 13:23:41,345 : worker.worker : DEBUG : Step 79784, finished rewards -12.95, envs finished 1
2026-01-17 13:23:41,363 : worker.worker : DEBUG : Step 79787, finished rewards -6.47, envs finished 2
2026-01-17 13:23:41,394 : worker.worker : DEBUG : Step 79794, finished rewards -2.46, envs finished 1
2026-01-17 13:23:41,406 : worker.worker : DEBUG : Step 79795, finished rewards 11.96, envs finished 1
2026-01-17 13:23:41,500 : agent.on_policy : DEBUG : Mean Losses: [10.802080243825912]
2026-01-17 13:23:41,509 : worker.worker : DEBUG : Step 79810, finished rewards 11.16, envs finished 1
2026-01-17 13:23:41,635 : worker.worker : DEBUG : Step 79833, finished rewards 5.76, envs finished 1
2026-01-17 13:23:41,754 : agent.on_policy : DEBUG : Mean Losses: [3.8260098434984684]
2026-01-17 13:23:41,893 : worker.worker : DEBUG : Step 79865, finished rewards 15.64, envs finished 1
2026-01-17 13:23:41,976 : agent.on_policy : DEBUG : Mean Losses: [4.134314700961113]
2026-01-17 13:23:41,982 : worker.worker : DEBUG : Step 79873, finished rewards 25.61, envs finished 1
2026-01-17 13:23:42,018 : worker.worker : DEBUG : Step 79881, finished rewards 22.76, envs finished 1
2026-01-17 13:23:42,090 : worker.worker : DEBUG : Step 79891, finished rewards 13.14, envs finished 1
2026-01-17 13:23:42,268 : agent.on_policy : DEBUG : Mean Losses: [6.5255724638700485]
2026-01-17 13:23:42,463 : worker.worker : DEBUG : Step 79933, finished rewards -9.14, envs finished 2
2026-01-17 13:23:42,479 : worker.worker : DEBUG : Step 79934, finished rewards -1.96, envs finished 1
2026-01-17 13:23:42,576 : agent.on_policy : DEBUG : Mean Losses: [6.659743225201964]
2026-01-17 13:23:42,735 : worker.worker : DEBUG : Step 79967, finished rewards -5.91, envs finished 1
2026-01-17 13:23:42,793 : agent.on_policy : DEBUG : Mean Losses: [4.376118812710047]
2026-01-17 13:23:42,843 : worker.worker : DEBUG : Step 79981, finished rewards 19.62, envs finished 1
2026-01-17 13:23:42,521 : worker.worker : DEBUG : Step 79988, finished rewards 7.78, envs finished 1
2026-01-17 13:23:42,171 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:23:42,250 : agent.on_policy : DEBUG : Mean Losses: [6.5657424703240395]
2026-01-17 13:23:42,260 : worker.worker : INFO : Step 80000, Avg Reward 7.7089, Max Reward 71.9776, Loss [5.91431877]
2026-01-17 13:23:42,408 : worker.worker : DEBUG : Step 80019, finished rewards -0.29, envs finished 1
2026-01-17 13:23:42,665 : agent.on_policy : DEBUG : Mean Losses: [3.373712219297886]
2026-01-17 13:23:42,702 : worker.worker : DEBUG : Step 80036, finished rewards -26.24, envs finished 1
2026-01-17 13:23:42,749 : worker.worker : DEBUG : Step 80047, finished rewards 7.23, envs finished 1
2026-01-17 13:23:42,792 : worker.worker : DEBUG : Step 80058, finished rewards -0.37, envs finished 1
2026-01-17 13:23:42,806 : worker.worker : DEBUG : Step 80061, finished rewards 2.51, envs finished 1
2026-01-17 13:23:42,874 : agent.on_policy : DEBUG : Mean Losses: [7.357385046780109]
2026-01-17 13:23:42,907 : worker.worker : DEBUG : Step 80074, finished rewards 25.02, envs finished 1
2026-01-17 13:23:42,917 : worker.worker : DEBUG : Step 80077, finished rewards 13.00, envs finished 1
2026-01-17 13:23:42,946 : worker.worker : DEBUG : Step 80083, finished rewards 23.40, envs finished 1
2026-01-17 13:23:43,072 : agent.on_policy : DEBUG : Mean Losses: [6.729653630405664]
2026-01-17 13:23:43,126 : worker.worker : DEBUG : Step 80106, finished rewards 28.22, envs finished 1
2026-01-17 13:23:43,284 : agent.on_policy : DEBUG : Mean Losses: [3.281719893217087]
2026-01-17 13:23:43,351 : worker.worker : DEBUG : Step 80152, finished rewards 14.13, envs finished 1
2026-01-17 13:23:43,477 : agent.on_policy : DEBUG : Mean Losses: [5.001310504972935]
2026-01-17 13:23:43,514 : worker.worker : DEBUG : Step 80171, finished rewards 10.89, envs finished 1
2026-01-17 13:23:43,528 : worker.worker : DEBUG : Step 80175, finished rewards 7.02, envs finished 1
2026-01-17 13:23:43,534 : worker.worker : DEBUG : Step 80176, finished rewards 20.34, envs finished 1
2026-01-17 13:23:43,557 : worker.worker : DEBUG : Step 80180, finished rewards -12.23, envs finished 1
2026-01-17 13:23:43,655 : agent.on_policy : DEBUG : Mean Losses: [8.674461171030998]
2026-01-17 13:23:43,656 : worker.worker : DEBUG : Step 80192, finished rewards 6.25, envs finished 1
2026-01-17 13:23:43,741 : worker.worker : DEBUG : Step 80204, finished rewards 19.19, envs finished 1
2026-01-17 13:23:43,771 : worker.worker : DEBUG : Step 80210, finished rewards 1.94, envs finished 1
2026-01-17 13:23:43,908 : agent.on_policy : DEBUG : Mean Losses: [5.126747500151396]
2026-01-17 13:23:44,065 : agent.on_policy : DEBUG : Mean Losses: [2.4525434523820877]
2026-01-17 13:23:44,098 : worker.worker : DEBUG : Step 80261, finished rewards 29.11, envs finished 1
2026-01-17 13:23:44,123 : worker.worker : DEBUG : Step 80266, finished rewards 29.16, envs finished 1
2026-01-17 13:23:44,164 : worker.worker : DEBUG : Step 80275, finished rewards 20.18, envs finished 1
2026-01-17 13:23:44,194 : worker.worker : DEBUG : Step 80281, finished rewards 10.50, envs finished 1
2026-01-17 13:23:44,280 : agent.on_policy : DEBUG : Mean Losses: [9.915929302573204]
2026-01-17 13:23:44,485 : agent.on_policy : DEBUG : Mean Losses: [5.192177310585976]
2026-01-17 13:23:44,506 : worker.worker : DEBUG : Step 80327, finished rewards 6.82, envs finished 1
2026-01-17 13:23:44,511 : worker.worker : DEBUG : Step 80328, finished rewards -1.27, envs finished 1
2026-01-17 13:23:44,555 : worker.worker : DEBUG : Step 80338, finished rewards -1.13, envs finished 1
2026-01-17 13:23:44,568 : worker.worker : DEBUG : Step 80340, finished rewards -10.21, envs finished 1
2026-01-17 13:23:44,672 : agent.on_policy : DEBUG : Mean Losses: [7.130747020244598]
2026-01-17 13:23:44,676 : worker.worker : DEBUG : Step 80353, finished rewards 27.08, envs finished 1
2026-01-17 13:23:44,768 : worker.worker : DEBUG : Step 80370, finished rewards 12.60, envs finished 1
2026-01-17 13:23:44,801 : worker.worker : DEBUG : Step 80378, finished rewards 21.17, envs finished 1
2026-01-17 13:23:44,900 : agent.on_policy : DEBUG : Mean Losses: [5.775474674999714]
2026-01-17 13:23:44,929 : worker.worker : DEBUG : Step 80393, finished rewards 4.81, envs finished 1
2026-01-17 13:23:45,107 : agent.on_policy : DEBUG : Mean Losses: [3.1084392685443163]
2026-01-17 13:23:45,261 : agent.on_policy : DEBUG : Mean Losses: [2.940441206097603]
2026-01-17 13:23:45,316 : worker.worker : DEBUG : Step 80459, finished rewards -5.45, envs finished 1
2026-01-17 13:23:45,356 : worker.worker : DEBUG : Step 80468, finished rewards -2.47, envs finished 2
2026-01-17 13:23:45,402 : worker.worker : DEBUG : Step 80478, finished rewards 18.88, envs finished 1
2026-01-17 13:23:45,419 : worker.worker : DEBUG : Step 80479, finished rewards 11.55, envs finished 1
2026-01-17 13:23:45,494 : agent.on_policy : DEBUG : Mean Losses: [13.33328714966774]
2026-01-17 13:23:45,498 : worker.worker : DEBUG : Step 80481, finished rewards -2.14, envs finished 1
2026-01-17 13:23:45,637 : worker.worker : DEBUG : Step 80510, finished rewards -36.94, envs finished 1
2026-01-17 13:23:45,690 : agent.on_policy : DEBUG : Mean Losses: [3.860828597098589]
2026-01-17 13:23:45,736 : worker.worker : DEBUG : Step 80526, finished rewards -7.09, envs finished 1
2026-01-17 13:23:45,902 : agent.on_policy : DEBUG : Mean Losses: [3.2206852063536644]
2026-01-17 13:23:45,943 : worker.worker : DEBUG : Step 80551, finished rewards 22.65, envs finished 1
2026-01-17 13:23:46,026 : worker.worker : DEBUG : Step 80569, finished rewards 26.39, envs finished 1
2026-01-17 13:23:46,071 : worker.worker : DEBUG : Step 80575, finished rewards 13.26, envs finished 1
2026-01-17 13:23:46,245 : agent.on_policy : DEBUG : Mean Losses: [8.717294052243233]
2026-01-17 13:23:46,246 : worker.worker : DEBUG : Step 80576, finished rewards 21.21, envs finished 1
2026-01-17 13:23:46,366 : worker.worker : DEBUG : Step 80596, finished rewards -1.79, envs finished 1
2026-01-17 13:23:46,405 : worker.worker : DEBUG : Step 80601, finished rewards 24.59, envs finished 1
2026-01-17 13:23:46,509 : agent.on_policy : DEBUG : Mean Losses: [5.85610631108284]
2026-01-17 13:23:46,517 : worker.worker : DEBUG : Step 80610, finished rewards 29.55, envs finished 1
2026-01-17 13:23:46,609 : worker.worker : DEBUG : Step 80627, finished rewards -14.83, envs finished 1
2026-01-17 13:23:46,644 : worker.worker : DEBUG : Step 80635, finished rewards 29.40, envs finished 1
2026-01-17 13:23:46,741 : agent.on_policy : DEBUG : Mean Losses: [7.081574387848377]
2026-01-17 13:23:46,844 : worker.worker : DEBUG : Step 80664, finished rewards 20.75, envs finished 1
2026-01-17 13:23:46,862 : worker.worker : DEBUG : Step 80668, finished rewards 23.99, envs finished 1
2026-01-17 13:23:46,975 : agent.on_policy : DEBUG : Mean Losses: [5.871925637125969]
2026-01-17 13:23:47,084 : worker.worker : DEBUG : Step 80696, finished rewards 13.44, envs finished 2
2026-01-17 13:23:47,195 : agent.on_policy : DEBUG : Mean Losses: [7.564123190939426]
2026-01-17 13:23:47,216 : worker.worker : DEBUG : Step 80710, finished rewards 7.90, envs finished 1
2026-01-17 13:23:47,256 : worker.worker : DEBUG : Step 80715, finished rewards 26.56, envs finished 1
2026-01-17 13:23:47,285 : worker.worker : DEBUG : Step 80720, finished rewards 10.69, envs finished 1
2026-01-17 13:23:47,400 : agent.on_policy : DEBUG : Mean Losses: [6.694265116006136]
2026-01-17 13:23:47,583 : agent.on_policy : DEBUG : Mean Losses: [1.9408337026834488]
2026-01-17 13:23:47,626 : worker.worker : DEBUG : Step 80781, finished rewards -7.32, envs finished 1
2026-01-17 13:23:47,632 : worker.worker : DEBUG : Step 80783, finished rewards 3.26, envs finished 1
2026-01-17 13:23:47,673 : worker.worker : DEBUG : Step 80793, finished rewards 30.83, envs finished 1
2026-01-17 13:23:47,679 : worker.worker : DEBUG : Step 80795, finished rewards 17.85, envs finished 1
2026-01-17 13:23:47,761 : agent.on_policy : DEBUG : Mean Losses: [10.540795087814331]
2026-01-17 13:23:47,950 : agent.on_policy : DEBUG : Mean Losses: [3.24348402954638]
2026-01-17 13:23:47,968 : worker.worker : DEBUG : Step 80838, finished rewards -14.13, envs finished 1
2026-01-17 13:23:48,029 : worker.worker : DEBUG : Step 80854, finished rewards -11.75, envs finished 1
2026-01-17 13:23:48,066 : worker.worker : DEBUG : Step 80862, finished rewards -2.72, envs finished 1
2026-01-17 13:23:48,163 : agent.on_policy : DEBUG : Mean Losses: [6.733178049325943]
2026-01-17 13:23:48,171 : worker.worker : DEBUG : Step 80865, finished rewards -28.46, envs finished 1
2026-01-17 13:23:48,261 : worker.worker : DEBUG : Step 80875, finished rewards 22.52, envs finished 1
2026-01-17 13:23:48,294 : worker.worker : DEBUG : Step 80881, finished rewards 17.90, envs finished 1
2026-01-17 13:23:48,457 : agent.on_policy : DEBUG : Mean Losses: [6.51648267172277]
2026-01-17 13:23:48,497 : worker.worker : DEBUG : Step 80909, finished rewards 13.97, envs finished 1
2026-01-17 13:23:48,536 : worker.worker : DEBUG : Step 80920, finished rewards -0.99, envs finished 1
2026-01-17 13:23:48,609 : agent.on_policy : DEBUG : Mean Losses: [5.584508046507835]
2026-01-17 13:23:48,750 : worker.worker : DEBUG : Step 80957, finished rewards 23.27, envs finished 1
2026-01-17 13:23:48,810 : agent.on_policy : DEBUG : Mean Losses: [5.611260261386633]
2026-01-17 13:23:48,849 : worker.worker : DEBUG : Step 80969, finished rewards 5.58, envs finished 1
2026-01-17 13:23:49,074 : worker.worker : DEBUG : Step 80989, finished rewards -2.67, envs finished 2
2026-01-17 13:23:49,170 : agent.on_policy : DEBUG : Mean Losses: [7.841991737484932]
2026-01-17 13:23:49,187 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:23:49,237 : worker.worker : DEBUG : Step 81008, finished rewards 7.94, envs finished 1
2026-01-17 13:23:49,287 : worker.worker : DEBUG : Step 81013, finished rewards 23.03, envs finished 1
2026-01-17 13:23:49,488 : agent.on_policy : DEBUG : Mean Losses: [5.602823033928871]
2026-01-17 13:23:49,499 : worker.worker : DEBUG : Step 81027, finished rewards -26.54, envs finished 1
2026-01-17 13:23:49,564 : worker.worker : DEBUG : Step 81048, finished rewards 8.43, envs finished 1
2026-01-17 13:23:49,572 : worker.worker : DEBUG : Step 81051, finished rewards 22.11, envs finished 1
2026-01-17 13:23:49,670 : agent.on_policy : DEBUG : Mean Losses: [5.724232941865921]
2026-01-17 13:23:49,774 : worker.worker : DEBUG : Step 81087, finished rewards 20.52, envs finished 1
2026-01-17 13:23:49,859 : agent.on_policy : DEBUG : Mean Losses: [3.8837255854159594]
2026-01-17 13:23:49,904 : worker.worker : DEBUG : Step 81102, finished rewards -6.34, envs finished 1
2026-01-17 13:23:49,951 : worker.worker : DEBUG : Step 81107, finished rewards 5.77, envs finished 1
2026-01-17 13:23:49,974 : worker.worker : DEBUG : Step 81111, finished rewards 16.62, envs finished 1
2026-01-17 13:23:50,054 : agent.on_policy : DEBUG : Mean Losses: [8.106385923922062]
2026-01-17 13:23:50,122 : worker.worker : DEBUG : Step 81136, finished rewards 21.10, envs finished 2
2026-01-17 13:23:50,158 : worker.worker : DEBUG : Step 81141, finished rewards 22.88, envs finished 1
2026-01-17 13:23:50,215 : worker.worker : DEBUG : Step 81150, finished rewards -5.72, envs finished 1
2026-01-17 13:23:50,299 : agent.on_policy : DEBUG : Mean Losses: [11.334127269685268]
2026-01-17 13:23:50,492 : agent.on_policy : DEBUG : Mean Losses: [2.897951640188694]
2026-01-17 13:23:50,536 : worker.worker : DEBUG : Step 81194, finished rewards 31.26, envs finished 1
2026-01-17 13:23:50,541 : worker.worker : DEBUG : Step 81195, finished rewards 25.06, envs finished 1
2026-01-17 13:23:50,734 : agent.on_policy : DEBUG : Mean Losses: [8.141577862203121]
2026-01-17 13:23:50,750 : worker.worker : DEBUG : Step 81219, finished rewards 9.52, envs finished 1
2026-01-17 13:23:50,805 : worker.worker : DEBUG : Step 81226, finished rewards 26.01, envs finished 1
2026-01-17 13:23:50,819 : worker.worker : DEBUG : Step 81228, finished rewards 24.28, envs finished 1
2026-01-17 13:23:50,875 : worker.worker : DEBUG : Step 81238, finished rewards -4.26, envs finished 1
2026-01-17 13:23:50,999 : agent.on_policy : DEBUG : Mean Losses: [8.571661423891783]
2026-01-17 13:23:51,023 : worker.worker : DEBUG : Step 81251, finished rewards 19.96, envs finished 1
2026-01-17 13:23:51,040 : worker.worker : DEBUG : Step 81252, finished rewards 10.67, envs finished 1
2026-01-17 13:23:51,280 : agent.on_policy : DEBUG : Mean Losses: [2.7632171511650085]
2026-01-17 13:23:51,420 : agent.on_policy : DEBUG : Mean Losses: [4.088853225111961]
2026-01-17 13:23:51,482 : worker.worker : DEBUG : Step 81322, finished rewards 23.10, envs finished 1
2026-01-17 13:23:51,496 : worker.worker : DEBUG : Step 81325, finished rewards 11.86, envs finished 1
2026-01-17 13:23:51,504 : worker.worker : DEBUG : Step 81326, finished rewards 6.96, envs finished 2
2026-01-17 13:23:51,510 : worker.worker : DEBUG : Step 81327, finished rewards -4.72, envs finished 1
2026-01-17 13:23:51,689 : agent.on_policy : DEBUG : Mean Losses: [11.7469742000103]
2026-01-17 13:23:51,733 : worker.worker : DEBUG : Step 81355, finished rewards 5.27, envs finished 1
2026-01-17 13:23:51,757 : worker.worker : DEBUG : Step 81361, finished rewards 12.04, envs finished 1
2026-01-17 13:23:51,867 : agent.on_policy : DEBUG : Mean Losses: [4.578259468078613]
2026-01-17 13:23:51,887 : worker.worker : DEBUG : Step 81380, finished rewards -1.38, envs finished 1
2026-01-17 13:23:52,084 : agent.on_policy : DEBUG : Mean Losses: [3.931138351559639]
2026-01-17 13:23:52,141 : worker.worker : DEBUG : Step 81423, finished rewards 21.60, envs finished 1
2026-01-17 13:23:52,182 : worker.worker : DEBUG : Step 81434, finished rewards 11.78, envs finished 1
2026-01-17 13:23:52,315 : agent.on_policy : DEBUG : Mean Losses: [7.192045524716377]
2026-01-17 13:23:52,412 : worker.worker : DEBUG : Step 81454, finished rewards 23.93, envs finished 1
2026-01-17 13:23:52,437 : worker.worker : DEBUG : Step 81459, finished rewards -6.92, envs finished 1
2026-01-17 13:23:52,484 : worker.worker : DEBUG : Step 81464, finished rewards -7.36, envs finished 1
2026-01-17 13:23:52,626 : agent.on_policy : DEBUG : Mean Losses: [9.199484430253506]
2026-01-17 13:23:52,834 : worker.worker : DEBUG : Step 81494, finished rewards -12.32, envs finished 1
2026-01-17 13:23:52,849 : worker.worker : DEBUG : Step 81495, finished rewards -28.76, envs finished 1
2026-01-17 13:23:53,004 : agent.on_policy : DEBUG : Mean Losses: [6.503872592002153]
2026-01-17 13:23:53,121 : worker.worker : DEBUG : Step 81527, finished rewards -18.32, envs finished 1
2026-01-17 13:23:53,136 : worker.worker : DEBUG : Step 81531, finished rewards 12.05, envs finished 1
2026-01-17 13:23:53,238 : agent.on_policy : DEBUG : Mean Losses: [4.894546415656805]
2026-01-17 13:23:53,455 : agent.on_policy : DEBUG : Mean Losses: [3.810921289026737]
2026-01-17 13:23:53,460 : worker.worker : DEBUG : Step 81569, finished rewards 1.19, envs finished 1
2026-01-17 13:23:53,470 : worker.worker : DEBUG : Step 81572, finished rewards 12.59, envs finished 1
2026-01-17 13:23:53,479 : worker.worker : DEBUG : Step 81573, finished rewards 6.99, envs finished 1
2026-01-17 13:23:53,524 : worker.worker : DEBUG : Step 81584, finished rewards -2.23, envs finished 1
2026-01-17 13:23:53,529 : worker.worker : DEBUG : Step 81585, finished rewards 25.85, envs finished 1
2026-01-17 13:23:53,565 : worker.worker : DEBUG : Step 81593, finished rewards 19.03, envs finished 1
2026-01-17 13:23:53,632 : agent.on_policy : DEBUG : Mean Losses: [10.31704705953598]
2026-01-17 13:23:53,824 : agent.on_policy : DEBUG : Mean Losses: [1.7928840033710003]
2026-01-17 13:23:53,871 : worker.worker : DEBUG : Step 81647, finished rewards 6.59, envs finished 1
2026-01-17 13:23:53,973 : agent.on_policy : DEBUG : Mean Losses: [3.751385048031807]
2026-01-17 13:23:54,067 : worker.worker : DEBUG : Step 81683, finished rewards 7.62, envs finished 1
2026-01-17 13:23:54,082 : worker.worker : DEBUG : Step 81686, finished rewards -20.58, envs finished 1
2026-01-17 13:23:54,122 : worker.worker : DEBUG : Step 81693, finished rewards 11.44, envs finished 1
2026-01-17 13:23:54,222 : agent.on_policy : DEBUG : Mean Losses: [8.454155564308167]
2026-01-17 13:23:54,230 : worker.worker : DEBUG : Step 81698, finished rewards 2.31, envs finished 1
2026-01-17 13:23:54,245 : worker.worker : DEBUG : Step 81702, finished rewards 5.88, envs finished 1
2026-01-17 13:23:54,312 : worker.worker : DEBUG : Step 81711, finished rewards 7.09, envs finished 1
2026-01-17 13:23:54,445 : agent.on_policy : DEBUG : Mean Losses: [4.327025707811117]
2026-01-17 13:23:54,492 : worker.worker : DEBUG : Step 81743, finished rewards 22.19, envs finished 1
2026-01-17 13:23:54,592 : agent.on_policy : DEBUG : Mean Losses: [3.3955305740237236]
2026-01-17 13:23:54,708 : worker.worker : DEBUG : Step 81786, finished rewards 25.69, envs finished 1
2026-01-17 13:23:54,808 : agent.on_policy : DEBUG : Mean Losses: [4.543141961097717]
2026-01-17 13:23:54,818 : worker.worker : DEBUG : Step 81795, finished rewards 23.78, envs finished 1
2026-01-17 13:23:54,879 : worker.worker : DEBUG : Step 81805, finished rewards 40.28, envs finished 1
2026-01-17 13:23:54,908 : worker.worker : DEBUG : Step 81811, finished rewards 18.98, envs finished 1
2026-01-17 13:23:54,921 : worker.worker : DEBUG : Step 81813, finished rewards 2.15, envs finished 1
2026-01-17 13:23:55,043 : agent.on_policy : DEBUG : Mean Losses: [7.8494639955461025]
2026-01-17 13:23:55,093 : worker.worker : DEBUG : Step 81833, finished rewards 24.62, envs finished 1
2026-01-17 13:23:55,099 : worker.worker : DEBUG : Step 81834, finished rewards -9.14, envs finished 1
2026-01-17 13:23:55,235 : agent.on_policy : DEBUG : Mean Losses: [4.976003810763359]
2026-01-17 13:23:55,238 : worker.worker : DEBUG : Step 81856, finished rewards -14.58, envs finished 1
2026-01-17 13:23:55,541 : agent.on_policy : DEBUG : Mean Losses: [2.0536788627505302]
2026-01-17 13:23:55,600 : worker.worker : DEBUG : Step 81898, finished rewards 8.35, envs finished 1
2026-01-17 13:23:55,658 : worker.worker : DEBUG : Step 81912, finished rewards 18.42, envs finished 1
2026-01-17 13:23:55,768 : agent.on_policy : DEBUG : Mean Losses: [7.136045828461647]
2026-01-17 13:23:55,787 : worker.worker : DEBUG : Step 81925, finished rewards 41.87, envs finished 1
2026-01-17 13:23:55,853 : worker.worker : DEBUG : Step 81930, finished rewards 0.42, envs finished 1
2026-01-17 13:23:55,885 : worker.worker : DEBUG : Step 81934, finished rewards -2.83, envs finished 1
2026-01-17 13:23:55,932 : worker.worker : DEBUG : Step 81943, finished rewards 9.40, envs finished 1
2026-01-17 13:23:55,967 : worker.worker : DEBUG : Step 81946, finished rewards -1.09, envs finished 1
2026-01-17 13:23:56,047 : agent.on_policy : DEBUG : Mean Losses: [9.800472341477871]
2026-01-17 13:23:56,092 : worker.worker : DEBUG : Step 81962, finished rewards -1.93, envs finished 1
2026-01-17 13:23:56,251 : agent.on_policy : DEBUG : Mean Losses: [2.1271090023219585]
2026-01-17 13:23:56,302 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:23:56,402 : agent.on_policy : DEBUG : Mean Losses: [2.99561158567667]
2026-01-17 13:23:56,419 : worker.worker : DEBUG : Step 82017, finished rewards 25.96, envs finished 1
2026-01-17 13:23:56,478 : worker.worker : DEBUG : Step 82031, finished rewards 41.75, envs finished 1
2026-01-17 13:23:56,507 : worker.worker : DEBUG : Step 82038, finished rewards 25.65, envs finished 1
2026-01-17 13:23:56,512 : worker.worker : DEBUG : Step 82039, finished rewards 14.25, envs finished 1
2026-01-17 13:23:56,546 : worker.worker : DEBUG : Step 82047, finished rewards -12.04, envs finished 1
2026-01-17 13:23:56,630 : agent.on_policy : DEBUG : Mean Losses: [13.41109213232994]
2026-01-17 13:23:56,639 : worker.worker : DEBUG : Step 82050, finished rewards 4.62, envs finished 1
2026-01-17 13:23:56,836 : agent.on_policy : DEBUG : Mean Losses: [2.707244098186493]
2026-01-17 13:23:56,900 : worker.worker : DEBUG : Step 82100, finished rewards 30.95, envs finished 1
2026-01-17 13:23:57,012 : agent.on_policy : DEBUG : Mean Losses: [5.299268715083599]
2026-01-17 13:23:57,057 : worker.worker : DEBUG : Step 82124, finished rewards -22.71, envs finished 1
2026-01-17 13:23:57,079 : worker.worker : DEBUG : Step 82130, finished rewards 25.54, envs finished 1
2026-01-17 13:23:57,180 : agent.on_policy : DEBUG : Mean Losses: [6.47790490090847]
2026-01-17 13:23:57,220 : worker.worker : DEBUG : Step 82155, finished rewards 5.83, envs finished 1
2026-01-17 13:23:57,244 : worker.worker : DEBUG : Step 82156, finished rewards 13.98, envs finished 1
2026-01-17 13:23:57,287 : worker.worker : DEBUG : Step 82164, finished rewards 9.42, envs finished 2
2026-01-17 13:23:57,379 : agent.on_policy : DEBUG : Mean Losses: [9.568794131278992]
2026-01-17 13:23:57,634 : agent.on_policy : DEBUG : Mean Losses: [2.2428530417382717]
2026-01-17 13:23:57,673 : worker.worker : DEBUG : Step 82214, finished rewards 7.18, envs finished 1
2026-01-17 13:23:57,737 : worker.worker : DEBUG : Step 82227, finished rewards 14.84, envs finished 1
2026-01-17 13:23:57,882 : agent.on_policy : DEBUG : Mean Losses: [5.610341489315033]
2026-01-17 13:23:57,910 : worker.worker : DEBUG : Step 82247, finished rewards -34.42, envs finished 1
2026-01-17 13:23:57,944 : worker.worker : DEBUG : Step 82255, finished rewards 25.90, envs finished 1
2026-01-17 13:23:57,991 : worker.worker : DEBUG : Step 82266, finished rewards 13.78, envs finished 1
2026-01-17 13:23:58,094 : agent.on_policy : DEBUG : Mean Losses: [7.751301735639572]
2026-01-17 13:23:58,120 : worker.worker : DEBUG : Step 82279, finished rewards 14.19, envs finished 1
2026-01-17 13:23:58,146 : worker.worker : DEBUG : Step 82282, finished rewards 0.37, envs finished 1
2026-01-17 13:23:58,346 : agent.on_policy : DEBUG : Mean Losses: [4.510523267090321]
2026-01-17 13:23:58,367 : worker.worker : DEBUG : Step 82308, finished rewards 15.73, envs finished 1
2026-01-17 13:23:58,433 : worker.worker : DEBUG : Step 82321, finished rewards 13.02, envs finished 1
2026-01-17 13:23:58,462 : worker.worker : DEBUG : Step 82327, finished rewards 18.71, envs finished 1
2026-01-17 13:23:58,607 : agent.on_policy : DEBUG : Mean Losses: [5.884252846240997]
2026-01-17 13:23:58,719 : worker.worker : DEBUG : Step 82361, finished rewards 13.64, envs finished 1
2026-01-17 13:23:58,863 : agent.on_policy : DEBUG : Mean Losses: [4.446280471980572]
2026-01-17 13:23:58,872 : worker.worker : DEBUG : Step 82370, finished rewards 6.50, envs finished 1
2026-01-17 13:23:58,877 : worker.worker : DEBUG : Step 82371, finished rewards 14.30, envs finished 1
2026-01-17 13:23:58,982 : worker.worker : DEBUG : Step 82397, finished rewards 7.51, envs finished 2
2026-01-17 13:23:59,115 : agent.on_policy : DEBUG : Mean Losses: [5.9783560037612915]
2026-01-17 13:23:59,148 : worker.worker : DEBUG : Step 82401, finished rewards 23.04, envs finished 1
2026-01-17 13:23:59,532 : agent.on_policy : DEBUG : Mean Losses: [1.5611756853759289]
2026-01-17 13:23:59,590 : worker.worker : DEBUG : Step 82447, finished rewards 7.59, envs finished 1
2026-01-17 13:23:59,780 : agent.on_policy : DEBUG : Mean Losses: [3.495469681918621]
2026-01-17 13:23:59,800 : worker.worker : DEBUG : Step 82468, finished rewards -4.06, envs finished 1
2026-01-17 13:23:59,814 : worker.worker : DEBUG : Step 82470, finished rewards 18.18, envs finished 1
2026-01-17 13:23:59,933 : worker.worker : DEBUG : Step 82491, finished rewards -1.93, envs finished 1
2026-01-17 13:23:59,962 : worker.worker : DEBUG : Step 82495, finished rewards 23.20, envs finished 1
2026-01-17 13:24:00,044 : agent.on_policy : DEBUG : Mean Losses: [9.36216602101922]
2026-01-17 13:24:00,046 : worker.worker : DEBUG : Step 82496, finished rewards 4.27, envs finished 1
2026-01-17 13:24:00,106 : worker.worker : DEBUG : Step 82507, finished rewards 8.98, envs finished 1
2026-01-17 13:24:00,316 : agent.on_policy : DEBUG : Mean Losses: [3.7402932792901993]
2026-01-17 13:24:00,371 : worker.worker : DEBUG : Step 82542, finished rewards -14.52, envs finished 1
2026-01-17 13:24:00,385 : worker.worker : DEBUG : Step 82544, finished rewards 21.63, envs finished 1
2026-01-17 13:24:00,567 : agent.on_policy : DEBUG : Mean Losses: [6.028619356453419]
2026-01-17 13:24:00,573 : worker.worker : DEBUG : Step 82561, finished rewards 26.37, envs finished 1
2026-01-17 13:24:00,622 : worker.worker : DEBUG : Step 82572, finished rewards 31.16, envs finished 1
2026-01-17 13:24:00,818 : agent.on_policy : DEBUG : Mean Losses: [4.642935499548912]
2026-01-17 13:24:00,852 : worker.worker : DEBUG : Step 82598, finished rewards 25.92, envs finished 1
2026-01-17 13:24:00,869 : worker.worker : DEBUG : Step 82601, finished rewards -2.79, envs finished 1
2026-01-17 13:24:00,898 : worker.worker : DEBUG : Step 82603, finished rewards 11.66, envs finished 1
2026-01-17 13:24:01,137 : agent.on_policy : DEBUG : Mean Losses: [5.904364991933107]
2026-01-17 13:24:01,233 : worker.worker : DEBUG : Step 82641, finished rewards 21.79, envs finished 1
2026-01-17 13:24:01,323 : worker.worker : DEBUG : Step 82651, finished rewards 11.30, envs finished 1
2026-01-17 13:24:01,502 : agent.on_policy : DEBUG : Mean Losses: [5.874257870018482]
2026-01-17 13:24:01,536 : worker.worker : DEBUG : Step 82662, finished rewards -26.24, envs finished 1
2026-01-17 13:24:01,546 : worker.worker : DEBUG : Step 82663, finished rewards 26.16, envs finished 1
2026-01-17 13:24:01,651 : worker.worker : DEBUG : Step 82682, finished rewards 7.88, envs finished 1
2026-01-17 13:24:01,671 : worker.worker : DEBUG : Step 82685, finished rewards 31.44, envs finished 1
2026-01-17 13:24:01,792 : agent.on_policy : DEBUG : Mean Losses: [8.767066273838282]
2026-01-17 13:24:01,952 : worker.worker : DEBUG : Step 82710, finished rewards 9.88, envs finished 1
2026-01-17 13:24:02,250 : agent.on_policy : DEBUG : Mean Losses: [3.2166521549224854]
2026-01-17 13:24:02,466 : worker.worker : DEBUG : Step 82740, finished rewards -1.98, envs finished 1
2026-01-17 13:24:02,492 : worker.worker : DEBUG : Step 82743, finished rewards 16.17, envs finished 1
2026-01-17 13:24:02,677 : agent.on_policy : DEBUG : Mean Losses: [5.135128077119589]
2026-01-17 13:24:02,784 : worker.worker : DEBUG : Step 82769, finished rewards 16.27, envs finished 1
2026-01-17 13:24:02,923 : worker.worker : DEBUG : Step 82782, finished rewards 7.12, envs finished 1
2026-01-17 13:24:03,041 : agent.on_policy : DEBUG : Mean Losses: [4.922434076666832]
2026-01-17 13:24:03,233 : worker.worker : DEBUG : Step 82800, finished rewards 3.87, envs finished 1
2026-01-17 13:24:03,295 : worker.worker : DEBUG : Step 82806, finished rewards 7.39, envs finished 1
2026-01-17 13:24:03,469 : agent.on_policy : DEBUG : Mean Losses: [5.5877943858504295]
2026-01-17 13:24:03,548 : worker.worker : DEBUG : Step 82830, finished rewards 0.83, envs finished 1
2026-01-17 13:24:03,653 : worker.worker : DEBUG : Step 82840, finished rewards -2.33, envs finished 1
2026-01-17 13:24:03,805 : agent.on_policy : DEBUG : Mean Losses: [5.495684690773487]
2026-01-17 13:24:03,838 : worker.worker : DEBUG : Step 82855, finished rewards 4.06, envs finished 1
2026-01-17 13:24:03,909 : worker.worker : DEBUG : Step 82867, finished rewards 2.96, envs finished 1
2026-01-17 13:24:03,925 : worker.worker : DEBUG : Step 82869, finished rewards 41.82, envs finished 1
2026-01-17 13:24:04,121 : agent.on_policy : DEBUG : Mean Losses: [9.467366360127926]
2026-01-17 13:24:04,133 : worker.worker : DEBUG : Step 82882, finished rewards 6.85, envs finished 1
2026-01-17 13:24:04,189 : worker.worker : DEBUG : Step 82893, finished rewards 10.87, envs finished 1
2026-01-17 13:24:04,396 : agent.on_policy : DEBUG : Mean Losses: [5.095132894814014]
2026-01-17 13:24:04,413 : worker.worker : DEBUG : Step 82915, finished rewards 38.62, envs finished 1
2026-01-17 13:24:04,479 : worker.worker : DEBUG : Step 82926, finished rewards 7.01, envs finished 1
2026-01-17 13:24:04,494 : worker.worker : DEBUG : Step 82928, finished rewards 19.00, envs finished 1
2026-01-17 13:24:04,662 : agent.on_policy : DEBUG : Mean Losses: [5.725707545876503]
2026-01-17 13:24:04,800 : agent.on_policy : DEBUG : Mean Losses: [2.291286177933216]
2026-01-17 13:24:04,837 : worker.worker : DEBUG : Step 82981, finished rewards 6.17, envs finished 1
2026-01-17 13:24:04,872 : worker.worker : DEBUG : Step 82988, finished rewards 6.85, envs finished 1
2026-01-17 13:24:04,881 : worker.worker : DEBUG : Step 82990, finished rewards 2.95, envs finished 1
2026-01-17 13:24:04,918 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:24:04,995 : agent.on_policy : DEBUG : Mean Losses: [7.3654095232486725]
2026-01-17 13:24:05,012 : worker.worker : DEBUG : Step 83013, finished rewards -4.80, envs finished 1
2026-01-17 13:24:05,038 : worker.worker : DEBUG : Step 83018, finished rewards 0.15, envs finished 1
2026-01-17 13:24:05,090 : worker.worker : DEBUG : Step 83025, finished rewards 11.48, envs finished 1
2026-01-17 13:24:05,131 : worker.worker : DEBUG : Step 83030, finished rewards 15.82, envs finished 1
2026-01-17 13:24:05,282 : agent.on_policy : DEBUG : Mean Losses: [8.621693551540375]
2026-01-17 13:24:05,540 : agent.on_policy : DEBUG : Mean Losses: [2.551649756729603]
2026-01-17 13:24:05,543 : worker.worker : DEBUG : Step 83072, finished rewards -14.33, envs finished 1
2026-01-17 13:24:05,574 : worker.worker : DEBUG : Step 83078, finished rewards 21.27, envs finished 1
2026-01-17 13:24:05,622 : worker.worker : DEBUG : Step 83086, finished rewards 21.97, envs finished 1
2026-01-17 13:24:05,686 : worker.worker : DEBUG : Step 83096, finished rewards 12.30, envs finished 1
2026-01-17 13:24:05,813 : agent.on_policy : DEBUG : Mean Losses: [7.404197946190834]
2026-01-17 13:24:05,867 : worker.worker : DEBUG : Step 83115, finished rewards 21.49, envs finished 1
2026-01-17 13:24:05,972 : worker.worker : DEBUG : Step 83133, finished rewards 6.83, envs finished 1
2026-01-17 13:24:06,090 : agent.on_policy : DEBUG : Mean Losses: [4.484737690538168]
2026-01-17 13:24:06,097 : worker.worker : DEBUG : Step 83137, finished rewards 8.25, envs finished 1
2026-01-17 13:24:06,185 : worker.worker : DEBUG : Step 83149, finished rewards 5.81, envs finished 1
2026-01-17 13:24:06,366 : agent.on_policy : DEBUG : Mean Losses: [4.301733378320932]
2026-01-17 13:24:06,376 : worker.worker : DEBUG : Step 83169, finished rewards 22.38, envs finished 2
2026-01-17 13:24:06,553 : worker.worker : DEBUG : Step 83199, finished rewards 8.37, envs finished 1
2026-01-17 13:24:06,658 : agent.on_policy : DEBUG : Mean Losses: [4.743780966848135]
2026-01-17 13:24:06,671 : worker.worker : DEBUG : Step 83203, finished rewards 13.44, envs finished 1
2026-01-17 13:24:06,726 : worker.worker : DEBUG : Step 83210, finished rewards 22.88, envs finished 1
2026-01-17 13:24:06,900 : agent.on_policy : DEBUG : Mean Losses: [4.394183415919542]
2026-01-17 13:24:06,975 : worker.worker : DEBUG : Step 83254, finished rewards 29.13, envs finished 1
2026-01-17 13:24:06,989 : worker.worker : DEBUG : Step 83257, finished rewards 0.59, envs finished 1
2026-01-17 13:24:07,140 : agent.on_policy : DEBUG : Mean Losses: [6.615250080823898]
2026-01-17 13:24:07,172 : worker.worker : DEBUG : Step 83265, finished rewards 22.45, envs finished 1
2026-01-17 13:24:07,210 : worker.worker : DEBUG : Step 83268, finished rewards 4.75, envs finished 1
2026-01-17 13:24:07,297 : worker.worker : DEBUG : Step 83278, finished rewards 36.83, envs finished 1
2026-01-17 13:24:07,307 : worker.worker : DEBUG : Step 83279, finished rewards -16.65, envs finished 1
2026-01-17 13:24:07,584 : agent.on_policy : DEBUG : Mean Losses: [7.282889872789383]
2026-01-17 13:24:07,588 : worker.worker : DEBUG : Step 83296, finished rewards 28.51, envs finished 1
2026-01-17 13:24:07,680 : worker.worker : DEBUG : Step 83305, finished rewards 16.68, envs finished 1
2026-01-17 13:24:07,875 : agent.on_policy : DEBUG : Mean Losses: [3.0356912203133106]
2026-01-17 13:24:08,042 : agent.on_policy : DEBUG : Mean Losses: [2.2551169395446777]
2026-01-17 13:24:08,068 : worker.worker : DEBUG : Step 83365, finished rewards 26.55, envs finished 1
2026-01-17 13:24:08,147 : worker.worker : DEBUG : Step 83386, finished rewards 25.56, envs finished 1
2026-01-17 13:24:08,158 : worker.worker : DEBUG : Step 83388, finished rewards 12.19, envs finished 1
2026-01-17 13:24:08,165 : worker.worker : DEBUG : Step 83389, finished rewards 3.31, envs finished 1
2026-01-17 13:24:08,250 : agent.on_policy : DEBUG : Mean Losses: [9.67516691237688]
2026-01-17 13:24:08,257 : worker.worker : DEBUG : Step 83393, finished rewards 5.98, envs finished 1
2026-01-17 13:24:08,291 : worker.worker : DEBUG : Step 83401, finished rewards -5.15, envs finished 1
2026-01-17 13:24:08,298 : worker.worker : DEBUG : Step 83402, finished rewards 20.80, envs finished 1
2026-01-17 13:24:08,524 : agent.on_policy : DEBUG : Mean Losses: [4.769013654440641]
2026-01-17 13:24:08,725 : agent.on_policy : DEBUG : Mean Losses: [1.7032043933868408]
2026-01-17 13:24:08,764 : worker.worker : DEBUG : Step 83465, finished rewards 18.11, envs finished 1
2026-01-17 13:24:08,795 : worker.worker : DEBUG : Step 83473, finished rewards 28.98, envs finished 1
2026-01-17 13:24:08,847 : worker.worker : DEBUG : Step 83486, finished rewards -41.80, envs finished 1
2026-01-17 13:24:08,909 : agent.on_policy : DEBUG : Mean Losses: [7.369557023048401]
2026-01-17 13:24:09,017 : worker.worker : DEBUG : Step 83509, finished rewards 3.24, envs finished 1
2026-01-17 13:24:09,055 : worker.worker : DEBUG : Step 83516, finished rewards 5.12, envs finished 1
2026-01-17 13:24:09,147 : agent.on_policy : DEBUG : Mean Losses: [5.809598580002785]
2026-01-17 13:24:09,150 : worker.worker : DEBUG : Step 83520, finished rewards 5.66, envs finished 1
2026-01-17 13:24:09,171 : worker.worker : DEBUG : Step 83524, finished rewards 3.64, envs finished 1
2026-01-17 13:24:09,246 : worker.worker : DEBUG : Step 83536, finished rewards -11.86, envs finished 1
2026-01-17 13:24:09,391 : agent.on_policy : DEBUG : Mean Losses: [3.48274577409029]
2026-01-17 13:24:09,429 : worker.worker : DEBUG : Step 83557, finished rewards 29.62, envs finished 1
2026-01-17 13:24:09,492 : worker.worker : DEBUG : Step 83564, finished rewards 20.45, envs finished 1
2026-01-17 13:24:09,740 : agent.on_policy : DEBUG : Mean Losses: [4.312983624637127]
2026-01-17 13:24:09,769 : worker.worker : DEBUG : Step 83593, finished rewards 41.91, envs finished 1
2026-01-17 13:24:09,881 : agent.on_policy : DEBUG : Mean Losses: [4.497281163930893]
2026-01-17 13:24:09,892 : worker.worker : DEBUG : Step 83618, finished rewards 13.92, envs finished 1
2026-01-17 13:24:09,939 : worker.worker : DEBUG : Step 83622, finished rewards 4.03, envs finished 2
2026-01-17 13:24:09,995 : worker.worker : DEBUG : Step 83630, finished rewards 22.27, envs finished 1
2026-01-17 13:24:10,031 : worker.worker : DEBUG : Step 83636, finished rewards 13.61, envs finished 1
2026-01-17 13:24:10,211 : agent.on_policy : DEBUG : Mean Losses: [8.535787761211395]
2026-01-17 13:24:10,421 : agent.on_policy : DEBUG : Mean Losses: [1.4845057539641857]
2026-01-17 13:24:10,430 : worker.worker : DEBUG : Step 83682, finished rewards 4.82, envs finished 1
2026-01-17 13:24:10,472 : worker.worker : DEBUG : Step 83692, finished rewards 0.42, envs finished 1
2026-01-17 13:24:10,599 : agent.on_policy : DEBUG : Mean Losses: [4.7996160089969635]
2026-01-17 13:24:10,614 : worker.worker : DEBUG : Step 83714, finished rewards 21.93, envs finished 1
2026-01-17 13:24:10,651 : worker.worker : DEBUG : Step 83718, finished rewards 27.46, envs finished 1
2026-01-17 13:24:10,674 : worker.worker : DEBUG : Step 83722, finished rewards 17.76, envs finished 1
2026-01-17 13:24:10,738 : worker.worker : DEBUG : Step 83740, finished rewards 16.01, envs finished 1
2026-01-17 13:24:10,798 : agent.on_policy : DEBUG : Mean Losses: [9.011727809906006]
2026-01-17 13:24:10,800 : worker.worker : DEBUG : Step 83744, finished rewards -9.70, envs finished 1
2026-01-17 13:24:11,005 : worker.worker : DEBUG : Step 83766, finished rewards -20.52, envs finished 1
2026-01-17 13:24:11,070 : worker.worker : DEBUG : Step 83774, finished rewards 24.89, envs finished 1
2026-01-17 13:24:11,159 : agent.on_policy : DEBUG : Mean Losses: [5.745498180389404]
2026-01-17 13:24:11,247 : worker.worker : DEBUG : Step 83791, finished rewards 20.62, envs finished 1
2026-01-17 13:24:11,403 : agent.on_policy : DEBUG : Mean Losses: [3.4472376070916653]
2026-01-17 13:24:11,409 : worker.worker : DEBUG : Step 83809, finished rewards 22.33, envs finished 1
2026-01-17 13:24:11,452 : worker.worker : DEBUG : Step 83820, finished rewards 21.02, envs finished 1
2026-01-17 13:24:11,467 : worker.worker : DEBUG : Step 83823, finished rewards 14.10, envs finished 1
2026-01-17 13:24:11,578 : agent.on_policy : DEBUG : Mean Losses: [4.996844068169594]
2026-01-17 13:24:11,588 : worker.worker : DEBUG : Step 83842, finished rewards 19.19, envs finished 1
2026-01-17 13:24:11,606 : worker.worker : DEBUG : Step 83846, finished rewards 12.19, envs finished 1
2026-01-17 13:24:11,742 : worker.worker : DEBUG : Step 83867, finished rewards 17.43, envs finished 1
2026-01-17 13:24:11,868 : agent.on_policy : DEBUG : Mean Losses: [5.641851479187608]
2026-01-17 13:24:12,020 : worker.worker : DEBUG : Step 83903, finished rewards -3.93, envs finished 1
2026-01-17 13:24:12,078 : agent.on_policy : DEBUG : Mean Losses: [3.1314850375056267]
2026-01-17 13:24:11,760 : worker.worker : DEBUG : Step 83913, finished rewards 8.82, envs finished 1
2026-01-17 13:24:11,843 : worker.worker : DEBUG : Step 83921, finished rewards 14.72, envs finished 2
2026-01-17 13:24:11,936 : worker.worker : DEBUG : Step 83930, finished rewards 30.17, envs finished 1
2026-01-17 13:24:12,112 : agent.on_policy : DEBUG : Mean Losses: [10.745413437485695]
2026-01-17 13:24:12,152 : worker.worker : DEBUG : Step 83940, finished rewards 20.95, envs finished 1
2026-01-17 13:24:12,319 : worker.worker : DEBUG : Step 83967, finished rewards 17.14, envs finished 1
2026-01-17 13:24:12,377 : agent.on_policy : DEBUG : Mean Losses: [4.403487630188465]
2026-01-17 13:24:12,431 : worker.worker : DEBUG : Step 83985, finished rewards 0.34, envs finished 1
2026-01-17 13:24:12,499 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:24:12,545 : agent.on_policy : DEBUG : Mean Losses: [2.8176802657544613]
2026-01-17 13:24:12,660 : worker.worker : DEBUG : Step 84019, finished rewards 5.96, envs finished 1
2026-01-17 13:24:12,820 : agent.on_policy : DEBUG : Mean Losses: [4.085517510771751]
2026-01-17 13:24:12,834 : worker.worker : DEBUG : Step 84035, finished rewards 5.45, envs finished 1
2026-01-17 13:24:12,846 : worker.worker : DEBUG : Step 84037, finished rewards 20.94, envs finished 1
2026-01-17 13:24:12,901 : worker.worker : DEBUG : Step 84048, finished rewards 5.32, envs finished 1
2026-01-17 13:24:12,935 : worker.worker : DEBUG : Step 84054, finished rewards -7.26, envs finished 1
2026-01-17 13:24:12,984 : worker.worker : DEBUG : Step 84061, finished rewards -15.00, envs finished 1
2026-01-17 13:24:13,077 : agent.on_policy : DEBUG : Mean Losses: [10.24955527484417]
2026-01-17 13:24:13,166 : worker.worker : DEBUG : Step 84084, finished rewards 19.95, envs finished 1
2026-01-17 13:24:13,194 : worker.worker : DEBUG : Step 84090, finished rewards 0.29, envs finished 1
2026-01-17 13:24:13,318 : agent.on_policy : DEBUG : Mean Losses: [4.765982106328011]
2026-01-17 13:24:13,445 : worker.worker : DEBUG : Step 84120, finished rewards 17.21, envs finished 1
2026-01-17 13:24:13,686 : agent.on_policy : DEBUG : Mean Losses: [4.253958590328693]
2026-01-17 13:24:13,765 : worker.worker : DEBUG : Step 84148, finished rewards 23.33, envs finished 1
2026-01-17 13:24:13,888 : agent.on_policy : DEBUG : Mean Losses: [5.653064914047718]
2026-01-17 13:24:13,891 : worker.worker : DEBUG : Step 84160, finished rewards -0.13, envs finished 1
2026-01-17 13:24:13,953 : worker.worker : DEBUG : Step 84166, finished rewards 5.52, envs finished 1
2026-01-17 13:24:14,006 : worker.worker : DEBUG : Step 84171, finished rewards 11.33, envs finished 1
2026-01-17 13:24:14,103 : worker.worker : DEBUG : Step 84186, finished rewards 21.29, envs finished 1
2026-01-17 13:24:14,211 : agent.on_policy : DEBUG : Mean Losses: [7.846414230763912]
2026-01-17 13:24:14,314 : worker.worker : DEBUG : Step 84214, finished rewards -1.33, envs finished 1
2026-01-17 13:24:14,334 : worker.worker : DEBUG : Step 84218, finished rewards -41.02, envs finished 1
2026-01-17 13:24:14,445 : agent.on_policy : DEBUG : Mean Losses: [4.680964583531022]
2026-01-17 13:24:14,561 : worker.worker : DEBUG : Step 84250, finished rewards 29.65, envs finished 1
2026-01-17 13:24:14,678 : agent.on_policy : DEBUG : Mean Losses: [7.066909551620483]
2026-01-17 13:24:14,681 : worker.worker : DEBUG : Step 84256, finished rewards -7.70, envs finished 1
2026-01-17 13:24:14,775 : worker.worker : DEBUG : Step 84273, finished rewards 9.51, envs finished 1
2026-01-17 13:24:14,802 : worker.worker : DEBUG : Step 84279, finished rewards 24.19, envs finished 1
2026-01-17 13:24:14,818 : worker.worker : DEBUG : Step 84281, finished rewards 10.47, envs finished 1
2026-01-17 13:24:14,937 : agent.on_policy : DEBUG : Mean Losses: [7.830861460417509]
2026-01-17 13:24:15,146 : agent.on_policy : DEBUG : Mean Losses: [2.4580733329057693]
2026-01-17 13:24:15,148 : worker.worker : DEBUG : Step 84320, finished rewards -35.78, envs finished 1
2026-01-17 13:24:15,245 : worker.worker : DEBUG : Step 84341, finished rewards -1.53, envs finished 1
2026-01-17 13:24:15,363 : agent.on_policy : DEBUG : Mean Losses: [3.7677846178412437]
2026-01-17 13:24:15,392 : worker.worker : DEBUG : Step 84359, finished rewards -9.95, envs finished 1
2026-01-17 13:24:15,470 : worker.worker : DEBUG : Step 84375, finished rewards 23.80, envs finished 1
2026-01-17 13:24:15,503 : worker.worker : DEBUG : Step 84382, finished rewards 10.58, envs finished 1
2026-01-17 13:24:15,595 : agent.on_policy : DEBUG : Mean Losses: [7.520118519663811]
2026-01-17 13:24:15,637 : worker.worker : DEBUG : Step 84398, finished rewards -16.55, envs finished 1
2026-01-17 13:24:15,666 : worker.worker : DEBUG : Step 84401, finished rewards -11.32, envs finished 1
2026-01-17 13:24:15,818 : agent.on_policy : DEBUG : Mean Losses: [5.920150451362133]
2026-01-17 13:24:15,924 : worker.worker : DEBUG : Step 84441, finished rewards 0.66, envs finished 1
2026-01-17 13:24:15,948 : worker.worker : DEBUG : Step 84446, finished rewards -27.26, envs finished 1
2026-01-17 13:24:16,127 : agent.on_policy : DEBUG : Mean Losses: [4.643698927015066]
2026-01-17 13:24:16,212 : worker.worker : DEBUG : Step 84460, finished rewards 3.00, envs finished 1
2026-01-17 13:24:16,359 : agent.on_policy : DEBUG : Mean Losses: [3.795136582106352]
2026-01-17 13:24:16,421 : worker.worker : DEBUG : Step 84498, finished rewards 0.55, envs finished 1
2026-01-17 13:24:16,450 : worker.worker : DEBUG : Step 84506, finished rewards -22.59, envs finished 1
2026-01-17 13:24:16,459 : worker.worker : DEBUG : Step 84508, finished rewards -0.39, envs finished 1
2026-01-17 13:24:16,559 : agent.on_policy : DEBUG : Mean Losses: [7.430335909128189]
2026-01-17 13:24:16,610 : worker.worker : DEBUG : Step 84525, finished rewards 0.32, envs finished 1
2026-01-17 13:24:16,767 : agent.on_policy : DEBUG : Mean Losses: [3.909012347459793]
2026-01-17 13:24:16,802 : worker.worker : DEBUG : Step 84552, finished rewards -10.53, envs finished 1
2026-01-17 13:24:16,853 : worker.worker : DEBUG : Step 84566, finished rewards 13.33, envs finished 1
2026-01-17 13:24:16,983 : agent.on_policy : DEBUG : Mean Losses: [5.362911507487297]
2026-01-17 13:24:17,025 : worker.worker : DEBUG : Step 84588, finished rewards -7.59, envs finished 1
2026-01-17 13:24:17,064 : worker.worker : DEBUG : Step 84598, finished rewards 24.24, envs finished 1
2026-01-17 13:24:17,073 : worker.worker : DEBUG : Step 84600, finished rewards 25.36, envs finished 1
2026-01-17 13:24:17,087 : worker.worker : DEBUG : Step 84602, finished rewards 15.40, envs finished 1
2026-01-17 13:24:17,155 : agent.on_policy : DEBUG : Mean Losses: [10.040074780583382]
2026-01-17 13:24:17,214 : worker.worker : DEBUG : Step 84617, finished rewards 25.23, envs finished 1
2026-01-17 13:24:17,331 : worker.worker : DEBUG : Step 84630, finished rewards -49.79, envs finished 1
2026-01-17 13:24:17,500 : agent.on_policy : DEBUG : Mean Losses: [5.272578880190849]
2026-01-17 13:24:17,669 : agent.on_policy : DEBUG : Mean Losses: [2.2279276065528393]
2026-01-17 13:24:17,695 : worker.worker : DEBUG : Step 84677, finished rewards 9.21, envs finished 1
2026-01-17 13:24:17,713 : worker.worker : DEBUG : Step 84681, finished rewards 23.81, envs finished 1
2026-01-17 13:24:17,769 : worker.worker : DEBUG : Step 84691, finished rewards -6.52, envs finished 1
2026-01-17 13:24:17,891 : agent.on_policy : DEBUG : Mean Losses: [7.039945125579834]
2026-01-17 13:24:17,951 : worker.worker : DEBUG : Step 84719, finished rewards 4.77, envs finished 1
2026-01-17 13:24:17,961 : worker.worker : DEBUG : Step 84721, finished rewards 14.89, envs finished 1
2026-01-17 13:24:18,006 : worker.worker : DEBUG : Step 84731, finished rewards 16.50, envs finished 1
2026-01-17 13:24:18,023 : worker.worker : DEBUG : Step 84734, finished rewards 0.25, envs finished 1
2026-01-17 13:24:18,112 : agent.on_policy : DEBUG : Mean Losses: [10.418692886829376]
2026-01-17 13:24:18,284 : agent.on_policy : DEBUG : Mean Losses: [1.0350979194045067]
2026-01-17 13:24:18,291 : worker.worker : DEBUG : Step 84769, finished rewards -14.53, envs finished 1
2026-01-17 13:24:18,344 : worker.worker : DEBUG : Step 84784, finished rewards 16.54, envs finished 1
2026-01-17 13:24:18,353 : worker.worker : DEBUG : Step 84785, finished rewards 11.81, envs finished 1
2026-01-17 13:24:18,372 : worker.worker : DEBUG : Step 84788, finished rewards 41.58, envs finished 1
2026-01-17 13:24:18,490 : agent.on_policy : DEBUG : Mean Losses: [8.415755774825811]
2026-01-17 13:24:18,552 : worker.worker : DEBUG : Step 84811, finished rewards 22.49, envs finished 1
2026-01-17 13:24:18,600 : worker.worker : DEBUG : Step 84823, finished rewards -4.23, envs finished 1
2026-01-17 13:24:18,720 : agent.on_policy : DEBUG : Mean Losses: [5.637540753930807]
2026-01-17 13:24:18,735 : worker.worker : DEBUG : Step 84835, finished rewards 16.69, envs finished 1
2026-01-17 13:24:18,800 : worker.worker : DEBUG : Step 84844, finished rewards 8.51, envs finished 1
2026-01-17 13:24:19,034 : agent.on_policy : DEBUG : Mean Losses: [4.301550071686506]
2026-01-17 13:24:19,120 : worker.worker : DEBUG : Step 84890, finished rewards 3.98, envs finished 1
2026-01-17 13:24:19,386 : agent.on_policy : DEBUG : Mean Losses: [5.129657581448555]
2026-01-17 13:24:19,468 : worker.worker : DEBUG : Step 84917, finished rewards -4.98, envs finished 1
2026-01-17 13:24:19,617 : agent.on_policy : DEBUG : Mean Losses: [3.911809131503105]
2026-01-17 13:24:19,627 : worker.worker : DEBUG : Step 84930, finished rewards 2.98, envs finished 1
2026-01-17 13:24:19,641 : worker.worker : DEBUG : Step 84933, finished rewards 26.03, envs finished 1
2026-01-17 13:24:19,648 : worker.worker : DEBUG : Step 84934, finished rewards -14.20, envs finished 1
2026-01-17 13:24:19,782 : agent.on_policy : DEBUG : Mean Losses: [5.7005743980407715]
2026-01-17 13:24:19,809 : worker.worker : DEBUG : Step 84962, finished rewards -38.40, envs finished 1
2026-01-17 13:24:19,825 : worker.worker : DEBUG : Step 84964, finished rewards -7.31, envs finished 1
2026-01-17 13:24:19,889 : worker.worker : DEBUG : Step 84980, finished rewards 26.27, envs finished 1
2026-01-17 13:24:20,006 : agent.on_policy : DEBUG : Mean Losses: [6.735782139003277]
2026-01-17 13:24:20,030 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:24:20,043 : worker.worker : INFO : Step 85000, Avg Reward 9.0138, Max Reward 41.9058, Loss [5.70199311]
2026-01-17 13:24:20,103 : worker.worker : DEBUG : Step 85014, finished rewards 29.88, envs finished 1
2026-01-17 13:24:20,230 : agent.on_policy : DEBUG : Mean Losses: [7.349991530179977]
2026-01-17 13:24:20,258 : worker.worker : DEBUG : Step 85030, finished rewards -43.33, envs finished 1
2026-01-17 13:24:20,262 : worker.worker : DEBUG : Step 85031, finished rewards 41.79, envs finished 1
2026-01-17 13:24:20,314 : worker.worker : DEBUG : Step 85044, finished rewards 2.59, envs finished 1
2026-01-17 13:24:20,354 : worker.worker : DEBUG : Step 85052, finished rewards 11.98, envs finished 1
2026-01-17 13:24:20,445 : agent.on_policy : DEBUG : Mean Losses: [8.820613078773022]
2026-01-17 13:24:20,535 : worker.worker : DEBUG : Step 85080, finished rewards 7.25, envs finished 1
2026-01-17 13:24:20,540 : worker.worker : DEBUG : Step 85081, finished rewards -16.59, envs finished 1
2026-01-17 13:24:20,649 : agent.on_policy : DEBUG : Mean Losses: [6.634407717734575]
2026-01-17 13:24:20,718 : worker.worker : DEBUG : Step 85100, finished rewards 6.25, envs finished 1
2026-01-17 13:24:20,867 : agent.on_policy : DEBUG : Mean Losses: [4.428163826465607]
2026-01-17 13:24:20,898 : worker.worker : DEBUG : Step 85128, finished rewards 20.96, envs finished 1
2026-01-17 13:24:20,903 : worker.worker : DEBUG : Step 85129, finished rewards 29.12, envs finished 1
2026-01-17 13:24:20,930 : worker.worker : DEBUG : Step 85134, finished rewards 31.49, envs finished 1
2026-01-17 13:24:20,953 : worker.worker : DEBUG : Step 85139, finished rewards 12.21, envs finished 1
2026-01-17 13:24:21,072 : agent.on_policy : DEBUG : Mean Losses: [9.380721367895603]
2026-01-17 13:24:21,131 : worker.worker : DEBUG : Step 85163, finished rewards -20.00, envs finished 1
2026-01-17 13:24:21,291 : agent.on_policy : DEBUG : Mean Losses: [4.754416778683662]
2026-01-17 13:24:21,298 : worker.worker : DEBUG : Step 85186, finished rewards 13.36, envs finished 1
2026-01-17 13:24:21,318 : worker.worker : DEBUG : Step 85192, finished rewards 24.08, envs finished 1
2026-01-17 13:24:21,359 : worker.worker : DEBUG : Step 85200, finished rewards 4.68, envs finished 1
2026-01-17 13:24:21,459 : agent.on_policy : DEBUG : Mean Losses: [5.614433117210865]
2026-01-17 13:24:21,497 : worker.worker : DEBUG : Step 85224, finished rewards 22.48, envs finished 1
2026-01-17 13:24:21,592 : worker.worker : DEBUG : Step 85238, finished rewards 19.56, envs finished 1
2026-01-17 13:24:21,718 : agent.on_policy : DEBUG : Mean Losses: [5.2439760491251945]
2026-01-17 13:24:21,734 : worker.worker : DEBUG : Step 85250, finished rewards 28.45, envs finished 1
2026-01-17 13:24:22,008 : agent.on_policy : DEBUG : Mean Losses: [4.403289185836911]
2026-01-17 13:24:22,021 : worker.worker : DEBUG : Step 85283, finished rewards 21.83, envs finished 1
2026-01-17 13:24:22,083 : worker.worker : DEBUG : Step 85291, finished rewards -21.62, envs finished 1
2026-01-17 13:24:22,126 : worker.worker : DEBUG : Step 85298, finished rewards -24.57, envs finished 1
2026-01-17 13:24:22,311 : agent.on_policy : DEBUG : Mean Losses: [7.750876992940903]
2026-01-17 13:24:22,377 : worker.worker : DEBUG : Step 85328, finished rewards -4.38, envs finished 1
2026-01-17 13:24:22,398 : worker.worker : DEBUG : Step 85333, finished rewards 12.60, envs finished 1
2026-01-17 13:24:22,511 : agent.on_policy : DEBUG : Mean Losses: [6.112460363656282]
2026-01-17 13:24:22,512 : worker.worker : DEBUG : Step 85344, finished rewards 13.23, envs finished 1
2026-01-17 13:24:22,833 : agent.on_policy : DEBUG : Mean Losses: [3.6816134601831436]
2026-01-17 13:24:22,834 : worker.worker : DEBUG : Step 85376, finished rewards 23.46, envs finished 1
2026-01-17 13:24:22,873 : worker.worker : DEBUG : Step 85384, finished rewards 22.88, envs finished 1
2026-01-17 13:24:22,881 : worker.worker : DEBUG : Step 85386, finished rewards -35.93, envs finished 1
2026-01-17 13:24:22,895 : worker.worker : DEBUG : Step 85388, finished rewards -10.16, envs finished 1
2026-01-17 13:24:22,913 : worker.worker : DEBUG : Step 85391, finished rewards 23.46, envs finished 1
2026-01-17 13:24:23,037 : agent.on_policy : DEBUG : Mean Losses: [10.012831404805183]
2026-01-17 13:24:23,075 : worker.worker : DEBUG : Step 85413, finished rewards 33.99, envs finished 1
2026-01-17 13:24:23,184 : worker.worker : DEBUG : Step 85435, finished rewards 24.81, envs finished 1
2026-01-17 13:24:23,281 : agent.on_policy : DEBUG : Mean Losses: [4.68123959377408]
2026-01-17 13:24:23,302 : worker.worker : DEBUG : Step 85445, finished rewards 15.30, envs finished 1
2026-01-17 13:24:23,420 : worker.worker : DEBUG : Step 85468, finished rewards 22.62, envs finished 1
2026-01-17 13:24:23,424 : worker.worker : DEBUG : Step 85469, finished rewards 29.65, envs finished 1
2026-01-17 13:24:23,518 : agent.on_policy : DEBUG : Mean Losses: [7.142094001173973]
2026-01-17 13:24:23,551 : worker.worker : DEBUG : Step 85482, finished rewards 25.98, envs finished 1
2026-01-17 13:24:23,599 : worker.worker : DEBUG : Step 85489, finished rewards 14.10, envs finished 1
2026-01-17 13:24:23,703 : agent.on_policy : DEBUG : Mean Losses: [5.71597358211875]
2026-01-17 13:24:23,786 : worker.worker : DEBUG : Step 85523, finished rewards 14.14, envs finished 1
2026-01-17 13:24:23,810 : worker.worker : DEBUG : Step 85528, finished rewards 24.37, envs finished 1
2026-01-17 13:24:23,820 : worker.worker : DEBUG : Step 85531, finished rewards -13.62, envs finished 1
2026-01-17 13:24:23,936 : agent.on_policy : DEBUG : Mean Losses: [7.549771327525377]
2026-01-17 13:24:24,141 : agent.on_policy : DEBUG : Mean Losses: [2.2662058360874653]
2026-01-17 13:24:24,150 : worker.worker : DEBUG : Step 85570, finished rewards 11.26, envs finished 2
2026-01-17 13:24:24,181 : worker.worker : DEBUG : Step 85575, finished rewards 23.66, envs finished 1
2026-01-17 13:24:24,223 : worker.worker : DEBUG : Step 85586, finished rewards 8.47, envs finished 1
2026-01-17 13:24:24,322 : agent.on_policy : DEBUG : Mean Losses: [5.501765698194504]
2026-01-17 13:24:24,490 : agent.on_policy : DEBUG : Mean Losses: [2.917470522224903]
2026-01-17 13:24:24,544 : worker.worker : DEBUG : Step 85647, finished rewards -23.19, envs finished 1
2026-01-17 13:24:24,548 : worker.worker : DEBUG : Step 85648, finished rewards 6.92, envs finished 1
2026-01-17 13:24:24,551 : worker.worker : DEBUG : Step 85649, finished rewards 5.81, envs finished 1
2026-01-17 13:24:24,710 : agent.on_policy : DEBUG : Mean Losses: [8.727096945047379]
2026-01-17 13:24:24,720 : worker.worker : DEBUG : Step 85667, finished rewards 24.23, envs finished 1
2026-01-17 13:24:24,796 : worker.worker : DEBUG : Step 85688, finished rewards -10.68, envs finished 1
2026-01-17 13:24:24,816 : worker.worker : DEBUG : Step 85693, finished rewards 3.94, envs finished 1
2026-01-17 13:24:24,912 : agent.on_policy : DEBUG : Mean Losses: [6.8224126398563385]
2026-01-17 13:24:24,948 : worker.worker : DEBUG : Step 85704, finished rewards -2.90, envs finished 1
2026-01-17 13:24:25,122 : agent.on_policy : DEBUG : Mean Losses: [3.5179588310420513]
2026-01-17 13:24:25,136 : worker.worker : DEBUG : Step 85732, finished rewards 29.20, envs finished 1
2026-01-17 13:24:25,175 : worker.worker : DEBUG : Step 85742, finished rewards 23.76, envs finished 1
2026-01-17 13:24:25,189 : worker.worker : DEBUG : Step 85746, finished rewards -28.06, envs finished 1
2026-01-17 13:24:25,234 : worker.worker : DEBUG : Step 85757, finished rewards 41.61, envs finished 1
2026-01-17 13:24:25,298 : agent.on_policy : DEBUG : Mean Losses: [10.303221486508846]
2026-01-17 13:24:25,327 : worker.worker : DEBUG : Step 85768, finished rewards 17.95, envs finished 1
2026-01-17 13:24:25,418 : worker.worker : DEBUG : Step 85785, finished rewards 24.32, envs finished 1
2026-01-17 13:24:25,435 : worker.worker : DEBUG : Step 85788, finished rewards -4.81, envs finished 1
2026-01-17 13:24:25,548 : agent.on_policy : DEBUG : Mean Losses: [7.69705636613071]
2026-01-17 13:24:25,638 : worker.worker : DEBUG : Step 85811, finished rewards 12.53, envs finished 1
2026-01-17 13:24:25,773 : agent.on_policy : DEBUG : Mean Losses: [2.833630778826773]
2026-01-17 13:24:25,779 : worker.worker : DEBUG : Step 85825, finished rewards 30.89, envs finished 1
2026-01-17 13:24:25,831 : worker.worker : DEBUG : Step 85838, finished rewards 24.39, envs finished 1
2026-01-17 13:24:26,044 : agent.on_policy : DEBUG : Mean Losses: [4.414111252874136]
2026-01-17 13:24:26,086 : worker.worker : DEBUG : Step 85860, finished rewards 24.58, envs finished 1
2026-01-17 13:24:26,151 : worker.worker : DEBUG : Step 85872, finished rewards 5.16, envs finished 1
2026-01-17 13:24:26,197 : worker.worker : DEBUG : Step 85881, finished rewards -7.60, envs finished 1
2026-01-17 13:24:26,216 : worker.worker : DEBUG : Step 85884, finished rewards 22.11, envs finished 1
2026-01-17 13:24:26,336 : agent.on_policy : DEBUG : Mean Losses: [8.168505132198334]
2026-01-17 13:24:26,437 : worker.worker : DEBUG : Step 85909, finished rewards 19.30, envs finished 1
2026-01-17 13:24:26,454 : worker.worker : DEBUG : Step 85913, finished rewards -1.65, envs finished 1
2026-01-17 13:24:26,566 : agent.on_policy : DEBUG : Mean Losses: [5.16706950776279]
2026-01-17 13:24:26,737 : agent.on_policy : DEBUG : Mean Losses: [1.960129003971815]
2026-01-17 13:24:26,741 : worker.worker : DEBUG : Step 85953, finished rewards 23.89, envs finished 1
2026-01-17 13:24:26,746 : worker.worker : DEBUG : Step 85954, finished rewards -4.00, envs finished 1
2026-01-17 13:24:26,754 : worker.worker : DEBUG : Step 85955, finished rewards 6.83, envs finished 1
2026-01-17 13:24:26,830 : worker.worker : DEBUG : Step 85972, finished rewards 25.68, envs finished 1
2026-01-17 13:24:26,844 : worker.worker : DEBUG : Step 85976, finished rewards 25.24, envs finished 1
2026-01-17 13:24:26,970 : agent.on_policy : DEBUG : Mean Losses: [7.342178355902433]
2026-01-17 13:24:27,038 : worker.worker : DEBUG : Step 85995, finished rewards 3.36, envs finished 1
2026-01-17 13:24:27,047 : worker.worker : DEBUG : Step 85996, finished rewards 30.96, envs finished 1
2026-01-17 13:24:27,056 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:24:27,216 : agent.on_policy : DEBUG : Mean Losses: [4.650435172021389]
2026-01-17 13:24:27,235 : worker.worker : DEBUG : Step 86021, finished rewards 12.00, envs finished 1
2026-01-17 13:24:27,348 : worker.worker : DEBUG : Step 86047, finished rewards 24.46, envs finished 1
2026-01-17 13:24:27,447 : agent.on_policy : DEBUG : Mean Losses: [5.582399956882]
2026-01-17 13:24:27,469 : worker.worker : DEBUG : Step 86055, finished rewards 30.71, envs finished 1
2026-01-17 13:24:27,548 : worker.worker : DEBUG : Step 86068, finished rewards 7.98, envs finished 1
2026-01-17 13:24:27,695 : agent.on_policy : DEBUG : Mean Losses: [6.058897994458675]
2026-01-17 13:24:27,710 : worker.worker : DEBUG : Step 86085, finished rewards -0.91, envs finished 1
2026-01-17 13:24:27,793 : worker.worker : DEBUG : Step 86101, finished rewards 14.12, envs finished 1
2026-01-17 13:24:27,913 : agent.on_policy : DEBUG : Mean Losses: [6.974538799375296]
2026-01-17 13:24:27,999 : worker.worker : DEBUG : Step 86126, finished rewards -0.79, envs finished 1
2026-01-17 13:24:28,090 : worker.worker : DEBUG : Step 86142, finished rewards 5.04, envs finished 1
2026-01-17 13:24:28,096 : worker.worker : DEBUG : Step 86143, finished rewards -24.95, envs finished 1
2026-01-17 13:24:28,196 : agent.on_policy : DEBUG : Mean Losses: [7.133822947740555]
2026-01-17 13:24:28,216 : worker.worker : DEBUG : Step 86148, finished rewards 23.94, envs finished 1
2026-01-17 13:24:28,245 : worker.worker : DEBUG : Step 86150, finished rewards 30.94, envs finished 1
2026-01-17 13:24:28,638 : agent.on_policy : DEBUG : Mean Losses: [4.527258686721325]
2026-01-17 13:24:28,722 : worker.worker : DEBUG : Step 86192, finished rewards 12.76, envs finished 1
2026-01-17 13:24:28,732 : worker.worker : DEBUG : Step 86193, finished rewards 24.52, envs finished 1
2026-01-17 13:24:28,914 : agent.on_policy : DEBUG : Mean Losses: [6.30330117046833]
2026-01-17 13:24:29,124 : agent.on_policy : DEBUG : Mean Losses: [3.6413871236145496]
2026-01-17 13:24:29,132 : worker.worker : DEBUG : Step 86242, finished rewards -8.00, envs finished 1
2026-01-17 13:24:29,189 : worker.worker : DEBUG : Step 86257, finished rewards -3.55, envs finished 1
2026-01-17 13:24:29,199 : worker.worker : DEBUG : Step 86259, finished rewards 5.66, envs finished 1
2026-01-17 13:24:29,229 : worker.worker : DEBUG : Step 86265, finished rewards 1.71, envs finished 1
2026-01-17 13:24:29,245 : worker.worker : DEBUG : Step 86268, finished rewards 3.65, envs finished 1
2026-01-17 13:24:29,400 : agent.on_policy : DEBUG : Mean Losses: [10.521999701857567]
2026-01-17 13:24:29,402 : worker.worker : DEBUG : Step 86272, finished rewards 3.98, envs finished 1
2026-01-17 13:24:29,582 : worker.worker : DEBUG : Step 86293, finished rewards 19.11, envs finished 1
2026-01-17 13:24:29,687 : agent.on_policy : DEBUG : Mean Losses: [3.2581750079989433]
2026-01-17 13:24:29,701 : worker.worker : DEBUG : Step 86307, finished rewards 6.21, envs finished 1
2026-01-17 13:24:29,902 : agent.on_policy : DEBUG : Mean Losses: [2.127901455387473]
2026-01-17 13:24:30,070 : agent.on_policy : DEBUG : Mean Losses: [2.68483629822731]
2026-01-17 13:24:30,082 : worker.worker : DEBUG : Step 86370, finished rewards 17.61, envs finished 1
2026-01-17 13:24:30,107 : worker.worker : DEBUG : Step 86375, finished rewards -0.52, envs finished 1
2026-01-17 13:24:30,112 : worker.worker : DEBUG : Step 86376, finished rewards 11.14, envs finished 2
2026-01-17 13:24:30,138 : worker.worker : DEBUG : Step 86383, finished rewards 5.26, envs finished 1
2026-01-17 13:24:30,144 : worker.worker : DEBUG : Step 86384, finished rewards -1.22, envs finished 1
2026-01-17 13:24:30,185 : worker.worker : DEBUG : Step 86394, finished rewards 17.95, envs finished 1
2026-01-17 13:24:30,261 : agent.on_policy : DEBUG : Mean Losses: [11.656794369220734]
2026-01-17 13:24:30,442 : agent.on_policy : DEBUG : Mean Losses: [1.4392823912203312]
2026-01-17 13:24:30,455 : worker.worker : DEBUG : Step 86435, finished rewards 0.14, envs finished 1
2026-01-17 13:24:30,655 : agent.on_policy : DEBUG : Mean Losses: [3.72043726593256]
2026-01-17 13:24:30,671 : worker.worker : DEBUG : Step 86468, finished rewards 39.09, envs finished 1
2026-01-17 13:24:30,733 : worker.worker : DEBUG : Step 86484, finished rewards 14.62, envs finished 1
2026-01-17 13:24:30,784 : worker.worker : DEBUG : Step 86493, finished rewards 6.24, envs finished 1
2026-01-17 13:24:30,791 : worker.worker : DEBUG : Step 86494, finished rewards 9.96, envs finished 1
2026-01-17 13:24:30,906 : agent.on_policy : DEBUG : Mean Losses: [9.63683458790183]
2026-01-17 13:24:31,001 : worker.worker : DEBUG : Step 86512, finished rewards -7.56, envs finished 1
2026-01-17 13:24:31,208 : agent.on_policy : DEBUG : Mean Losses: [4.163665113970637]
2026-01-17 13:24:31,214 : worker.worker : DEBUG : Step 86529, finished rewards 2.20, envs finished 1
2026-01-17 13:24:31,294 : worker.worker : DEBUG : Step 86544, finished rewards -18.05, envs finished 1
2026-01-17 13:24:31,482 : agent.on_policy : DEBUG : Mean Losses: [5.013931281864643]
2026-01-17 13:24:31,502 : worker.worker : DEBUG : Step 86564, finished rewards 3.56, envs finished 1
2026-01-17 13:24:31,548 : worker.worker : DEBUG : Step 86573, finished rewards 15.76, envs finished 1
2026-01-17 13:24:31,619 : worker.worker : DEBUG : Step 86586, finished rewards 17.26, envs finished 1
2026-01-17 13:24:31,771 : agent.on_policy : DEBUG : Mean Losses: [7.528921566903591]
2026-01-17 13:24:31,817 : worker.worker : DEBUG : Step 86600, finished rewards 13.41, envs finished 1
2026-01-17 13:24:31,916 : worker.worker : DEBUG : Step 86621, finished rewards 0.40, envs finished 1
2026-01-17 13:24:32,032 : agent.on_policy : DEBUG : Mean Losses: [6.044869914650917]
2026-01-17 13:24:32,233 : worker.worker : DEBUG : Step 86649, finished rewards 14.84, envs finished 1
2026-01-17 13:24:32,345 : agent.on_policy : DEBUG : Mean Losses: [5.0327640771865845]
2026-01-17 13:24:32,402 : worker.worker : DEBUG : Step 86663, finished rewards 19.47, envs finished 1
2026-01-17 13:24:32,418 : worker.worker : DEBUG : Step 86664, finished rewards -11.39, envs finished 1
2026-01-17 13:24:32,428 : worker.worker : DEBUG : Step 86665, finished rewards 24.05, envs finished 1
2026-01-17 13:24:32,542 : worker.worker : DEBUG : Step 86683, finished rewards -19.77, envs finished 1
2026-01-17 13:24:32,648 : agent.on_policy : DEBUG : Mean Losses: [8.677336633205414]
2026-01-17 13:24:32,715 : worker.worker : DEBUG : Step 86701, finished rewards 5.91, envs finished 1
2026-01-17 13:24:32,750 : worker.worker : DEBUG : Step 86707, finished rewards 13.28, envs finished 1
2026-01-17 13:24:32,908 : agent.on_policy : DEBUG : Mean Losses: [4.535858342424035]
2026-01-17 13:24:32,999 : worker.worker : DEBUG : Step 86739, finished rewards 35.57, envs finished 1
2026-01-17 13:24:33,017 : worker.worker : DEBUG : Step 86741, finished rewards 5.75, envs finished 1
2026-01-17 13:24:33,166 : agent.on_policy : DEBUG : Mean Losses: [8.045503221452236]
2026-01-17 13:24:33,268 : worker.worker : DEBUG : Step 86776, finished rewards -0.92, envs finished 1
2026-01-17 13:24:33,273 : worker.worker : DEBUG : Step 86777, finished rewards 9.56, envs finished 1
2026-01-17 13:24:33,406 : agent.on_policy : DEBUG : Mean Losses: [5.938708212226629]
2026-01-17 13:24:33,482 : worker.worker : DEBUG : Step 86797, finished rewards 9.34, envs finished 1
2026-01-17 13:24:33,491 : worker.worker : DEBUG : Step 86799, finished rewards 18.26, envs finished 1
2026-01-17 13:24:33,503 : worker.worker : DEBUG : Step 86801, finished rewards -6.69, envs finished 1
2026-01-17 13:24:33,676 : agent.on_policy : DEBUG : Mean Losses: [6.726294219493866]
2026-01-17 13:24:33,761 : worker.worker : DEBUG : Step 86841, finished rewards 17.34, envs finished 1
2026-01-17 13:24:33,857 : agent.on_policy : DEBUG : Mean Losses: [6.29102735593915]
2026-01-17 13:24:33,962 : worker.worker : DEBUG : Step 86867, finished rewards 1.13, envs finished 1
2026-01-17 13:24:34,091 : agent.on_policy : DEBUG : Mean Losses: [5.485936991870403]
2026-01-17 13:24:34,093 : worker.worker : DEBUG : Step 86880, finished rewards 14.88, envs finished 1
2026-01-17 13:24:34,108 : worker.worker : DEBUG : Step 86882, finished rewards -24.80, envs finished 1
2026-01-17 13:24:34,230 : worker.worker : DEBUG : Step 86909, finished rewards -5.73, envs finished 1
2026-01-17 13:24:34,326 : agent.on_policy : DEBUG : Mean Losses: [6.792833186686039]
2026-01-17 13:24:34,358 : worker.worker : DEBUG : Step 86922, finished rewards 1.14, envs finished 1
2026-01-17 13:24:34,535 : agent.on_policy : DEBUG : Mean Losses: [4.345529146492481]
2026-01-17 13:24:34,543 : worker.worker : DEBUG : Step 86946, finished rewards 14.95, envs finished 1
2026-01-17 13:24:34,550 : worker.worker : DEBUG : Step 86948, finished rewards -15.70, envs finished 1
2026-01-17 13:24:34,746 : agent.on_policy : DEBUG : Mean Losses: [3.79305350035429]
2026-01-17 13:24:34,770 : worker.worker : DEBUG : Step 86980, finished rewards -7.82, envs finished 2
2026-01-17 13:24:34,808 : worker.worker : DEBUG : Step 86984, finished rewards 6.06, envs finished 1
2026-01-17 13:24:34,917 : worker.worker : DEBUG : Step 86994, finished rewards 9.60, envs finished 1
2026-01-17 13:24:34,942 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:24:35,091 : agent.on_policy : DEBUG : Mean Losses: [6.776987835764885]
2026-01-17 13:24:35,149 : worker.worker : DEBUG : Step 87023, finished rewards 19.10, envs finished 1
2026-01-17 13:24:35,155 : worker.worker : DEBUG : Step 87024, finished rewards 9.82, envs finished 1
2026-01-17 13:24:35,218 : worker.worker : DEBUG : Step 87036, finished rewards 26.02, envs finished 1
2026-01-17 13:24:35,332 : agent.on_policy : DEBUG : Mean Losses: [8.1383311226964]
2026-01-17 13:24:35,561 : agent.on_policy : DEBUG : Mean Losses: [1.3611749038100243]
2026-01-17 13:24:35,636 : worker.worker : DEBUG : Step 87085, finished rewards 14.21, envs finished 1
2026-01-17 13:24:35,650 : worker.worker : DEBUG : Step 87087, finished rewards 23.37, envs finished 1
2026-01-17 13:24:35,734 : worker.worker : DEBUG : Step 87097, finished rewards 6.74, envs finished 1
2026-01-17 13:24:35,771 : worker.worker : DEBUG : Step 87101, finished rewards 11.68, envs finished 1
2026-01-17 13:24:35,920 : agent.on_policy : DEBUG : Mean Losses: [8.898109398782253]
2026-01-17 13:24:35,936 : worker.worker : DEBUG : Step 87106, finished rewards -8.83, envs finished 1
2026-01-17 13:24:36,095 : worker.worker : DEBUG : Step 87126, finished rewards 17.29, envs finished 1
2026-01-17 13:24:36,123 : worker.worker : DEBUG : Step 87130, finished rewards 15.39, envs finished 1
2026-01-17 13:24:36,242 : agent.on_policy : DEBUG : Mean Losses: [5.743562210351229]
2026-01-17 13:24:36,493 : agent.on_policy : DEBUG : Mean Losses: [1.7943523973226547]
2026-01-17 13:24:36,521 : worker.worker : DEBUG : Step 87175, finished rewards -11.28, envs finished 1
2026-01-17 13:24:36,548 : worker.worker : DEBUG : Step 87179, finished rewards 23.69, envs finished 1
2026-01-17 13:24:36,763 : agent.on_policy : DEBUG : Mean Losses: [5.263755463063717]
2026-01-17 13:24:36,796 : worker.worker : DEBUG : Step 87206, finished rewards 11.06, envs finished 2
2026-01-17 13:24:36,916 : worker.worker : DEBUG : Step 87228, finished rewards 19.12, envs finished 1
2026-01-17 13:24:36,921 : worker.worker : DEBUG : Step 87229, finished rewards 3.56, envs finished 1
2026-01-17 13:24:37,018 : agent.on_policy : DEBUG : Mean Losses: [7.965945549309254]
2026-01-17 13:24:37,057 : worker.worker : DEBUG : Step 87244, finished rewards -10.79, envs finished 1
2026-01-17 13:24:37,141 : worker.worker : DEBUG : Step 87257, finished rewards -5.70, envs finished 1
2026-01-17 13:24:37,243 : agent.on_policy : DEBUG : Mean Losses: [4.4020116943866014]
2026-01-17 13:24:37,315 : worker.worker : DEBUG : Step 87277, finished rewards 17.16, envs finished 1
2026-01-17 13:24:37,385 : worker.worker : DEBUG : Step 87293, finished rewards 7.25, envs finished 1
2026-01-17 13:24:37,477 : agent.on_policy : DEBUG : Mean Losses: [5.5363854095339775]
2026-01-17 13:24:37,510 : worker.worker : DEBUG : Step 87305, finished rewards 18.29, envs finished 1
2026-01-17 13:24:37,571 : worker.worker : DEBUG : Step 87312, finished rewards 29.76, envs finished 1
2026-01-17 13:24:37,617 : worker.worker : DEBUG : Step 87323, finished rewards 4.79, envs finished 1
2026-01-17 13:24:37,764 : agent.on_policy : DEBUG : Mean Losses: [7.643577340990305]
2026-01-17 13:24:37,963 : agent.on_policy : DEBUG : Mean Losses: [2.1925658620893955]
2026-01-17 13:24:37,979 : worker.worker : DEBUG : Step 87363, finished rewards 3.98, envs finished 1
2026-01-17 13:24:38,022 : worker.worker : DEBUG : Step 87373, finished rewards -14.81, envs finished 1
2026-01-17 13:24:38,027 : worker.worker : DEBUG : Step 87374, finished rewards 5.73, envs finished 1
2026-01-17 13:24:38,085 : worker.worker : DEBUG : Step 87389, finished rewards 18.61, envs finished 2
2026-01-17 13:24:38,155 : agent.on_policy : DEBUG : Mean Losses: [11.67995472252369]
2026-01-17 13:24:38,157 : worker.worker : DEBUG : Step 87392, finished rewards 18.61, envs finished 1
2026-01-17 13:24:38,240 : worker.worker : DEBUG : Step 87401, finished rewards 24.72, envs finished 1
2026-01-17 13:24:38,498 : agent.on_policy : DEBUG : Mean Losses: [2.7288214303553104]
2026-01-17 13:24:38,701 : agent.on_policy : DEBUG : Mean Losses: [1.8597506806254387]
2026-01-17 13:24:38,714 : worker.worker : DEBUG : Step 87458, finished rewards -3.22, envs finished 1
2026-01-17 13:24:38,900 : agent.on_policy : DEBUG : Mean Losses: [3.6637102663517]
2026-01-17 13:24:38,927 : worker.worker : DEBUG : Step 87495, finished rewards 13.62, envs finished 1
2026-01-17 13:24:38,938 : worker.worker : DEBUG : Step 87498, finished rewards 11.69, envs finished 1
2026-01-17 13:24:38,996 : worker.worker : DEBUG : Step 87512, finished rewards -8.84, envs finished 1
2026-01-17 13:24:39,072 : agent.on_policy : DEBUG : Mean Losses: [7.918720029294491]
2026-01-17 13:24:39,074 : worker.worker : DEBUG : Step 87520, finished rewards 5.26, envs finished 1
2026-01-17 13:24:39,156 : worker.worker : DEBUG : Step 87530, finished rewards -9.00, envs finished 2
2026-01-17 13:24:39,176 : worker.worker : DEBUG : Step 87535, finished rewards -31.78, envs finished 1
2026-01-17 13:24:39,259 : worker.worker : DEBUG : Step 87549, finished rewards 24.20, envs finished 1
2026-01-17 13:24:39,330 : agent.on_policy : DEBUG : Mean Losses: [8.409603912383318]
2026-01-17 13:24:39,499 : worker.worker : DEBUG : Step 87581, finished rewards 30.88, envs finished 1
2026-01-17 13:24:39,581 : agent.on_policy : DEBUG : Mean Losses: [4.982263218611479]
2026-01-17 13:24:39,599 : worker.worker : DEBUG : Step 87586, finished rewards 26.10, envs finished 1
2026-01-17 13:24:39,890 : agent.on_policy : DEBUG : Mean Losses: [2.589761681854725]
2026-01-17 13:24:39,893 : worker.worker : DEBUG : Step 87616, finished rewards 15.16, envs finished 1
2026-01-17 13:24:39,958 : worker.worker : DEBUG : Step 87632, finished rewards 23.16, envs finished 2
2026-01-17 13:24:40,056 : worker.worker : DEBUG : Step 87646, finished rewards 0.23, envs finished 1
2026-01-17 13:24:40,175 : agent.on_policy : DEBUG : Mean Losses: [8.783226452767849]
2026-01-17 13:24:40,292 : worker.worker : DEBUG : Step 87669, finished rewards 30.09, envs finished 1
2026-01-17 13:24:40,297 : worker.worker : DEBUG : Step 87670, finished rewards -7.07, envs finished 2
2026-01-17 13:24:40,420 : agent.on_policy : DEBUG : Mean Losses: [6.904701691120863]
2026-01-17 13:24:40,538 : worker.worker : DEBUG : Step 87702, finished rewards 2.80, envs finished 1
2026-01-17 13:24:40,662 : agent.on_policy : DEBUG : Mean Losses: [3.7663110941648483]
2026-01-17 13:24:40,736 : worker.worker : DEBUG : Step 87724, finished rewards 23.97, envs finished 1
2026-01-17 13:24:40,919 : agent.on_policy : DEBUG : Mean Losses: [4.170103944838047]
2026-01-17 13:24:40,949 : worker.worker : DEBUG : Step 87752, finished rewards -4.69, envs finished 1
2026-01-17 13:24:40,973 : worker.worker : DEBUG : Step 87758, finished rewards 25.51, envs finished 1
2026-01-17 13:24:40,983 : worker.worker : DEBUG : Step 87760, finished rewards -0.26, envs finished 1
2026-01-17 13:24:41,008 : worker.worker : DEBUG : Step 87765, finished rewards 22.15, envs finished 1
2026-01-17 13:24:41,108 : agent.on_policy : DEBUG : Mean Losses: [8.851033166050911]
2026-01-17 13:24:41,125 : worker.worker : DEBUG : Step 87780, finished rewards 2.80, envs finished 1
2026-01-17 13:24:41,211 : worker.worker : DEBUG : Step 87792, finished rewards 1.20, envs finished 1
2026-01-17 13:24:41,363 : agent.on_policy : DEBUG : Mean Losses: [3.975786805152893]
2026-01-17 13:24:41,375 : worker.worker : DEBUG : Step 87811, finished rewards 12.30, envs finished 1
2026-01-17 13:24:41,415 : worker.worker : DEBUG : Step 87822, finished rewards 20.53, envs finished 1
2026-01-17 13:24:41,518 : agent.on_policy : DEBUG : Mean Losses: [3.756573579274118]
2026-01-17 13:24:41,627 : worker.worker : DEBUG : Step 87851, finished rewards 24.22, envs finished 1
2026-01-17 13:24:41,284 : worker.worker : DEBUG : Step 87865, finished rewards 13.77, envs finished 1
2026-01-17 13:24:40,873 : worker.worker : DEBUG : Step 87866, finished rewards 8.61, envs finished 1
2026-01-17 13:24:41,035 : agent.on_policy : DEBUG : Mean Losses: [7.786551617085934]
2026-01-17 13:24:41,134 : worker.worker : DEBUG : Step 87892, finished rewards 18.22, envs finished 1
2026-01-17 13:24:41,250 : agent.on_policy : DEBUG : Mean Losses: [5.081360876560211]
2026-01-17 13:24:41,264 : worker.worker : DEBUG : Step 87908, finished rewards -14.56, envs finished 1
2026-01-17 13:24:41,346 : worker.worker : DEBUG : Step 87919, finished rewards -9.68, envs finished 1
2026-01-17 13:24:41,468 : worker.worker : DEBUG : Step 87934, finished rewards 30.94, envs finished 1
2026-01-17 13:24:41,608 : agent.on_policy : DEBUG : Mean Losses: [7.817670837044716]
2026-01-17 13:24:41,647 : worker.worker : DEBUG : Step 87943, finished rewards -2.65, envs finished 2
2026-01-17 13:24:41,892 : agent.on_policy : DEBUG : Mean Losses: [4.842542804777622]
2026-01-17 13:24:41,917 : worker.worker : DEBUG : Step 87973, finished rewards 11.48, envs finished 1
2026-01-17 13:24:42,010 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:24:42,054 : agent.on_policy : DEBUG : Mean Losses: [4.278023838996887]
2026-01-17 13:24:42,057 : worker.worker : DEBUG : Step 88000, finished rewards -9.32, envs finished 1
2026-01-17 13:24:42,127 : worker.worker : DEBUG : Step 88010, finished rewards 5.03, envs finished 1
2026-01-17 13:24:42,172 : worker.worker : DEBUG : Step 88017, finished rewards 30.82, envs finished 1
2026-01-17 13:24:42,237 : worker.worker : DEBUG : Step 88022, finished rewards 7.67, envs finished 1
2026-01-17 13:24:42,268 : worker.worker : DEBUG : Step 88026, finished rewards 30.57, envs finished 1
2026-01-17 13:24:42,440 : agent.on_policy : DEBUG : Mean Losses: [11.656603053212166]
2026-01-17 13:24:42,515 : worker.worker : DEBUG : Step 88042, finished rewards 20.42, envs finished 1
2026-01-17 13:24:42,545 : worker.worker : DEBUG : Step 88047, finished rewards -3.40, envs finished 1
2026-01-17 13:24:42,705 : agent.on_policy : DEBUG : Mean Losses: [4.69959007948637]
2026-01-17 13:24:42,900 : agent.on_policy : DEBUG : Mean Losses: [1.4453193992376328]
2026-01-17 13:24:42,942 : worker.worker : DEBUG : Step 88106, finished rewards -4.48, envs finished 1
2026-01-17 13:24:42,976 : worker.worker : DEBUG : Step 88113, finished rewards 23.88, envs finished 1
2026-01-17 13:24:42,990 : worker.worker : DEBUG : Step 88116, finished rewards 26.15, envs finished 1
2026-01-17 13:24:43,007 : worker.worker : DEBUG : Step 88119, finished rewards 36.50, envs finished 1
2026-01-17 13:24:43,014 : worker.worker : DEBUG : Step 88120, finished rewards 5.52, envs finished 1
2026-01-17 13:24:43,042 : worker.worker : DEBUG : Step 88125, finished rewards 6.29, envs finished 1
2026-01-17 13:24:43,103 : agent.on_policy : DEBUG : Mean Losses: [14.36004638671875]
2026-01-17 13:24:43,106 : worker.worker : DEBUG : Step 88128, finished rewards 31.74, envs finished 1
2026-01-17 13:24:43,131 : worker.worker : DEBUG : Step 88134, finished rewards 6.16, envs finished 1
2026-01-17 13:24:43,303 : agent.on_policy : DEBUG : Mean Losses: [1.76591220125556]
2026-01-17 13:24:43,455 : agent.on_policy : DEBUG : Mean Losses: [1.084825187921524]
2026-01-17 13:24:43,686 : worker.worker : DEBUG : Step 88222, finished rewards 6.32, envs finished 1
2026-01-17 13:24:43,792 : agent.on_policy : DEBUG : Mean Losses: [5.439082652330399]
2026-01-17 13:24:43,820 : worker.worker : DEBUG : Step 88229, finished rewards 15.48, envs finished 1
2026-01-17 13:24:43,890 : worker.worker : DEBUG : Step 88235, finished rewards 0.49, envs finished 1
2026-01-17 13:24:43,899 : worker.worker : DEBUG : Step 88236, finished rewards 4.27, envs finished 1
2026-01-17 13:24:43,926 : worker.worker : DEBUG : Step 88241, finished rewards 5.03, envs finished 1
2026-01-17 13:24:43,942 : worker.worker : DEBUG : Step 88244, finished rewards 3.03, envs finished 1
2026-01-17 13:24:44,080 : agent.on_policy : DEBUG : Mean Losses: [11.52430409193039]
2026-01-17 13:24:44,093 : worker.worker : DEBUG : Step 88258, finished rewards -1.39, envs finished 1
2026-01-17 13:24:44,124 : worker.worker : DEBUG : Step 88266, finished rewards -11.24, envs finished 1
2026-01-17 13:24:44,247 : agent.on_policy : DEBUG : Mean Losses: [3.2297132834792137]
2026-01-17 13:24:44,438 : agent.on_policy : DEBUG : Mean Losses: [1.4661344140768051]
2026-01-17 13:24:44,448 : worker.worker : DEBUG : Step 88323, finished rewards 17.91, envs finished 1
2026-01-17 13:24:44,482 : worker.worker : DEBUG : Step 88331, finished rewards 21.68, envs finished 1
2026-01-17 13:24:44,535 : worker.worker : DEBUG : Step 88346, finished rewards 6.07, envs finished 1
2026-01-17 13:24:44,612 : agent.on_policy : DEBUG : Mean Losses: [6.566261257976294]
2026-01-17 13:24:44,703 : worker.worker : DEBUG : Step 88370, finished rewards 0.53, envs finished 1
2026-01-17 13:24:44,839 : agent.on_policy : DEBUG : Mean Losses: [5.29346850886941]
2026-01-17 13:24:44,845 : worker.worker : DEBUG : Step 88384, finished rewards 0.93, envs finished 2
2026-01-17 13:24:44,872 : worker.worker : DEBUG : Step 88390, finished rewards -8.92, envs finished 1
2026-01-17 13:24:44,923 : worker.worker : DEBUG : Step 88403, finished rewards -27.79, envs finished 1
2026-01-17 13:24:45,063 : agent.on_policy : DEBUG : Mean Losses: [3.8389036832377315]
2026-01-17 13:24:45,106 : worker.worker : DEBUG : Step 88429, finished rewards 13.45, envs finished 1
2026-01-17 13:24:45,212 : agent.on_policy : DEBUG : Mean Losses: [3.266758158802986]
2026-01-17 13:24:45,223 : worker.worker : DEBUG : Step 88451, finished rewards 7.01, envs finished 1
2026-01-17 13:24:45,317 : worker.worker : DEBUG : Step 88463, finished rewards 24.10, envs finished 1
2026-01-17 13:24:45,372 : worker.worker : DEBUG : Step 88474, finished rewards 26.07, envs finished 1
2026-01-17 13:24:45,406 : worker.worker : DEBUG : Step 88477, finished rewards -3.46, envs finished 1
2026-01-17 13:24:45,497 : agent.on_policy : DEBUG : Mean Losses: [9.901090294122696]
2026-01-17 13:24:45,500 : worker.worker : DEBUG : Step 88480, finished rewards 26.11, envs finished 1
2026-01-17 13:24:45,719 : agent.on_policy : DEBUG : Mean Losses: [1.7231001295149326]
2026-01-17 13:24:45,751 : worker.worker : DEBUG : Step 88521, finished rewards 6.62, envs finished 1
2026-01-17 13:24:45,781 : worker.worker : DEBUG : Step 88529, finished rewards 20.32, envs finished 1
2026-01-17 13:24:45,892 : agent.on_policy : DEBUG : Mean Losses: [5.02401814609766]
2026-01-17 13:24:45,908 : worker.worker : DEBUG : Step 88546, finished rewards -25.58, envs finished 1
2026-01-17 13:24:46,010 : worker.worker : DEBUG : Step 88560, finished rewards 31.78, envs finished 2
2026-01-17 13:24:46,171 : agent.on_policy : DEBUG : Mean Losses: [7.732979953289032]
2026-01-17 13:24:46,184 : worker.worker : DEBUG : Step 88580, finished rewards -4.21, envs finished 1
2026-01-17 13:24:46,252 : worker.worker : DEBUG : Step 88601, finished rewards 3.41, envs finished 1
2026-01-17 13:24:46,269 : worker.worker : DEBUG : Step 88604, finished rewards -10.39, envs finished 1
2026-01-17 13:24:46,373 : agent.on_policy : DEBUG : Mean Losses: [5.505609208717942]
2026-01-17 13:24:46,559 : agent.on_policy : DEBUG : Mean Losses: [1.9455888979136944]
2026-01-17 13:24:46,612 : worker.worker : DEBUG : Step 88656, finished rewards -1.12, envs finished 1
2026-01-17 13:24:46,639 : worker.worker : DEBUG : Step 88663, finished rewards 3.97, envs finished 1
2026-01-17 13:24:46,773 : agent.on_policy : DEBUG : Mean Losses: [6.634496942162514]
2026-01-17 13:24:46,855 : worker.worker : DEBUG : Step 88678, finished rewards 4.04, envs finished 1
2026-01-17 13:24:46,923 : worker.worker : DEBUG : Step 88686, finished rewards 3.28, envs finished 1
2026-01-17 13:24:47,034 : worker.worker : DEBUG : Step 88700, finished rewards 22.51, envs finished 1
2026-01-17 13:24:47,134 : agent.on_policy : DEBUG : Mean Losses: [8.741575457155704]
2026-01-17 13:24:47,139 : worker.worker : DEBUG : Step 88705, finished rewards -33.73, envs finished 1
2026-01-17 13:24:47,253 : worker.worker : DEBUG : Step 88726, finished rewards -5.71, envs finished 1
2026-01-17 13:24:47,368 : agent.on_policy : DEBUG : Mean Losses: [3.751304192468524]
2026-01-17 13:24:47,567 : agent.on_policy : DEBUG : Mean Losses: [4.126663867384195]
2026-01-17 13:24:47,610 : worker.worker : DEBUG : Step 88779, finished rewards 7.34, envs finished 1
2026-01-17 13:24:47,638 : worker.worker : DEBUG : Step 88784, finished rewards -29.40, envs finished 1
2026-01-17 13:24:47,672 : worker.worker : DEBUG : Step 88792, finished rewards -7.27, envs finished 1
2026-01-17 13:24:47,689 : worker.worker : DEBUG : Step 88796, finished rewards 4.18, envs finished 1
2026-01-17 13:24:47,762 : agent.on_policy : DEBUG : Mean Losses: [9.679324686527252]
2026-01-17 13:24:47,800 : worker.worker : DEBUG : Step 88810, finished rewards -2.29, envs finished 1
2026-01-17 13:24:47,819 : worker.worker : DEBUG : Step 88815, finished rewards 7.99, envs finished 1
2026-01-17 13:24:47,950 : agent.on_policy : DEBUG : Mean Losses: [4.932058550417423]
2026-01-17 13:24:47,993 : worker.worker : DEBUG : Step 88836, finished rewards -1.45, envs finished 1
2026-01-17 13:24:48,089 : worker.worker : DEBUG : Step 88858, finished rewards -6.41, envs finished 1
2026-01-17 13:24:48,205 : agent.on_policy : DEBUG : Mean Losses: [4.154819056391716]
2026-01-17 13:24:48,438 : agent.on_policy : DEBUG : Mean Losses: [2.553688645362854]
2026-01-17 13:24:48,447 : worker.worker : DEBUG : Step 88898, finished rewards 9.80, envs finished 1
2026-01-17 13:24:48,467 : worker.worker : DEBUG : Step 88902, finished rewards 25.43, envs finished 1
2026-01-17 13:24:48,474 : worker.worker : DEBUG : Step 88903, finished rewards 3.70, envs finished 1
2026-01-17 13:24:48,518 : worker.worker : DEBUG : Step 88913, finished rewards 7.70, envs finished 1
2026-01-17 13:24:48,558 : worker.worker : DEBUG : Step 88923, finished rewards 0.13, envs finished 1
2026-01-17 13:24:48,625 : agent.on_policy : DEBUG : Mean Losses: [7.245270751416683]
2026-01-17 13:24:48,638 : worker.worker : DEBUG : Step 88931, finished rewards 6.71, envs finished 1
2026-01-17 13:24:48,767 : worker.worker : DEBUG : Step 88954, finished rewards 8.47, envs finished 1
2026-01-17 13:24:48,892 : agent.on_policy : DEBUG : Mean Losses: [2.8779803216457367]
2026-01-17 13:24:49,093 : worker.worker : DEBUG : Step 88983, finished rewards 1.64, envs finished 1
2026-01-17 13:24:49,137 : worker.worker : DEBUG : Step 88985, finished rewards 30.43, envs finished 1
2026-01-17 13:24:49,254 : agent.on_policy : DEBUG : Mean Losses: [5.628594815731049]
2026-01-17 13:24:49,274 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:24:49,325 : worker.worker : DEBUG : Step 89005, finished rewards 14.79, envs finished 1
2026-01-17 13:24:49,407 : worker.worker : DEBUG : Step 89023, finished rewards 3.63, envs finished 1
2026-01-17 13:24:49,492 : agent.on_policy : DEBUG : Mean Losses: [5.6886780969798565]
2026-01-17 13:24:49,495 : worker.worker : DEBUG : Step 89024, finished rewards 24.20, envs finished 1
2026-01-17 13:24:49,546 : worker.worker : DEBUG : Step 89037, finished rewards 8.08, envs finished 1
2026-01-17 13:24:49,615 : worker.worker : DEBUG : Step 89044, finished rewards 26.61, envs finished 1
2026-01-17 13:24:49,842 : agent.on_policy : DEBUG : Mean Losses: [5.682958913967013]
2026-01-17 13:24:49,887 : worker.worker : DEBUG : Step 89066, finished rewards 30.25, envs finished 1
2026-01-17 13:24:50,131 : agent.on_policy : DEBUG : Mean Losses: [4.080378457903862]
2026-01-17 13:24:50,428 : agent.on_policy : DEBUG : Mean Losses: [3.5865093618631363]
2026-01-17 13:24:50,472 : worker.worker : DEBUG : Step 89129, finished rewards 23.51, envs finished 1
2026-01-17 13:24:50,502 : worker.worker : DEBUG : Step 89135, finished rewards 24.42, envs finished 1
2026-01-17 13:24:50,531 : worker.worker : DEBUG : Step 89140, finished rewards 5.79, envs finished 1
2026-01-17 13:24:50,544 : worker.worker : DEBUG : Step 89142, finished rewards 5.76, envs finished 1
2026-01-17 13:24:50,561 : worker.worker : DEBUG : Step 89143, finished rewards -16.26, envs finished 2
2026-01-17 13:24:50,689 : agent.on_policy : DEBUG : Mean Losses: [13.849173784255981]
2026-01-17 13:24:50,790 : worker.worker : DEBUG : Step 89166, finished rewards -97.68, envs finished 1
2026-01-17 13:24:50,974 : agent.on_policy : DEBUG : Mean Losses: [3.3229704620316625]
2026-01-17 13:24:50,998 : worker.worker : DEBUG : Step 89190, finished rewards 3.41, envs finished 1
2026-01-17 13:24:51,189 : agent.on_policy : DEBUG : Mean Losses: [2.9381646141409874]
2026-01-17 13:24:51,229 : worker.worker : DEBUG : Step 89226, finished rewards 30.15, envs finished 1
2026-01-17 13:24:51,241 : worker.worker : DEBUG : Step 89228, finished rewards 23.55, envs finished 1
2026-01-17 13:24:51,274 : worker.worker : DEBUG : Step 89235, finished rewards 21.17, envs finished 1
2026-01-17 13:24:51,279 : worker.worker : DEBUG : Step 89236, finished rewards 23.53, envs finished 1
2026-01-17 13:24:51,367 : agent.on_policy : DEBUG : Mean Losses: [11.557292103767395]
2026-01-17 13:24:51,412 : worker.worker : DEBUG : Step 89258, finished rewards 24.91, envs finished 1
2026-01-17 13:24:51,480 : worker.worker : DEBUG : Step 89263, finished rewards 8.00, envs finished 1
2026-01-17 13:24:51,621 : agent.on_policy : DEBUG : Mean Losses: [4.44574449211359]
2026-01-17 13:24:51,743 : worker.worker : DEBUG : Step 89307, finished rewards 5.48, envs finished 1
2026-01-17 13:24:51,750 : worker.worker : DEBUG : Step 89308, finished rewards -27.85, envs finished 1
2026-01-17 13:24:51,859 : agent.on_policy : DEBUG : Mean Losses: [4.202435255050659]
2026-01-17 13:24:51,943 : worker.worker : DEBUG : Step 89324, finished rewards 18.99, envs finished 1
2026-01-17 13:24:52,220 : agent.on_policy : DEBUG : Mean Losses: [3.784834761172533]
2026-01-17 13:24:52,246 : worker.worker : DEBUG : Step 89350, finished rewards 2.50, envs finished 1
2026-01-17 13:24:52,311 : worker.worker : DEBUG : Step 89363, finished rewards -3.01, envs finished 1
2026-01-17 13:24:52,343 : worker.worker : DEBUG : Step 89368, finished rewards -4.10, envs finished 1
2026-01-17 13:24:52,463 : agent.on_policy : DEBUG : Mean Losses: [6.834054917097092]
2026-01-17 13:24:52,466 : worker.worker : DEBUG : Step 89376, finished rewards 8.33, envs finished 1
2026-01-17 13:24:52,594 : worker.worker : DEBUG : Step 89397, finished rewards -3.87, envs finished 1
2026-01-17 13:24:52,619 : worker.worker : DEBUG : Step 89399, finished rewards 25.12, envs finished 1
2026-01-17 13:24:52,749 : agent.on_policy : DEBUG : Mean Losses: [5.2789739072322845]
2026-01-17 13:24:52,818 : worker.worker : DEBUG : Step 89416, finished rewards 24.60, envs finished 1
2026-01-17 13:24:52,933 : worker.worker : DEBUG : Step 89433, finished rewards -1.14, envs finished 1
2026-01-17 13:24:53,037 : agent.on_policy : DEBUG : Mean Losses: [4.184987973421812]
2026-01-17 13:24:53,062 : worker.worker : DEBUG : Step 89445, finished rewards 21.69, envs finished 1
2026-01-17 13:24:53,356 : agent.on_policy : DEBUG : Mean Losses: [2.7949400022625923]
2026-01-17 13:24:53,380 : worker.worker : DEBUG : Step 89478, finished rewards 5.10, envs finished 1
2026-01-17 13:24:53,414 : worker.worker : DEBUG : Step 89485, finished rewards 26.37, envs finished 1
2026-01-17 13:24:53,523 : agent.on_policy : DEBUG : Mean Losses: [6.120063669979572]
2026-01-17 13:24:53,589 : worker.worker : DEBUG : Step 89516, finished rewards -10.27, envs finished 1
2026-01-17 13:24:53,656 : worker.worker : DEBUG : Step 89531, finished rewards -8.56, envs finished 1
2026-01-17 13:24:53,751 : agent.on_policy : DEBUG : Mean Losses: [5.404586113989353]
2026-01-17 13:24:53,826 : worker.worker : DEBUG : Step 89550, finished rewards -6.53, envs finished 1
2026-01-17 13:24:53,835 : worker.worker : DEBUG : Step 89551, finished rewards -5.89, envs finished 2
2026-01-17 13:24:53,852 : worker.worker : DEBUG : Step 89553, finished rewards 11.79, envs finished 1
2026-01-17 13:24:53,987 : agent.on_policy : DEBUG : Mean Losses: [8.726104035973549]
2026-01-17 13:24:54,032 : worker.worker : DEBUG : Step 89579, finished rewards 17.76, envs finished 1
2026-01-17 13:24:54,104 : worker.worker : DEBUG : Step 89598, finished rewards 11.44, envs finished 1
2026-01-17 13:24:54,188 : agent.on_policy : DEBUG : Mean Losses: [4.345898458734155]
2026-01-17 13:24:54,318 : worker.worker : DEBUG : Step 89626, finished rewards 11.22, envs finished 1
2026-01-17 13:24:54,329 : worker.worker : DEBUG : Step 89628, finished rewards 21.83, envs finished 1
2026-01-17 13:24:54,449 : agent.on_policy : DEBUG : Mean Losses: [5.500170025974512]
2026-01-17 13:24:54,460 : worker.worker : DEBUG : Step 89633, finished rewards 30.85, envs finished 1
2026-01-17 13:24:54,501 : worker.worker : DEBUG : Step 89636, finished rewards 30.58, envs finished 1
2026-01-17 13:24:54,688 : agent.on_policy : DEBUG : Mean Losses: [3.2774725761264563]
2026-01-17 13:24:54,699 : worker.worker : DEBUG : Step 89665, finished rewards 7.79, envs finished 1
2026-01-17 13:24:54,762 : worker.worker : DEBUG : Step 89681, finished rewards -1.82, envs finished 1
2026-01-17 13:24:54,919 : agent.on_policy : DEBUG : Mean Losses: [3.2926803193986416]
2026-01-17 13:24:54,968 : worker.worker : DEBUG : Step 89710, finished rewards -3.25, envs finished 1
2026-01-17 13:24:55,020 : worker.worker : DEBUG : Step 89723, finished rewards 25.09, envs finished 1
2026-01-17 13:24:55,081 : agent.on_policy : DEBUG : Mean Losses: [6.525937553495169]
2026-01-17 13:24:55,165 : worker.worker : DEBUG : Step 89742, finished rewards -8.14, envs finished 1
2026-01-17 13:24:55,193 : worker.worker : DEBUG : Step 89748, finished rewards 1.71, envs finished 1
2026-01-17 13:24:55,327 : agent.on_policy : DEBUG : Mean Losses: [5.876825302839279]
2026-01-17 13:24:55,339 : worker.worker : DEBUG : Step 89761, finished rewards 32.05, envs finished 1
2026-01-17 13:24:55,421 : worker.worker : DEBUG : Step 89770, finished rewards -14.18, envs finished 1
2026-01-17 13:24:55,615 : agent.on_policy : DEBUG : Mean Losses: [6.012749455869198]
2026-01-17 13:24:55,621 : worker.worker : DEBUG : Step 89793, finished rewards -10.47, envs finished 1
2026-01-17 13:24:55,627 : worker.worker : DEBUG : Step 89794, finished rewards 29.69, envs finished 1
2026-01-17 13:24:55,730 : worker.worker : DEBUG : Step 89823, finished rewards 36.62, envs finished 1
2026-01-17 13:24:55,817 : agent.on_policy : DEBUG : Mean Losses: [5.977948362007737]
2026-01-17 13:24:55,905 : worker.worker : DEBUG : Step 89836, finished rewards 10.19, envs finished 1
2026-01-17 13:24:55,967 : worker.worker : DEBUG : Step 89843, finished rewards -39.79, envs finished 1
2026-01-17 13:24:56,050 : worker.worker : DEBUG : Step 89848, finished rewards 13.18, envs finished 1
2026-01-17 13:24:56,225 : agent.on_policy : DEBUG : Mean Losses: [7.716627813875675]
2026-01-17 13:24:56,265 : worker.worker : DEBUG : Step 89862, finished rewards 15.83, envs finished 1
2026-01-17 13:24:56,385 : worker.worker : DEBUG : Step 89887, finished rewards 23.67, envs finished 1
2026-01-17 13:24:56,482 : agent.on_policy : DEBUG : Mean Losses: [4.793584832921624]
2026-01-17 13:24:56,514 : worker.worker : DEBUG : Step 89895, finished rewards 17.35, envs finished 1
2026-01-17 13:24:56,696 : agent.on_policy : DEBUG : Mean Losses: [2.6657336242496967]
2026-01-17 13:24:56,700 : worker.worker : DEBUG : Step 89920, finished rewards -8.79, envs finished 1
2026-01-17 13:24:56,728 : worker.worker : DEBUG : Step 89926, finished rewards 30.81, envs finished 1
2026-01-17 13:24:56,793 : worker.worker : DEBUG : Step 89944, finished rewards 3.43, envs finished 1
2026-01-17 13:24:56,900 : agent.on_policy : DEBUG : Mean Losses: [6.306423483416438]
2026-01-17 13:24:56,950 : worker.worker : DEBUG : Step 89965, finished rewards 6.01, envs finished 1
2026-01-17 13:24:57,056 : agent.on_policy : DEBUG : Mean Losses: [3.816045120358467]
2026-01-17 13:24:57,062 : worker.worker : DEBUG : Step 89985, finished rewards 3.25, envs finished 1
2026-01-17 13:24:57,080 : worker.worker : DEBUG : Step 89989, finished rewards 41.82, envs finished 1
2026-01-17 13:24:57,147 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:24:57,164 : worker.worker : INFO : Step 90000, Avg Reward 8.7569, Max Reward 41.8151, Loss [5.64871466]
2026-01-17 13:24:57,196 : worker.worker : DEBUG : Step 90008, finished rewards 10.66, envs finished 1
2026-01-17 13:24:57,200 : worker.worker : DEBUG : Step 90009, finished rewards -31.83, envs finished 1
2026-01-17 13:24:57,221 : worker.worker : DEBUG : Step 90013, finished rewards 41.93, envs finished 1
2026-01-17 13:24:57,317 : agent.on_policy : DEBUG : Mean Losses: [10.163688734173775]
2026-01-17 13:24:57,337 : worker.worker : DEBUG : Step 90021, finished rewards -8.03, envs finished 1
2026-01-17 13:24:57,517 : agent.on_policy : DEBUG : Mean Losses: [4.328681718558073]
2026-01-17 13:24:57,554 : worker.worker : DEBUG : Step 90059, finished rewards -3.41, envs finished 1
2026-01-17 13:24:57,671 : agent.on_policy : DEBUG : Mean Losses: [3.8610187135636806]
2026-01-17 13:24:57,679 : worker.worker : DEBUG : Step 90082, finished rewards 12.64, envs finished 1
2026-01-17 13:24:57,789 : worker.worker : DEBUG : Step 90097, finished rewards 12.19, envs finished 1
2026-01-17 13:24:57,862 : worker.worker : DEBUG : Step 90106, finished rewards 23.05, envs finished 1
2026-01-17 13:24:57,884 : worker.worker : DEBUG : Step 90111, finished rewards 17.39, envs finished 1
2026-01-17 13:24:57,996 : agent.on_policy : DEBUG : Mean Losses: [8.684818420559168]
2026-01-17 13:24:58,031 : worker.worker : DEBUG : Step 90118, finished rewards 12.26, envs finished 1
2026-01-17 13:24:58,080 : worker.worker : DEBUG : Step 90124, finished rewards 15.51, envs finished 1
2026-01-17 13:24:58,101 : worker.worker : DEBUG : Step 90128, finished rewards -15.75, envs finished 1
2026-01-17 13:24:58,207 : agent.on_policy : DEBUG : Mean Losses: [5.104650344699621]
2026-01-17 13:24:58,407 : agent.on_policy : DEBUG : Mean Losses: [1.0878107361495495]
2026-01-17 13:24:58,416 : worker.worker : DEBUG : Step 90179, finished rewards 10.68, envs finished 1
2026-01-17 13:24:58,647 : agent.on_policy : DEBUG : Mean Losses: [2.7425698563456535]
2026-01-17 13:24:58,675 : worker.worker : DEBUG : Step 90215, finished rewards 20.09, envs finished 1
2026-01-17 13:24:58,682 : worker.worker : DEBUG : Step 90217, finished rewards -3.86, envs finished 1
2026-01-17 13:24:58,714 : worker.worker : DEBUG : Step 90224, finished rewards 16.92, envs finished 1
2026-01-17 13:24:58,732 : worker.worker : DEBUG : Step 90228, finished rewards 9.35, envs finished 2
2026-01-17 13:24:58,769 : worker.worker : DEBUG : Step 90237, finished rewards -7.45, envs finished 1
2026-01-17 13:24:58,829 : agent.on_policy : DEBUG : Mean Losses: [11.726574301719666]
2026-01-17 13:24:58,885 : worker.worker : DEBUG : Step 90256, finished rewards -11.48, envs finished 1
2026-01-17 13:24:58,921 : worker.worker : DEBUG : Step 90263, finished rewards 29.58, envs finished 1
2026-01-17 13:24:59,136 : agent.on_policy : DEBUG : Mean Losses: [5.300581831485033]
2026-01-17 13:24:59,499 : agent.on_policy : DEBUG : Mean Losses: [0.9552976451814175]
2026-01-17 13:24:59,528 : worker.worker : DEBUG : Step 90313, finished rewards 19.65, envs finished 1
2026-01-17 13:24:59,640 : agent.on_policy : DEBUG : Mean Losses: [4.48230803757906]
2026-01-17 13:24:59,644 : worker.worker : DEBUG : Step 90337, finished rewards 17.91, envs finished 1
2026-01-17 13:24:59,699 : worker.worker : DEBUG : Step 90346, finished rewards 30.85, envs finished 1
2026-01-17 13:24:59,737 : worker.worker : DEBUG : Step 90351, finished rewards -5.71, envs finished 1
2026-01-17 13:24:59,768 : worker.worker : DEBUG : Step 90358, finished rewards -0.65, envs finished 1
2026-01-17 13:24:59,919 : agent.on_policy : DEBUG : Mean Losses: [9.063919454813004]
2026-01-17 13:24:59,954 : worker.worker : DEBUG : Step 90379, finished rewards -19.60, envs finished 1
2026-01-17 13:24:59,957 : worker.worker : DEBUG : Step 90380, finished rewards -21.04, envs finished 1
2026-01-17 13:25:00,129 : agent.on_policy : DEBUG : Mean Losses: [4.507637524977326]
2026-01-17 13:25:00,157 : worker.worker : DEBUG : Step 90406, finished rewards 24.24, envs finished 1
2026-01-17 13:25:00,172 : worker.worker : DEBUG : Step 90410, finished rewards -12.43, envs finished 1
2026-01-17 13:25:00,287 : agent.on_policy : DEBUG : Mean Losses: [3.834308620542288]
2026-01-17 13:25:00,301 : worker.worker : DEBUG : Step 90435, finished rewards 30.10, envs finished 1
2026-01-17 13:25:00,497 : agent.on_policy : DEBUG : Mean Losses: [3.1447068974375725]
2026-01-17 13:25:00,539 : worker.worker : DEBUG : Step 90474, finished rewards -7.44, envs finished 1
2026-01-17 13:25:00,547 : worker.worker : DEBUG : Step 90476, finished rewards 3.43, envs finished 2
2026-01-17 13:25:00,590 : worker.worker : DEBUG : Step 90487, finished rewards 10.71, envs finished 1
2026-01-17 13:25:00,598 : worker.worker : DEBUG : Step 90489, finished rewards 30.35, envs finished 1
2026-01-17 13:25:00,621 : worker.worker : DEBUG : Step 90494, finished rewards 29.90, envs finished 1
2026-01-17 13:25:00,679 : agent.on_policy : DEBUG : Mean Losses: [14.244077295064926]
2026-01-17 13:25:00,875 : agent.on_policy : DEBUG : Mean Losses: [1.0280339233577251]
2026-01-17 13:25:00,941 : worker.worker : DEBUG : Step 90545, finished rewards 10.85, envs finished 1
2026-01-17 13:25:01,082 : agent.on_policy : DEBUG : Mean Losses: [3.708804562687874]
2026-01-17 13:25:01,130 : worker.worker : DEBUG : Step 90576, finished rewards 18.42, envs finished 1
2026-01-17 13:25:01,154 : worker.worker : DEBUG : Step 90583, finished rewards 12.07, envs finished 1
2026-01-17 13:25:01,165 : worker.worker : DEBUG : Step 90586, finished rewards -37.68, envs finished 1
2026-01-17 13:25:01,179 : worker.worker : DEBUG : Step 90589, finished rewards 17.46, envs finished 1
2026-01-17 13:25:01,240 : agent.on_policy : DEBUG : Mean Losses: [11.436541691422462]
2026-01-17 13:25:01,249 : worker.worker : DEBUG : Step 90594, finished rewards 5.10, envs finished 1
2026-01-17 13:25:01,311 : worker.worker : DEBUG : Step 90611, finished rewards 5.59, envs finished 1
2026-01-17 13:25:01,408 : worker.worker : DEBUG : Step 90622, finished rewards -6.15, envs finished 1
2026-01-17 13:25:01,508 : agent.on_policy : DEBUG : Mean Losses: [5.825424216687679]
2026-01-17 13:25:01,637 : worker.worker : DEBUG : Step 90653, finished rewards 11.79, envs finished 1
2026-01-17 13:25:01,737 : agent.on_policy : DEBUG : Mean Losses: [2.836496762931347]
2026-01-17 13:25:01,789 : worker.worker : DEBUG : Step 90667, finished rewards 29.29, envs finished 1
2026-01-17 13:25:01,978 : agent.on_policy : DEBUG : Mean Losses: [4.673385567963123]
2026-01-17 13:25:02,037 : worker.worker : DEBUG : Step 90702, finished rewards 0.04, envs finished 1
2026-01-17 13:25:02,085 : worker.worker : DEBUG : Step 90714, finished rewards 5.68, envs finished 1
2026-01-17 13:25:02,108 : worker.worker : DEBUG : Step 90718, finished rewards 11.65, envs finished 1
2026-01-17 13:25:02,233 : agent.on_policy : DEBUG : Mean Losses: [8.245210841298103]
2026-01-17 13:25:02,293 : worker.worker : DEBUG : Step 90727, finished rewards -13.32, envs finished 1
2026-01-17 13:25:02,375 : worker.worker : DEBUG : Step 90733, finished rewards -11.29, envs finished 1
2026-01-17 13:25:02,630 : agent.on_policy : DEBUG : Mean Losses: [4.620129533112049]
2026-01-17 13:25:02,661 : worker.worker : DEBUG : Step 90760, finished rewards 1.15, envs finished 1
2026-01-17 13:25:02,743 : worker.worker : DEBUG : Step 90781, finished rewards -3.92, envs finished 1
2026-01-17 13:25:02,801 : agent.on_policy : DEBUG : Mean Losses: [4.189685489982367]
2026-01-17 13:25:02,952 : worker.worker : DEBUG : Step 90807, finished rewards 24.17, envs finished 1
2026-01-17 13:25:03,047 : agent.on_policy : DEBUG : Mean Losses: [4.598596468567848]
2026-01-17 13:25:03,048 : worker.worker : DEBUG : Step 90816, finished rewards 19.65, envs finished 1
2026-01-17 13:25:03,075 : worker.worker : DEBUG : Step 90822, finished rewards -14.94, envs finished 1
2026-01-17 13:25:03,099 : worker.worker : DEBUG : Step 90826, finished rewards 18.39, envs finished 1
2026-01-17 13:25:03,127 : worker.worker : DEBUG : Step 90827, finished rewards -2.43, envs finished 1
2026-01-17 13:25:03,157 : worker.worker : DEBUG : Step 90831, finished rewards 19.54, envs finished 1
2026-01-17 13:25:03,276 : agent.on_policy : DEBUG : Mean Losses: [8.906654000282288]
2026-01-17 13:25:03,381 : worker.worker : DEBUG : Step 90864, finished rewards 30.65, envs finished 1
2026-01-17 13:25:03,525 : agent.on_policy : DEBUG : Mean Losses: [3.9984462410211563]
2026-01-17 13:25:03,580 : worker.worker : DEBUG : Step 90895, finished rewards -9.81, envs finished 1
2026-01-17 13:25:03,594 : worker.worker : DEBUG : Step 90899, finished rewards 30.85, envs finished 1
2026-01-17 13:25:03,640 : worker.worker : DEBUG : Step 90910, finished rewards 30.86, envs finished 1
2026-01-17 13:25:03,741 : agent.on_policy : DEBUG : Mean Losses: [10.143089033663273]
2026-01-17 13:25:03,773 : worker.worker : DEBUG : Step 90922, finished rewards 24.59, envs finished 1
2026-01-17 13:25:03,789 : worker.worker : DEBUG : Step 90924, finished rewards 3.92, envs finished 1
2026-01-17 13:25:03,848 : worker.worker : DEBUG : Step 90931, finished rewards 11.54, envs finished 1
2026-01-17 13:25:03,937 : agent.on_policy : DEBUG : Mean Losses: [7.017043307423592]
2026-01-17 13:25:03,952 : worker.worker : DEBUG : Step 90948, finished rewards 3.52, envs finished 1
2026-01-17 13:25:04,131 : agent.on_policy : DEBUG : Mean Losses: [2.5599577501416206]
2026-01-17 13:25:04,199 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:25:04,264 : agent.on_policy : DEBUG : Mean Losses: [3.864574611186981]
2026-01-17 13:25:04,270 : worker.worker : DEBUG : Step 91009, finished rewards -7.26, envs finished 1
2026-01-17 13:25:04,356 : worker.worker : DEBUG : Step 91025, finished rewards 23.53, envs finished 1
2026-01-17 13:25:04,370 : worker.worker : DEBUG : Step 91029, finished rewards 4.13, envs finished 1
2026-01-17 13:25:04,499 : agent.on_policy : DEBUG : Mean Losses: [7.8269747495651245]
2026-01-17 13:25:04,502 : worker.worker : DEBUG : Step 91040, finished rewards -7.75, envs finished 1
2026-01-17 13:25:04,536 : worker.worker : DEBUG : Step 91044, finished rewards 0.84, envs finished 1
2026-01-17 13:25:04,557 : worker.worker : DEBUG : Step 91046, finished rewards -2.34, envs finished 1
2026-01-17 13:25:04,596 : worker.worker : DEBUG : Step 91053, finished rewards -0.83, envs finished 1
2026-01-17 13:25:04,612 : worker.worker : DEBUG : Step 91056, finished rewards 12.37, envs finished 1
2026-01-17 13:25:04,753 : agent.on_policy : DEBUG : Mean Losses: [6.585048206150532]
2026-01-17 13:25:05,031 : agent.on_policy : DEBUG : Mean Losses: [1.5894222483038902]
2026-01-17 13:25:05,110 : worker.worker : DEBUG : Step 91124, finished rewards 23.95, envs finished 1
2026-01-17 13:25:05,153 : worker.worker : DEBUG : Step 91133, finished rewards 11.05, envs finished 1
2026-01-17 13:25:05,259 : agent.on_policy : DEBUG : Mean Losses: [7.008371129631996]
2026-01-17 13:25:05,325 : worker.worker : DEBUG : Step 91144, finished rewards 25.82, envs finished 1
2026-01-17 13:25:05,361 : worker.worker : DEBUG : Step 91149, finished rewards -10.30, envs finished 1
2026-01-17 13:25:05,451 : worker.worker : DEBUG : Step 91161, finished rewards 5.91, envs finished 1
2026-01-17 13:25:05,638 : agent.on_policy : DEBUG : Mean Losses: [7.8092776872217655]
2026-01-17 13:25:05,651 : worker.worker : DEBUG : Step 91170, finished rewards 8.08, envs finished 1
2026-01-17 13:25:05,711 : worker.worker : DEBUG : Step 91176, finished rewards -9.79, envs finished 1
2026-01-17 13:25:05,792 : worker.worker : DEBUG : Step 91188, finished rewards -7.59, envs finished 1
2026-01-17 13:25:05,993 : agent.on_policy : DEBUG : Mean Losses: [5.769906632602215]
2026-01-17 13:25:06,055 : worker.worker : DEBUG : Step 91213, finished rewards 42.01, envs finished 1
2026-01-17 13:25:06,233 : agent.on_policy : DEBUG : Mean Losses: [4.227186772972345]
2026-01-17 13:25:06,238 : worker.worker : DEBUG : Step 91233, finished rewards 14.39, envs finished 1
2026-01-17 13:25:06,448 : agent.on_policy : DEBUG : Mean Losses: [3.2459700778126717]
2026-01-17 13:25:06,477 : worker.worker : DEBUG : Step 91270, finished rewards 12.55, envs finished 1
2026-01-17 13:25:06,511 : worker.worker : DEBUG : Step 91277, finished rewards -12.81, envs finished 1
2026-01-17 13:25:06,717 : agent.on_policy : DEBUG : Mean Losses: [4.92049677670002]
2026-01-17 13:25:06,719 : worker.worker : DEBUG : Step 91296, finished rewards -5.93, envs finished 1
2026-01-17 13:25:06,757 : worker.worker : DEBUG : Step 91302, finished rewards -1.49, envs finished 1
2026-01-17 13:25:06,975 : agent.on_policy : DEBUG : Mean Losses: [3.777149435132742]
2026-01-17 13:25:06,982 : worker.worker : DEBUG : Step 91329, finished rewards -7.86, envs finished 1
2026-01-17 13:25:06,995 : worker.worker : DEBUG : Step 91331, finished rewards -22.28, envs finished 1
2026-01-17 13:25:07,068 : worker.worker : DEBUG : Step 91345, finished rewards 9.77, envs finished 1
2026-01-17 13:25:07,226 : agent.on_policy : DEBUG : Mean Losses: [5.959970861673355]
2026-01-17 13:25:07,255 : worker.worker : DEBUG : Step 91368, finished rewards 25.66, envs finished 1
2026-01-17 13:25:07,326 : worker.worker : DEBUG : Step 91383, finished rewards -32.29, envs finished 1
2026-01-17 13:25:07,523 : agent.on_policy : DEBUG : Mean Losses: [5.263668555766344]
2026-01-17 13:25:07,531 : worker.worker : DEBUG : Step 91392, finished rewards 1.43, envs finished 1
2026-01-17 13:25:07,549 : worker.worker : DEBUG : Step 91393, finished rewards 22.20, envs finished 1
2026-01-17 13:25:07,606 : worker.worker : DEBUG : Step 91400, finished rewards 18.94, envs finished 1
2026-01-17 13:25:07,665 : worker.worker : DEBUG : Step 91406, finished rewards 36.77, envs finished 1
2026-01-17 13:25:07,865 : agent.on_policy : DEBUG : Mean Losses: [5.900259571149945]
2026-01-17 13:25:07,934 : worker.worker : DEBUG : Step 91439, finished rewards 23.04, envs finished 1
2026-01-17 13:25:08,026 : worker.worker : DEBUG : Step 91454, finished rewards 28.29, envs finished 1
2026-01-17 13:25:08,119 : agent.on_policy : DEBUG : Mean Losses: [6.419655993580818]
2026-01-17 13:25:08,147 : worker.worker : DEBUG : Step 91463, finished rewards 1.12, envs finished 1
2026-01-17 13:25:08,215 : worker.worker : DEBUG : Step 91472, finished rewards 26.38, envs finished 1
2026-01-17 13:25:08,377 : agent.on_policy : DEBUG : Mean Losses: [5.21800097823143]
2026-01-17 13:25:08,382 : worker.worker : DEBUG : Step 91489, finished rewards 25.44, envs finished 1
2026-01-17 13:25:08,399 : worker.worker : DEBUG : Step 91493, finished rewards 18.61, envs finished 1
2026-01-17 13:25:08,535 : agent.on_policy : DEBUG : Mean Losses: [3.9252748414874077]
2026-01-17 13:25:08,554 : worker.worker : DEBUG : Step 91522, finished rewards -1.97, envs finished 1
2026-01-17 13:25:08,655 : worker.worker : DEBUG : Step 91539, finished rewards 18.92, envs finished 1
2026-01-17 13:25:08,681 : worker.worker : DEBUG : Step 91544, finished rewards 26.76, envs finished 1
2026-01-17 13:25:08,789 : agent.on_policy : DEBUG : Mean Losses: [7.163645997643471]
2026-01-17 13:25:08,824 : worker.worker : DEBUG : Step 91560, finished rewards -22.35, envs finished 1
2026-01-17 13:25:08,931 : worker.worker : DEBUG : Step 91581, finished rewards 9.54, envs finished 1
2026-01-17 13:25:09,035 : agent.on_policy : DEBUG : Mean Losses: [4.797520089894533]
2026-01-17 13:25:09,037 : worker.worker : DEBUG : Step 91584, finished rewards 26.75, envs finished 1
2026-01-17 13:25:09,080 : worker.worker : DEBUG : Step 91593, finished rewards 11.94, envs finished 1
2026-01-17 13:25:09,208 : worker.worker : DEBUG : Step 91609, finished rewards -8.53, envs finished 1
2026-01-17 13:25:09,360 : agent.on_policy : DEBUG : Mean Losses: [5.336011003702879]
2026-01-17 13:25:09,549 : worker.worker : DEBUG : Step 91639, finished rewards 5.80, envs finished 1
2026-01-17 13:25:09,809 : agent.on_policy : DEBUG : Mean Losses: [3.4213374145329]
2026-01-17 13:25:09,855 : worker.worker : DEBUG : Step 91660, finished rewards 4.69, envs finished 1
2026-01-17 13:25:09,870 : worker.worker : DEBUG : Step 91663, finished rewards 4.18, envs finished 1
2026-01-17 13:25:09,976 : agent.on_policy : DEBUG : Mean Losses: [5.669638365507126]
2026-01-17 13:25:09,984 : worker.worker : DEBUG : Step 91682, finished rewards 21.81, envs finished 1
2026-01-17 13:25:10,055 : worker.worker : DEBUG : Step 91691, finished rewards -1.26, envs finished 1
2026-01-17 13:25:10,079 : worker.worker : DEBUG : Step 91695, finished rewards 17.18, envs finished 1
2026-01-17 13:25:10,097 : worker.worker : DEBUG : Step 91698, finished rewards 25.37, envs finished 1
2026-01-17 13:25:10,297 : agent.on_policy : DEBUG : Mean Losses: [7.655182838439941]
2026-01-17 13:25:10,316 : worker.worker : DEBUG : Step 91717, finished rewards -5.89, envs finished 1
2026-01-17 13:25:10,362 : worker.worker : DEBUG : Step 91727, finished rewards 26.26, envs finished 1
2026-01-17 13:25:10,465 : agent.on_policy : DEBUG : Mean Losses: [4.502751812338829]
2026-01-17 13:25:10,509 : worker.worker : DEBUG : Step 91753, finished rewards 25.38, envs finished 1
2026-01-17 13:25:10,740 : agent.on_policy : DEBUG : Mean Losses: [3.4534990042448044]
2026-01-17 13:25:10,742 : worker.worker : DEBUG : Step 91776, finished rewards 22.30, envs finished 1
2026-01-17 13:25:10,789 : worker.worker : DEBUG : Step 91789, finished rewards 1.10, envs finished 1
2026-01-17 13:25:10,807 : worker.worker : DEBUG : Step 91793, finished rewards 20.05, envs finished 1
2026-01-17 13:25:10,526 : worker.worker : DEBUG : Step 91806, finished rewards 27.50, envs finished 1
2026-01-17 13:25:10,164 : agent.on_policy : DEBUG : Mean Losses: [8.360835835337639]
2026-01-17 13:25:10,220 : worker.worker : DEBUG : Step 91825, finished rewards -9.53, envs finished 1
2026-01-17 13:25:10,362 : agent.on_policy : DEBUG : Mean Losses: [3.3360679522156715]
2026-01-17 13:25:10,406 : worker.worker : DEBUG : Step 91853, finished rewards 17.77, envs finished 1
2026-01-17 13:25:10,438 : worker.worker : DEBUG : Step 91861, finished rewards -27.45, envs finished 1
2026-01-17 13:25:10,467 : worker.worker : DEBUG : Step 91866, finished rewards -1.53, envs finished 1
2026-01-17 13:25:10,552 : agent.on_policy : DEBUG : Mean Losses: [6.783143192529678]
2026-01-17 13:25:10,561 : worker.worker : DEBUG : Step 91874, finished rewards 28.24, envs finished 1
2026-01-17 13:25:10,661 : worker.worker : DEBUG : Step 91889, finished rewards 9.14, envs finished 1
2026-01-17 13:25:10,667 : worker.worker : DEBUG : Step 91890, finished rewards 19.86, envs finished 1
2026-01-17 13:25:10,810 : agent.on_policy : DEBUG : Mean Losses: [5.944454465061426]
2026-01-17 13:25:10,876 : worker.worker : DEBUG : Step 91925, finished rewards 3.30, envs finished 1
2026-01-17 13:25:11,025 : agent.on_policy : DEBUG : Mean Losses: [2.947866663336754]
2026-01-17 13:25:11,030 : worker.worker : DEBUG : Step 91937, finished rewards 9.93, envs finished 1
2026-01-17 13:25:11,158 : agent.on_policy : DEBUG : Mean Losses: [3.5618520975112915]
2026-01-17 13:25:11,370 : worker.worker : DEBUG : Step 91993, finished rewards -4.74, envs finished 1
2026-01-17 13:25:11,390 : worker.worker : DEBUG : Step 91996, finished rewards -1.62, envs finished 2
2026-01-17 13:25:11,401 : worker.worker : DEBUG : Step 91997, finished rewards 12.05, envs finished 1
2026-01-17 13:25:11,408 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:25:11,481 : agent.on_policy : DEBUG : Mean Losses: [12.079329445958138]
2026-01-17 13:25:11,594 : worker.worker : DEBUG : Step 92020, finished rewards -23.73, envs finished 1
2026-01-17 13:25:11,621 : worker.worker : DEBUG : Step 92025, finished rewards 18.97, envs finished 1
2026-01-17 13:25:11,729 : agent.on_policy : DEBUG : Mean Losses: [6.679389236494899]
2026-01-17 13:25:11,731 : worker.worker : DEBUG : Step 92032, finished rewards 22.20, envs finished 1
2026-01-17 13:25:11,898 : worker.worker : DEBUG : Step 92056, finished rewards -17.17, envs finished 1
2026-01-17 13:25:12,009 : agent.on_policy : DEBUG : Mean Losses: [3.4525559321045876]
2026-01-17 13:25:12,211 : agent.on_policy : DEBUG : Mean Losses: [2.302123762667179]
2026-01-17 13:25:12,217 : worker.worker : DEBUG : Step 92097, finished rewards 17.69, envs finished 1
2026-01-17 13:25:12,238 : worker.worker : DEBUG : Step 92101, finished rewards 15.11, envs finished 1
2026-01-17 13:25:12,255 : worker.worker : DEBUG : Step 92104, finished rewards 29.50, envs finished 1
2026-01-17 13:25:12,459 : agent.on_policy : DEBUG : Mean Losses: [7.097805581055582]
2026-01-17 13:25:12,469 : worker.worker : DEBUG : Step 92130, finished rewards -3.34, envs finished 1
2026-01-17 13:25:12,506 : worker.worker : DEBUG : Step 92138, finished rewards -11.43, envs finished 1
2026-01-17 13:25:12,584 : worker.worker : DEBUG : Step 92156, finished rewards 16.92, envs finished 1
2026-01-17 13:25:12,702 : agent.on_policy : DEBUG : Mean Losses: [7.28907272964716]
2026-01-17 13:25:12,747 : worker.worker : DEBUG : Step 92169, finished rewards -12.07, envs finished 1
2026-01-17 13:25:12,853 : worker.worker : DEBUG : Step 92189, finished rewards 23.94, envs finished 1
2026-01-17 13:25:12,997 : agent.on_policy : DEBUG : Mean Losses: [7.849499333649874]
2026-01-17 13:25:13,006 : worker.worker : DEBUG : Step 92192, finished rewards 26.00, envs finished 1
2026-01-17 13:25:13,015 : worker.worker : DEBUG : Step 92193, finished rewards -31.79, envs finished 1
2026-01-17 13:25:13,076 : worker.worker : DEBUG : Step 92202, finished rewards 20.32, envs finished 1
2026-01-17 13:25:13,274 : agent.on_policy : DEBUG : Mean Losses: [3.5232534538954496]
2026-01-17 13:25:13,369 : worker.worker : DEBUG : Step 92246, finished rewards 24.47, envs finished 1
2026-01-17 13:25:13,522 : agent.on_policy : DEBUG : Mean Losses: [4.426289461553097]
2026-01-17 13:25:13,569 : worker.worker : DEBUG : Step 92269, finished rewards -11.11, envs finished 1
2026-01-17 13:25:13,598 : worker.worker : DEBUG : Step 92277, finished rewards 36.78, envs finished 1
2026-01-17 13:25:13,607 : worker.worker : DEBUG : Step 92279, finished rewards 27.59, envs finished 1
2026-01-17 13:25:13,643 : worker.worker : DEBUG : Step 92287, finished rewards 19.91, envs finished 1
2026-01-17 13:25:13,701 : agent.on_policy : DEBUG : Mean Losses: [14.561156839132309]
2026-01-17 13:25:13,775 : worker.worker : DEBUG : Step 92308, finished rewards 5.86, envs finished 1
2026-01-17 13:25:13,839 : worker.worker : DEBUG : Step 92315, finished rewards -8.79, envs finished 1
2026-01-17 13:25:13,959 : agent.on_policy : DEBUG : Mean Losses: [4.887189876288176]
2026-01-17 13:25:13,962 : worker.worker : DEBUG : Step 92320, finished rewards -16.63, envs finished 1
2026-01-17 13:25:14,164 : agent.on_policy : DEBUG : Mean Losses: [1.1358177680522203]
2026-01-17 13:25:14,182 : worker.worker : DEBUG : Step 92355, finished rewards 11.61, envs finished 1
2026-01-17 13:25:14,216 : worker.worker : DEBUG : Step 92363, finished rewards 29.98, envs finished 1
2026-01-17 13:25:14,264 : worker.worker : DEBUG : Step 92376, finished rewards 27.94, envs finished 1
2026-01-17 13:25:14,339 : agent.on_policy : DEBUG : Mean Losses: [7.4114977568387985]
2026-01-17 13:25:14,363 : worker.worker : DEBUG : Step 92389, finished rewards 9.33, envs finished 1
2026-01-17 13:25:14,441 : worker.worker : DEBUG : Step 92402, finished rewards 23.17, envs finished 1
2026-01-17 13:25:14,469 : worker.worker : DEBUG : Step 92407, finished rewards 24.90, envs finished 1
2026-01-17 13:25:14,477 : worker.worker : DEBUG : Step 92408, finished rewards 3.27, envs finished 1
2026-01-17 13:25:14,592 : agent.on_policy : DEBUG : Mean Losses: [7.860649712383747]
2026-01-17 13:25:14,611 : worker.worker : DEBUG : Step 92421, finished rewards 17.78, envs finished 1
2026-01-17 13:25:14,813 : agent.on_policy : DEBUG : Mean Losses: [2.303916497156024]
2026-01-17 13:25:14,904 : worker.worker : DEBUG : Step 92470, finished rewards 13.91, envs finished 1
2026-01-17 13:25:14,951 : worker.worker : DEBUG : Step 92474, finished rewards 5.14, envs finished 1
2026-01-17 13:25:15,081 : agent.on_policy : DEBUG : Mean Losses: [5.82076583057642]
2026-01-17 13:25:15,141 : worker.worker : DEBUG : Step 92487, finished rewards 9.98, envs finished 1
2026-01-17 13:25:15,197 : worker.worker : DEBUG : Step 92498, finished rewards 11.13, envs finished 1
2026-01-17 13:25:15,220 : worker.worker : DEBUG : Step 92503, finished rewards 20.89, envs finished 1
2026-01-17 13:25:15,352 : agent.on_policy : DEBUG : Mean Losses: [6.95809406042099]
2026-01-17 13:25:15,424 : worker.worker : DEBUG : Step 92525, finished rewards 8.86, envs finished 1
2026-01-17 13:25:15,593 : worker.worker : DEBUG : Step 92543, finished rewards 4.73, envs finished 1
2026-01-17 13:25:15,688 : agent.on_policy : DEBUG : Mean Losses: [3.2923490330576897]
2026-01-17 13:25:15,787 : worker.worker : DEBUG : Step 92565, finished rewards -15.60, envs finished 1
2026-01-17 13:25:15,909 : agent.on_policy : DEBUG : Mean Losses: [3.8977746330201626]
2026-01-17 13:25:15,921 : worker.worker : DEBUG : Step 92579, finished rewards 18.08, envs finished 2
2026-01-17 13:25:15,980 : worker.worker : DEBUG : Step 92587, finished rewards 30.03, envs finished 1
2026-01-17 13:25:16,003 : worker.worker : DEBUG : Step 92590, finished rewards 23.49, envs finished 1
2026-01-17 13:25:16,017 : worker.worker : DEBUG : Step 92592, finished rewards 7.02, envs finished 1
2026-01-17 13:25:16,181 : agent.on_policy : DEBUG : Mean Losses: [8.112685667350888]
2026-01-17 13:25:16,319 : agent.on_policy : DEBUG : Mean Losses: [1.591493010520935]
2026-01-17 13:25:16,365 : worker.worker : DEBUG : Step 92645, finished rewards 6.18, envs finished 1
2026-01-17 13:25:16,425 : worker.worker : DEBUG : Step 92661, finished rewards 31.31, envs finished 1
2026-01-17 13:25:16,530 : agent.on_policy : DEBUG : Mean Losses: [6.887096613645554]
2026-01-17 13:25:16,589 : worker.worker : DEBUG : Step 92682, finished rewards 22.38, envs finished 1
2026-01-17 13:25:16,595 : worker.worker : DEBUG : Step 92683, finished rewards -16.14, envs finished 1
2026-01-17 13:25:16,605 : worker.worker : DEBUG : Step 92685, finished rewards 13.09, envs finished 1
2026-01-17 13:25:16,755 : agent.on_policy : DEBUG : Mean Losses: [8.512487724423409]
2026-01-17 13:25:16,796 : worker.worker : DEBUG : Step 92715, finished rewards 2.06, envs finished 1
2026-01-17 13:25:16,837 : worker.worker : DEBUG : Step 92726, finished rewards -8.36, envs finished 1
2026-01-17 13:25:16,856 : worker.worker : DEBUG : Step 92730, finished rewards -28.72, envs finished 1
2026-01-17 13:25:16,940 : agent.on_policy : DEBUG : Mean Losses: [8.393265061080456]
2026-01-17 13:25:17,124 : worker.worker : DEBUG : Step 92762, finished rewards 37.01, envs finished 1
2026-01-17 13:25:17,139 : worker.worker : DEBUG : Step 92764, finished rewards 31.70, envs finished 1
2026-01-17 13:25:17,228 : agent.on_policy : DEBUG : Mean Losses: [7.971252910792828]
2026-01-17 13:25:17,373 : worker.worker : DEBUG : Step 92794, finished rewards -7.10, envs finished 1
2026-01-17 13:25:17,440 : agent.on_policy : DEBUG : Mean Losses: [4.286507081240416]
2026-01-17 13:25:17,462 : worker.worker : DEBUG : Step 92806, finished rewards 3.62, envs finished 1
2026-01-17 13:25:17,486 : worker.worker : DEBUG : Step 92812, finished rewards 19.88, envs finished 1
2026-01-17 13:25:17,517 : worker.worker : DEBUG : Step 92818, finished rewards -33.66, envs finished 1
2026-01-17 13:25:17,588 : worker.worker : DEBUG : Step 92828, finished rewards 20.40, envs finished 1
2026-01-17 13:25:17,649 : agent.on_policy : DEBUG : Mean Losses: [8.375613626092672]
2026-01-17 13:25:17,698 : worker.worker : DEBUG : Step 92838, finished rewards 9.56, envs finished 1
2026-01-17 13:25:17,746 : worker.worker : DEBUG : Step 92848, finished rewards 29.78, envs finished 1
2026-01-17 13:25:17,790 : worker.worker : DEBUG : Step 92859, finished rewards 21.80, envs finished 1
2026-01-17 13:25:17,856 : agent.on_policy : DEBUG : Mean Losses: [6.18103046156466]
2026-01-17 13:25:17,935 : worker.worker : DEBUG : Step 92887, finished rewards 23.49, envs finished 1
2026-01-17 13:25:18,048 : agent.on_policy : DEBUG : Mean Losses: [4.426390962675214]
2026-01-17 13:25:18,092 : worker.worker : DEBUG : Step 92903, finished rewards 21.63, envs finished 1
2026-01-17 13:25:18,155 : worker.worker : DEBUG : Step 92914, finished rewards 16.36, envs finished 1
2026-01-17 13:25:18,182 : worker.worker : DEBUG : Step 92919, finished rewards 25.25, envs finished 1
2026-01-17 13:25:18,218 : worker.worker : DEBUG : Step 92926, finished rewards 12.65, envs finished 1
2026-01-17 13:25:18,317 : agent.on_policy : DEBUG : Mean Losses: [8.374645810574293]
2026-01-17 13:25:18,387 : worker.worker : DEBUG : Step 92942, finished rewards 14.73, envs finished 1
2026-01-17 13:25:18,539 : agent.on_policy : DEBUG : Mean Losses: [3.412926120683551]
2026-01-17 13:25:18,583 : worker.worker : DEBUG : Step 92974, finished rewards 6.76, envs finished 1
2026-01-17 13:25:18,637 : worker.worker : DEBUG : Step 92989, finished rewards 41.35, envs finished 1
2026-01-17 13:25:18,694 : agent.on_policy : DEBUG : Mean Losses: [6.7634753584861755]
2026-01-17 13:25:18,705 : worker.worker : DEBUG : Step 92994, finished rewards 23.97, envs finished 1
2026-01-17 13:25:18,736 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:25:18,763 : worker.worker : DEBUG : Step 93000, finished rewards -14.11, envs finished 1
2026-01-17 13:25:18,803 : worker.worker : DEBUG : Step 93006, finished rewards 23.81, envs finished 1
2026-01-17 13:25:18,919 : agent.on_policy : DEBUG : Mean Losses: [5.803369343280792]
2026-01-17 13:25:18,925 : worker.worker : DEBUG : Step 93025, finished rewards 18.58, envs finished 1
2026-01-17 13:25:18,942 : worker.worker : DEBUG : Step 93028, finished rewards -2.29, envs finished 1
2026-01-17 13:25:19,306 : agent.on_policy : DEBUG : Mean Losses: [3.2050604932010174]
2026-01-17 13:25:19,317 : worker.worker : DEBUG : Step 93058, finished rewards 7.36, envs finished 1
2026-01-17 13:25:19,391 : worker.worker : DEBUG : Step 93074, finished rewards 28.63, envs finished 1
2026-01-17 13:25:19,550 : agent.on_policy : DEBUG : Mean Losses: [4.625424146652222]
2026-01-17 13:25:19,563 : worker.worker : DEBUG : Step 93090, finished rewards 11.06, envs finished 1
2026-01-17 13:25:19,616 : worker.worker : DEBUG : Step 93100, finished rewards 13.45, envs finished 1
2026-01-17 13:25:19,695 : worker.worker : DEBUG : Step 93116, finished rewards 24.54, envs finished 1
2026-01-17 13:25:19,882 : agent.on_policy : DEBUG : Mean Losses: [7.302272148430347]
2026-01-17 13:25:19,892 : worker.worker : DEBUG : Step 93120, finished rewards 23.65, envs finished 1
2026-01-17 13:25:19,967 : worker.worker : DEBUG : Step 93129, finished rewards -2.93, envs finished 1
2026-01-17 13:25:19,995 : worker.worker : DEBUG : Step 93134, finished rewards -0.35, envs finished 1
2026-01-17 13:25:20,153 : agent.on_policy : DEBUG : Mean Losses: [3.747744992375374]
2026-01-17 13:25:20,215 : worker.worker : DEBUG : Step 93165, finished rewards 24.54, envs finished 1
2026-01-17 13:25:20,415 : agent.on_policy : DEBUG : Mean Losses: [3.7677692770957947]
2026-01-17 13:25:20,446 : worker.worker : DEBUG : Step 93191, finished rewards 17.41, envs finished 1
2026-01-17 13:25:20,533 : worker.worker : DEBUG : Step 93212, finished rewards -11.74, envs finished 1
2026-01-17 13:25:20,638 : agent.on_policy : DEBUG : Mean Losses: [5.2676165625452995]
2026-01-17 13:25:20,656 : worker.worker : DEBUG : Step 93220, finished rewards 3.10, envs finished 1
2026-01-17 13:25:20,708 : worker.worker : DEBUG : Step 93226, finished rewards 23.06, envs finished 1
2026-01-17 13:25:20,779 : worker.worker : DEBUG : Step 93241, finished rewards 7.54, envs finished 1
2026-01-17 13:25:20,898 : agent.on_policy : DEBUG : Mean Losses: [7.2667007222771645]
2026-01-17 13:25:20,975 : worker.worker : DEBUG : Step 93259, finished rewards 22.46, envs finished 1
2026-01-17 13:25:21,135 : worker.worker : DEBUG : Step 93276, finished rewards -19.20, envs finished 1
2026-01-17 13:25:21,283 : agent.on_policy : DEBUG : Mean Losses: [4.954679571092129]
2026-01-17 13:25:21,294 : worker.worker : DEBUG : Step 93282, finished rewards 24.32, envs finished 1
2026-01-17 13:25:21,334 : worker.worker : DEBUG : Step 93287, finished rewards -28.05, envs finished 1
2026-01-17 13:25:21,556 : agent.on_policy : DEBUG : Mean Losses: [2.9465289637446404]
2026-01-17 13:25:21,599 : worker.worker : DEBUG : Step 93325, finished rewards 13.31, envs finished 1
2026-01-17 13:25:21,662 : worker.worker : DEBUG : Step 93339, finished rewards -0.97, envs finished 1
2026-01-17 13:25:21,694 : worker.worker : DEBUG : Step 93343, finished rewards 29.66, envs finished 1
2026-01-17 13:25:21,810 : agent.on_policy : DEBUG : Mean Losses: [8.108828775584698]
2026-01-17 13:25:21,813 : worker.worker : DEBUG : Step 93344, finished rewards 15.77, envs finished 1
2026-01-17 13:25:22,007 : agent.on_policy : DEBUG : Mean Losses: [3.230646226555109]
2026-01-17 13:25:22,094 : worker.worker : DEBUG : Step 93391, finished rewards -19.88, envs finished 1
2026-01-17 13:25:22,109 : worker.worker : DEBUG : Step 93393, finished rewards 5.91, envs finished 1
2026-01-17 13:25:22,124 : worker.worker : DEBUG : Step 93395, finished rewards 8.74, envs finished 1
2026-01-17 13:25:22,255 : agent.on_policy : DEBUG : Mean Losses: [7.194985244423151]
2026-01-17 13:25:22,367 : worker.worker : DEBUG : Step 93430, finished rewards -11.62, envs finished 1
2026-01-17 13:25:22,508 : agent.on_policy : DEBUG : Mean Losses: [4.357605546712875]
2026-01-17 13:25:22,578 : worker.worker : DEBUG : Step 93451, finished rewards 12.19, envs finished 1
2026-01-17 13:25:22,592 : worker.worker : DEBUG : Step 93453, finished rewards -1.51, envs finished 1
2026-01-17 13:25:22,711 : worker.worker : DEBUG : Step 93469, finished rewards -0.37, envs finished 1
2026-01-17 13:25:22,722 : worker.worker : DEBUG : Step 93470, finished rewards -3.20, envs finished 1
2026-01-17 13:25:22,827 : agent.on_policy : DEBUG : Mean Losses: [7.910436175763607]
2026-01-17 13:25:22,897 : worker.worker : DEBUG : Step 93482, finished rewards 24.54, envs finished 1
2026-01-17 13:25:23,056 : agent.on_policy : DEBUG : Mean Losses: [2.8981663435697556]
2026-01-17 13:25:23,097 : worker.worker : DEBUG : Step 93515, finished rewards 29.11, envs finished 1
2026-01-17 13:25:23,134 : worker.worker : DEBUG : Step 93524, finished rewards -4.28, envs finished 1
2026-01-17 13:25:23,154 : worker.worker : DEBUG : Step 93528, finished rewards -10.84, envs finished 1
2026-01-17 13:25:23,238 : agent.on_policy : DEBUG : Mean Losses: [7.147955808788538]
2026-01-17 13:25:23,359 : worker.worker : DEBUG : Step 93558, finished rewards 26.20, envs finished 1
2026-01-17 13:25:23,490 : agent.on_policy : DEBUG : Mean Losses: [4.374905113130808]
2026-01-17 13:25:23,499 : worker.worker : DEBUG : Step 93569, finished rewards 5.75, envs finished 1
2026-01-17 13:25:23,552 : worker.worker : DEBUG : Step 93575, finished rewards 13.65, envs finished 1
2026-01-17 13:25:23,591 : worker.worker : DEBUG : Step 93582, finished rewards 18.11, envs finished 1
2026-01-17 13:25:23,603 : worker.worker : DEBUG : Step 93584, finished rewards -4.25, envs finished 1
2026-01-17 13:25:23,757 : agent.on_policy : DEBUG : Mean Losses: [6.417859826236963]
2026-01-17 13:25:23,968 : agent.on_policy : DEBUG : Mean Losses: [1.7746963202953339]
2026-01-17 13:25:24,019 : worker.worker : DEBUG : Step 93640, finished rewards 5.65, envs finished 1
2026-01-17 13:25:24,079 : worker.worker : DEBUG : Step 93656, finished rewards -4.33, envs finished 1
2026-01-17 13:25:24,190 : agent.on_policy : DEBUG : Mean Losses: [5.084888398647308]
2026-01-17 13:25:24,289 : worker.worker : DEBUG : Step 93681, finished rewards 18.17, envs finished 1
2026-01-17 13:25:24,325 : worker.worker : DEBUG : Step 93689, finished rewards 5.40, envs finished 1
2026-01-17 13:25:24,335 : worker.worker : DEBUG : Step 93690, finished rewards -16.10, envs finished 1
2026-01-17 13:25:24,441 : agent.on_policy : DEBUG : Mean Losses: [7.262276217341423]
2026-01-17 13:25:24,456 : worker.worker : DEBUG : Step 93699, finished rewards 5.11, envs finished 1
2026-01-17 13:25:24,481 : worker.worker : DEBUG : Step 93703, finished rewards -15.22, envs finished 1
2026-01-17 13:25:24,597 : worker.worker : DEBUG : Step 93723, finished rewards -8.24, envs finished 1
2026-01-17 13:25:24,694 : agent.on_policy : DEBUG : Mean Losses: [5.996474526822567]
2026-01-17 13:25:24,785 : worker.worker : DEBUG : Step 93746, finished rewards 16.31, envs finished 1
2026-01-17 13:25:24,926 : agent.on_policy : DEBUG : Mean Losses: [2.9195369593799114]
2026-01-17 13:25:24,963 : worker.worker : DEBUG : Step 93771, finished rewards 7.61, envs finished 1
2026-01-17 13:25:25,014 : worker.worker : DEBUG : Step 93786, finished rewards 26.19, envs finished 2
2026-01-17 13:25:25,079 : agent.on_policy : DEBUG : Mean Losses: [7.942222096025944]
2026-01-17 13:25:25,144 : worker.worker : DEBUG : Step 93802, finished rewards 4.58, envs finished 1
2026-01-17 13:25:25,154 : worker.worker : DEBUG : Step 93803, finished rewards 7.76, envs finished 1
2026-01-17 13:25:25,335 : agent.on_policy : DEBUG : Mean Losses: [4.745122339576483]
2026-01-17 13:25:25,342 : worker.worker : DEBUG : Step 93825, finished rewards -2.20, envs finished 1
2026-01-17 13:25:25,387 : worker.worker : DEBUG : Step 93836, finished rewards 24.51, envs finished 1
2026-01-17 13:25:25,411 : worker.worker : DEBUG : Step 93841, finished rewards 3.70, envs finished 1
2026-01-17 13:25:25,520 : agent.on_policy : DEBUG : Mean Losses: [6.013975527137518]
2026-01-17 13:25:25,544 : worker.worker : DEBUG : Step 93862, finished rewards 23.94, envs finished 1
2026-01-17 13:25:25,592 : worker.worker : DEBUG : Step 93869, finished rewards 30.19, envs finished 1
2026-01-17 13:25:25,704 : agent.on_policy : DEBUG : Mean Losses: [4.590353883802891]
2026-01-17 13:25:25,990 : agent.on_policy : DEBUG : Mean Losses: [2.4340134263038635]
2026-01-17 13:25:25,998 : worker.worker : DEBUG : Step 93922, finished rewards -9.58, envs finished 1
2026-01-17 13:25:26,030 : worker.worker : DEBUG : Step 93930, finished rewards -5.45, envs finished 1
2026-01-17 13:25:26,044 : worker.worker : DEBUG : Step 93933, finished rewards -4.65, envs finished 1
2026-01-17 13:25:26,090 : worker.worker : DEBUG : Step 93945, finished rewards 30.80, envs finished 1
2026-01-17 13:25:26,102 : worker.worker : DEBUG : Step 93947, finished rewards 14.67, envs finished 1
2026-01-17 13:25:26,191 : agent.on_policy : DEBUG : Mean Losses: [11.321412205696106]
2026-01-17 13:25:26,221 : worker.worker : DEBUG : Step 93959, finished rewards -4.84, envs finished 1
2026-01-17 13:25:26,297 : worker.worker : DEBUG : Step 93970, finished rewards 4.64, envs finished 1
2026-01-17 13:25:26,460 : agent.on_policy : DEBUG : Mean Losses: [4.4363280311226845]
2026-01-17 13:25:26,472 : worker.worker : DEBUG : Step 93987, finished rewards 4.90, envs finished 1
2026-01-17 13:25:26,538 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:25:26,597 : worker.worker : DEBUG : Step 94015, finished rewards 31.16, envs finished 1
2026-01-17 13:25:26,705 : agent.on_policy : DEBUG : Mean Losses: [5.047109737992287]
2026-01-17 13:25:26,929 : agent.on_policy : DEBUG : Mean Losses: [2.5737590566277504]
2026-01-17 13:25:26,970 : worker.worker : DEBUG : Step 94059, finished rewards -9.50, envs finished 2
2026-01-17 13:25:27,033 : worker.worker : DEBUG : Step 94077, finished rewards -5.64, envs finished 1
2026-01-17 13:25:27,040 : worker.worker : DEBUG : Step 94078, finished rewards 24.26, envs finished 1
2026-01-17 13:25:27,097 : agent.on_policy : DEBUG : Mean Losses: [10.438606396317482]
2026-01-17 13:25:27,101 : worker.worker : DEBUG : Step 94080, finished rewards -5.93, envs finished 1
2026-01-17 13:25:27,112 : worker.worker : DEBUG : Step 94081, finished rewards 1.11, envs finished 1
2026-01-17 13:25:27,203 : worker.worker : DEBUG : Step 94099, finished rewards 30.26, envs finished 1
2026-01-17 13:25:27,331 : agent.on_policy : DEBUG : Mean Losses: [5.332000826485455]
2026-01-17 13:25:27,477 : worker.worker : DEBUG : Step 94143, finished rewards 30.08, envs finished 1
2026-01-17 13:25:27,529 : agent.on_policy : DEBUG : Mean Losses: [3.959695130586624]
2026-01-17 13:25:27,553 : worker.worker : DEBUG : Step 94150, finished rewards -36.88, envs finished 1
2026-01-17 13:25:27,601 : worker.worker : DEBUG : Step 94163, finished rewards 30.71, envs finished 1
2026-01-17 13:25:27,727 : agent.on_policy : DEBUG : Mean Losses: [5.895450197160244]
2026-01-17 13:25:27,787 : worker.worker : DEBUG : Step 94182, finished rewards 2.46, envs finished 1
2026-01-17 13:25:27,843 : worker.worker : DEBUG : Step 94194, finished rewards 9.13, envs finished 1
2026-01-17 13:25:27,995 : agent.on_policy : DEBUG : Mean Losses: [4.920449450612068]
2026-01-17 13:25:28,010 : worker.worker : DEBUG : Step 94211, finished rewards -8.66, envs finished 1
2026-01-17 13:25:28,093 : worker.worker : DEBUG : Step 94233, finished rewards 30.72, envs finished 1
2026-01-17 13:25:28,109 : worker.worker : DEBUG : Step 94237, finished rewards -9.83, envs finished 1
2026-01-17 13:25:28,213 : agent.on_policy : DEBUG : Mean Losses: [9.147222615778446]
2026-01-17 13:25:28,325 : worker.worker : DEBUG : Step 94247, finished rewards 30.01, envs finished 1
2026-01-17 13:25:28,616 : agent.on_policy : DEBUG : Mean Losses: [4.484984654933214]
2026-01-17 13:25:28,644 : worker.worker : DEBUG : Step 94278, finished rewards 29.79, envs finished 1
2026-01-17 13:25:28,659 : worker.worker : DEBUG : Step 94281, finished rewards 18.29, envs finished 1
2026-01-17 13:25:28,694 : worker.worker : DEBUG : Step 94289, finished rewards -15.27, envs finished 1
2026-01-17 13:25:28,706 : worker.worker : DEBUG : Step 94291, finished rewards -38.54, envs finished 1
2026-01-17 13:25:28,815 : agent.on_policy : DEBUG : Mean Losses: [8.449926719069481]
2026-01-17 13:25:28,850 : worker.worker : DEBUG : Step 94312, finished rewards 17.54, envs finished 1
2026-01-17 13:25:29,039 : agent.on_policy : DEBUG : Mean Losses: [2.6365191005170345]
2026-01-17 13:25:29,051 : worker.worker : DEBUG : Step 94338, finished rewards 21.03, envs finished 2
2026-01-17 13:25:29,250 : agent.on_policy : DEBUG : Mean Losses: [3.9893316254019737]
2026-01-17 13:25:29,296 : worker.worker : DEBUG : Step 94375, finished rewards 23.24, envs finished 1
2026-01-17 13:25:29,589 : agent.on_policy : DEBUG : Mean Losses: [4.522353500127792]
2026-01-17 13:25:29,616 : worker.worker : DEBUG : Step 94408, finished rewards 5.91, envs finished 1
2026-01-17 13:25:29,653 : worker.worker : DEBUG : Step 94416, finished rewards -32.09, envs finished 1
2026-01-17 13:25:29,701 : worker.worker : DEBUG : Step 94429, finished rewards -15.29, envs finished 1
2026-01-17 13:25:29,706 : worker.worker : DEBUG : Step 94430, finished rewards 23.47, envs finished 1
2026-01-17 13:25:29,768 : agent.on_policy : DEBUG : Mean Losses: [9.611945033073425]
2026-01-17 13:25:29,796 : worker.worker : DEBUG : Step 94439, finished rewards -3.83, envs finished 1
2026-01-17 13:25:29,819 : worker.worker : DEBUG : Step 94445, finished rewards -22.44, envs finished 1
2026-01-17 13:25:29,825 : worker.worker : DEBUG : Step 94446, finished rewards 12.24, envs finished 1
2026-01-17 13:25:29,999 : agent.on_policy : DEBUG : Mean Losses: [5.0857463255524635]
2026-01-17 13:25:30,031 : worker.worker : DEBUG : Step 94475, finished rewards 18.23, envs finished 1
2026-01-17 13:25:30,139 : agent.on_policy : DEBUG : Mean Losses: [2.9303647447377443]
2026-01-17 13:25:30,152 : worker.worker : DEBUG : Step 94499, finished rewards 25.78, envs finished 1
2026-01-17 13:25:30,226 : worker.worker : DEBUG : Step 94508, finished rewards 23.38, envs finished 1
2026-01-17 13:25:30,245 : worker.worker : DEBUG : Step 94511, finished rewards 32.31, envs finished 1
2026-01-17 13:25:30,408 : agent.on_policy : DEBUG : Mean Losses: [6.726903185248375]
2026-01-17 13:25:30,472 : worker.worker : DEBUG : Step 94546, finished rewards 13.19, envs finished 1
2026-01-17 13:25:30,496 : worker.worker : DEBUG : Step 94552, finished rewards 2.67, envs finished 1
2026-01-17 13:25:30,508 : worker.worker : DEBUG : Step 94555, finished rewards 11.67, envs finished 1
2026-01-17 13:25:30,619 : agent.on_policy : DEBUG : Mean Losses: [5.934146348387003]
2026-01-17 13:25:30,632 : worker.worker : DEBUG : Step 94563, finished rewards 4.03, envs finished 1
2026-01-17 13:25:30,861 : agent.on_policy : DEBUG : Mean Losses: [2.8376811742782593]
2026-01-17 13:25:30,964 : worker.worker : DEBUG : Step 94621, finished rewards 8.63, envs finished 1
2026-01-17 13:25:30,973 : worker.worker : DEBUG : Step 94623, finished rewards -3.92, envs finished 1
2026-01-17 13:25:31,066 : agent.on_policy : DEBUG : Mean Losses: [6.457089088857174]
2026-01-17 13:25:31,107 : worker.worker : DEBUG : Step 94637, finished rewards 29.64, envs finished 1
2026-01-17 13:25:31,157 : worker.worker : DEBUG : Step 94643, finished rewards -12.94, envs finished 1
2026-01-17 13:25:31,165 : worker.worker : DEBUG : Step 94644, finished rewards 21.37, envs finished 1
2026-01-17 13:25:31,192 : worker.worker : DEBUG : Step 94648, finished rewards -7.10, envs finished 1
2026-01-17 13:25:31,334 : agent.on_policy : DEBUG : Mean Losses: [9.043739379383624]
2026-01-17 13:25:31,402 : worker.worker : DEBUG : Step 94669, finished rewards 6.98, envs finished 1
2026-01-17 13:25:31,605 : agent.on_policy : DEBUG : Mean Losses: [2.6137976869940758]
2026-01-17 13:25:31,612 : worker.worker : DEBUG : Step 94688, finished rewards -0.14, envs finished 1
2026-01-17 13:25:31,795 : agent.on_policy : DEBUG : Mean Losses: [2.1660227589309216]
2026-01-17 13:25:31,809 : worker.worker : DEBUG : Step 94722, finished rewards 18.68, envs finished 1
2026-01-17 13:25:32,006 : agent.on_policy : DEBUG : Mean Losses: [3.4407133162021637]
2026-01-17 13:25:32,009 : worker.worker : DEBUG : Step 94752, finished rewards 0.11, envs finished 1
2026-01-17 13:25:32,026 : worker.worker : DEBUG : Step 94754, finished rewards 29.31, envs finished 1
2026-01-17 13:25:32,113 : worker.worker : DEBUG : Step 94772, finished rewards -0.12, envs finished 1
2026-01-17 13:25:32,141 : worker.worker : DEBUG : Step 94775, finished rewards -0.66, envs finished 1
2026-01-17 13:25:32,168 : worker.worker : DEBUG : Step 94778, finished rewards -6.17, envs finished 1
2026-01-17 13:25:32,293 : agent.on_policy : DEBUG : Mean Losses: [7.801624562591314]
2026-01-17 13:25:32,380 : worker.worker : DEBUG : Step 94795, finished rewards -4.67, envs finished 1
2026-01-17 13:25:32,709 : agent.on_policy : DEBUG : Mean Losses: [2.9518587067723274]
2026-01-17 13:25:32,941 : agent.on_policy : DEBUG : Mean Losses: [3.3846770972013474]
2026-01-17 13:25:32,955 : worker.worker : DEBUG : Step 94851, finished rewards -3.68, envs finished 1
2026-01-17 13:25:33,026 : worker.worker : DEBUG : Step 94866, finished rewards 24.49, envs finished 1
2026-01-17 13:25:33,033 : worker.worker : DEBUG : Step 94867, finished rewards -10.73, envs finished 2
2026-01-17 13:25:33,068 : worker.worker : DEBUG : Step 94872, finished rewards 5.39, envs finished 1
2026-01-17 13:25:33,096 : worker.worker : DEBUG : Step 94875, finished rewards 17.82, envs finished 1
2026-01-17 13:25:33,234 : agent.on_policy : DEBUG : Mean Losses: [13.363197341561317]
2026-01-17 13:25:33,296 : worker.worker : DEBUG : Step 94886, finished rewards -8.10, envs finished 1
2026-01-17 13:25:33,314 : worker.worker : DEBUG : Step 94888, finished rewards 23.42, envs finished 1
2026-01-17 13:25:33,525 : agent.on_policy : DEBUG : Mean Losses: [3.1857280088588595]
2026-01-17 13:25:33,654 : agent.on_policy : DEBUG : Mean Losses: [1.325466588139534]
2026-01-17 13:25:33,799 : worker.worker : DEBUG : Step 94969, finished rewards 15.77, envs finished 1
2026-01-17 13:25:33,822 : worker.worker : DEBUG : Step 94974, finished rewards 18.15, envs finished 1
2026-01-17 13:25:33,882 : agent.on_policy : DEBUG : Mean Losses: [7.075687810778618]
2026-01-17 13:25:33,886 : worker.worker : DEBUG : Step 94976, finished rewards -0.97, envs finished 1
2026-01-17 13:25:33,896 : worker.worker : DEBUG : Step 94977, finished rewards 26.96, envs finished 1
2026-01-17 13:25:33,955 : worker.worker : DEBUG : Step 94991, finished rewards 0.25, envs finished 1
2026-01-17 13:25:34,027 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:25:34,046 : worker.worker : INFO : Step 95000, Avg Reward 8.5613, Max Reward 42.0110, Loss [5.56260398]
2026-01-17 13:25:34,061 : worker.worker : DEBUG : Step 95003, finished rewards -5.62, envs finished 1
2026-01-17 13:25:34,171 : agent.on_policy : DEBUG : Mean Losses: [6.933322221040726]
2026-01-17 13:25:34,179 : worker.worker : DEBUG : Step 95010, finished rewards 4.53, envs finished 1
2026-01-17 13:25:34,208 : worker.worker : DEBUG : Step 95016, finished rewards -11.53, envs finished 1
2026-01-17 13:25:34,418 : agent.on_policy : DEBUG : Mean Losses: [2.371675278991461]
2026-01-17 13:25:34,459 : worker.worker : DEBUG : Step 95052, finished rewards 30.29, envs finished 1
2026-01-17 13:25:34,581 : agent.on_policy : DEBUG : Mean Losses: [4.693999521434307]
2026-01-17 13:25:34,730 : worker.worker : DEBUG : Step 95102, finished rewards 5.78, envs finished 2
2026-01-17 13:25:34,783 : agent.on_policy : DEBUG : Mean Losses: [6.69000917673111]
2026-01-17 13:25:34,802 : worker.worker : DEBUG : Step 95110, finished rewards -12.67, envs finished 1
2026-01-17 13:25:34,917 : worker.worker : DEBUG : Step 95134, finished rewards 6.94, envs finished 1
2026-01-17 13:25:34,921 : worker.worker : DEBUG : Step 95135, finished rewards -28.28, envs finished 1
2026-01-17 13:25:34,974 : agent.on_policy : DEBUG : Mean Losses: [6.992250703275204]
2026-01-17 13:25:35,016 : worker.worker : DEBUG : Step 95149, finished rewards 23.15, envs finished 1
2026-01-17 13:25:35,035 : worker.worker : DEBUG : Step 95152, finished rewards -15.12, envs finished 1
2026-01-17 13:25:35,065 : worker.worker : DEBUG : Step 95157, finished rewards 1.15, envs finished 1
2026-01-17 13:25:35,180 : agent.on_policy : DEBUG : Mean Losses: [8.438577130436897]
2026-01-17 13:25:35,366 : agent.on_policy : DEBUG : Mean Losses: [1.8675271272659302]
2026-01-17 13:25:35,367 : worker.worker : DEBUG : Step 95200, finished rewards 19.34, envs finished 1
2026-01-17 13:25:35,370 : worker.worker : DEBUG : Step 95201, finished rewards 24.77, envs finished 1
2026-01-17 13:25:35,425 : worker.worker : DEBUG : Step 95217, finished rewards 31.22, envs finished 1
2026-01-17 13:25:35,572 : agent.on_policy : DEBUG : Mean Losses: [4.516468897461891]
2026-01-17 13:25:35,645 : worker.worker : DEBUG : Step 95246, finished rewards -15.51, envs finished 1
2026-01-17 13:25:35,655 : worker.worker : DEBUG : Step 95248, finished rewards 25.79, envs finished 1
2026-01-17 13:25:35,705 : worker.worker : DEBUG : Step 95256, finished rewards 13.13, envs finished 1
2026-01-17 13:25:35,823 : agent.on_policy : DEBUG : Mean Losses: [7.265720225870609]
2026-01-17 13:25:35,839 : worker.worker : DEBUG : Step 95268, finished rewards -5.43, envs finished 1
2026-01-17 13:25:35,858 : worker.worker : DEBUG : Step 95271, finished rewards 7.21, envs finished 1
2026-01-17 13:25:36,060 : agent.on_policy : DEBUG : Mean Losses: [3.829587873071432]
2026-01-17 13:25:36,099 : worker.worker : DEBUG : Step 95309, finished rewards 11.33, envs finished 1
2026-01-17 13:25:36,122 : worker.worker : DEBUG : Step 95314, finished rewards 9.79, envs finished 1
2026-01-17 13:25:36,211 : agent.on_policy : DEBUG : Mean Losses: [5.082052309066057]
2026-01-17 13:25:36,216 : worker.worker : DEBUG : Step 95329, finished rewards 30.50, envs finished 1
2026-01-17 13:25:36,264 : worker.worker : DEBUG : Step 95340, finished rewards 25.31, envs finished 1
2026-01-17 13:25:36,370 : worker.worker : DEBUG : Step 95358, finished rewards -2.00, envs finished 1
2026-01-17 13:25:36,484 : agent.on_policy : DEBUG : Mean Losses: [5.330819204449654]
2026-01-17 13:25:36,516 : worker.worker : DEBUG : Step 95368, finished rewards 17.45, envs finished 1
2026-01-17 13:25:36,821 : agent.on_policy : DEBUG : Mean Losses: [4.124848438426852]
2026-01-17 13:25:36,853 : worker.worker : DEBUG : Step 95400, finished rewards 11.75, envs finished 2
2026-01-17 13:25:36,884 : worker.worker : DEBUG : Step 95408, finished rewards -20.65, envs finished 1
2026-01-17 13:25:36,989 : agent.on_policy : DEBUG : Mean Losses: [6.071805473417044]
2026-01-17 13:25:37,011 : worker.worker : DEBUG : Step 95430, finished rewards 16.19, envs finished 1
2026-01-17 13:25:37,121 : worker.worker : DEBUG : Step 95451, finished rewards 23.59, envs finished 1
2026-01-17 13:25:37,217 : agent.on_policy : DEBUG : Mean Losses: [5.543134208768606]
2026-01-17 13:25:37,253 : worker.worker : DEBUG : Step 95464, finished rewards -29.35, envs finished 1
2026-01-17 13:25:37,317 : worker.worker : DEBUG : Step 95473, finished rewards -6.39, envs finished 1
2026-01-17 13:25:37,534 : agent.on_policy : DEBUG : Mean Losses: [4.590877579525113]
2026-01-17 13:25:37,557 : worker.worker : DEBUG : Step 95493, finished rewards 6.44, envs finished 1
2026-01-17 13:25:37,627 : worker.worker : DEBUG : Step 95509, finished rewards 16.76, envs finished 1
2026-01-17 13:25:37,669 : worker.worker : DEBUG : Step 95518, finished rewards 5.47, envs finished 1
2026-01-17 13:25:37,765 : agent.on_policy : DEBUG : Mean Losses: [6.001256158575416]
2026-01-17 13:25:37,782 : worker.worker : DEBUG : Step 95525, finished rewards 2.59, envs finished 1
2026-01-17 13:25:37,891 : worker.worker : DEBUG : Step 95543, finished rewards 24.23, envs finished 1
2026-01-17 13:25:38,063 : agent.on_policy : DEBUG : Mean Losses: [5.656070401892066]
2026-01-17 13:25:38,102 : worker.worker : DEBUG : Step 95564, finished rewards -6.52, envs finished 1
2026-01-17 13:25:38,158 : worker.worker : DEBUG : Step 95580, finished rewards 27.80, envs finished 1
2026-01-17 13:25:38,222 : agent.on_policy : DEBUG : Mean Losses: [7.087066039443016]
2026-01-17 13:25:38,239 : worker.worker : DEBUG : Step 95587, finished rewards 8.56, envs finished 1
2026-01-17 13:25:38,288 : worker.worker : DEBUG : Step 95592, finished rewards -3.30, envs finished 1
2026-01-17 13:25:38,458 : agent.on_policy : DEBUG : Mean Losses: [4.418832153081894]
2026-01-17 13:25:38,496 : worker.worker : DEBUG : Step 95625, finished rewards 13.44, envs finished 1
2026-01-17 13:25:38,565 : worker.worker : DEBUG : Step 95645, finished rewards 31.84, envs finished 1
2026-01-17 13:25:38,615 : agent.on_policy : DEBUG : Mean Losses: [7.065936364233494]
2026-01-17 13:25:38,625 : worker.worker : DEBUG : Step 95651, finished rewards -7.98, envs finished 1
2026-01-17 13:25:38,672 : worker.worker : DEBUG : Step 95656, finished rewards -2.63, envs finished 1
2026-01-17 13:25:38,718 : worker.worker : DEBUG : Step 95664, finished rewards 29.45, envs finished 1
2026-01-17 13:25:38,742 : worker.worker : DEBUG : Step 95669, finished rewards 5.24, envs finished 1
2026-01-17 13:25:38,843 : agent.on_policy : DEBUG : Mean Losses: [7.404866047203541]
2026-01-17 13:25:38,887 : worker.worker : DEBUG : Step 95689, finished rewards 22.08, envs finished 1
2026-01-17 13:25:38,964 : worker.worker : DEBUG : Step 95701, finished rewards 5.77, envs finished 1
2026-01-17 13:25:39,092 : agent.on_policy : DEBUG : Mean Losses: [4.582925569266081]
2026-01-17 13:25:39,185 : worker.worker : DEBUG : Step 95728, finished rewards 36.88, envs finished 1
2026-01-17 13:25:39,322 : agent.on_policy : DEBUG : Mean Losses: [4.3929819241166115]
2026-01-17 13:25:39,330 : worker.worker : DEBUG : Step 95746, finished rewards 4.22, envs finished 1
2026-01-17 13:25:39,360 : worker.worker : DEBUG : Step 95753, finished rewards 25.84, envs finished 2
2026-01-17 13:25:39,395 : worker.worker : DEBUG : Step 95762, finished rewards 20.40, envs finished 1
2026-01-17 13:25:39,497 : agent.on_policy : DEBUG : Mean Losses: [8.30629613995552]
2026-01-17 13:25:39,614 : worker.worker : DEBUG : Step 95786, finished rewards -13.44, envs finished 1
2026-01-17 13:25:39,755 : worker.worker : DEBUG : Step 95797, finished rewards 12.16, envs finished 1
2026-01-17 13:25:39,949 : agent.on_policy : DEBUG : Mean Losses: [4.986365048214793]
2026-01-17 13:25:39,957 : worker.worker : DEBUG : Step 95810, finished rewards 11.37, envs finished 1
2026-01-17 13:25:39,418 : agent.on_policy : DEBUG : Mean Losses: [2.3854045383632183]
2026-01-17 13:25:39,479 : worker.worker : DEBUG : Step 95853, finished rewards 2.55, envs finished 1
2026-01-17 13:25:39,503 : worker.worker : DEBUG : Step 95856, finished rewards 18.29, envs finished 1
2026-01-17 13:25:39,652 : agent.on_policy : DEBUG : Mean Losses: [8.151440978050232]
2026-01-17 13:25:39,697 : worker.worker : DEBUG : Step 95878, finished rewards 1.72, envs finished 1
2026-01-17 13:25:39,721 : worker.worker : DEBUG : Step 95884, finished rewards 2.11, envs finished 1
2026-01-17 13:25:39,762 : worker.worker : DEBUG : Step 95894, finished rewards -5.08, envs finished 1
2026-01-17 13:25:39,851 : agent.on_policy : DEBUG : Mean Losses: [7.8981698974967]
2026-01-17 13:25:39,868 : worker.worker : DEBUG : Step 95909, finished rewards 18.58, envs finished 1
2026-01-17 13:25:39,895 : worker.worker : DEBUG : Step 95916, finished rewards 13.31, envs finished 1
2026-01-17 13:25:39,956 : worker.worker : DEBUG : Step 95924, finished rewards -9.10, envs finished 1
2026-01-17 13:25:40,091 : agent.on_policy : DEBUG : Mean Losses: [6.865554496645927]
2026-01-17 13:25:40,096 : worker.worker : DEBUG : Step 95937, finished rewards 30.16, envs finished 1
2026-01-17 13:25:40,194 : worker.worker : DEBUG : Step 95961, finished rewards 17.02, envs finished 1
2026-01-17 13:25:40,201 : worker.worker : DEBUG : Step 95962, finished rewards 30.31, envs finished 1
2026-01-17 13:25:40,318 : agent.on_policy : DEBUG : Mean Losses: [6.867939593270421]
2026-01-17 13:25:40,403 : worker.worker : DEBUG : Step 95985, finished rewards 25.61, envs finished 1
2026-01-17 13:25:40,450 : worker.worker : DEBUG : Step 95998, finished rewards 26.60, envs finished 1
2026-01-17 13:25:40,451 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:25:40,460 : worker.worker : DEBUG : Step 95999, finished rewards 30.53, envs finished 1
2026-01-17 13:25:40,552 : agent.on_policy : DEBUG : Mean Losses: [8.840175118297338]
2026-01-17 13:25:40,563 : worker.worker : DEBUG : Step 96003, finished rewards 6.89, envs finished 1
2026-01-17 13:25:40,626 : worker.worker : DEBUG : Step 96014, finished rewards 26.54, envs finished 1
2026-01-17 13:25:40,707 : worker.worker : DEBUG : Step 96028, finished rewards 25.83, envs finished 1
2026-01-17 13:25:40,800 : agent.on_policy : DEBUG : Mean Losses: [5.924220195040107]
2026-01-17 13:25:40,933 : worker.worker : DEBUG : Step 96062, finished rewards 19.96, envs finished 1
2026-01-17 13:25:41,028 : agent.on_policy : DEBUG : Mean Losses: [3.685666438192129]
2026-01-17 13:25:41,165 : worker.worker : DEBUG : Step 96091, finished rewards 1.01, envs finished 1
2026-01-17 13:25:41,239 : agent.on_policy : DEBUG : Mean Losses: [6.080834299325943]
2026-01-17 13:25:41,249 : worker.worker : DEBUG : Step 96098, finished rewards 19.13, envs finished 1
2026-01-17 13:25:41,275 : worker.worker : DEBUG : Step 96104, finished rewards 26.73, envs finished 1
2026-01-17 13:25:41,281 : worker.worker : DEBUG : Step 96105, finished rewards 11.86, envs finished 1
2026-01-17 13:25:41,369 : worker.worker : DEBUG : Step 96118, finished rewards -4.16, envs finished 1
2026-01-17 13:25:41,525 : agent.on_policy : DEBUG : Mean Losses: [6.6853967644274235]
2026-01-17 13:25:41,536 : worker.worker : DEBUG : Step 96131, finished rewards 15.78, envs finished 1
2026-01-17 13:25:41,615 : worker.worker : DEBUG : Step 96140, finished rewards -3.97, envs finished 1
2026-01-17 13:25:41,870 : agent.on_policy : DEBUG : Mean Losses: [2.7228414863348007]
2026-01-17 13:25:41,966 : worker.worker : DEBUG : Step 96180, finished rewards 31.27, envs finished 1
2026-01-17 13:25:42,017 : worker.worker : DEBUG : Step 96188, finished rewards 30.97, envs finished 1
2026-01-17 13:25:42,025 : worker.worker : DEBUG : Step 96189, finished rewards 4.20, envs finished 1
2026-01-17 13:25:42,203 : agent.on_policy : DEBUG : Mean Losses: [8.210883930325508]
2026-01-17 13:25:42,260 : worker.worker : DEBUG : Step 96202, finished rewards 30.09, envs finished 1
2026-01-17 13:25:42,495 : agent.on_policy : DEBUG : Mean Losses: [4.614256538450718]
2026-01-17 13:25:42,510 : worker.worker : DEBUG : Step 96228, finished rewards -11.42, envs finished 1
2026-01-17 13:25:42,519 : worker.worker : DEBUG : Step 96230, finished rewards 21.04, envs finished 1
2026-01-17 13:25:42,565 : worker.worker : DEBUG : Step 96240, finished rewards -2.49, envs finished 1
2026-01-17 13:25:42,690 : agent.on_policy : DEBUG : Mean Losses: [4.5899145901203156]
2026-01-17 13:25:42,830 : worker.worker : DEBUG : Step 96273, finished rewards 29.65, envs finished 1
2026-01-17 13:25:42,888 : worker.worker : DEBUG : Step 96278, finished rewards 21.01, envs finished 1
2026-01-17 13:25:43,041 : agent.on_policy : DEBUG : Mean Losses: [6.821457449346781]
2026-01-17 13:25:43,162 : worker.worker : DEBUG : Step 96317, finished rewards 1.22, envs finished 1
2026-01-17 13:25:43,168 : worker.worker : DEBUG : Step 96318, finished rewards -22.33, envs finished 1
2026-01-17 13:25:43,298 : agent.on_policy : DEBUG : Mean Losses: [4.6812554486095905]
2026-01-17 13:25:43,307 : worker.worker : DEBUG : Step 96322, finished rewards 18.32, envs finished 2
2026-01-17 13:25:43,385 : worker.worker : DEBUG : Step 96334, finished rewards 13.02, envs finished 1
2026-01-17 13:25:43,565 : agent.on_policy : DEBUG : Mean Losses: [5.577807014808059]
2026-01-17 13:25:43,602 : worker.worker : DEBUG : Step 96361, finished rewards -5.08, envs finished 1
2026-01-17 13:25:43,629 : worker.worker : DEBUG : Step 96367, finished rewards 22.91, envs finished 1
2026-01-17 13:25:43,680 : worker.worker : DEBUG : Step 96377, finished rewards 19.62, envs finished 1
2026-01-17 13:25:43,804 : agent.on_policy : DEBUG : Mean Losses: [6.107840159907937]
2026-01-17 13:25:44,041 : agent.on_policy : DEBUG : Mean Losses: [1.788264762610197]
2026-01-17 13:25:44,044 : worker.worker : DEBUG : Step 96416, finished rewards 19.70, envs finished 1
2026-01-17 13:25:44,083 : worker.worker : DEBUG : Step 96422, finished rewards 18.92, envs finished 1
2026-01-17 13:25:44,128 : worker.worker : DEBUG : Step 96430, finished rewards 8.98, envs finished 1
2026-01-17 13:25:44,170 : worker.worker : DEBUG : Step 96438, finished rewards 16.00, envs finished 1
2026-01-17 13:25:44,225 : worker.worker : DEBUG : Step 96447, finished rewards -0.89, envs finished 1
2026-01-17 13:25:44,314 : agent.on_policy : DEBUG : Mean Losses: [7.368933875113726]
2026-01-17 13:25:44,564 : agent.on_policy : DEBUG : Mean Losses: [2.3810886330902576]
2026-01-17 13:25:44,581 : worker.worker : DEBUG : Step 96482, finished rewards 6.35, envs finished 1
2026-01-17 13:25:44,948 : agent.on_policy : DEBUG : Mean Losses: [3.5690998882055283]
2026-01-17 13:25:45,043 : worker.worker : DEBUG : Step 96536, finished rewards -9.12, envs finished 2
2026-01-17 13:25:45,074 : worker.worker : DEBUG : Step 96542, finished rewards 7.82, envs finished 1
2026-01-17 13:25:45,190 : agent.on_policy : DEBUG : Mean Losses: [10.620564967393875]
2026-01-17 13:25:45,194 : worker.worker : DEBUG : Step 96544, finished rewards -32.08, envs finished 1
2026-01-17 13:25:45,282 : worker.worker : DEBUG : Step 96555, finished rewards -6.70, envs finished 1
2026-01-17 13:25:45,509 : agent.on_policy : DEBUG : Mean Losses: [3.50689569208771]
2026-01-17 13:25:45,518 : worker.worker : DEBUG : Step 96578, finished rewards 20.06, envs finished 1
2026-01-17 13:25:45,600 : worker.worker : DEBUG : Step 96595, finished rewards -15.71, envs finished 1
2026-01-17 13:25:45,756 : agent.on_policy : DEBUG : Mean Losses: [3.984582681208849]
2026-01-17 13:25:45,796 : worker.worker : DEBUG : Step 96619, finished rewards -47.37, envs finished 1
2026-01-17 13:25:45,846 : worker.worker : DEBUG : Step 96628, finished rewards 24.41, envs finished 1
2026-01-17 13:25:45,894 : worker.worker : DEBUG : Step 96638, finished rewards 31.13, envs finished 1
2026-01-17 13:25:45,959 : agent.on_policy : DEBUG : Mean Losses: [8.700240775942802]
2026-01-17 13:25:45,972 : worker.worker : DEBUG : Step 96642, finished rewards 21.17, envs finished 1
2026-01-17 13:25:46,009 : worker.worker : DEBUG : Step 96650, finished rewards 14.04, envs finished 1
2026-01-17 13:25:46,024 : worker.worker : DEBUG : Step 96653, finished rewards 5.68, envs finished 1
2026-01-17 13:25:46,220 : agent.on_policy : DEBUG : Mean Losses: [4.001108356751502]
2026-01-17 13:25:46,419 : agent.on_policy : DEBUG : Mean Losses: [1.9144316241145134]
2026-01-17 13:25:46,508 : worker.worker : DEBUG : Step 96721, finished rewards -4.52, envs finished 1
2026-01-17 13:25:46,537 : worker.worker : DEBUG : Step 96727, finished rewards 18.17, envs finished 1
2026-01-17 13:25:46,697 : agent.on_policy : DEBUG : Mean Losses: [7.027103573083878]
2026-01-17 13:25:46,703 : worker.worker : DEBUG : Step 96737, finished rewards 5.15, envs finished 1
2026-01-17 13:25:46,708 : worker.worker : DEBUG : Step 96738, finished rewards -13.75, envs finished 1
2026-01-17 13:25:46,776 : worker.worker : DEBUG : Step 96753, finished rewards 17.95, envs finished 1
2026-01-17 13:25:46,935 : agent.on_policy : DEBUG : Mean Losses: [5.914283163845539]
2026-01-17 13:25:46,974 : worker.worker : DEBUG : Step 96779, finished rewards -2.14, envs finished 1
2026-01-17 13:25:47,022 : worker.worker : DEBUG : Step 96790, finished rewards -10.30, envs finished 1
2026-01-17 13:25:47,051 : worker.worker : DEBUG : Step 96795, finished rewards -22.41, envs finished 1
2026-01-17 13:25:47,220 : agent.on_policy : DEBUG : Mean Losses: [6.008857512846589]
2026-01-17 13:25:47,309 : worker.worker : DEBUG : Step 96819, finished rewards 18.84, envs finished 1
2026-01-17 13:25:47,317 : worker.worker : DEBUG : Step 96820, finished rewards 31.01, envs finished 1
2026-01-17 13:25:47,480 : agent.on_policy : DEBUG : Mean Losses: [6.171657390892506]
2026-01-17 13:25:47,511 : worker.worker : DEBUG : Step 96838, finished rewards 16.90, envs finished 1
2026-01-17 13:25:47,619 : worker.worker : DEBUG : Step 96863, finished rewards -7.29, envs finished 1
2026-01-17 13:25:47,749 : agent.on_policy : DEBUG : Mean Losses: [4.517688617110252]
2026-01-17 13:25:47,857 : worker.worker : DEBUG : Step 96883, finished rewards 23.40, envs finished 1
2026-01-17 13:25:48,011 : agent.on_policy : DEBUG : Mean Losses: [4.360549388453364]
2026-01-17 13:25:48,013 : worker.worker : DEBUG : Step 96896, finished rewards -5.70, envs finished 1
2026-01-17 13:25:48,048 : worker.worker : DEBUG : Step 96903, finished rewards 30.75, envs finished 1
2026-01-17 13:25:48,079 : worker.worker : DEBUG : Step 96909, finished rewards -4.65, envs finished 1
2026-01-17 13:25:48,139 : worker.worker : DEBUG : Step 96922, finished rewards 15.27, envs finished 1
2026-01-17 13:25:48,267 : agent.on_policy : DEBUG : Mean Losses: [7.4889070764184]
2026-01-17 13:25:48,425 : worker.worker : DEBUG : Step 96946, finished rewards 10.90, envs finished 1
2026-01-17 13:25:48,633 : agent.on_policy : DEBUG : Mean Losses: [4.128062464296818]
2026-01-17 13:25:48,680 : worker.worker : DEBUG : Step 96970, finished rewards -35.61, envs finished 1
2026-01-17 13:25:48,714 : worker.worker : DEBUG : Step 96975, finished rewards 25.30, envs finished 1
2026-01-17 13:25:48,759 : worker.worker : DEBUG : Step 96985, finished rewards 2.19, envs finished 1
2026-01-17 13:25:48,857 : agent.on_policy : DEBUG : Mean Losses: [7.014621384441853]
2026-01-17 13:25:48,878 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:25:48,940 : worker.worker : DEBUG : Step 97005, finished rewards 21.30, envs finished 1
2026-01-17 13:25:49,057 : worker.worker : DEBUG : Step 97021, finished rewards 3.34, envs finished 2
2026-01-17 13:25:49,336 : agent.on_policy : DEBUG : Mean Losses: [6.05130260810256]
2026-01-17 13:25:49,561 : worker.worker : DEBUG : Step 97054, finished rewards -3.77, envs finished 1
2026-01-17 13:25:49,635 : agent.on_policy : DEBUG : Mean Losses: [2.5569913797080517]
2026-01-17 13:25:49,839 : agent.on_policy : DEBUG : Mean Losses: [3.1113489493727684]
2026-01-17 13:25:49,882 : worker.worker : DEBUG : Step 97100, finished rewards -0.85, envs finished 1
2026-01-17 13:25:49,890 : worker.worker : DEBUG : Step 97102, finished rewards 5.69, envs finished 1
2026-01-17 13:25:49,932 : worker.worker : DEBUG : Step 97112, finished rewards 12.96, envs finished 1
2026-01-17 13:25:50,040 : agent.on_policy : DEBUG : Mean Losses: [7.949867784976959]
2026-01-17 13:25:50,042 : worker.worker : DEBUG : Step 97120, finished rewards -37.08, envs finished 1
2026-01-17 13:25:50,128 : worker.worker : DEBUG : Step 97130, finished rewards -27.43, envs finished 1
2026-01-17 13:25:50,163 : worker.worker : DEBUG : Step 97135, finished rewards 6.11, envs finished 1
2026-01-17 13:25:50,357 : agent.on_policy : DEBUG : Mean Losses: [5.308130802586675]
2026-01-17 13:25:50,366 : worker.worker : DEBUG : Step 97154, finished rewards -6.53, envs finished 1
2026-01-17 13:25:50,371 : worker.worker : DEBUG : Step 97155, finished rewards 17.69, envs finished 1
2026-01-17 13:25:50,583 : agent.on_policy : DEBUG : Mean Losses: [2.333650268614292]
2026-01-17 13:25:50,685 : worker.worker : DEBUG : Step 97203, finished rewards 24.75, envs finished 1
2026-01-17 13:25:50,768 : worker.worker : DEBUG : Step 97213, finished rewards 30.77, envs finished 1
2026-01-17 13:25:50,871 : agent.on_policy : DEBUG : Mean Losses: [6.5914533622562885]
2026-01-17 13:25:50,906 : worker.worker : DEBUG : Step 97220, finished rewards 6.43, envs finished 1
2026-01-17 13:25:50,980 : worker.worker : DEBUG : Step 97234, finished rewards -3.53, envs finished 1
2026-01-17 13:25:51,242 : agent.on_policy : DEBUG : Mean Losses: [4.523821175098419]
2026-01-17 13:25:51,298 : worker.worker : DEBUG : Step 97256, finished rewards -8.63, envs finished 1
2026-01-17 13:25:51,336 : worker.worker : DEBUG : Step 97262, finished rewards 5.40, envs finished 1
2026-01-17 13:25:51,392 : worker.worker : DEBUG : Step 97270, finished rewards 7.41, envs finished 2
2026-01-17 13:25:51,600 : agent.on_policy : DEBUG : Mean Losses: [7.373957857489586]
2026-01-17 13:25:51,943 : agent.on_policy : DEBUG : Mean Losses: [1.6064206920564175]
2026-01-17 13:25:51,975 : worker.worker : DEBUG : Step 97320, finished rewards 6.11, envs finished 1
2026-01-17 13:25:52,062 : worker.worker : DEBUG : Step 97333, finished rewards 8.73, envs finished 1
2026-01-17 13:25:52,267 : agent.on_policy : DEBUG : Mean Losses: [6.088012933731079]
2026-01-17 13:25:52,315 : worker.worker : DEBUG : Step 97351, finished rewards -8.15, envs finished 1
2026-01-17 13:25:52,337 : worker.worker : DEBUG : Step 97353, finished rewards 4.49, envs finished 1
2026-01-17 13:25:52,384 : worker.worker : DEBUG : Step 97359, finished rewards 21.66, envs finished 1
2026-01-17 13:25:52,451 : worker.worker : DEBUG : Step 97370, finished rewards 18.88, envs finished 1
2026-01-17 13:25:52,486 : worker.worker : DEBUG : Step 97375, finished rewards 3.19, envs finished 1
2026-01-17 13:25:52,595 : agent.on_policy : DEBUG : Mean Losses: [9.629333049058914]
2026-01-17 13:25:52,622 : worker.worker : DEBUG : Step 97381, finished rewards 9.45, envs finished 1
2026-01-17 13:25:52,877 : agent.on_policy : DEBUG : Mean Losses: [1.8244384862482548]
2026-01-17 13:25:52,927 : worker.worker : DEBUG : Step 97419, finished rewards 18.91, envs finished 1
2026-01-17 13:25:53,114 : agent.on_policy : DEBUG : Mean Losses: [3.175278104841709]
2026-01-17 13:25:53,192 : worker.worker : DEBUG : Step 97449, finished rewards 22.28, envs finished 1
2026-01-17 13:25:53,290 : worker.worker : DEBUG : Step 97458, finished rewards 19.17, envs finished 1
2026-01-17 13:25:53,502 : agent.on_policy : DEBUG : Mean Losses: [6.352764546871185]
2026-01-17 13:25:53,606 : worker.worker : DEBUG : Step 97496, finished rewards -28.50, envs finished 1
2026-01-17 13:25:53,612 : worker.worker : DEBUG : Step 97497, finished rewards 2.82, envs finished 1
2026-01-17 13:25:53,624 : worker.worker : DEBUG : Step 97499, finished rewards -19.23, envs finished 1
2026-01-17 13:25:53,654 : worker.worker : DEBUG : Step 97503, finished rewards 7.93, envs finished 1
2026-01-17 13:25:53,744 : agent.on_policy : DEBUG : Mean Losses: [7.795501362532377]
2026-01-17 13:25:53,785 : worker.worker : DEBUG : Step 97515, finished rewards -6.06, envs finished 1
2026-01-17 13:25:53,953 : agent.on_policy : DEBUG : Mean Losses: [2.600891986861825]
2026-01-17 13:25:53,981 : worker.worker : DEBUG : Step 97543, finished rewards -1.38, envs finished 1
2026-01-17 13:25:54,052 : worker.worker : DEBUG : Step 97557, finished rewards 11.07, envs finished 1
2026-01-17 13:25:54,164 : agent.on_policy : DEBUG : Mean Losses: [5.839238196611404]
2026-01-17 13:25:54,194 : worker.worker : DEBUG : Step 97573, finished rewards 37.02, envs finished 1
2026-01-17 13:25:54,228 : worker.worker : DEBUG : Step 97581, finished rewards 18.27, envs finished 2
2026-01-17 13:25:54,362 : agent.on_policy : DEBUG : Mean Losses: [5.853148544207215]
2026-01-17 13:25:54,647 : worker.worker : DEBUG : Step 97631, finished rewards 5.45, envs finished 1
2026-01-17 13:25:54,703 : agent.on_policy : DEBUG : Mean Losses: [3.93994677066803]
2026-01-17 13:25:54,751 : worker.worker : DEBUG : Step 97644, finished rewards -12.44, envs finished 1
2026-01-17 13:25:54,791 : worker.worker : DEBUG : Step 97654, finished rewards 9.94, envs finished 1
2026-01-17 13:25:54,800 : worker.worker : DEBUG : Step 97655, finished rewards -18.66, envs finished 1
2026-01-17 13:25:54,910 : agent.on_policy : DEBUG : Mean Losses: [6.350656893104315]
2026-01-17 13:25:54,969 : worker.worker : DEBUG : Step 97675, finished rewards 3.94, envs finished 1
2026-01-17 13:25:54,987 : worker.worker : DEBUG : Step 97678, finished rewards 20.79, envs finished 1
2026-01-17 13:25:55,018 : worker.worker : DEBUG : Step 97683, finished rewards 10.99, envs finished 1
2026-01-17 13:25:55,174 : agent.on_policy : DEBUG : Mean Losses: [6.0330793634057045]
2026-01-17 13:25:55,182 : worker.worker : DEBUG : Step 97698, finished rewards 7.85, envs finished 1
2026-01-17 13:25:55,339 : agent.on_policy : DEBUG : Mean Losses: [1.952998099848628]
2026-01-17 13:25:55,439 : worker.worker : DEBUG : Step 97748, finished rewards 6.39, envs finished 1
2026-01-17 13:25:55,566 : agent.on_policy : DEBUG : Mean Losses: [4.492906264960766]
2026-01-17 13:25:55,626 : worker.worker : DEBUG : Step 97768, finished rewards 5.10, envs finished 1
2026-01-17 13:25:55,648 : worker.worker : DEBUG : Step 97771, finished rewards 20.28, envs finished 1
2026-01-17 13:25:55,829 : agent.on_policy : DEBUG : Mean Losses: [6.567163962870836]
2026-01-17 13:25:55,861 : worker.worker : DEBUG : Step 97803, finished rewards 5.16, envs finished 1
2026-01-17 13:25:55,893 : worker.worker : DEBUG : Step 97812, finished rewards -23.78, envs finished 1
2026-01-17 13:25:55,914 : worker.worker : DEBUG : Step 97816, finished rewards -6.21, envs finished 2
2026-01-17 13:25:55,995 : agent.on_policy : DEBUG : Mean Losses: [7.610118076205254]
2026-01-17 13:25:56,222 : agent.on_policy : DEBUG : Mean Losses: [2.893068552017212]
2026-01-17 13:25:56,287 : worker.worker : DEBUG : Step 97869, finished rewards 1.55, envs finished 1
2026-01-17 13:25:56,437 : agent.on_policy : DEBUG : Mean Losses: [4.327950686216354]
2026-01-17 13:25:56,491 : worker.worker : DEBUG : Step 97907, finished rewards -13.13, envs finished 1
2026-01-17 13:25:56,633 : agent.on_policy : DEBUG : Mean Losses: [6.056083366274834]
2026-01-17 13:25:56,640 : worker.worker : DEBUG : Step 97921, finished rewards -19.19, envs finished 1
2026-01-17 13:25:56,683 : worker.worker : DEBUG : Step 97930, finished rewards 3.14, envs finished 1
2026-01-17 13:25:56,721 : worker.worker : DEBUG : Step 97939, finished rewards -9.80, envs finished 1
2026-01-17 13:25:56,725 : worker.worker : DEBUG : Step 97940, finished rewards -99.53, envs finished 1
2026-01-17 13:25:56,773 : worker.worker : DEBUG : Step 97950, finished rewards -5.00, envs finished 1
2026-01-17 13:25:56,834 : agent.on_policy : DEBUG : Mean Losses: [9.232370529323816]
2026-01-17 13:25:56,868 : worker.worker : DEBUG : Step 97961, finished rewards -17.48, envs finished 1
2026-01-17 13:25:56,932 : worker.worker : DEBUG : Step 97975, finished rewards 14.15, envs finished 1
2026-01-17 13:25:57,080 : agent.on_policy : DEBUG : Mean Losses: [3.969801254570484]
2026-01-17 13:25:57,122 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:25:57,218 : agent.on_policy : DEBUG : Mean Losses: [1.5438469089567661]
2026-01-17 13:25:57,420 : agent.on_policy : DEBUG : Mean Losses: [4.706953875720501]
2026-01-17 13:25:57,422 : worker.worker : DEBUG : Step 98048, finished rewards 12.88, envs finished 1
2026-01-17 13:25:57,431 : worker.worker : DEBUG : Step 98050, finished rewards 11.90, envs finished 2
2026-01-17 13:25:57,455 : worker.worker : DEBUG : Step 98054, finished rewards 33.71, envs finished 1
2026-01-17 13:25:57,470 : worker.worker : DEBUG : Step 98057, finished rewards 20.56, envs finished 1
2026-01-17 13:25:57,590 : agent.on_policy : DEBUG : Mean Losses: [8.096065916121006]
2026-01-17 13:25:57,608 : worker.worker : DEBUG : Step 98083, finished rewards -27.34, envs finished 1
2026-01-17 13:25:57,640 : worker.worker : DEBUG : Step 98086, finished rewards -18.23, envs finished 1
2026-01-17 13:25:57,844 : agent.on_policy : DEBUG : Mean Losses: [3.161299355328083]
2026-01-17 13:25:57,939 : worker.worker : DEBUG : Step 98139, finished rewards 29.47, envs finished 1
2026-01-17 13:25:57,946 : worker.worker : DEBUG : Step 98141, finished rewards 24.77, envs finished 1
2026-01-17 13:25:57,953 : worker.worker : DEBUG : Step 98142, finished rewards -70.90, envs finished 1
2026-01-17 13:25:58,050 : agent.on_policy : DEBUG : Mean Losses: [9.265667658299208]
2026-01-17 13:25:58,059 : worker.worker : DEBUG : Step 98146, finished rewards 27.46, envs finished 1
2026-01-17 13:25:58,146 : worker.worker : DEBUG : Step 98161, finished rewards 15.33, envs finished 1
2026-01-17 13:25:58,239 : worker.worker : DEBUG : Step 98169, finished rewards 30.78, envs finished 1
2026-01-17 13:25:58,271 : worker.worker : DEBUG : Step 98170, finished rewards 1.19, envs finished 1
2026-01-17 13:25:58,478 : agent.on_policy : DEBUG : Mean Losses: [7.276364881545305]
2026-01-17 13:25:58,675 : agent.on_policy : DEBUG : Mean Losses: [1.8217558395117521]
2026-01-17 13:25:58,678 : worker.worker : DEBUG : Step 98208, finished rewards -0.53, envs finished 1
2026-01-17 13:25:58,711 : worker.worker : DEBUG : Step 98216, finished rewards 36.55, envs finished 1
2026-01-17 13:25:58,770 : worker.worker : DEBUG : Step 98228, finished rewards 30.84, envs finished 1
2026-01-17 13:25:58,893 : agent.on_policy : DEBUG : Mean Losses: [5.832873325794935]
2026-01-17 13:25:58,941 : worker.worker : DEBUG : Step 98251, finished rewards 26.70, envs finished 1
2026-01-17 13:25:58,965 : worker.worker : DEBUG : Step 98257, finished rewards 5.37, envs finished 1
2026-01-17 13:25:59,063 : agent.on_policy : DEBUG : Mean Losses: [5.704766746610403]
2026-01-17 13:25:59,141 : worker.worker : DEBUG : Step 98287, finished rewards 6.22, envs finished 1
2026-01-17 13:25:59,181 : worker.worker : DEBUG : Step 98296, finished rewards 2.86, envs finished 1
2026-01-17 13:25:59,343 : agent.on_policy : DEBUG : Mean Losses: [5.6161030530929565]
2026-01-17 13:25:59,536 : worker.worker : DEBUG : Step 98325, finished rewards -34.04, envs finished 1
2026-01-17 13:25:59,593 : worker.worker : DEBUG : Step 98332, finished rewards 31.28, envs finished 1
2026-01-17 13:25:59,604 : worker.worker : DEBUG : Step 98334, finished rewards -1.60, envs finished 1
2026-01-17 13:25:59,662 : agent.on_policy : DEBUG : Mean Losses: [9.927945844829082]
2026-01-17 13:25:59,773 : worker.worker : DEBUG : Step 98360, finished rewards -8.36, envs finished 1
2026-01-17 13:25:59,885 : agent.on_policy : DEBUG : Mean Losses: [4.265650320798159]
2026-01-17 13:25:59,913 : worker.worker : DEBUG : Step 98374, finished rewards 9.02, envs finished 1
2026-01-17 13:25:59,956 : worker.worker : DEBUG : Step 98378, finished rewards -14.16, envs finished 1
2026-01-17 13:26:00,012 : worker.worker : DEBUG : Step 98391, finished rewards 21.23, envs finished 1
2026-01-17 13:26:00,031 : worker.worker : DEBUG : Step 98395, finished rewards 11.48, envs finished 1
2026-01-17 13:26:00,115 : agent.on_policy : DEBUG : Mean Losses: [7.035788055509329]
2026-01-17 13:26:00,213 : worker.worker : DEBUG : Step 98418, finished rewards 30.25, envs finished 1
2026-01-17 13:26:00,340 : agent.on_policy : DEBUG : Mean Losses: [4.514370437711477]
2026-01-17 13:26:00,659 : agent.on_policy : DEBUG : Mean Losses: [2.1809073351323605]
2026-01-17 13:26:00,677 : worker.worker : DEBUG : Step 98468, finished rewards -5.65, envs finished 1
2026-01-17 13:26:00,755 : worker.worker : DEBUG : Step 98484, finished rewards 24.36, envs finished 1
2026-01-17 13:26:00,786 : worker.worker : DEBUG : Step 98490, finished rewards 9.17, envs finished 1
2026-01-17 13:26:00,949 : agent.on_policy : DEBUG : Mean Losses: [8.31620578467846]
2026-01-17 13:26:00,964 : worker.worker : DEBUG : Step 98500, finished rewards -13.34, envs finished 1
2026-01-17 13:26:00,969 : worker.worker : DEBUG : Step 98501, finished rewards -12.45, envs finished 1
2026-01-17 13:26:00,989 : worker.worker : DEBUG : Step 98505, finished rewards -1.00, envs finished 1
2026-01-17 13:26:01,070 : worker.worker : DEBUG : Step 98523, finished rewards -3.21, envs finished 1
2026-01-17 13:26:01,165 : agent.on_policy : DEBUG : Mean Losses: [6.957266166806221]
2026-01-17 13:26:01,363 : agent.on_policy : DEBUG : Mean Losses: [2.108266120776534]
2026-01-17 13:26:01,369 : worker.worker : DEBUG : Step 98561, finished rewards 22.62, envs finished 1
2026-01-17 13:26:01,426 : worker.worker : DEBUG : Step 98578, finished rewards -27.22, envs finished 1
2026-01-17 13:26:01,573 : agent.on_policy : DEBUG : Mean Losses: [5.211220446974039]
2026-01-17 13:26:01,629 : worker.worker : DEBUG : Step 98607, finished rewards 6.94, envs finished 1
2026-01-17 13:26:01,662 : worker.worker : DEBUG : Step 98614, finished rewards 12.01, envs finished 1
2026-01-17 13:26:01,795 : agent.on_policy : DEBUG : Mean Losses: [5.335619755089283]
2026-01-17 13:26:01,799 : worker.worker : DEBUG : Step 98624, finished rewards 4.74, envs finished 1
2026-01-17 13:26:01,857 : worker.worker : DEBUG : Step 98631, finished rewards -15.91, envs finished 1
2026-01-17 13:26:01,939 : worker.worker : DEBUG : Step 98646, finished rewards 4.14, envs finished 1
2026-01-17 13:26:01,998 : worker.worker : DEBUG : Step 98654, finished rewards 2.08, envs finished 1
2026-01-17 13:26:02,072 : agent.on_policy : DEBUG : Mean Losses: [6.594703443348408]
2026-01-17 13:26:02,309 : agent.on_policy : DEBUG : Mean Losses: [2.0705736596137285]
2026-01-17 13:26:02,320 : worker.worker : DEBUG : Step 98690, finished rewards 9.15, envs finished 1
2026-01-17 13:26:02,444 : worker.worker : DEBUG : Step 98712, finished rewards -1.30, envs finished 1
2026-01-17 13:26:02,597 : agent.on_policy : DEBUG : Mean Losses: [5.4811092130839825]
2026-01-17 13:26:02,617 : worker.worker : DEBUG : Step 98725, finished rewards 4.13, envs finished 1
2026-01-17 13:26:02,658 : worker.worker : DEBUG : Step 98736, finished rewards 12.12, envs finished 1
2026-01-17 13:26:02,758 : agent.on_policy : DEBUG : Mean Losses: [4.383229029364884]
2026-01-17 13:26:02,778 : worker.worker : DEBUG : Step 98757, finished rewards 0.25, envs finished 1
2026-01-17 13:26:02,808 : worker.worker : DEBUG : Step 98761, finished rewards 8.41, envs finished 1
2026-01-17 13:26:02,863 : worker.worker : DEBUG : Step 98766, finished rewards -20.86, envs finished 1
2026-01-17 13:26:03,046 : agent.on_policy : DEBUG : Mean Losses: [4.882992964237928]
2026-01-17 13:26:03,064 : worker.worker : DEBUG : Step 98787, finished rewards 0.13, envs finished 1
2026-01-17 13:26:03,296 : agent.on_policy : DEBUG : Mean Losses: [2.565519668161869]
2026-01-17 13:26:03,307 : worker.worker : DEBUG : Step 98818, finished rewards 1.47, envs finished 1
2026-01-17 13:26:03,507 : agent.on_policy : DEBUG : Mean Losses: [3.226025518961251]
2026-01-17 13:26:03,530 : worker.worker : DEBUG : Step 98852, finished rewards -0.49, envs finished 1
2026-01-17 13:26:03,552 : worker.worker : DEBUG : Step 98856, finished rewards 3.94, envs finished 1
2026-01-17 13:26:03,605 : worker.worker : DEBUG : Step 98869, finished rewards 12.52, envs finished 1
2026-01-17 13:26:03,612 : worker.worker : DEBUG : Step 98870, finished rewards -8.36, envs finished 1
2026-01-17 13:26:03,704 : agent.on_policy : DEBUG : Mean Losses: [7.815914016216993]
2026-01-17 13:26:03,766 : worker.worker : DEBUG : Step 98890, finished rewards 14.79, envs finished 1
2026-01-17 13:26:03,785 : worker.worker : DEBUG : Step 98893, finished rewards -4.22, envs finished 1
2026-01-17 13:26:03,952 : agent.on_policy : DEBUG : Mean Losses: [5.660991307348013]
2026-01-17 13:26:04,048 : worker.worker : DEBUG : Step 98920, finished rewards 17.79, envs finished 1
2026-01-17 13:26:04,137 : worker.worker : DEBUG : Step 98931, finished rewards -20.07, envs finished 1
2026-01-17 13:26:04,277 : agent.on_policy : DEBUG : Mean Losses: [4.693463817238808]
2026-01-17 13:26:04,352 : worker.worker : DEBUG : Step 98968, finished rewards 6.99, envs finished 1
2026-01-17 13:26:04,358 : worker.worker : DEBUG : Step 98969, finished rewards 19.75, envs finished 1
2026-01-17 13:26:04,384 : worker.worker : DEBUG : Step 98975, finished rewards 14.48, envs finished 1
2026-01-17 13:26:04,477 : agent.on_policy : DEBUG : Mean Losses: [7.934814028441906]
2026-01-17 13:26:04,552 : worker.worker : DEBUG : Step 98987, finished rewards 21.54, envs finished 1
2026-01-17 13:26:04,588 : worker.worker : DEBUG : Step 98993, finished rewards 17.90, envs finished 1
2026-01-17 13:26:04,618 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:26:04,721 : agent.on_policy : DEBUG : Mean Losses: [5.834191903471947]
2026-01-17 13:26:04,735 : worker.worker : DEBUG : Step 99011, finished rewards 24.32, envs finished 1
2026-01-17 13:26:04,756 : worker.worker : DEBUG : Step 99015, finished rewards 29.53, envs finished 1
2026-01-17 13:26:04,805 : worker.worker : DEBUG : Step 99019, finished rewards -24.36, envs finished 1
2026-01-17 13:26:04,970 : agent.on_policy : DEBUG : Mean Losses: [5.540788967162371]
2026-01-17 13:26:05,023 : worker.worker : DEBUG : Step 99049, finished rewards 32.31, envs finished 1
2026-01-17 13:26:05,197 : agent.on_policy : DEBUG : Mean Losses: [3.6388968117535114]
2026-01-17 13:26:05,219 : worker.worker : DEBUG : Step 99078, finished rewards 26.14, envs finished 1
2026-01-17 13:26:05,245 : worker.worker : DEBUG : Step 99083, finished rewards 13.63, envs finished 1
2026-01-17 13:26:05,364 : agent.on_policy : DEBUG : Mean Losses: [4.771457899361849]
2026-01-17 13:26:05,378 : worker.worker : DEBUG : Step 99107, finished rewards 24.06, envs finished 1
2026-01-17 13:26:05,488 : worker.worker : DEBUG : Step 99120, finished rewards -20.32, envs finished 1
2026-01-17 13:26:05,511 : worker.worker : DEBUG : Step 99123, finished rewards 3.81, envs finished 1
2026-01-17 13:26:05,591 : worker.worker : DEBUG : Step 99130, finished rewards 31.94, envs finished 1
2026-01-17 13:26:05,611 : worker.worker : DEBUG : Step 99132, finished rewards 1.13, envs finished 1
2026-01-17 13:26:05,730 : agent.on_policy : DEBUG : Mean Losses: [10.506574213504791]
2026-01-17 13:26:05,739 : worker.worker : DEBUG : Step 99138, finished rewards 4.30, envs finished 1
2026-01-17 13:26:05,864 : worker.worker : DEBUG : Step 99160, finished rewards 36.83, envs finished 1
2026-01-17 13:26:05,987 : agent.on_policy : DEBUG : Mean Losses: [3.856215436011553]
2026-01-17 13:26:06,171 : agent.on_policy : DEBUG : Mean Losses: [1.5544378943741322]
2026-01-17 13:26:06,177 : worker.worker : DEBUG : Step 99201, finished rewards 22.98, envs finished 1
2026-01-17 13:26:06,247 : worker.worker : DEBUG : Step 99222, finished rewards 26.78, envs finished 1
2026-01-17 13:26:06,270 : worker.worker : DEBUG : Step 99228, finished rewards 21.13, envs finished 1
2026-01-17 13:26:06,276 : worker.worker : DEBUG : Step 99229, finished rewards -1.29, envs finished 1
2026-01-17 13:26:06,382 : agent.on_policy : DEBUG : Mean Losses: [8.756353091448545]
2026-01-17 13:26:06,390 : worker.worker : DEBUG : Step 99233, finished rewards 10.08, envs finished 1
2026-01-17 13:26:06,462 : worker.worker : DEBUG : Step 99244, finished rewards 7.35, envs finished 1
2026-01-17 13:26:06,613 : agent.on_policy : DEBUG : Mean Losses: [3.119240801781416]
2026-01-17 13:26:06,642 : worker.worker : DEBUG : Step 99269, finished rewards -2.52, envs finished 1
2026-01-17 13:26:06,703 : worker.worker : DEBUG : Step 99285, finished rewards -0.58, envs finished 1
2026-01-17 13:26:06,744 : worker.worker : DEBUG : Step 99295, finished rewards 22.76, envs finished 1
2026-01-17 13:26:06,830 : agent.on_policy : DEBUG : Mean Losses: [5.9814826883375645]
2026-01-17 13:26:06,987 : worker.worker : DEBUG : Step 99326, finished rewards 21.64, envs finished 1
2026-01-17 13:26:06,999 : worker.worker : DEBUG : Step 99327, finished rewards 30.66, envs finished 1
2026-01-17 13:26:07,056 : agent.on_policy : DEBUG : Mean Losses: [6.553790098056197]
2026-01-17 13:26:07,070 : worker.worker : DEBUG : Step 99331, finished rewards 20.94, envs finished 1
2026-01-17 13:26:07,181 : worker.worker : DEBUG : Step 99353, finished rewards -3.08, envs finished 1
2026-01-17 13:26:07,262 : agent.on_policy : DEBUG : Mean Losses: [5.029210574924946]
2026-01-17 13:26:07,358 : worker.worker : DEBUG : Step 99382, finished rewards 20.31, envs finished 1
2026-01-17 13:26:07,381 : worker.worker : DEBUG : Step 99385, finished rewards 26.20, envs finished 1
2026-01-17 13:26:07,570 : agent.on_policy : DEBUG : Mean Losses: [6.6213167402893305]
2026-01-17 13:26:07,623 : worker.worker : DEBUG : Step 99400, finished rewards 8.84, envs finished 1
2026-01-17 13:26:07,701 : worker.worker : DEBUG : Step 99413, finished rewards -18.78, envs finished 1
2026-01-17 13:26:07,946 : agent.on_policy : DEBUG : Mean Losses: [4.330922763794661]
2026-01-17 13:26:08,033 : worker.worker : DEBUG : Step 99438, finished rewards 9.52, envs finished 1
2026-01-17 13:26:08,112 : worker.worker : DEBUG : Step 99445, finished rewards 23.76, envs finished 1
2026-01-17 13:26:08,143 : worker.worker : DEBUG : Step 99448, finished rewards 3.60, envs finished 1
2026-01-17 13:26:08,197 : worker.worker : DEBUG : Step 99454, finished rewards 2.24, envs finished 1
2026-01-17 13:26:08,311 : agent.on_policy : DEBUG : Mean Losses: [8.529397837817669]
2026-01-17 13:26:08,453 : worker.worker : DEBUG : Step 99482, finished rewards 19.38, envs finished 2
2026-01-17 13:26:08,595 : agent.on_policy : DEBUG : Mean Losses: [5.298509145155549]
2026-01-17 13:26:08,780 : worker.worker : DEBUG : Step 99514, finished rewards 18.27, envs finished 1
2026-01-17 13:26:08,869 : agent.on_policy : DEBUG : Mean Losses: [3.565873861312866]
2026-01-17 13:26:08,876 : worker.worker : DEBUG : Step 99521, finished rewards 5.66, envs finished 1
2026-01-17 13:26:09,029 : worker.worker : DEBUG : Step 99541, finished rewards 15.74, envs finished 1
2026-01-17 13:26:09,102 : worker.worker : DEBUG : Step 99547, finished rewards 17.94, envs finished 1
2026-01-17 13:26:09,220 : agent.on_policy : DEBUG : Mean Losses: [6.7371798269450665]
2026-01-17 13:26:09,255 : worker.worker : DEBUG : Step 99560, finished rewards 13.68, envs finished 1
2026-01-17 13:26:08,964 : worker.worker : DEBUG : Step 99574, finished rewards -2.68, envs finished 1
2026-01-17 13:26:08,651 : agent.on_policy : DEBUG : Mean Losses: [4.625713323242962]
2026-01-17 13:26:08,668 : worker.worker : DEBUG : Step 99587, finished rewards 11.47, envs finished 1
2026-01-17 13:26:09,032 : agent.on_policy : DEBUG : Mean Losses: [2.5772324167191982]
2026-01-17 13:26:09,078 : worker.worker : DEBUG : Step 99620, finished rewards -9.94, envs finished 1
2026-01-17 13:26:09,140 : worker.worker : DEBUG : Step 99634, finished rewards 22.58, envs finished 1
2026-01-17 13:26:09,196 : worker.worker : DEBUG : Step 99647, finished rewards 18.04, envs finished 1
2026-01-17 13:26:09,328 : agent.on_policy : DEBUG : Mean Losses: [6.848914623260498]
2026-01-17 13:26:09,339 : worker.worker : DEBUG : Step 99649, finished rewards -3.95, envs finished 1
2026-01-17 13:26:09,507 : worker.worker : DEBUG : Step 99673, finished rewards 19.15, envs finished 1
2026-01-17 13:26:09,522 : worker.worker : DEBUG : Step 99675, finished rewards -19.17, envs finished 1
2026-01-17 13:26:09,612 : agent.on_policy : DEBUG : Mean Losses: [6.168855711817741]
2026-01-17 13:26:09,661 : worker.worker : DEBUG : Step 99689, finished rewards -1.44, envs finished 1
2026-01-17 13:26:09,909 : agent.on_policy : DEBUG : Mean Losses: [2.3199912775307894]
2026-01-17 13:26:09,913 : worker.worker : DEBUG : Step 99712, finished rewards 23.61, envs finished 1
2026-01-17 13:26:09,926 : worker.worker : DEBUG : Step 99714, finished rewards -1.94, envs finished 1
2026-01-17 13:26:10,160 : agent.on_policy : DEBUG : Mean Losses: [2.531489845365286]
2026-01-17 13:26:10,178 : worker.worker : DEBUG : Step 99748, finished rewards 17.11, envs finished 1
2026-01-17 13:26:10,236 : worker.worker : DEBUG : Step 99760, finished rewards -1.19, envs finished 1
2026-01-17 13:26:10,396 : agent.on_policy : DEBUG : Mean Losses: [4.593648491427302]
2026-01-17 13:26:10,454 : worker.worker : DEBUG : Step 99790, finished rewards -3.25, envs finished 2
2026-01-17 13:26:10,548 : worker.worker : DEBUG : Step 99806, finished rewards 23.43, envs finished 1
2026-01-17 13:26:10,666 : agent.on_policy : DEBUG : Mean Losses: [9.32327101007104]
2026-01-17 13:26:10,728 : worker.worker : DEBUG : Step 99816, finished rewards 14.18, envs finished 1
2026-01-17 13:26:10,736 : worker.worker : DEBUG : Step 99817, finished rewards -7.68, envs finished 1
2026-01-17 13:26:10,857 : worker.worker : DEBUG : Step 99836, finished rewards 36.41, envs finished 1
2026-01-17 13:26:10,936 : agent.on_policy : DEBUG : Mean Losses: [8.010776832699776]
2026-01-17 13:26:10,953 : worker.worker : DEBUG : Step 99843, finished rewards -21.95, envs finished 1
2026-01-17 13:26:11,096 : worker.worker : DEBUG : Step 99863, finished rewards 9.46, envs finished 1
2026-01-17 13:26:11,193 : agent.on_policy : DEBUG : Mean Losses: [3.511731691658497]
2026-01-17 13:26:11,406 : agent.on_policy : DEBUG : Mean Losses: [2.141178820282221]
2026-01-17 13:26:11,417 : worker.worker : DEBUG : Step 99906, finished rewards 7.18, envs finished 1
2026-01-17 13:26:11,430 : worker.worker : DEBUG : Step 99908, finished rewards 25.35, envs finished 1
2026-01-17 13:26:11,468 : worker.worker : DEBUG : Step 99910, finished rewards 38.05, envs finished 1
2026-01-17 13:26:11,566 : worker.worker : DEBUG : Step 99919, finished rewards 9.01, envs finished 1
2026-01-17 13:26:11,593 : worker.worker : DEBUG : Step 99921, finished rewards 2.79, envs finished 1
2026-01-17 13:26:11,790 : agent.on_policy : DEBUG : Mean Losses: [8.058647219091654]
2026-01-17 13:26:11,831 : worker.worker : DEBUG : Step 99945, finished rewards -4.04, envs finished 1
2026-01-17 13:26:11,894 : worker.worker : DEBUG : Step 99960, finished rewards 21.83, envs finished 1
2026-01-17 13:26:12,003 : agent.on_policy : DEBUG : Mean Losses: [5.612487033009529]
2026-01-17 13:26:12,055 : worker.worker : DEBUG : Step 99977, finished rewards 0.27, envs finished 1
2026-01-17 13:26:12,109 : worker.worker : DEBUG : Step 99991, finished rewards 31.16, envs finished 1
2026-01-17 13:26:12,138 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:26:12,226 : agent.on_policy : DEBUG : Mean Losses: [5.1705855540931225]
2026-01-17 13:26:12,232 : worker.worker : INFO : Step 100000, Avg Reward 7.3655, Max Reward 38.0470, Loss [5.39696565]
2026-01-17 13:26:12,235 : network.model : INFO : Saved model to logs/Acrobot-Sarsa/model.pt
2026-01-17 13:26:14,358 : evaluate.evaluate : INFO : Evaluation results: mean = -158.00, std = 0.00, min = -158.00, max = -158.00, count = 1
2026-01-17 13:26:15,725 : worker.worker : DEBUG : Step 100023, finished rewards 9.59, envs finished 1
2026-01-17 13:26:15,728 : worker.worker : DEBUG : Step 100024, finished rewards 6.23, envs finished 1
2026-01-17 13:26:15,749 : worker.worker : DEBUG : Step 100030, finished rewards 11.01, envs finished 1
2026-01-17 13:26:15,808 : agent.on_policy : DEBUG : Mean Losses: [7.429357670247555]
2026-01-17 13:26:15,844 : worker.worker : DEBUG : Step 100040, finished rewards 4.62, envs finished 1
2026-01-17 13:26:15,927 : worker.worker : DEBUG : Step 100056, finished rewards 9.65, envs finished 1
2026-01-17 13:26:16,067 : agent.on_policy : DEBUG : Mean Losses: [4.293587997555733]
2026-01-17 13:26:16,131 : worker.worker : DEBUG : Step 100084, finished rewards 2.89, envs finished 1
2026-01-17 13:26:16,212 : agent.on_policy : DEBUG : Mean Losses: [2.8616204615682364]
2026-01-17 13:26:16,247 : worker.worker : DEBUG : Step 100100, finished rewards 11.18, envs finished 1
2026-01-17 13:26:16,299 : worker.worker : DEBUG : Step 100114, finished rewards 30.21, envs finished 1
2026-01-17 13:26:16,308 : worker.worker : DEBUG : Step 100117, finished rewards -11.36, envs finished 1
2026-01-17 13:26:16,329 : worker.worker : DEBUG : Step 100121, finished rewards 20.11, envs finished 1
2026-01-17 13:26:16,435 : agent.on_policy : DEBUG : Mean Losses: [9.794159658253193]
2026-01-17 13:26:16,485 : worker.worker : DEBUG : Step 100138, finished rewards 31.12, envs finished 1
2026-01-17 13:26:16,536 : worker.worker : DEBUG : Step 100148, finished rewards -0.54, envs finished 1
2026-01-17 13:26:16,668 : agent.on_policy : DEBUG : Mean Losses: [4.851806707680225]
2026-01-17 13:26:16,679 : worker.worker : DEBUG : Step 100164, finished rewards 2.52, envs finished 1
2026-01-17 13:26:16,850 : agent.on_policy : DEBUG : Mean Losses: [2.1658668220043182]
2026-01-17 13:26:16,884 : worker.worker : DEBUG : Step 100198, finished rewards 29.28, envs finished 1
2026-01-17 13:26:17,043 : worker.worker : DEBUG : Step 100214, finished rewards -3.20, envs finished 1
2026-01-17 13:26:17,217 : agent.on_policy : DEBUG : Mean Losses: [6.0913581773638725]
2026-01-17 13:26:17,235 : worker.worker : DEBUG : Step 100230, finished rewards 7.62, envs finished 1
2026-01-17 13:26:17,294 : worker.worker : DEBUG : Step 100245, finished rewards 4.28, envs finished 1
2026-01-17 13:26:17,329 : worker.worker : DEBUG : Step 100254, finished rewards 12.67, envs finished 1
2026-01-17 13:26:17,426 : agent.on_policy : DEBUG : Mean Losses: [7.193309001624584]
2026-01-17 13:26:17,450 : worker.worker : DEBUG : Step 100261, finished rewards 21.30, envs finished 1
2026-01-17 13:26:17,460 : worker.worker : DEBUG : Step 100263, finished rewards 5.36, envs finished 1
2026-01-17 13:26:17,565 : worker.worker : DEBUG : Step 100277, finished rewards 35.61, envs finished 1
2026-01-17 13:26:17,720 : agent.on_policy : DEBUG : Mean Losses: [5.894304082728922]
2026-01-17 13:26:17,743 : worker.worker : DEBUG : Step 100294, finished rewards -42.67, envs finished 1
2026-01-17 13:26:17,874 : agent.on_policy : DEBUG : Mean Losses: [2.204142214730382]
2026-01-17 13:26:17,980 : worker.worker : DEBUG : Step 100344, finished rewards 1.24, envs finished 1
2026-01-17 13:26:18,093 : agent.on_policy : DEBUG : Mean Losses: [4.813296765089035]
2026-01-17 13:26:18,100 : worker.worker : DEBUG : Step 100354, finished rewards 24.67, envs finished 1
2026-01-17 13:26:18,125 : worker.worker : DEBUG : Step 100359, finished rewards 19.75, envs finished 1
2026-01-17 13:26:18,236 : worker.worker : DEBUG : Step 100378, finished rewards -0.82, envs finished 1
2026-01-17 13:26:18,340 : agent.on_policy : DEBUG : Mean Losses: [7.195410631597042]
2026-01-17 13:26:18,344 : worker.worker : DEBUG : Step 100385, finished rewards 10.71, envs finished 1
2026-01-17 13:26:18,366 : worker.worker : DEBUG : Step 100391, finished rewards -16.07, envs finished 1
2026-01-17 13:26:18,389 : worker.worker : DEBUG : Step 100394, finished rewards -24.21, envs finished 1
2026-01-17 13:26:18,459 : worker.worker : DEBUG : Step 100406, finished rewards 9.32, envs finished 1
2026-01-17 13:26:18,582 : agent.on_policy : DEBUG : Mean Losses: [6.102449793368578]
2026-01-17 13:26:18,673 : worker.worker : DEBUG : Step 100443, finished rewards 29.80, envs finished 1
2026-01-17 13:26:18,775 : agent.on_policy : DEBUG : Mean Losses: [3.9264911748468876]
2026-01-17 13:26:18,899 : worker.worker : DEBUG : Step 100471, finished rewards 23.41, envs finished 1
2026-01-17 13:26:19,014 : agent.on_policy : DEBUG : Mean Losses: [6.3079987317323685]
2026-01-17 13:26:19,029 : worker.worker : DEBUG : Step 100484, finished rewards 26.03, envs finished 1
2026-01-17 13:26:19,093 : worker.worker : DEBUG : Step 100490, finished rewards -6.38, envs finished 1
2026-01-17 13:26:19,110 : worker.worker : DEBUG : Step 100491, finished rewards 18.20, envs finished 1
2026-01-17 13:26:19,160 : worker.worker : DEBUG : Step 100498, finished rewards -13.38, envs finished 1
2026-01-17 13:26:19,240 : worker.worker : DEBUG : Step 100503, finished rewards 6.59, envs finished 1
2026-01-17 13:26:19,489 : agent.on_policy : DEBUG : Mean Losses: [8.887297540903091]
2026-01-17 13:26:19,638 : agent.on_policy : DEBUG : Mean Losses: [1.1671830229461193]
2026-01-17 13:26:19,685 : worker.worker : DEBUG : Step 100548, finished rewards -6.76, envs finished 1
2026-01-17 13:26:19,876 : agent.on_policy : DEBUG : Mean Losses: [3.306284138932824]
2026-01-17 13:26:19,909 : worker.worker : DEBUG : Step 100584, finished rewards -7.06, envs finished 1
2026-01-17 13:26:19,950 : worker.worker : DEBUG : Step 100595, finished rewards 3.97, envs finished 1
2026-01-17 13:26:19,959 : worker.worker : DEBUG : Step 100597, finished rewards 12.53, envs finished 1
2026-01-17 13:26:19,971 : worker.worker : DEBUG : Step 100600, finished rewards 11.63, envs finished 1
2026-01-17 13:26:20,008 : worker.worker : DEBUG : Step 100607, finished rewards 5.28, envs finished 1
2026-01-17 13:26:20,064 : agent.on_policy : DEBUG : Mean Losses: [9.717565760016441]
2026-01-17 13:26:20,116 : worker.worker : DEBUG : Step 100623, finished rewards 2.28, envs finished 1
2026-01-17 13:26:20,125 : worker.worker : DEBUG : Step 100625, finished rewards -2.65, envs finished 1
2026-01-17 13:26:20,277 : agent.on_policy : DEBUG : Mean Losses: [3.6268168967217207]
2026-01-17 13:26:20,302 : worker.worker : DEBUG : Step 100647, finished rewards 18.74, envs finished 1
2026-01-17 13:26:20,479 : agent.on_policy : DEBUG : Mean Losses: [2.3229594193398952]
2026-01-17 13:26:20,561 : worker.worker : DEBUG : Step 100694, finished rewards 13.17, envs finished 1
2026-01-17 13:26:20,690 : agent.on_policy : DEBUG : Mean Losses: [3.7092770785093307]
2026-01-17 13:26:20,745 : worker.worker : DEBUG : Step 100712, finished rewards 10.79, envs finished 1
2026-01-17 13:26:20,750 : worker.worker : DEBUG : Step 100713, finished rewards 14.55, envs finished 2
2026-01-17 13:26:20,767 : worker.worker : DEBUG : Step 100716, finished rewards 12.77, envs finished 1
2026-01-17 13:26:20,860 : worker.worker : DEBUG : Step 100733, finished rewards -5.39, envs finished 1
2026-01-17 13:26:20,950 : agent.on_policy : DEBUG : Mean Losses: [10.087832257151604]
2026-01-17 13:26:21,176 : agent.on_policy : DEBUG : Mean Losses: [2.4323515072464943]
2026-01-17 13:26:21,278 : worker.worker : DEBUG : Step 100792, finished rewards -20.75, envs finished 1
2026-01-17 13:26:21,411 : agent.on_policy : DEBUG : Mean Losses: [4.906064122915268]
2026-01-17 13:26:21,482 : worker.worker : DEBUG : Step 100812, finished rewards 21.64, envs finished 1
2026-01-17 13:26:21,486 : worker.worker : DEBUG : Step 100813, finished rewards -30.56, envs finished 1
2026-01-17 13:26:21,549 : worker.worker : DEBUG : Step 100830, finished rewards 19.84, envs finished 1
2026-01-17 13:26:21,659 : agent.on_policy : DEBUG : Mean Losses: [8.589424937963486]
2026-01-17 13:26:21,660 : worker.worker : DEBUG : Step 100832, finished rewards -11.00, envs finished 1
2026-01-17 13:26:21,805 : worker.worker : DEBUG : Step 100848, finished rewards -9.59, envs finished 2
2026-01-17 13:26:21,972 : worker.worker : DEBUG : Step 100860, finished rewards -19.59, envs finished 1
2026-01-17 13:26:22,089 : agent.on_policy : DEBUG : Mean Losses: [7.4964693412184715]
2026-01-17 13:26:22,311 : agent.on_policy : DEBUG : Mean Losses: [1.2671894393861294]
2026-01-17 13:26:22,313 : worker.worker : DEBUG : Step 100896, finished rewards 16.33, envs finished 1
2026-01-17 13:26:22,371 : worker.worker : DEBUG : Step 100911, finished rewards 20.01, envs finished 1
2026-01-17 13:26:22,413 : worker.worker : DEBUG : Step 100923, finished rewards 23.62, envs finished 1
2026-01-17 13:26:22,535 : agent.on_policy : DEBUG : Mean Losses: [6.333825193345547]
2026-01-17 13:26:22,556 : worker.worker : DEBUG : Step 100932, finished rewards 4.46, envs finished 1
2026-01-17 13:26:22,609 : worker.worker : DEBUG : Step 100937, finished rewards 13.60, envs finished 1
2026-01-17 13:26:22,664 : worker.worker : DEBUG : Step 100944, finished rewards 21.66, envs finished 1
2026-01-17 13:26:22,715 : worker.worker : DEBUG : Step 100951, finished rewards 25.19, envs finished 1
2026-01-17 13:26:22,887 : agent.on_policy : DEBUG : Mean Losses: [9.849664524197578]
2026-01-17 13:26:22,942 : worker.worker : DEBUG : Step 100973, finished rewards 3.15, envs finished 1
2026-01-17 13:26:23,107 : agent.on_policy : DEBUG : Mean Losses: [2.16272746399045]
2026-01-17 13:26:23,117 : worker.worker : DEBUG : Step 100995, finished rewards 19.13, envs finished 1
2026-01-17 13:26:23,128 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:26:23,189 : worker.worker : DEBUG : Step 101015, finished rewards 30.14, envs finished 1
2026-01-17 13:26:23,273 : agent.on_policy : DEBUG : Mean Losses: [5.741719424724579]
2026-01-17 13:26:23,290 : worker.worker : DEBUG : Step 101025, finished rewards 6.51, envs finished 1
2026-01-17 13:26:23,375 : worker.worker : DEBUG : Step 101043, finished rewards 21.03, envs finished 1
2026-01-17 13:26:23,522 : agent.on_policy : DEBUG : Mean Losses: [5.112217612564564]
2026-01-17 13:26:23,530 : worker.worker : DEBUG : Step 101058, finished rewards 4.59, envs finished 1
2026-01-17 13:26:23,538 : worker.worker : DEBUG : Step 101060, finished rewards -8.88, envs finished 1
2026-01-17 13:26:23,559 : worker.worker : DEBUG : Step 101063, finished rewards 8.10, envs finished 1
2026-01-17 13:26:23,618 : worker.worker : DEBUG : Step 101079, finished rewards 13.32, envs finished 1
2026-01-17 13:26:23,706 : agent.on_policy : DEBUG : Mean Losses: [5.460786012932658]
2026-01-17 13:26:23,807 : worker.worker : DEBUG : Step 101106, finished rewards 25.75, envs finished 1
2026-01-17 13:26:24,061 : agent.on_policy : DEBUG : Mean Losses: [3.483770802617073]
2026-01-17 13:26:24,105 : worker.worker : DEBUG : Step 101127, finished rewards 30.12, envs finished 1
2026-01-17 13:26:24,170 : worker.worker : DEBUG : Step 101141, finished rewards 18.98, envs finished 2
2026-01-17 13:26:24,283 : agent.on_policy : DEBUG : Mean Losses: [7.699101705104113]
2026-01-17 13:26:24,304 : worker.worker : DEBUG : Step 101156, finished rewards -21.01, envs finished 1
2026-01-17 13:26:24,374 : worker.worker : DEBUG : Step 101172, finished rewards 13.82, envs finished 1
2026-01-17 13:26:24,502 : agent.on_policy : DEBUG : Mean Losses: [4.459198415279388]
2026-01-17 13:26:24,543 : worker.worker : DEBUG : Step 101196, finished rewards 26.25, envs finished 1
2026-01-17 13:26:24,568 : worker.worker : DEBUG : Step 101202, finished rewards 3.47, envs finished 1
2026-01-17 13:26:24,582 : worker.worker : DEBUG : Step 101205, finished rewards -10.24, envs finished 1
2026-01-17 13:26:24,663 : agent.on_policy : DEBUG : Mean Losses: [5.017259489744902]
2026-01-17 13:26:24,781 : worker.worker : DEBUG : Step 101237, finished rewards 12.94, envs finished 1
2026-01-17 13:26:24,856 : worker.worker : DEBUG : Step 101246, finished rewards 24.60, envs finished 1
2026-01-17 13:26:24,918 : agent.on_policy : DEBUG : Mean Losses: [5.322038620710373]
2026-01-17 13:26:25,143 : agent.on_policy : DEBUG : Mean Losses: [2.3270340263843536]
2026-01-17 13:26:25,160 : worker.worker : DEBUG : Step 101285, finished rewards 5.19, envs finished 1
2026-01-17 13:26:25,241 : worker.worker : DEBUG : Step 101308, finished rewards -30.62, envs finished 1
2026-01-17 13:26:25,247 : worker.worker : DEBUG : Step 101309, finished rewards 11.24, envs finished 1
2026-01-17 13:26:25,354 : agent.on_policy : DEBUG : Mean Losses: [6.912925969809294]
2026-01-17 13:26:25,391 : worker.worker : DEBUG : Step 101318, finished rewards -28.88, envs finished 1
2026-01-17 13:26:25,488 : worker.worker : DEBUG : Step 101336, finished rewards -10.12, envs finished 1
2026-01-17 13:26:25,597 : agent.on_policy : DEBUG : Mean Losses: [3.8682652935385704]
2026-01-17 13:26:25,599 : worker.worker : DEBUG : Step 101344, finished rewards 19.65, envs finished 1
2026-01-17 13:26:25,615 : worker.worker : DEBUG : Step 101348, finished rewards 10.97, envs finished 1
2026-01-17 13:26:25,796 : agent.on_policy : DEBUG : Mean Losses: [2.854073276743293]
2026-01-17 13:26:25,798 : worker.worker : DEBUG : Step 101376, finished rewards -36.25, envs finished 1
2026-01-17 13:26:25,835 : worker.worker : DEBUG : Step 101385, finished rewards 18.95, envs finished 1
2026-01-17 13:26:25,911 : worker.worker : DEBUG : Step 101407, finished rewards 18.67, envs finished 1
2026-01-17 13:26:25,957 : agent.on_policy : DEBUG : Mean Losses: [5.302595913410187]
2026-01-17 13:26:26,170 : agent.on_policy : DEBUG : Mean Losses: [1.9429879747331142]
2026-01-17 13:26:26,179 : worker.worker : DEBUG : Step 101443, finished rewards -7.38, envs finished 1
2026-01-17 13:26:26,360 : agent.on_policy : DEBUG : Mean Losses: [4.513630360364914]
2026-01-17 13:26:26,384 : worker.worker : DEBUG : Step 101476, finished rewards 24.75, envs finished 1
2026-01-17 13:26:26,413 : worker.worker : DEBUG : Step 101481, finished rewards -6.49, envs finished 1
2026-01-17 13:26:26,465 : worker.worker : DEBUG : Step 101493, finished rewards -33.67, envs finished 1
2026-01-17 13:26:26,481 : worker.worker : DEBUG : Step 101496, finished rewards -19.20, envs finished 1
2026-01-17 13:26:26,494 : worker.worker : DEBUG : Step 101499, finished rewards 25.60, envs finished 1
2026-01-17 13:26:26,586 : agent.on_policy : DEBUG : Mean Losses: [9.408040319569409]
2026-01-17 13:26:26,748 : worker.worker : DEBUG : Step 101529, finished rewards -15.15, envs finished 1
2026-01-17 13:26:26,837 : agent.on_policy : DEBUG : Mean Losses: [2.9672657661139965]
2026-01-17 13:26:26,844 : worker.worker : DEBUG : Step 101538, finished rewards -54.71, envs finished 1
2026-01-17 13:26:27,040 : agent.on_policy : DEBUG : Mean Losses: [3.086067121475935]
2026-01-17 13:26:27,050 : worker.worker : DEBUG : Step 101571, finished rewards 26.78, envs finished 1
2026-01-17 13:26:27,057 : worker.worker : DEBUG : Step 101573, finished rewards 20.99, envs finished 1
2026-01-17 13:26:27,116 : worker.worker : DEBUG : Step 101589, finished rewards 23.67, envs finished 1
2026-01-17 13:26:27,223 : agent.on_policy : DEBUG : Mean Losses: [5.828048233874142]
2026-01-17 13:26:27,304 : worker.worker : DEBUG : Step 101617, finished rewards -21.97, envs finished 1
2026-01-17 13:26:27,401 : worker.worker : DEBUG : Step 101629, finished rewards 26.14, envs finished 1
2026-01-17 13:26:27,564 : agent.on_policy : DEBUG : Mean Losses: [6.036072235554457]
2026-01-17 13:26:27,572 : worker.worker : DEBUG : Step 101633, finished rewards -6.95, envs finished 1
2026-01-17 13:26:27,673 : worker.worker : DEBUG : Step 101654, finished rewards -9.75, envs finished 1
2026-01-17 13:26:27,791 : agent.on_policy : DEBUG : Mean Losses: [5.028508523479104]
2026-01-17 13:26:27,811 : worker.worker : DEBUG : Step 101667, finished rewards 22.55, envs finished 1
2026-01-17 13:26:27,866 : worker.worker : DEBUG : Step 101674, finished rewards -7.99, envs finished 1
2026-01-17 13:26:27,905 : worker.worker : DEBUG : Step 101682, finished rewards 11.49, envs finished 1
2026-01-17 13:26:28,035 : agent.on_policy : DEBUG : Mean Losses: [5.80377434194088]
2026-01-17 13:26:28,273 : agent.on_policy : DEBUG : Mean Losses: [2.993471149355173]
2026-01-17 13:26:28,295 : worker.worker : DEBUG : Step 101732, finished rewards 19.11, envs finished 1
2026-01-17 13:26:28,302 : worker.worker : DEBUG : Step 101733, finished rewards -10.85, envs finished 1
2026-01-17 13:26:28,387 : worker.worker : DEBUG : Step 101746, finished rewards 6.06, envs finished 1
2026-01-17 13:26:28,422 : worker.worker : DEBUG : Step 101752, finished rewards 21.75, envs finished 1
2026-01-17 13:26:28,557 : agent.on_policy : DEBUG : Mean Losses: [7.87794891372323]
2026-01-17 13:26:28,633 : worker.worker : DEBUG : Step 101768, finished rewards -13.30, envs finished 1
2026-01-17 13:26:28,702 : worker.worker : DEBUG : Step 101778, finished rewards 21.42, envs finished 1
2026-01-17 13:26:28,769 : worker.worker : DEBUG : Step 101784, finished rewards 10.65, envs finished 1
2026-01-17 13:26:28,799 : worker.worker : DEBUG : Step 101789, finished rewards 1.61, envs finished 1
2026-01-17 13:26:28,906 : agent.on_policy : DEBUG : Mean Losses: [8.533977292478085]
2026-01-17 13:26:29,108 : agent.on_policy : DEBUG : Mean Losses: [1.224674141034484]
2026-01-17 13:26:29,132 : worker.worker : DEBUG : Step 101831, finished rewards 18.54, envs finished 1
2026-01-17 13:26:29,164 : worker.worker : DEBUG : Step 101839, finished rewards 22.80, envs finished 1
2026-01-17 13:26:29,168 : worker.worker : DEBUG : Step 101840, finished rewards 12.53, envs finished 1
2026-01-17 13:26:29,260 : agent.on_policy : DEBUG : Mean Losses: [6.469124376773834]
2026-01-17 13:26:29,276 : worker.worker : DEBUG : Step 101860, finished rewards 11.84, envs finished 1
2026-01-17 13:26:29,302 : worker.worker : DEBUG : Step 101865, finished rewards 21.60, envs finished 1
2026-01-17 13:26:29,528 : worker.worker : DEBUG : Step 101887, finished rewards 16.26, envs finished 1
2026-01-17 13:26:29,644 : agent.on_policy : DEBUG : Mean Losses: [6.290249869227409]
2026-01-17 13:26:29,676 : worker.worker : DEBUG : Step 101897, finished rewards 6.57, envs finished 1
2026-01-17 13:26:29,713 : worker.worker : DEBUG : Step 101900, finished rewards 12.50, envs finished 1
2026-01-17 13:26:29,837 : agent.on_policy : DEBUG : Mean Losses: [4.323780309408903]
2026-01-17 13:26:29,917 : worker.worker : DEBUG : Step 101931, finished rewards 25.83, envs finished 1
2026-01-17 13:26:29,955 : worker.worker : DEBUG : Step 101938, finished rewards 20.95, envs finished 1
2026-01-17 13:26:30,051 : worker.worker : DEBUG : Step 101950, finished rewards 3.10, envs finished 1
2026-01-17 13:26:30,150 : agent.on_policy : DEBUG : Mean Losses: [7.266035880893469]
2026-01-17 13:26:30,252 : worker.worker : DEBUG : Step 101970, finished rewards 17.10, envs finished 1
2026-01-17 13:26:30,397 : agent.on_policy : DEBUG : Mean Losses: [4.760531708598137]
2026-01-17 13:26:30,407 : worker.worker : DEBUG : Step 101986, finished rewards 27.81, envs finished 1
2026-01-17 13:26:30,412 : worker.worker : DEBUG : Step 101987, finished rewards 17.66, envs finished 1
2026-01-17 13:26:30,454 : worker.worker : DEBUG : Step 101998, finished rewards -12.54, envs finished 1
2026-01-17 13:26:30,455 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:26:30,575 : agent.on_policy : DEBUG : Mean Losses: [4.574815168976784]
2026-01-17 13:26:30,587 : worker.worker : DEBUG : Step 102019, finished rewards 26.45, envs finished 1
2026-01-17 13:26:30,700 : worker.worker : DEBUG : Step 102041, finished rewards 24.52, envs finished 1
2026-01-17 13:26:30,885 : agent.on_policy : DEBUG : Mean Losses: [5.683735080063343]
2026-01-17 13:26:31,199 : agent.on_policy : DEBUG : Mean Losses: [3.3941138684749603]
2026-01-17 13:26:31,219 : worker.worker : DEBUG : Step 102084, finished rewards 21.37, envs finished 1
2026-01-17 13:26:31,325 : worker.worker : DEBUG : Step 102102, finished rewards 7.22, envs finished 1
2026-01-17 13:26:31,338 : worker.worker : DEBUG : Step 102104, finished rewards -22.39, envs finished 2
2026-01-17 13:26:31,466 : agent.on_policy : DEBUG : Mean Losses: [9.071499980986118]
2026-01-17 13:26:31,522 : worker.worker : DEBUG : Step 102119, finished rewards 2.32, envs finished 1
2026-01-17 13:26:31,614 : worker.worker : DEBUG : Step 102133, finished rewards 24.75, envs finished 1
2026-01-17 13:26:31,653 : worker.worker : DEBUG : Step 102137, finished rewards 6.58, envs finished 1
2026-01-17 13:26:31,729 : agent.on_policy : DEBUG : Mean Losses: [5.995562786236405]
2026-01-17 13:26:31,743 : worker.worker : DEBUG : Step 102148, finished rewards -78.15, envs finished 1
2026-01-17 13:26:31,925 : agent.on_policy : DEBUG : Mean Losses: [2.20254148170352]
2026-01-17 13:26:31,970 : worker.worker : DEBUG : Step 102190, finished rewards 28.72, envs finished 1
2026-01-17 13:26:31,998 : worker.worker : DEBUG : Step 102197, finished rewards 23.82, envs finished 1
2026-01-17 13:26:32,011 : worker.worker : DEBUG : Step 102200, finished rewards 18.94, envs finished 1
2026-01-17 13:26:32,026 : worker.worker : DEBUG : Step 102203, finished rewards 3.27, envs finished 1
2026-01-17 13:26:32,137 : agent.on_policy : DEBUG : Mean Losses: [10.155731819570065]
2026-01-17 13:26:32,247 : worker.worker : DEBUG : Step 102226, finished rewards 12.72, envs finished 1
2026-01-17 13:26:32,421 : agent.on_policy : DEBUG : Mean Losses: [3.429587360471487]
2026-01-17 13:26:32,482 : worker.worker : DEBUG : Step 102252, finished rewards 6.27, envs finished 1
2026-01-17 13:26:32,526 : worker.worker : DEBUG : Step 102260, finished rewards 1.75, envs finished 1
2026-01-17 13:26:32,689 : agent.on_policy : DEBUG : Mean Losses: [4.738720715045929]
2026-01-17 13:26:32,763 : worker.worker : DEBUG : Step 102289, finished rewards 26.14, envs finished 1
2026-01-17 13:26:32,802 : worker.worker : DEBUG : Step 102299, finished rewards 17.03, envs finished 1
2026-01-17 13:26:32,932 : agent.on_policy : DEBUG : Mean Losses: [6.000927582383156]
2026-01-17 13:26:33,056 : worker.worker : DEBUG : Step 102320, finished rewards -5.03, envs finished 1
2026-01-17 13:26:33,174 : worker.worker : DEBUG : Step 102334, finished rewards -6.10, envs finished 1
2026-01-17 13:26:33,358 : agent.on_policy : DEBUG : Mean Losses: [5.404377639293671]
2026-01-17 13:26:33,435 : worker.worker : DEBUG : Step 102342, finished rewards 6.59, envs finished 1
2026-01-17 13:26:33,699 : agent.on_policy : DEBUG : Mean Losses: [2.553095083683729]
2026-01-17 13:26:33,736 : worker.worker : DEBUG : Step 102377, finished rewards -70.76, envs finished 1
2026-01-17 13:26:33,753 : worker.worker : DEBUG : Step 102381, finished rewards 24.36, envs finished 1
2026-01-17 13:26:33,791 : worker.worker : DEBUG : Step 102390, finished rewards -4.30, envs finished 1
2026-01-17 13:26:33,826 : worker.worker : DEBUG : Step 102399, finished rewards -7.24, envs finished 1
2026-01-17 13:26:33,884 : agent.on_policy : DEBUG : Mean Losses: [6.805352438241243]
2026-01-17 13:26:33,939 : worker.worker : DEBUG : Step 102416, finished rewards 6.06, envs finished 1
2026-01-17 13:26:34,091 : agent.on_policy : DEBUG : Mean Losses: [2.6593112470582128]
2026-01-17 13:26:34,138 : worker.worker : DEBUG : Step 102446, finished rewards -0.81, envs finished 1
2026-01-17 13:26:34,154 : worker.worker : DEBUG : Step 102450, finished rewards 6.55, envs finished 1
2026-01-17 13:26:34,249 : agent.on_policy : DEBUG : Mean Losses: [4.813172556459904]
2026-01-17 13:26:34,279 : worker.worker : DEBUG : Step 102471, finished rewards 25.56, envs finished 1
2026-01-17 13:26:34,292 : worker.worker : DEBUG : Step 102473, finished rewards -0.90, envs finished 1
2026-01-17 13:26:34,529 : agent.on_policy : DEBUG : Mean Losses: [4.571990791708231]
2026-01-17 13:26:34,531 : worker.worker : DEBUG : Step 102496, finished rewards 20.28, envs finished 1
2026-01-17 13:26:34,611 : worker.worker : DEBUG : Step 102516, finished rewards 3.02, envs finished 1
2026-01-17 13:26:34,616 : worker.worker : DEBUG : Step 102517, finished rewards 1.85, envs finished 1
2026-01-17 13:26:34,750 : agent.on_policy : DEBUG : Mean Losses: [4.952376753091812]
2026-01-17 13:26:34,860 : worker.worker : DEBUG : Step 102548, finished rewards 16.38, envs finished 1
2026-01-17 13:26:34,979 : agent.on_policy : DEBUG : Mean Losses: [4.0757115483284]
2026-01-17 13:26:34,991 : worker.worker : DEBUG : Step 102563, finished rewards 25.05, envs finished 1
2026-01-17 13:26:35,021 : worker.worker : DEBUG : Step 102566, finished rewards -16.57, envs finished 1
2026-01-17 13:26:35,084 : worker.worker : DEBUG : Step 102577, finished rewards -3.25, envs finished 1
2026-01-17 13:26:35,122 : worker.worker : DEBUG : Step 102588, finished rewards 24.49, envs finished 1
2026-01-17 13:26:35,229 : agent.on_policy : DEBUG : Mean Losses: [7.473112705163658]
2026-01-17 13:26:35,381 : worker.worker : DEBUG : Step 102621, finished rewards -18.45, envs finished 1
2026-01-17 13:26:35,441 : agent.on_policy : DEBUG : Mean Losses: [2.98764106631279]
2026-01-17 13:26:35,506 : worker.worker : DEBUG : Step 102642, finished rewards 1.45, envs finished 2
2026-01-17 13:26:35,658 : agent.on_policy : DEBUG : Mean Losses: [4.707707565277815]
2026-01-17 13:26:35,672 : worker.worker : DEBUG : Step 102660, finished rewards 30.81, envs finished 1
2026-01-17 13:26:35,696 : worker.worker : DEBUG : Step 102666, finished rewards 4.08, envs finished 1
2026-01-17 13:26:35,745 : worker.worker : DEBUG : Step 102678, finished rewards 24.97, envs finished 1
2026-01-17 13:26:35,764 : worker.worker : DEBUG : Step 102681, finished rewards 5.39, envs finished 1
2026-01-17 13:26:35,886 : agent.on_policy : DEBUG : Mean Losses: [7.473292401060462]
2026-01-17 13:26:35,954 : worker.worker : DEBUG : Step 102696, finished rewards -3.19, envs finished 1
2026-01-17 13:26:36,124 : agent.on_policy : DEBUG : Mean Losses: [2.4050638154149055]
2026-01-17 13:26:36,217 : worker.worker : DEBUG : Step 102749, finished rewards -2.89, envs finished 1
2026-01-17 13:26:36,315 : agent.on_policy : DEBUG : Mean Losses: [3.6137761995196342]
2026-01-17 13:26:36,597 : worker.worker : DEBUG : Step 102782, finished rewards 6.35, envs finished 1
2026-01-17 13:26:36,669 : agent.on_policy : DEBUG : Mean Losses: [5.834344694390893]
2026-01-17 13:26:36,686 : worker.worker : DEBUG : Step 102788, finished rewards -2.47, envs finished 1
2026-01-17 13:26:36,691 : worker.worker : DEBUG : Step 102789, finished rewards -13.80, envs finished 1
2026-01-17 13:26:36,721 : worker.worker : DEBUG : Step 102796, finished rewards -6.42, envs finished 1
2026-01-17 13:26:36,758 : worker.worker : DEBUG : Step 102800, finished rewards 4.86, envs finished 1
2026-01-17 13:26:36,807 : worker.worker : DEBUG : Step 102808, finished rewards -3.17, envs finished 1
2026-01-17 13:26:36,881 : agent.on_policy : DEBUG : Mean Losses: [10.303087061271071]
2026-01-17 13:26:36,907 : worker.worker : DEBUG : Step 102825, finished rewards -4.04, envs finished 1
2026-01-17 13:26:37,071 : agent.on_policy : DEBUG : Mean Losses: [3.003220669925213]
2026-01-17 13:26:37,212 : agent.on_policy : DEBUG : Mean Losses: [3.0867332071065903]
2026-01-17 13:26:37,215 : worker.worker : DEBUG : Step 102880, finished rewards 23.16, envs finished 1
2026-01-17 13:26:37,264 : worker.worker : DEBUG : Step 102886, finished rewards 16.25, envs finished 1
2026-01-17 13:26:37,312 : worker.worker : DEBUG : Step 102899, finished rewards 9.33, envs finished 1
2026-01-17 13:26:37,420 : agent.on_policy : DEBUG : Mean Losses: [6.894592508673668]
2026-01-17 13:26:37,495 : worker.worker : DEBUG : Step 102927, finished rewards -4.45, envs finished 1
2026-01-17 13:26:37,527 : worker.worker : DEBUG : Step 102932, finished rewards -8.46, envs finished 1
2026-01-17 13:26:37,681 : agent.on_policy : DEBUG : Mean Losses: [6.942843183875084]
2026-01-17 13:26:37,695 : worker.worker : DEBUG : Step 102948, finished rewards 8.27, envs finished 1
2026-01-17 13:26:37,715 : worker.worker : DEBUG : Step 102953, finished rewards -15.99, envs finished 1
2026-01-17 13:26:37,833 : agent.on_policy : DEBUG : Mean Losses: [5.201853562146425]
2026-01-17 13:26:37,911 : worker.worker : DEBUG : Step 102989, finished rewards -74.81, envs finished 1
2026-01-17 13:26:37,943 : worker.worker : DEBUG : Step 102996, finished rewards 21.78, envs finished 1
2026-01-17 13:26:37,953 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:26:37,964 : worker.worker : DEBUG : Step 103000, finished rewards 9.35, envs finished 1
2026-01-17 13:26:38,110 : agent.on_policy : DEBUG : Mean Losses: [7.314058735966682]
2026-01-17 13:26:38,128 : worker.worker : DEBUG : Step 103012, finished rewards -1.46, envs finished 1
2026-01-17 13:26:38,171 : worker.worker : DEBUG : Step 103021, finished rewards 23.19, envs finished 1
2026-01-17 13:26:38,213 : worker.worker : DEBUG : Step 103032, finished rewards 19.06, envs finished 1
2026-01-17 13:26:38,294 : agent.on_policy : DEBUG : Mean Losses: [6.247316800057888]
2026-01-17 13:26:38,338 : worker.worker : DEBUG : Step 103052, finished rewards 20.00, envs finished 1
2026-01-17 13:26:38,396 : worker.worker : DEBUG : Step 103058, finished rewards 11.36, envs finished 1
2026-01-17 13:26:37,771 : agent.on_policy : DEBUG : Mean Losses: [3.906660709530115]
2026-01-17 13:26:37,820 : worker.worker : DEBUG : Step 103083, finished rewards 30.79, envs finished 1
2026-01-17 13:26:37,943 : agent.on_policy : DEBUG : Mean Losses: [4.120053723454475]
2026-01-17 13:26:38,033 : worker.worker : DEBUG : Step 103119, finished rewards 12.10, envs finished 1
2026-01-17 13:26:38,069 : worker.worker : DEBUG : Step 103129, finished rewards -6.49, envs finished 1
2026-01-17 13:26:38,079 : worker.worker : DEBUG : Step 103130, finished rewards -11.72, envs finished 1
2026-01-17 13:26:38,134 : worker.worker : DEBUG : Step 103134, finished rewards 8.81, envs finished 1
2026-01-17 13:26:38,205 : agent.on_policy : DEBUG : Mean Losses: [11.66483947634697]
2026-01-17 13:26:38,207 : worker.worker : DEBUG : Step 103136, finished rewards 14.69, envs finished 1
2026-01-17 13:26:38,420 : agent.on_policy : DEBUG : Mean Losses: [1.5283446963876486]
2026-01-17 13:26:38,436 : worker.worker : DEBUG : Step 103173, finished rewards 10.42, envs finished 1
2026-01-17 13:26:38,457 : worker.worker : DEBUG : Step 103178, finished rewards -0.14, envs finished 1
2026-01-17 13:26:38,566 : agent.on_policy : DEBUG : Mean Losses: [3.3393750190734863]
2026-01-17 13:26:38,574 : worker.worker : DEBUG : Step 103202, finished rewards 30.77, envs finished 1
2026-01-17 13:26:38,677 : worker.worker : DEBUG : Step 103218, finished rewards -8.35, envs finished 1
2026-01-17 13:26:38,718 : worker.worker : DEBUG : Step 103228, finished rewards 20.73, envs finished 1
2026-01-17 13:26:38,821 : agent.on_policy : DEBUG : Mean Losses: [6.676789291203022]
2026-01-17 13:26:39,174 : agent.on_policy : DEBUG : Mean Losses: [2.4956169500947]
2026-01-17 13:26:39,208 : worker.worker : DEBUG : Step 103276, finished rewards -6.76, envs finished 1
2026-01-17 13:26:39,247 : worker.worker : DEBUG : Step 103287, finished rewards 7.57, envs finished 1
2026-01-17 13:26:39,258 : worker.worker : DEBUG : Step 103289, finished rewards 10.00, envs finished 1
2026-01-17 13:26:39,265 : worker.worker : DEBUG : Step 103290, finished rewards -17.66, envs finished 1
2026-01-17 13:26:39,289 : worker.worker : DEBUG : Step 103294, finished rewards 0.20, envs finished 2
2026-01-17 13:26:39,347 : agent.on_policy : DEBUG : Mean Losses: [13.00740447640419]
2026-01-17 13:26:39,349 : worker.worker : DEBUG : Step 103296, finished rewards 34.49, envs finished 1
2026-01-17 13:26:39,424 : worker.worker : DEBUG : Step 103317, finished rewards 25.18, envs finished 1
2026-01-17 13:26:39,678 : agent.on_policy : DEBUG : Mean Losses: [2.970436066389084]
2026-01-17 13:26:39,787 : worker.worker : DEBUG : Step 103351, finished rewards 38.41, envs finished 1
2026-01-17 13:26:39,910 : agent.on_policy : DEBUG : Mean Losses: [3.927898347377777]
2026-01-17 13:26:39,987 : worker.worker : DEBUG : Step 103370, finished rewards 37.55, envs finished 1
2026-01-17 13:26:40,033 : worker.worker : DEBUG : Step 103380, finished rewards 23.65, envs finished 1
2026-01-17 13:26:40,040 : worker.worker : DEBUG : Step 103381, finished rewards 25.41, envs finished 1
2026-01-17 13:26:40,056 : worker.worker : DEBUG : Step 103383, finished rewards 22.36, envs finished 1
2026-01-17 13:26:40,272 : agent.on_policy : DEBUG : Mean Losses: [9.673416055738926]
2026-01-17 13:26:40,404 : worker.worker : DEBUG : Step 103423, finished rewards 1.77, envs finished 1
2026-01-17 13:26:40,506 : agent.on_policy : DEBUG : Mean Losses: [2.942002845928073]
2026-01-17 13:26:40,675 : worker.worker : DEBUG : Step 103454, finished rewards 29.21, envs finished 1
2026-01-17 13:26:40,743 : agent.on_policy : DEBUG : Mean Losses: [6.291069179773331]
2026-01-17 13:26:40,783 : worker.worker : DEBUG : Step 103464, finished rewards -30.78, envs finished 1
2026-01-17 13:26:40,919 : worker.worker : DEBUG : Step 103486, finished rewards -36.68, envs finished 1
2026-01-17 13:26:41,032 : agent.on_policy : DEBUG : Mean Losses: [6.151223197579384]
2026-01-17 13:26:41,118 : worker.worker : DEBUG : Step 103498, finished rewards -21.34, envs finished 1
2026-01-17 13:26:41,128 : worker.worker : DEBUG : Step 103499, finished rewards 7.17, envs finished 1
2026-01-17 13:26:41,158 : worker.worker : DEBUG : Step 103504, finished rewards 5.29, envs finished 1
2026-01-17 13:26:41,327 : agent.on_policy : DEBUG : Mean Losses: [5.618896484375]
2026-01-17 13:26:41,339 : worker.worker : DEBUG : Step 103523, finished rewards -13.92, envs finished 1
2026-01-17 13:26:41,485 : agent.on_policy : DEBUG : Mean Losses: [2.9813386127352715]
2026-01-17 13:26:41,554 : worker.worker : DEBUG : Step 103563, finished rewards 11.09, envs finished 1
2026-01-17 13:26:41,605 : worker.worker : DEBUG : Step 103576, finished rewards -26.46, envs finished 1
2026-01-17 13:26:41,746 : agent.on_policy : DEBUG : Mean Losses: [6.130280435085297]
2026-01-17 13:26:41,776 : worker.worker : DEBUG : Step 103592, finished rewards -2.55, envs finished 1
2026-01-17 13:26:41,828 : worker.worker : DEBUG : Step 103603, finished rewards 18.84, envs finished 1
2026-01-17 13:26:41,839 : worker.worker : DEBUG : Step 103605, finished rewards 12.96, envs finished 1
2026-01-17 13:26:42,012 : agent.on_policy : DEBUG : Mean Losses: [7.2318508438766]
2026-01-17 13:26:42,061 : worker.worker : DEBUG : Step 103628, finished rewards -12.55, envs finished 1
2026-01-17 13:26:42,117 : worker.worker : DEBUG : Step 103642, finished rewards 8.01, envs finished 1
2026-01-17 13:26:42,182 : agent.on_policy : DEBUG : Mean Losses: [4.589461646974087]
2026-01-17 13:26:42,314 : worker.worker : DEBUG : Step 103668, finished rewards -37.35, envs finished 1
2026-01-17 13:26:42,493 : agent.on_policy : DEBUG : Mean Losses: [3.9066005758941174]
2026-01-17 13:26:42,516 : worker.worker : DEBUG : Step 103686, finished rewards 32.41, envs finished 1
2026-01-17 13:26:42,537 : worker.worker : DEBUG : Step 103690, finished rewards -1.62, envs finished 1
2026-01-17 13:26:42,548 : worker.worker : DEBUG : Step 103691, finished rewards 8.10, envs finished 1
2026-01-17 13:26:42,599 : worker.worker : DEBUG : Step 103699, finished rewards 17.43, envs finished 2
2026-01-17 13:26:42,756 : agent.on_policy : DEBUG : Mean Losses: [9.15409166738391]
2026-01-17 13:26:42,992 : agent.on_policy : DEBUG : Mean Losses: [1.8023596443235874]
2026-01-17 13:26:42,995 : worker.worker : DEBUG : Step 103744, finished rewards 36.62, envs finished 1
2026-01-17 13:26:43,178 : agent.on_policy : DEBUG : Mean Losses: [3.3600393757224083]
2026-01-17 13:26:43,216 : worker.worker : DEBUG : Step 103784, finished rewards -11.83, envs finished 1
2026-01-17 13:26:43,250 : worker.worker : DEBUG : Step 103792, finished rewards 23.62, envs finished 1
2026-01-17 13:26:43,272 : worker.worker : DEBUG : Step 103797, finished rewards -31.80, envs finished 1
2026-01-17 13:26:43,283 : worker.worker : DEBUG : Step 103798, finished rewards 14.51, envs finished 1
2026-01-17 13:26:43,379 : agent.on_policy : DEBUG : Mean Losses: [10.013841360807419]
2026-01-17 13:26:43,434 : worker.worker : DEBUG : Step 103820, finished rewards 2.21, envs finished 1
2026-01-17 13:26:43,477 : worker.worker : DEBUG : Step 103823, finished rewards -9.44, envs finished 1
2026-01-17 13:26:43,669 : agent.on_policy : DEBUG : Mean Losses: [4.204499989748001]
2026-01-17 13:26:43,694 : worker.worker : DEBUG : Step 103847, finished rewards -14.69, envs finished 1
2026-01-17 13:26:43,850 : agent.on_policy : DEBUG : Mean Losses: [3.192617094144225]
2026-01-17 13:26:43,875 : worker.worker : DEBUG : Step 103873, finished rewards 25.96, envs finished 1
2026-01-17 13:26:43,894 : worker.worker : DEBUG : Step 103876, finished rewards -3.67, envs finished 1
2026-01-17 13:26:44,139 : agent.on_policy : DEBUG : Mean Losses: [3.3303195014595985]
2026-01-17 13:26:44,156 : worker.worker : DEBUG : Step 103906, finished rewards 31.57, envs finished 1
2026-01-17 13:26:44,173 : worker.worker : DEBUG : Step 103908, finished rewards 11.63, envs finished 1
2026-01-17 13:26:44,246 : worker.worker : DEBUG : Step 103924, finished rewards -1.21, envs finished 1
2026-01-17 13:26:44,261 : worker.worker : DEBUG : Step 103926, finished rewards -0.86, envs finished 1
2026-01-17 13:26:44,422 : agent.on_policy : DEBUG : Mean Losses: [5.731057453900576]
2026-01-17 13:26:44,436 : worker.worker : DEBUG : Step 103939, finished rewards 7.60, envs finished 1
2026-01-17 13:26:44,606 : worker.worker : DEBUG : Step 103967, finished rewards 24.53, envs finished 1
2026-01-17 13:26:44,666 : agent.on_policy : DEBUG : Mean Losses: [3.9579088427126408]
2026-01-17 13:26:44,710 : worker.worker : DEBUG : Step 103977, finished rewards 16.13, envs finished 1
2026-01-17 13:26:44,842 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:26:44,959 : agent.on_policy : DEBUG : Mean Losses: [5.361791102215648]
2026-01-17 13:26:45,161 : worker.worker : DEBUG : Step 104029, finished rewards 25.12, envs finished 1
2026-01-17 13:26:45,347 : agent.on_policy : DEBUG : Mean Losses: [5.134644888341427]
2026-01-17 13:26:45,358 : worker.worker : DEBUG : Step 104033, finished rewards 13.25, envs finished 1
2026-01-17 13:26:45,477 : worker.worker : DEBUG : Step 104049, finished rewards -39.37, envs finished 1
2026-01-17 13:26:45,492 : worker.worker : DEBUG : Step 104050, finished rewards -0.79, envs finished 1
2026-01-17 13:26:45,578 : worker.worker : DEBUG : Step 104058, finished rewards 24.59, envs finished 1
2026-01-17 13:26:45,609 : worker.worker : DEBUG : Step 104061, finished rewards -18.88, envs finished 1
2026-01-17 13:26:45,735 : agent.on_policy : DEBUG : Mean Losses: [9.995425593107939]
2026-01-17 13:26:45,827 : worker.worker : DEBUG : Step 104075, finished rewards -33.69, envs finished 1
2026-01-17 13:26:46,042 : agent.on_policy : DEBUG : Mean Losses: [3.3439539819955826]
2026-01-17 13:26:46,119 : worker.worker : DEBUG : Step 104115, finished rewards -9.42, envs finished 1
2026-01-17 13:26:46,283 : agent.on_policy : DEBUG : Mean Losses: [3.7666568756103516]
2026-01-17 13:26:46,399 : worker.worker : DEBUG : Step 104148, finished rewards 21.12, envs finished 1
2026-01-17 13:26:46,408 : worker.worker : DEBUG : Step 104149, finished rewards 6.75, envs finished 1
2026-01-17 13:26:46,438 : worker.worker : DEBUG : Step 104153, finished rewards 4.95, envs finished 1
2026-01-17 13:26:46,556 : agent.on_policy : DEBUG : Mean Losses: [7.272060602903366]
2026-01-17 13:26:46,569 : worker.worker : DEBUG : Step 104162, finished rewards 16.05, envs finished 1
2026-01-17 13:26:46,686 : worker.worker : DEBUG : Step 104181, finished rewards -4.70, envs finished 1
2026-01-17 13:26:46,877 : agent.on_policy : DEBUG : Mean Losses: [4.806989092379808]
2026-01-17 13:26:47,080 : agent.on_policy : DEBUG : Mean Losses: [3.0590511709451675]
2026-01-17 13:26:47,113 : worker.worker : DEBUG : Step 104229, finished rewards -33.96, envs finished 1
2026-01-17 13:26:47,177 : worker.worker : DEBUG : Step 104243, finished rewards 23.41, envs finished 1
2026-01-17 13:26:47,227 : worker.worker : DEBUG : Step 104254, finished rewards 24.94, envs finished 1
2026-01-17 13:26:47,329 : agent.on_policy : DEBUG : Mean Losses: [8.682951502501965]
2026-01-17 13:26:47,357 : worker.worker : DEBUG : Step 104260, finished rewards -21.28, envs finished 1
2026-01-17 13:26:47,450 : worker.worker : DEBUG : Step 104274, finished rewards -0.82, envs finished 1
2026-01-17 13:26:47,458 : worker.worker : DEBUG : Step 104275, finished rewards 5.56, envs finished 1
2026-01-17 13:26:47,505 : worker.worker : DEBUG : Step 104282, finished rewards -29.79, envs finished 1
2026-01-17 13:26:47,616 : agent.on_policy : DEBUG : Mean Losses: [7.22234208509326]
2026-01-17 13:26:47,704 : worker.worker : DEBUG : Step 104300, finished rewards 4.76, envs finished 1
2026-01-17 13:26:47,891 : agent.on_policy : DEBUG : Mean Losses: [2.1373081505298615]
2026-01-17 13:26:48,025 : worker.worker : DEBUG : Step 104349, finished rewards 14.87, envs finished 1
2026-01-17 13:26:48,130 : agent.on_policy : DEBUG : Mean Losses: [4.095593050122261]
2026-01-17 13:26:48,243 : worker.worker : DEBUG : Step 104368, finished rewards 13.03, envs finished 1
2026-01-17 13:26:48,346 : worker.worker : DEBUG : Step 104381, finished rewards -0.15, envs finished 2
2026-01-17 13:26:48,470 : agent.on_policy : DEBUG : Mean Losses: [7.06774839758873]
2026-01-17 13:26:48,524 : worker.worker : DEBUG : Step 104390, finished rewards 10.75, envs finished 1
2026-01-17 13:26:48,554 : worker.worker : DEBUG : Step 104394, finished rewards 10.71, envs finished 1
2026-01-17 13:26:48,571 : worker.worker : DEBUG : Step 104396, finished rewards 22.53, envs finished 1
2026-01-17 13:26:48,695 : worker.worker : DEBUG : Step 104414, finished rewards -22.44, envs finished 1
2026-01-17 13:26:48,823 : agent.on_policy : DEBUG : Mean Losses: [6.259640399366617]
2026-01-17 13:26:49,296 : agent.on_policy : DEBUG : Mean Losses: [0.9127492606639862]
2026-01-17 13:26:49,316 : worker.worker : DEBUG : Step 104448, finished rewards 17.99, envs finished 1
2026-01-17 13:26:49,570 : agent.on_policy : DEBUG : Mean Losses: [2.36849744617939]
2026-01-17 13:26:49,603 : worker.worker : DEBUG : Step 104488, finished rewards 24.45, envs finished 1
2026-01-17 13:26:49,612 : worker.worker : DEBUG : Step 104489, finished rewards 18.35, envs finished 1
2026-01-17 13:26:49,656 : worker.worker : DEBUG : Step 104495, finished rewards 7.35, envs finished 1
2026-01-17 13:26:49,694 : worker.worker : DEBUG : Step 104500, finished rewards -6.67, envs finished 1
2026-01-17 13:26:49,872 : agent.on_policy : DEBUG : Mean Losses: [10.138495713472366]
2026-01-17 13:26:49,908 : worker.worker : DEBUG : Step 104516, finished rewards 16.73, envs finished 1
2026-01-17 13:26:49,996 : worker.worker : DEBUG : Step 104531, finished rewards -9.70, envs finished 1
2026-01-17 13:26:50,155 : agent.on_policy : DEBUG : Mean Losses: [4.428660599514842]
2026-01-17 13:26:50,245 : worker.worker : DEBUG : Step 104568, finished rewards -21.65, envs finished 2
2026-01-17 13:26:50,255 : worker.worker : DEBUG : Step 104570, finished rewards 31.49, envs finished 1
2026-01-17 13:26:50,373 : agent.on_policy : DEBUG : Mean Losses: [9.049138844013214]
2026-01-17 13:26:50,390 : worker.worker : DEBUG : Step 104580, finished rewards 24.34, envs finished 1
2026-01-17 13:26:50,446 : worker.worker : DEBUG : Step 104586, finished rewards 25.89, envs finished 1
2026-01-17 13:26:50,472 : worker.worker : DEBUG : Step 104591, finished rewards 25.08, envs finished 1
2026-01-17 13:26:50,639 : agent.on_policy : DEBUG : Mean Losses: [5.140099655836821]
2026-01-17 13:26:50,699 : worker.worker : DEBUG : Step 104623, finished rewards 24.35, envs finished 1
2026-01-17 13:26:50,886 : agent.on_policy : DEBUG : Mean Losses: [3.9134522303938866]
2026-01-17 13:26:50,932 : worker.worker : DEBUG : Step 104650, finished rewards 31.49, envs finished 1
2026-01-17 13:26:50,944 : worker.worker : DEBUG : Step 104652, finished rewards 31.45, envs finished 1
2026-01-17 13:26:50,989 : worker.worker : DEBUG : Step 104661, finished rewards 23.84, envs finished 1
2026-01-17 13:26:51,034 : worker.worker : DEBUG : Step 104669, finished rewards -21.24, envs finished 1
2026-01-17 13:26:51,104 : agent.on_policy : DEBUG : Mean Losses: [10.401971757411957]
2026-01-17 13:26:51,112 : worker.worker : DEBUG : Step 104673, finished rewards 31.26, envs finished 1
2026-01-17 13:26:51,136 : worker.worker : DEBUG : Step 104677, finished rewards 21.66, envs finished 1
2026-01-17 13:26:51,367 : agent.on_policy : DEBUG : Mean Losses: [2.7055587247014046]
2026-01-17 13:26:51,602 : agent.on_policy : DEBUG : Mean Losses: [2.3593961857259274]
2026-01-17 13:26:51,605 : worker.worker : DEBUG : Step 104736, finished rewards -22.18, envs finished 1
2026-01-17 13:26:51,624 : worker.worker : DEBUG : Step 104739, finished rewards 8.14, envs finished 1
2026-01-17 13:26:51,731 : worker.worker : DEBUG : Step 104761, finished rewards 17.75, envs finished 1
2026-01-17 13:26:51,871 : agent.on_policy : DEBUG : Mean Losses: [6.450288139283657]
2026-01-17 13:26:51,930 : worker.worker : DEBUG : Step 104774, finished rewards 16.47, envs finished 1
2026-01-17 13:26:52,180 : worker.worker : DEBUG : Step 104798, finished rewards 2.43, envs finished 1
2026-01-17 13:26:52,305 : agent.on_policy : DEBUG : Mean Losses: [7.041218942031264]
2026-01-17 13:26:52,458 : worker.worker : DEBUG : Step 104816, finished rewards -26.81, envs finished 1
2026-01-17 13:26:52,548 : worker.worker : DEBUG : Step 104827, finished rewards -19.70, envs finished 1
2026-01-17 13:26:52,568 : worker.worker : DEBUG : Step 104828, finished rewards -39.52, envs finished 1
2026-01-17 13:26:52,723 : agent.on_policy : DEBUG : Mean Losses: [7.524722933769226]
2026-01-17 13:26:52,904 : worker.worker : DEBUG : Step 104858, finished rewards 4.36, envs finished 1
2026-01-17 13:26:52,996 : agent.on_policy : DEBUG : Mean Losses: [3.6576641760766506]
2026-01-17 13:26:53,003 : worker.worker : DEBUG : Step 104865, finished rewards -1.20, envs finished 1
2026-01-17 13:26:53,058 : worker.worker : DEBUG : Step 104873, finished rewards 17.87, envs finished 1
2026-01-17 13:26:53,157 : worker.worker : DEBUG : Step 104889, finished rewards 26.02, envs finished 1
2026-01-17 13:26:53,203 : worker.worker : DEBUG : Step 104894, finished rewards -5.44, envs finished 1
2026-01-17 13:26:53,262 : agent.on_policy : DEBUG : Mean Losses: [7.385414723306894]
2026-01-17 13:26:53,453 : agent.on_policy : DEBUG : Mean Losses: [1.8413924612104893]
2026-01-17 13:26:53,462 : worker.worker : DEBUG : Step 104929, finished rewards 7.92, envs finished 1
2026-01-17 13:26:53,641 : agent.on_policy : DEBUG : Mean Losses: [3.3600764498114586]
2026-01-17 13:26:53,704 : worker.worker : DEBUG : Step 104976, finished rewards 11.48, envs finished 1
2026-01-17 13:26:53,710 : worker.worker : DEBUG : Step 104977, finished rewards -16.29, envs finished 1
2026-01-17 13:26:53,736 : worker.worker : DEBUG : Step 104983, finished rewards 16.06, envs finished 2
2026-01-17 13:26:53,748 : worker.worker : DEBUG : Step 104986, finished rewards -1.55, envs finished 1
2026-01-17 13:26:53,763 : worker.worker : DEBUG : Step 104989, finished rewards -17.79, envs finished 1
2026-01-17 13:26:53,861 : agent.on_policy : DEBUG : Mean Losses: [12.716800272464752]
2026-01-17 13:26:53,880 : worker.worker : DEBUG : Step 104998, finished rewards 15.12, envs finished 1
2026-01-17 13:26:53,881 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:26:53,895 : worker.worker : INFO : Step 105000, Avg Reward 5.8440, Max Reward 38.4136, Loss [5.33959349]
2026-01-17 13:26:54,038 : worker.worker : DEBUG : Step 105023, finished rewards 24.50, envs finished 1
2026-01-17 13:26:54,097 : agent.on_policy : DEBUG : Mean Losses: [2.8473643753677607]
2026-01-17 13:26:54,281 : agent.on_policy : DEBUG : Mean Losses: [1.3076907359063625]
2026-01-17 13:26:54,362 : worker.worker : DEBUG : Step 105082, finished rewards 22.89, envs finished 1
2026-01-17 13:26:54,459 : agent.on_policy : DEBUG : Mean Losses: [6.05078487098217]
2026-01-17 13:26:54,474 : worker.worker : DEBUG : Step 105091, finished rewards 6.08, envs finished 1
2026-01-17 13:26:54,545 : worker.worker : DEBUG : Step 105101, finished rewards 16.39, envs finished 1
2026-01-17 13:26:54,558 : worker.worker : DEBUG : Step 105103, finished rewards 3.80, envs finished 1
2026-01-17 13:26:54,721 : agent.on_policy : DEBUG : Mean Losses: [6.576141191646457]
2026-01-17 13:26:54,729 : worker.worker : DEBUG : Step 105122, finished rewards -9.10, envs finished 1
2026-01-17 13:26:54,784 : worker.worker : DEBUG : Step 105136, finished rewards -18.68, envs finished 1
2026-01-17 13:26:54,852 : worker.worker : DEBUG : Step 105150, finished rewards -0.48, envs finished 1
2026-01-17 13:26:54,948 : agent.on_policy : DEBUG : Mean Losses: [5.740059619769454]
2026-01-17 13:26:55,163 : agent.on_policy : DEBUG : Mean Losses: [2.3078522123396397]
2026-01-17 13:26:55,378 : agent.on_policy : DEBUG : Mean Losses: [3.423244133591652]
2026-01-17 13:26:55,405 : worker.worker : DEBUG : Step 105221, finished rewards -8.17, envs finished 1
2026-01-17 13:26:55,444 : worker.worker : DEBUG : Step 105229, finished rewards -0.54, envs finished 1
2026-01-17 13:26:55,473 : worker.worker : DEBUG : Step 105236, finished rewards -12.56, envs finished 1
2026-01-17 13:26:55,501 : worker.worker : DEBUG : Step 105242, finished rewards 24.13, envs finished 1
2026-01-17 13:26:55,507 : worker.worker : DEBUG : Step 105243, finished rewards 1.21, envs finished 1
2026-01-17 13:26:55,576 : agent.on_policy : DEBUG : Mean Losses: [11.198996871709824]
2026-01-17 13:26:55,597 : worker.worker : DEBUG : Step 105255, finished rewards -64.59, envs finished 1
2026-01-17 13:26:55,629 : worker.worker : DEBUG : Step 105264, finished rewards -3.61, envs finished 1
2026-01-17 13:26:55,780 : agent.on_policy : DEBUG : Mean Losses: [5.161224290728569]
2026-01-17 13:26:55,931 : agent.on_policy : DEBUG : Mean Losses: [1.8279639072716236]
2026-01-17 13:26:55,972 : worker.worker : DEBUG : Step 105317, finished rewards -14.61, envs finished 2
2026-01-17 13:26:56,030 : worker.worker : DEBUG : Step 105333, finished rewards 25.49, envs finished 2
2026-01-17 13:26:56,057 : worker.worker : DEBUG : Step 105339, finished rewards 30.27, envs finished 1
2026-01-17 13:26:56,159 : agent.on_policy : DEBUG : Mean Losses: [10.96253740042448]
2026-01-17 13:26:56,414 : worker.worker : DEBUG : Step 105373, finished rewards 12.59, envs finished 1
2026-01-17 13:26:56,480 : agent.on_policy : DEBUG : Mean Losses: [4.962646339088678]
2026-01-17 13:26:56,493 : worker.worker : DEBUG : Step 105379, finished rewards -6.11, envs finished 1
2026-01-17 13:26:56,500 : worker.worker : DEBUG : Step 105381, finished rewards -11.40, envs finished 1
2026-01-17 13:26:56,696 : agent.on_policy : DEBUG : Mean Losses: [2.3435015715658665]
2026-01-17 13:26:56,758 : worker.worker : DEBUG : Step 105425, finished rewards 25.42, envs finished 1
2026-01-17 13:26:56,800 : worker.worker : DEBUG : Step 105435, finished rewards 16.94, envs finished 1
2026-01-17 13:26:56,811 : worker.worker : DEBUG : Step 105437, finished rewards 4.41, envs finished 1
2026-01-17 13:26:56,923 : agent.on_policy : DEBUG : Mean Losses: [8.498584639281034]
2026-01-17 13:26:56,994 : worker.worker : DEBUG : Step 105450, finished rewards -0.55, envs finished 1
2026-01-17 13:26:57,030 : worker.worker : DEBUG : Step 105457, finished rewards 30.39, envs finished 1
2026-01-17 13:26:57,048 : worker.worker : DEBUG : Step 105461, finished rewards 31.64, envs finished 1
2026-01-17 13:26:57,094 : worker.worker : DEBUG : Step 105466, finished rewards -1.48, envs finished 1
2026-01-17 13:26:57,276 : agent.on_policy : DEBUG : Mean Losses: [9.413100816309452]
2026-01-17 13:26:57,486 : agent.on_policy : DEBUG : Mean Losses: [1.1575010027736425]
2026-01-17 13:26:57,505 : worker.worker : DEBUG : Step 105509, finished rewards 3.49, envs finished 1
2026-01-17 13:26:57,586 : worker.worker : DEBUG : Step 105532, finished rewards 21.24, envs finished 1
2026-01-17 13:26:57,649 : agent.on_policy : DEBUG : Mean Losses: [4.744894631206989]
2026-01-17 13:26:57,710 : worker.worker : DEBUG : Step 105546, finished rewards 3.47, envs finished 1
2026-01-17 13:26:57,729 : worker.worker : DEBUG : Step 105549, finished rewards 9.19, envs finished 1
2026-01-17 13:26:57,821 : worker.worker : DEBUG : Step 105562, finished rewards 16.90, envs finished 1
2026-01-17 13:26:57,957 : agent.on_policy : DEBUG : Mean Losses: [6.891348646953702]
2026-01-17 13:26:58,020 : worker.worker : DEBUG : Step 105582, finished rewards -0.40, envs finished 1
2026-01-17 13:26:58,045 : worker.worker : DEBUG : Step 105585, finished rewards 4.10, envs finished 1
2026-01-17 13:26:58,207 : agent.on_policy : DEBUG : Mean Losses: [4.071030605584383]
2026-01-17 13:26:58,227 : worker.worker : DEBUG : Step 105605, finished rewards -8.32, envs finished 1
2026-01-17 13:26:58,314 : worker.worker : DEBUG : Step 105623, finished rewards 7.49, envs finished 1
2026-01-17 13:26:58,472 : agent.on_policy : DEBUG : Mean Losses: [3.786469057202339]
2026-01-17 13:26:58,636 : worker.worker : DEBUG : Step 105661, finished rewards 1.14, envs finished 1
2026-01-17 13:26:58,719 : agent.on_policy : DEBUG : Mean Losses: [3.9867539554834366]
2026-01-17 13:26:58,731 : worker.worker : DEBUG : Step 105667, finished rewards 30.05, envs finished 1
2026-01-17 13:26:58,834 : worker.worker : DEBUG : Step 105682, finished rewards -7.86, envs finished 1
2026-01-17 13:26:58,917 : worker.worker : DEBUG : Step 105695, finished rewards 14.50, envs finished 1
2026-01-17 13:26:58,981 : agent.on_policy : DEBUG : Mean Losses: [5.5896164402365685]
2026-01-17 13:26:59,021 : worker.worker : DEBUG : Step 105699, finished rewards -13.61, envs finished 1
2026-01-17 13:26:59,056 : worker.worker : DEBUG : Step 105705, finished rewards -12.01, envs finished 1
2026-01-17 13:26:59,149 : worker.worker : DEBUG : Step 105719, finished rewards 22.37, envs finished 1
2026-01-17 13:26:59,282 : agent.on_policy : DEBUG : Mean Losses: [5.5316451117396355]
2026-01-17 13:26:59,406 : worker.worker : DEBUG : Step 105748, finished rewards -2.30, envs finished 1
2026-01-17 13:26:59,738 : agent.on_policy : DEBUG : Mean Losses: [3.134228467941284]
2026-01-17 13:26:59,759 : worker.worker : DEBUG : Step 105764, finished rewards 21.52, envs finished 1
2026-01-17 13:26:59,853 : worker.worker : DEBUG : Step 105784, finished rewards 16.72, envs finished 1
2026-01-17 13:26:59,860 : worker.worker : DEBUG : Step 105786, finished rewards -0.44, envs finished 1
2026-01-17 13:26:59,979 : agent.on_policy : DEBUG : Mean Losses: [6.430077105760574]
2026-01-17 13:27:00,004 : worker.worker : DEBUG : Step 105796, finished rewards 21.15, envs finished 1
2026-01-17 13:27:00,065 : worker.worker : DEBUG : Step 105802, finished rewards 30.94, envs finished 1
2026-01-17 13:27:00,118 : worker.worker : DEBUG : Step 105815, finished rewards 5.90, envs finished 1
2026-01-17 13:27:00,238 : agent.on_policy : DEBUG : Mean Losses: [5.480044707655907]
2026-01-17 13:27:00,253 : worker.worker : DEBUG : Step 105828, finished rewards 2.29, envs finished 1
2026-01-17 13:27:00,358 : worker.worker : DEBUG : Step 105848, finished rewards 18.08, envs finished 1
2026-01-17 13:27:00,477 : agent.on_policy : DEBUG : Mean Losses: [4.6035072058439255]
2026-01-17 13:27:00,599 : worker.worker : DEBUG : Step 105875, finished rewards 24.10, envs finished 1
2026-01-17 13:27:00,838 : agent.on_policy : DEBUG : Mean Losses: [4.706641800701618]
2026-01-17 13:27:00,909 : worker.worker : DEBUG : Step 105909, finished rewards 12.02, envs finished 1
2026-01-17 13:27:00,944 : worker.worker : DEBUG : Step 105919, finished rewards -0.41, envs finished 1
2026-01-17 13:27:01,036 : agent.on_policy : DEBUG : Mean Losses: [6.8910103887319565]
2026-01-17 13:27:01,043 : worker.worker : DEBUG : Step 105921, finished rewards 22.90, envs finished 1
2026-01-17 13:27:01,060 : worker.worker : DEBUG : Step 105924, finished rewards -9.06, envs finished 1
2026-01-17 13:27:01,154 : worker.worker : DEBUG : Step 105936, finished rewards -14.78, envs finished 1
2026-01-17 13:27:01,202 : worker.worker : DEBUG : Step 105947, finished rewards 17.90, envs finished 1
2026-01-17 13:27:01,377 : agent.on_policy : DEBUG : Mean Losses: [6.944535681977868]
2026-01-17 13:27:01,424 : worker.worker : DEBUG : Step 105964, finished rewards -18.67, envs finished 1
2026-01-17 13:27:01,533 : agent.on_policy : DEBUG : Mean Losses: [2.696389202028513]
2026-01-17 13:27:01,620 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:27:01,638 : worker.worker : DEBUG : Step 106002, finished rewards 23.99, envs finished 1
2026-01-17 13:27:01,781 : agent.on_policy : DEBUG : Mean Losses: [4.958961494266987]
2026-01-17 13:27:01,882 : worker.worker : DEBUG : Step 106040, finished rewards 5.71, envs finished 1
2026-01-17 13:27:01,886 : worker.worker : DEBUG : Step 106041, finished rewards 11.73, envs finished 1
2026-01-17 13:27:02,043 : agent.on_policy : DEBUG : Mean Losses: [6.72842338681221]
2026-01-17 13:27:02,063 : worker.worker : DEBUG : Step 106053, finished rewards 15.57, envs finished 1
2026-01-17 13:27:02,079 : worker.worker : DEBUG : Step 106057, finished rewards 23.40, envs finished 1
2026-01-17 13:27:02,262 : agent.on_policy : DEBUG : Mean Losses: [4.7072012312710285]
2026-01-17 13:27:02,315 : worker.worker : DEBUG : Step 106090, finished rewards -33.54, envs finished 1
2026-01-17 13:27:02,320 : worker.worker : DEBUG : Step 106091, finished rewards -58.55, envs finished 1
2026-01-17 13:27:02,374 : worker.worker : DEBUG : Step 106099, finished rewards -26.88, envs finished 1
2026-01-17 13:27:02,559 : agent.on_policy : DEBUG : Mean Losses: [5.148645497858524]
2026-01-17 13:27:02,709 : worker.worker : DEBUG : Step 106142, finished rewards -11.10, envs finished 1
2026-01-17 13:27:02,831 : agent.on_policy : DEBUG : Mean Losses: [4.006658662110567]
2026-01-17 13:27:03,101 : agent.on_policy : DEBUG : Mean Losses: [3.7878401279449463]
2026-01-17 13:27:03,136 : worker.worker : DEBUG : Step 106183, finished rewards -8.93, envs finished 1
2026-01-17 13:27:03,184 : worker.worker : DEBUG : Step 106193, finished rewards -20.02, envs finished 1
2026-01-17 13:27:03,214 : worker.worker : DEBUG : Step 106199, finished rewards -14.02, envs finished 1
2026-01-17 13:27:03,313 : agent.on_policy : DEBUG : Mean Losses: [8.37603671848774]
2026-01-17 13:27:03,336 : worker.worker : DEBUG : Step 106215, finished rewards 0.93, envs finished 1
2026-01-17 13:27:03,417 : worker.worker : DEBUG : Step 106228, finished rewards 6.13, envs finished 1
2026-01-17 13:27:03,440 : worker.worker : DEBUG : Step 106232, finished rewards -38.24, envs finished 1
2026-01-17 13:27:03,561 : agent.on_policy : DEBUG : Mean Losses: [7.501756057143211]
2026-01-17 13:27:03,574 : worker.worker : DEBUG : Step 106243, finished rewards -20.07, envs finished 1
2026-01-17 13:27:03,679 : worker.worker : DEBUG : Step 106260, finished rewards 35.67, envs finished 1
2026-01-17 13:27:03,721 : worker.worker : DEBUG : Step 106268, finished rewards 0.16, envs finished 1
2026-01-17 13:27:03,819 : agent.on_policy : DEBUG : Mean Losses: [6.565657104365528]
2026-01-17 13:27:03,948 : worker.worker : DEBUG : Step 106296, finished rewards 19.40, envs finished 1
2026-01-17 13:27:04,070 : agent.on_policy : DEBUG : Mean Losses: [2.8765387684106827]
2026-01-17 13:27:04,076 : worker.worker : DEBUG : Step 106305, finished rewards 35.93, envs finished 1
2026-01-17 13:27:04,088 : worker.worker : DEBUG : Step 106307, finished rewards 24.06, envs finished 1
2026-01-17 13:27:04,133 : worker.worker : DEBUG : Step 106311, finished rewards 10.94, envs finished 1
2026-01-17 13:27:04,291 : worker.worker : DEBUG : Step 106324, finished rewards 25.59, envs finished 1
2026-01-17 13:27:04,492 : agent.on_policy : DEBUG : Mean Losses: [6.752694338560104]
2026-01-17 13:27:04,602 : worker.worker : DEBUG : Step 106367, finished rewards -0.82, envs finished 1
2026-01-17 13:27:04,723 : agent.on_policy : DEBUG : Mean Losses: [3.442392726428807]
2026-01-17 13:27:04,729 : worker.worker : DEBUG : Step 106369, finished rewards 18.17, envs finished 1
2026-01-17 13:27:04,838 : worker.worker : DEBUG : Step 106387, finished rewards 25.87, envs finished 1
2026-01-17 13:27:04,966 : agent.on_policy : DEBUG : Mean Losses: [5.404089380055666]
2026-01-17 13:27:05,008 : worker.worker : DEBUG : Step 106404, finished rewards 21.69, envs finished 1
2026-01-17 13:27:05,051 : worker.worker : DEBUG : Step 106409, finished rewards -20.24, envs finished 1
2026-01-17 13:27:05,071 : worker.worker : DEBUG : Step 106412, finished rewards 17.34, envs finished 1
2026-01-17 13:27:05,092 : worker.worker : DEBUG : Step 106415, finished rewards 12.82, envs finished 1
2026-01-17 13:27:05,110 : worker.worker : DEBUG : Step 106418, finished rewards 24.17, envs finished 1
2026-01-17 13:27:05,206 : agent.on_policy : DEBUG : Mean Losses: [10.011105984449387]
2026-01-17 13:27:05,405 : agent.on_policy : DEBUG : Mean Losses: [1.2228834703564644]
2026-01-17 13:27:05,433 : worker.worker : DEBUG : Step 106472, finished rewards 21.98, envs finished 2
2026-01-17 13:27:05,504 : worker.worker : DEBUG : Step 106489, finished rewards 29.18, envs finished 1
2026-01-17 13:27:05,614 : agent.on_policy : DEBUG : Mean Losses: [7.6680141761898994]
2026-01-17 13:27:05,658 : worker.worker : DEBUG : Step 106507, finished rewards 23.83, envs finished 2
2026-01-17 13:27:05,772 : agent.on_policy : DEBUG : Mean Losses: [6.53412327170372]
2026-01-17 13:27:05,816 : worker.worker : DEBUG : Step 106535, finished rewards 3.41, envs finished 1
2026-01-17 13:27:05,835 : worker.worker : DEBUG : Step 106539, finished rewards -2.49, envs finished 1
2026-01-17 13:27:06,026 : agent.on_policy : DEBUG : Mean Losses: [4.148331791162491]
2026-01-17 13:27:06,081 : worker.worker : DEBUG : Step 106573, finished rewards -13.12, envs finished 2
2026-01-17 13:27:06,140 : worker.worker : DEBUG : Step 106590, finished rewards 5.36, envs finished 1
2026-01-17 13:27:06,238 : agent.on_policy : DEBUG : Mean Losses: [7.213537476956844]
2026-01-17 13:27:06,263 : worker.worker : DEBUG : Step 106600, finished rewards 23.90, envs finished 1
2026-01-17 13:27:06,285 : worker.worker : DEBUG : Step 106605, finished rewards 19.20, envs finished 1
2026-01-17 13:27:06,349 : worker.worker : DEBUG : Step 106612, finished rewards -5.15, envs finished 1
2026-01-17 13:27:06,482 : agent.on_policy : DEBUG : Mean Losses: [7.678262736648321]
2026-01-17 13:27:06,550 : worker.worker : DEBUG : Step 106639, finished rewards 18.54, envs finished 1
2026-01-17 13:27:06,608 : worker.worker : DEBUG : Step 106652, finished rewards 7.61, envs finished 1
2026-01-17 13:27:06,634 : worker.worker : DEBUG : Step 106655, finished rewards 31.38, envs finished 1
2026-01-17 13:27:06,756 : agent.on_policy : DEBUG : Mean Losses: [8.314028795808554]
2026-01-17 13:27:06,875 : worker.worker : DEBUG : Step 106679, finished rewards 11.54, envs finished 1
2026-01-17 13:27:06,891 : worker.worker : DEBUG : Step 106680, finished rewards 25.68, envs finished 1
2026-01-17 13:27:07,015 : agent.on_policy : DEBUG : Mean Losses: [6.2069913148880005]
2026-01-17 13:27:07,080 : worker.worker : DEBUG : Step 106697, finished rewards 24.61, envs finished 1
2026-01-17 13:27:07,275 : agent.on_policy : DEBUG : Mean Losses: [4.22366813570261]
2026-01-17 13:27:07,280 : worker.worker : DEBUG : Step 106721, finished rewards 31.42, envs finished 1
2026-01-17 13:27:07,377 : worker.worker : DEBUG : Step 106749, finished rewards -9.07, envs finished 1
2026-01-17 13:27:07,493 : agent.on_policy : DEBUG : Mean Losses: [5.003625424578786]
2026-01-17 13:27:07,497 : worker.worker : DEBUG : Step 106752, finished rewards -0.06, envs finished 2
2026-01-17 13:27:07,654 : worker.worker : DEBUG : Step 106771, finished rewards 24.93, envs finished 1
2026-01-17 13:27:07,668 : worker.worker : DEBUG : Step 106773, finished rewards 4.48, envs finished 1
2026-01-17 13:27:07,716 : worker.worker : DEBUG : Step 106780, finished rewards 30.34, envs finished 1
2026-01-17 13:27:07,025 : agent.on_policy : DEBUG : Mean Losses: [8.940498527139425]
2026-01-17 13:27:07,118 : worker.worker : DEBUG : Step 106812, finished rewards 24.22, envs finished 1
2026-01-17 13:27:07,232 : agent.on_policy : DEBUG : Mean Losses: [3.703274577856064]
2026-01-17 13:27:07,237 : worker.worker : DEBUG : Step 106817, finished rewards -0.81, envs finished 1
2026-01-17 13:27:07,344 : worker.worker : DEBUG : Step 106835, finished rewards 30.98, envs finished 1
2026-01-17 13:27:07,372 : worker.worker : DEBUG : Step 106841, finished rewards 27.32, envs finished 1
2026-01-17 13:27:07,627 : agent.on_policy : DEBUG : Mean Losses: [7.888132041320205]
2026-01-17 13:27:07,855 : agent.on_policy : DEBUG : Mean Losses: [2.4885323867201805]
2026-01-17 13:27:07,860 : worker.worker : DEBUG : Step 106881, finished rewards -6.69, envs finished 1
2026-01-17 13:27:07,905 : worker.worker : DEBUG : Step 106890, finished rewards 6.77, envs finished 1
2026-01-17 13:27:08,053 : agent.on_policy : DEBUG : Mean Losses: [3.927778020501137]
2026-01-17 13:27:08,141 : worker.worker : DEBUG : Step 106924, finished rewards 10.32, envs finished 1
2026-01-17 13:27:08,152 : worker.worker : DEBUG : Step 106926, finished rewards 11.53, envs finished 1
2026-01-17 13:27:08,343 : agent.on_policy : DEBUG : Mean Losses: [5.943004760891199]
2026-01-17 13:27:08,352 : worker.worker : DEBUG : Step 106946, finished rewards 11.81, envs finished 1
2026-01-17 13:27:08,382 : worker.worker : DEBUG : Step 106954, finished rewards -33.30, envs finished 1
2026-01-17 13:27:08,399 : worker.worker : DEBUG : Step 106958, finished rewards 7.27, envs finished 1
2026-01-17 13:27:08,440 : worker.worker : DEBUG : Step 106966, finished rewards -39.14, envs finished 1
2026-01-17 13:27:08,465 : worker.worker : DEBUG : Step 106971, finished rewards 25.43, envs finished 1
2026-01-17 13:27:08,531 : agent.on_policy : DEBUG : Mean Losses: [9.689905317500234]
2026-01-17 13:27:08,543 : worker.worker : DEBUG : Step 106978, finished rewards 26.49, envs finished 1
2026-01-17 13:27:08,670 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:27:08,820 : agent.on_policy : DEBUG : Mean Losses: [1.415866557508707]
2026-01-17 13:27:08,836 : worker.worker : DEBUG : Step 107012, finished rewards 29.31, envs finished 1
2026-01-17 13:27:09,048 : worker.worker : DEBUG : Step 107039, finished rewards 32.49, envs finished 1
2026-01-17 13:27:09,175 : agent.on_policy : DEBUG : Mean Losses: [6.118103224784136]
2026-01-17 13:27:09,248 : worker.worker : DEBUG : Step 107052, finished rewards -1.71, envs finished 1
2026-01-17 13:27:09,300 : worker.worker : DEBUG : Step 107064, finished rewards 19.43, envs finished 1
2026-01-17 13:27:09,377 : worker.worker : DEBUG : Step 107071, finished rewards 18.25, envs finished 1
2026-01-17 13:27:09,436 : agent.on_policy : DEBUG : Mean Losses: [10.442466117441654]
2026-01-17 13:27:09,615 : worker.worker : DEBUG : Step 107100, finished rewards -17.77, envs finished 1
2026-01-17 13:27:09,619 : worker.worker : DEBUG : Step 107101, finished rewards 2.19, envs finished 1
2026-01-17 13:27:09,676 : agent.on_policy : DEBUG : Mean Losses: [6.132576126605272]
2026-01-17 13:27:09,726 : worker.worker : DEBUG : Step 107119, finished rewards 15.91, envs finished 1
2026-01-17 13:27:09,754 : worker.worker : DEBUG : Step 107124, finished rewards -28.17, envs finished 1
2026-01-17 13:27:09,898 : agent.on_policy : DEBUG : Mean Losses: [4.943985376507044]
2026-01-17 13:27:09,941 : worker.worker : DEBUG : Step 107149, finished rewards 29.07, envs finished 1
2026-01-17 13:27:10,015 : worker.worker : DEBUG : Step 107166, finished rewards 7.17, envs finished 1
2026-01-17 13:27:10,075 : agent.on_policy : DEBUG : Mean Losses: [7.084821429103613]
2026-01-17 13:27:10,151 : worker.worker : DEBUG : Step 107175, finished rewards 38.15, envs finished 1
2026-01-17 13:27:10,159 : worker.worker : DEBUG : Step 107176, finished rewards -7.15, envs finished 1
2026-01-17 13:27:10,330 : agent.on_policy : DEBUG : Mean Losses: [5.463710719719529]
2026-01-17 13:27:10,409 : worker.worker : DEBUG : Step 107218, finished rewards -5.22, envs finished 2
2026-01-17 13:27:10,572 : agent.on_policy : DEBUG : Mean Losses: [5.418843902647495]
2026-01-17 13:27:10,598 : worker.worker : DEBUG : Step 107239, finished rewards 7.64, envs finished 1
2026-01-17 13:27:10,707 : worker.worker : DEBUG : Step 107251, finished rewards 35.54, envs finished 1
2026-01-17 13:27:10,925 : agent.on_policy : DEBUG : Mean Losses: [6.780566342175007]
2026-01-17 13:27:10,936 : worker.worker : DEBUG : Step 107265, finished rewards 8.08, envs finished 1
2026-01-17 13:27:11,053 : worker.worker : DEBUG : Step 107284, finished rewards -34.02, envs finished 1
2026-01-17 13:27:11,331 : agent.on_policy : DEBUG : Mean Losses: [4.24427792057395]
2026-01-17 13:27:11,412 : worker.worker : DEBUG : Step 107309, finished rewards 25.89, envs finished 1
2026-01-17 13:27:11,447 : worker.worker : DEBUG : Step 107315, finished rewards -20.42, envs finished 1
2026-01-17 13:27:11,625 : agent.on_policy : DEBUG : Mean Losses: [6.574058890342712]
2026-01-17 13:27:11,693 : worker.worker : DEBUG : Step 107343, finished rewards -1.85, envs finished 1
2026-01-17 13:27:11,782 : worker.worker : DEBUG : Step 107355, finished rewards -19.11, envs finished 2
2026-01-17 13:27:11,934 : agent.on_policy : DEBUG : Mean Losses: [7.793652947992086]
2026-01-17 13:27:11,972 : worker.worker : DEBUG : Step 107362, finished rewards 10.71, envs finished 1
2026-01-17 13:27:12,054 : worker.worker : DEBUG : Step 107373, finished rewards 25.37, envs finished 1
2026-01-17 13:27:12,258 : agent.on_policy : DEBUG : Mean Losses: [4.546789683401585]
2026-01-17 13:27:12,318 : worker.worker : DEBUG : Step 107405, finished rewards 21.30, envs finished 1
2026-01-17 13:27:12,326 : worker.worker : DEBUG : Step 107406, finished rewards 24.88, envs finished 1
2026-01-17 13:27:12,403 : worker.worker : DEBUG : Step 107419, finished rewards -8.40, envs finished 1
2026-01-17 13:27:12,605 : agent.on_policy : DEBUG : Mean Losses: [6.674524907022715]
2026-01-17 13:27:12,902 : agent.on_policy : DEBUG : Mean Losses: [1.5399076072499156]
2026-01-17 13:27:12,956 : worker.worker : DEBUG : Step 107464, finished rewards 2.58, envs finished 1
2026-01-17 13:27:13,245 : agent.on_policy : DEBUG : Mean Losses: [5.090427249670029]
2026-01-17 13:27:13,276 : worker.worker : DEBUG : Step 107494, finished rewards -6.79, envs finished 1
2026-01-17 13:27:13,288 : worker.worker : DEBUG : Step 107496, finished rewards 36.00, envs finished 1
2026-01-17 13:27:13,302 : worker.worker : DEBUG : Step 107498, finished rewards 24.99, envs finished 1
2026-01-17 13:27:13,359 : worker.worker : DEBUG : Step 107509, finished rewards -3.76, envs finished 1
2026-01-17 13:27:13,531 : agent.on_policy : DEBUG : Mean Losses: [8.502353429794312]
2026-01-17 13:27:13,593 : worker.worker : DEBUG : Step 107534, finished rewards 7.12, envs finished 1
2026-01-17 13:27:13,664 : worker.worker : DEBUG : Step 107548, finished rewards -47.89, envs finished 1
2026-01-17 13:27:13,803 : agent.on_policy : DEBUG : Mean Losses: [4.7329106433317065]
2026-01-17 13:27:13,806 : worker.worker : DEBUG : Step 107552, finished rewards -54.14, envs finished 1
2026-01-17 13:27:13,867 : worker.worker : DEBUG : Step 107564, finished rewards 18.85, envs finished 1
2026-01-17 13:27:14,168 : agent.on_policy : DEBUG : Mean Losses: [2.80215528793633]
2026-01-17 13:27:14,420 : agent.on_policy : DEBUG : Mean Losses: [2.2903872318565845]
2026-01-17 13:27:14,426 : worker.worker : DEBUG : Step 107617, finished rewards 2.77, envs finished 1
2026-01-17 13:27:14,432 : worker.worker : DEBUG : Step 107618, finished rewards 1.94, envs finished 1
2026-01-17 13:27:14,464 : worker.worker : DEBUG : Step 107625, finished rewards 7.53, envs finished 1
2026-01-17 13:27:14,480 : worker.worker : DEBUG : Step 107627, finished rewards -6.71, envs finished 1
2026-01-17 13:27:14,491 : worker.worker : DEBUG : Step 107629, finished rewards 23.03, envs finished 1
2026-01-17 13:27:14,532 : worker.worker : DEBUG : Step 107638, finished rewards 27.97, envs finished 1
2026-01-17 13:27:14,619 : agent.on_policy : DEBUG : Mean Losses: [9.81027464568615]
2026-01-17 13:27:14,642 : worker.worker : DEBUG : Step 107654, finished rewards 26.91, envs finished 1
2026-01-17 13:27:14,847 : agent.on_policy : DEBUG : Mean Losses: [2.252621768042445]
2026-01-17 13:27:14,853 : worker.worker : DEBUG : Step 107681, finished rewards -0.15, envs finished 1
2026-01-17 13:27:14,969 : worker.worker : DEBUG : Step 107708, finished rewards 24.55, envs finished 1
2026-01-17 13:27:15,106 : agent.on_policy : DEBUG : Mean Losses: [4.280287887901068]
2026-01-17 13:27:15,129 : worker.worker : DEBUG : Step 107715, finished rewards 21.73, envs finished 1
2026-01-17 13:27:15,148 : worker.worker : DEBUG : Step 107717, finished rewards 24.37, envs finished 1
2026-01-17 13:27:15,178 : worker.worker : DEBUG : Step 107721, finished rewards 25.28, envs finished 1
2026-01-17 13:27:15,196 : worker.worker : DEBUG : Step 107724, finished rewards 21.75, envs finished 1
2026-01-17 13:27:15,263 : worker.worker : DEBUG : Step 107736, finished rewards 20.79, envs finished 1
2026-01-17 13:27:15,383 : agent.on_policy : DEBUG : Mean Losses: [8.388487555086613]
2026-01-17 13:27:15,484 : worker.worker : DEBUG : Step 107772, finished rewards 3.99, envs finished 1
2026-01-17 13:27:15,489 : worker.worker : DEBUG : Step 107773, finished rewards 23.46, envs finished 1
2026-01-17 13:27:15,598 : agent.on_policy : DEBUG : Mean Losses: [4.696398753672838]
2026-01-17 13:27:15,797 : agent.on_policy : DEBUG : Mean Losses: [1.7976186610758305]
2026-01-17 13:27:15,817 : worker.worker : DEBUG : Step 107813, finished rewards 20.37, envs finished 1
2026-01-17 13:27:15,870 : worker.worker : DEBUG : Step 107827, finished rewards 14.57, envs finished 1
2026-01-17 13:27:16,014 : agent.on_policy : DEBUG : Mean Losses: [6.125313878059387]
2026-01-17 13:27:16,032 : worker.worker : DEBUG : Step 107843, finished rewards 40.83, envs finished 1
2026-01-17 13:27:16,062 : worker.worker : DEBUG : Step 107849, finished rewards -1.06, envs finished 1
2026-01-17 13:27:16,205 : agent.on_policy : DEBUG : Mean Losses: [6.6559777446091175]
2026-01-17 13:27:16,246 : worker.worker : DEBUG : Step 107875, finished rewards -31.92, envs finished 1
2026-01-17 13:27:16,305 : worker.worker : DEBUG : Step 107889, finished rewards 5.66, envs finished 1
2026-01-17 13:27:16,333 : worker.worker : DEBUG : Step 107895, finished rewards -23.59, envs finished 1
2026-01-17 13:27:16,481 : agent.on_policy : DEBUG : Mean Losses: [6.022952746599913]
2026-01-17 13:27:16,584 : worker.worker : DEBUG : Step 107922, finished rewards -14.38, envs finished 2
2026-01-17 13:27:16,750 : agent.on_policy : DEBUG : Mean Losses: [4.883219845592976]
2026-01-17 13:27:16,788 : worker.worker : DEBUG : Step 107947, finished rewards 21.08, envs finished 1
2026-01-17 13:27:16,902 : agent.on_policy : DEBUG : Mean Losses: [4.087290234863758]
2026-01-17 13:27:16,914 : worker.worker : DEBUG : Step 107971, finished rewards 21.81, envs finished 1
2026-01-17 13:27:17,075 : worker.worker : DEBUG : Step 107988, finished rewards 24.25, envs finished 1
2026-01-17 13:27:17,111 : worker.worker : DEBUG : Step 107990, finished rewards -17.07, envs finished 1
2026-01-17 13:27:17,152 : worker.worker : DEBUG : Step 107996, finished rewards 10.95, envs finished 1
2026-01-17 13:27:17,179 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:27:17,270 : agent.on_policy : DEBUG : Mean Losses: [8.753243118524551]
2026-01-17 13:27:17,429 : worker.worker : DEBUG : Step 108026, finished rewards -46.33, envs finished 1
2026-01-17 13:27:17,532 : agent.on_policy : DEBUG : Mean Losses: [3.0836614221334457]
2026-01-17 13:27:17,602 : worker.worker : DEBUG : Step 108041, finished rewards 22.64, envs finished 1
2026-01-17 13:27:17,625 : worker.worker : DEBUG : Step 108045, finished rewards 1.67, envs finished 1
2026-01-17 13:27:17,814 : agent.on_policy : DEBUG : Mean Losses: [5.733295109122992]
2026-01-17 13:27:17,833 : worker.worker : DEBUG : Step 108069, finished rewards 19.36, envs finished 1
2026-01-17 13:27:17,885 : worker.worker : DEBUG : Step 108083, finished rewards 26.52, envs finished 1
2026-01-17 13:27:17,987 : agent.on_policy : DEBUG : Mean Losses: [5.572871387004852]
2026-01-17 13:27:18,051 : worker.worker : DEBUG : Step 108106, finished rewards 6.54, envs finished 1
2026-01-17 13:27:18,059 : worker.worker : DEBUG : Step 108107, finished rewards 9.98, envs finished 1
2026-01-17 13:27:18,240 : agent.on_policy : DEBUG : Mean Losses: [4.832273796200752]
2026-01-17 13:27:18,286 : worker.worker : DEBUG : Step 108140, finished rewards 8.59, envs finished 1
2026-01-17 13:27:18,337 : worker.worker : DEBUG : Step 108155, finished rewards 27.92, envs finished 1
2026-01-17 13:27:18,405 : agent.on_policy : DEBUG : Mean Losses: [6.48096077889204]
2026-01-17 13:27:18,426 : worker.worker : DEBUG : Step 108164, finished rewards -84.81, envs finished 1
2026-01-17 13:27:18,628 : agent.on_policy : DEBUG : Mean Losses: [5.1548759043216705]
2026-01-17 13:27:18,644 : worker.worker : DEBUG : Step 108196, finished rewards 9.09, envs finished 1
2026-01-17 13:27:18,667 : worker.worker : DEBUG : Step 108201, finished rewards 23.99, envs finished 1
2026-01-17 13:27:18,679 : worker.worker : DEBUG : Step 108203, finished rewards -28.62, envs finished 1
2026-01-17 13:27:18,809 : agent.on_policy : DEBUG : Mean Losses: [7.731715679168701]
2026-01-17 13:27:18,872 : worker.worker : DEBUG : Step 108233, finished rewards -49.90, envs finished 1
2026-01-17 13:27:18,931 : worker.worker : DEBUG : Step 108246, finished rewards 3.84, envs finished 2
2026-01-17 13:27:19,059 : agent.on_policy : DEBUG : Mean Losses: [6.576895080506802]
2026-01-17 13:27:19,149 : worker.worker : DEBUG : Step 108263, finished rewards 12.19, envs finished 1
2026-01-17 13:27:19,471 : agent.on_policy : DEBUG : Mean Losses: [3.336141061037779]
2026-01-17 13:27:19,524 : worker.worker : DEBUG : Step 108305, finished rewards -12.06, envs finished 1
2026-01-17 13:27:19,533 : worker.worker : DEBUG : Step 108307, finished rewards 11.62, envs finished 1
2026-01-17 13:27:19,668 : agent.on_policy : DEBUG : Mean Losses: [7.194991290569305]
2026-01-17 13:27:19,708 : worker.worker : DEBUG : Step 108326, finished rewards 5.03, envs finished 1
2026-01-17 13:27:19,730 : worker.worker : DEBUG : Step 108330, finished rewards 29.30, envs finished 1
2026-01-17 13:27:19,754 : worker.worker : DEBUG : Step 108334, finished rewards 28.27, envs finished 1
2026-01-17 13:27:19,790 : worker.worker : DEBUG : Step 108340, finished rewards 14.11, envs finished 1
2026-01-17 13:27:19,826 : worker.worker : DEBUG : Step 108346, finished rewards -18.66, envs finished 1
2026-01-17 13:27:19,903 : agent.on_policy : DEBUG : Mean Losses: [10.669060485437512]
2026-01-17 13:27:20,023 : worker.worker : DEBUG : Step 108377, finished rewards 8.52, envs finished 1
2026-01-17 13:27:20,143 : agent.on_policy : DEBUG : Mean Losses: [2.3257962302304804]
2026-01-17 13:27:20,215 : worker.worker : DEBUG : Step 108395, finished rewards 26.82, envs finished 1
2026-01-17 13:27:20,396 : agent.on_policy : DEBUG : Mean Losses: [3.5640117339789867]
2026-01-17 13:27:20,398 : worker.worker : DEBUG : Step 108416, finished rewards 31.73, envs finished 1
2026-01-17 13:27:20,446 : worker.worker : DEBUG : Step 108426, finished rewards 21.90, envs finished 1
2026-01-17 13:27:20,451 : worker.worker : DEBUG : Step 108427, finished rewards 17.30, envs finished 1
2026-01-17 13:27:20,472 : worker.worker : DEBUG : Step 108431, finished rewards 1.80, envs finished 1
2026-01-17 13:27:20,486 : worker.worker : DEBUG : Step 108433, finished rewards 23.66, envs finished 1
2026-01-17 13:27:20,593 : agent.on_policy : DEBUG : Mean Losses: [9.702866181731224]
2026-01-17 13:27:20,704 : worker.worker : DEBUG : Step 108463, finished rewards 6.94, envs finished 1
2026-01-17 13:27:20,973 : agent.on_policy : DEBUG : Mean Losses: [2.7363352477550507]
2026-01-17 13:27:21,031 : worker.worker : DEBUG : Step 108496, finished rewards 18.57, envs finished 1
2026-01-17 13:27:21,037 : worker.worker : DEBUG : Step 108497, finished rewards 4.78, envs finished 1
2026-01-17 13:27:21,187 : agent.on_policy : DEBUG : Mean Losses: [4.29221111163497]
2026-01-17 13:27:21,235 : worker.worker : DEBUG : Step 108527, finished rewards 17.52, envs finished 1
2026-01-17 13:27:21,356 : agent.on_policy : DEBUG : Mean Losses: [5.563588805496693]
2026-01-17 13:27:21,362 : worker.worker : DEBUG : Step 108545, finished rewards 6.42, envs finished 1
2026-01-17 13:27:21,492 : worker.worker : DEBUG : Step 108567, finished rewards -11.64, envs finished 1
2026-01-17 13:27:21,570 : worker.worker : DEBUG : Step 108575, finished rewards -23.34, envs finished 1
2026-01-17 13:27:21,657 : agent.on_policy : DEBUG : Mean Losses: [7.764686615206301]
2026-01-17 13:27:21,753 : worker.worker : DEBUG : Step 108589, finished rewards 4.60, envs finished 1
2026-01-17 13:27:21,873 : worker.worker : DEBUG : Step 108599, finished rewards 17.23, envs finished 1
2026-01-17 13:27:22,103 : agent.on_policy : DEBUG : Mean Losses: [5.68358700722456]
2026-01-17 13:27:22,134 : worker.worker : DEBUG : Step 108612, finished rewards -34.42, envs finished 1
2026-01-17 13:27:22,199 : worker.worker : DEBUG : Step 108621, finished rewards 36.46, envs finished 1
2026-01-17 13:27:22,315 : worker.worker : DEBUG : Step 108636, finished rewards -1.64, envs finished 1
2026-01-17 13:27:22,338 : worker.worker : DEBUG : Step 108638, finished rewards 11.61, envs finished 1
2026-01-17 13:27:22,465 : agent.on_policy : DEBUG : Mean Losses: [6.872156322002411]
2026-01-17 13:27:22,618 : worker.worker : DEBUG : Step 108666, finished rewards 26.17, envs finished 1
2026-01-17 13:27:22,712 : agent.on_policy : DEBUG : Mean Losses: [3.2790466472506523]
2026-01-17 13:27:22,769 : worker.worker : DEBUG : Step 108681, finished rewards 9.73, envs finished 1
2026-01-17 13:27:23,015 : agent.on_policy : DEBUG : Mean Losses: [3.3938535004854202]
2026-01-17 13:27:23,044 : worker.worker : DEBUG : Step 108712, finished rewards 24.96, envs finished 1
2026-01-17 13:27:23,050 : worker.worker : DEBUG : Step 108713, finished rewards 2.13, envs finished 1
2026-01-17 13:27:23,095 : worker.worker : DEBUG : Step 108722, finished rewards 11.20, envs finished 1
2026-01-17 13:27:23,116 : worker.worker : DEBUG : Step 108726, finished rewards -3.47, envs finished 1
2026-01-17 13:27:23,149 : worker.worker : DEBUG : Step 108733, finished rewards 22.76, envs finished 1
2026-01-17 13:27:23,212 : agent.on_policy : DEBUG : Mean Losses: [9.94843440502882]
2026-01-17 13:27:23,227 : worker.worker : DEBUG : Step 108739, finished rewards 16.61, envs finished 1
2026-01-17 13:27:23,430 : agent.on_policy : DEBUG : Mean Losses: [2.209288578480482]
2026-01-17 13:27:23,523 : worker.worker : DEBUG : Step 108798, finished rewards -4.19, envs finished 1
2026-01-17 13:27:23,601 : agent.on_policy : DEBUG : Mean Losses: [3.1930356547236443]
2026-01-17 13:27:23,644 : worker.worker : DEBUG : Step 108806, finished rewards 32.40, envs finished 1
2026-01-17 13:27:23,705 : worker.worker : DEBUG : Step 108811, finished rewards 20.11, envs finished 1
2026-01-17 13:27:23,876 : agent.on_policy : DEBUG : Mean Losses: [5.008923411369324]
2026-01-17 13:27:23,941 : worker.worker : DEBUG : Step 108848, finished rewards -33.76, envs finished 1
2026-01-17 13:27:23,965 : worker.worker : DEBUG : Step 108852, finished rewards 3.41, envs finished 1
2026-01-17 13:27:23,979 : worker.worker : DEBUG : Step 108855, finished rewards -16.24, envs finished 1
2026-01-17 13:27:24,120 : agent.on_policy : DEBUG : Mean Losses: [7.8897256553173065]
2026-01-17 13:27:24,160 : worker.worker : DEBUG : Step 108875, finished rewards -12.65, envs finished 1
2026-01-17 13:27:24,188 : worker.worker : DEBUG : Step 108881, finished rewards -9.33, envs finished 1
2026-01-17 13:27:24,236 : worker.worker : DEBUG : Step 108894, finished rewards 21.84, envs finished 1
2026-01-17 13:27:24,293 : agent.on_policy : DEBUG : Mean Losses: [5.606124684214592]
2026-01-17 13:27:24,487 : agent.on_policy : DEBUG : Mean Losses: [1.425636607222259]
2026-01-17 13:27:24,516 : worker.worker : DEBUG : Step 108936, finished rewards 31.99, envs finished 1
2026-01-17 13:27:24,556 : worker.worker : DEBUG : Step 108945, finished rewards -8.34, envs finished 1
2026-01-17 13:27:24,594 : worker.worker : DEBUG : Step 108954, finished rewards -10.96, envs finished 1
2026-01-17 13:27:24,619 : worker.worker : DEBUG : Step 108959, finished rewards 10.14, envs finished 1
2026-01-17 13:27:24,676 : agent.on_policy : DEBUG : Mean Losses: [8.062017798423767]
2026-01-17 13:27:24,756 : worker.worker : DEBUG : Step 108981, finished rewards 30.20, envs finished 1
2026-01-17 13:27:24,884 : agent.on_policy : DEBUG : Mean Losses: [3.7773474380373955]
2026-01-17 13:27:24,939 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:27:25,082 : worker.worker : DEBUG : Step 109018, finished rewards -8.11, envs finished 1
2026-01-17 13:27:25,220 : agent.on_policy : DEBUG : Mean Losses: [4.5158869829028845]
2026-01-17 13:27:25,272 : worker.worker : DEBUG : Step 109036, finished rewards -47.32, envs finished 1
2026-01-17 13:27:25,296 : worker.worker : DEBUG : Step 109040, finished rewards -24.89, envs finished 1
2026-01-17 13:27:25,329 : worker.worker : DEBUG : Step 109045, finished rewards 24.31, envs finished 1
2026-01-17 13:27:25,493 : agent.on_policy : DEBUG : Mean Losses: [7.198799557983875]
2026-01-17 13:27:25,525 : worker.worker : DEBUG : Step 109066, finished rewards -1.40, envs finished 1
2026-01-17 13:27:25,571 : worker.worker : DEBUG : Step 109077, finished rewards -3.69, envs finished 1
2026-01-17 13:27:25,655 : agent.on_policy : DEBUG : Mean Losses: [5.523897487670183]
2026-01-17 13:27:25,662 : worker.worker : DEBUG : Step 109089, finished rewards 12.25, envs finished 1
2026-01-17 13:27:25,744 : worker.worker : DEBUG : Step 109104, finished rewards 28.41, envs finished 1
2026-01-17 13:27:25,905 : agent.on_policy : DEBUG : Mean Losses: [4.287527192384005]
2026-01-17 13:27:25,984 : worker.worker : DEBUG : Step 109140, finished rewards -32.64, envs finished 1
2026-01-17 13:27:26,004 : worker.worker : DEBUG : Step 109145, finished rewards 18.29, envs finished 1
2026-01-17 13:27:26,126 : agent.on_policy : DEBUG : Mean Losses: [5.672876790165901]
2026-01-17 13:27:26,306 : agent.on_policy : DEBUG : Mean Losses: [2.446560814976692]
2026-01-17 13:27:26,312 : worker.worker : DEBUG : Step 109185, finished rewards 3.88, envs finished 1
2026-01-17 13:27:26,350 : worker.worker : DEBUG : Step 109193, finished rewards 2.80, envs finished 1
2026-01-17 13:27:26,368 : worker.worker : DEBUG : Step 109197, finished rewards -17.15, envs finished 1
2026-01-17 13:27:26,384 : worker.worker : DEBUG : Step 109200, finished rewards 20.06, envs finished 1
2026-01-17 13:27:26,420 : worker.worker : DEBUG : Step 109206, finished rewards -2.31, envs finished 1
2026-01-17 13:27:26,524 : agent.on_policy : DEBUG : Mean Losses: [9.10492199845612]
2026-01-17 13:27:26,547 : worker.worker : DEBUG : Step 109223, finished rewards 30.77, envs finished 1
2026-01-17 13:27:26,554 : worker.worker : DEBUG : Step 109224, finished rewards -2.78, envs finished 1
2026-01-17 13:27:26,767 : agent.on_policy : DEBUG : Mean Losses: [4.263011650182307]
2026-01-17 13:27:26,860 : worker.worker : DEBUG : Step 109276, finished rewards 26.56, envs finished 1
2026-01-17 13:27:26,961 : agent.on_policy : DEBUG : Mean Losses: [3.74954342097044]
2026-01-17 13:27:26,986 : worker.worker : DEBUG : Step 109284, finished rewards -5.93, envs finished 1
2026-01-17 13:27:27,058 : worker.worker : DEBUG : Step 109293, finished rewards 24.34, envs finished 1
2026-01-17 13:27:27,124 : worker.worker : DEBUG : Step 109305, finished rewards 31.22, envs finished 1
2026-01-17 13:27:27,143 : worker.worker : DEBUG : Step 109306, finished rewards 11.45, envs finished 1
2026-01-17 13:27:27,193 : worker.worker : DEBUG : Step 109310, finished rewards 29.13, envs finished 1
2026-01-17 13:27:27,208 : worker.worker : DEBUG : Step 109311, finished rewards 6.23, envs finished 1
2026-01-17 13:27:27,269 : agent.on_policy : DEBUG : Mean Losses: [14.676309458911419]
2026-01-17 13:27:27,388 : worker.worker : DEBUG : Step 109337, finished rewards -5.07, envs finished 1
2026-01-17 13:27:27,515 : agent.on_policy : DEBUG : Mean Losses: [2.752719212323427]
2026-01-17 13:27:27,624 : worker.worker : DEBUG : Step 109361, finished rewards 36.83, envs finished 1
2026-01-17 13:27:27,772 : agent.on_policy : DEBUG : Mean Losses: [3.885674260556698]
2026-01-17 13:27:27,930 : agent.on_policy : DEBUG : Mean Losses: [3.2657053470611572]
2026-01-17 13:27:27,958 : worker.worker : DEBUG : Step 109409, finished rewards 19.52, envs finished 1
2026-01-17 13:27:28,024 : worker.worker : DEBUG : Step 109420, finished rewards -16.49, envs finished 1
2026-01-17 13:27:28,072 : worker.worker : DEBUG : Step 109426, finished rewards -6.20, envs finished 1
2026-01-17 13:27:28,085 : worker.worker : DEBUG : Step 109427, finished rewards 8.28, envs finished 1
2026-01-17 13:27:28,159 : worker.worker : DEBUG : Step 109434, finished rewards 5.29, envs finished 1
2026-01-17 13:27:28,172 : worker.worker : DEBUG : Step 109435, finished rewards 20.50, envs finished 1
2026-01-17 13:27:28,328 : agent.on_policy : DEBUG : Mean Losses: [11.21822089701891]
2026-01-17 13:27:28,344 : worker.worker : DEBUG : Step 109444, finished rewards 31.08, envs finished 1
2026-01-17 13:27:28,408 : worker.worker : DEBUG : Step 109457, finished rewards -5.90, envs finished 1
2026-01-17 13:27:28,561 : agent.on_policy : DEBUG : Mean Losses: [2.9173442255705595]
2026-01-17 13:27:28,784 : agent.on_policy : DEBUG : Mean Losses: [1.071192553266883]
2026-01-17 13:27:28,922 : worker.worker : DEBUG : Step 109526, finished rewards 4.65, envs finished 1
2026-01-17 13:27:28,958 : worker.worker : DEBUG : Step 109528, finished rewards 23.36, envs finished 1
2026-01-17 13:27:29,060 : agent.on_policy : DEBUG : Mean Losses: [7.484483510255814]
2026-01-17 13:27:29,063 : worker.worker : DEBUG : Step 109536, finished rewards 24.67, envs finished 1
2026-01-17 13:27:29,073 : worker.worker : DEBUG : Step 109538, finished rewards 32.18, envs finished 1
2026-01-17 13:27:29,141 : worker.worker : DEBUG : Step 109546, finished rewards -0.74, envs finished 1
2026-01-17 13:27:29,166 : worker.worker : DEBUG : Step 109547, finished rewards 6.06, envs finished 1
2026-01-17 13:27:29,350 : agent.on_policy : DEBUG : Mean Losses: [5.975777208805084]
2026-01-17 13:27:29,360 : worker.worker : DEBUG : Step 109570, finished rewards -4.36, envs finished 1
2026-01-17 13:27:29,367 : worker.worker : DEBUG : Step 109571, finished rewards -11.73, envs finished 1
2026-01-17 13:27:29,730 : agent.on_policy : DEBUG : Mean Losses: [1.8842198252677917]
2026-01-17 13:27:29,826 : worker.worker : DEBUG : Step 109622, finished rewards 37.79, envs finished 1
2026-01-17 13:27:29,856 : worker.worker : DEBUG : Step 109629, finished rewards 31.35, envs finished 1
2026-01-17 13:27:29,971 : agent.on_policy : DEBUG : Mean Losses: [8.810867838561535]
2026-01-17 13:27:30,162 : worker.worker : DEBUG : Step 109651, finished rewards 5.81, envs finished 1
2026-01-17 13:27:30,219 : worker.worker : DEBUG : Step 109659, finished rewards 27.26, envs finished 1
2026-01-17 13:27:30,391 : agent.on_policy : DEBUG : Mean Losses: [6.495858658105135]
2026-01-17 13:27:30,431 : worker.worker : DEBUG : Step 109672, finished rewards -15.85, envs finished 1
2026-01-17 13:27:30,454 : worker.worker : DEBUG : Step 109676, finished rewards -8.21, envs finished 1
2026-01-17 13:27:30,499 : worker.worker : DEBUG : Step 109687, finished rewards -22.36, envs finished 1
2026-01-17 13:27:30,588 : agent.on_policy : DEBUG : Mean Losses: [6.024003077298403]
2026-01-17 13:27:30,602 : worker.worker : DEBUG : Step 109698, finished rewards 37.29, envs finished 1
2026-01-17 13:27:30,621 : worker.worker : DEBUG : Step 109703, finished rewards -8.22, envs finished 1
2026-01-17 13:27:30,811 : agent.on_policy : DEBUG : Mean Losses: [3.8931686505675316]
2026-01-17 13:27:31,065 : agent.on_policy : DEBUG : Mean Losses: [2.8064944557845592]
2026-01-17 13:27:31,101 : worker.worker : DEBUG : Step 109766, finished rewards 16.01, envs finished 3
2026-01-17 13:27:31,214 : worker.worker : DEBUG : Step 109787, finished rewards -22.37, envs finished 1
2026-01-17 13:27:31,368 : agent.on_policy : DEBUG : Mean Losses: [9.15828400850296]
2026-01-17 13:27:31,394 : worker.worker : DEBUG : Step 109796, finished rewards 23.63, envs finished 1
2026-01-17 13:27:31,433 : worker.worker : DEBUG : Step 109803, finished rewards -6.30, envs finished 1
2026-01-17 13:27:31,661 : agent.on_policy : DEBUG : Mean Losses: [4.661608112975955]
2026-01-17 13:27:31,733 : worker.worker : DEBUG : Step 109841, finished rewards -14.73, envs finished 1
2026-01-17 13:27:31,881 : agent.on_policy : DEBUG : Mean Losses: [3.9103799611330032]
2026-01-17 13:27:31,894 : worker.worker : DEBUG : Step 109859, finished rewards 23.61, envs finished 1
2026-01-17 13:27:31,901 : worker.worker : DEBUG : Step 109860, finished rewards 23.47, envs finished 1
2026-01-17 13:27:32,037 : worker.worker : DEBUG : Step 109887, finished rewards 17.74, envs finished 1
2026-01-17 13:27:32,147 : agent.on_policy : DEBUG : Mean Losses: [7.048158159479499]
2026-01-17 13:27:32,174 : worker.worker : DEBUG : Step 109893, finished rewards 21.91, envs finished 1
2026-01-17 13:27:32,217 : worker.worker : DEBUG : Step 109896, finished rewards 23.79, envs finished 1
2026-01-17 13:27:32,475 : agent.on_policy : DEBUG : Mean Losses: [5.23056965880096]
2026-01-17 13:27:32,604 : worker.worker : DEBUG : Step 109936, finished rewards -27.24, envs finished 1
2026-01-17 13:27:32,813 : agent.on_policy : DEBUG : Mean Losses: [5.299660317599773]
2026-01-17 13:27:32,871 : worker.worker : DEBUG : Step 109968, finished rewards 1.94, envs finished 1
2026-01-17 13:27:32,877 : worker.worker : DEBUG : Step 109969, finished rewards 12.18, envs finished 1
2026-01-17 13:27:32,918 : worker.worker : DEBUG : Step 109978, finished rewards 5.19, envs finished 1
2026-01-17 13:27:33,051 : agent.on_policy : DEBUG : Mean Losses: [8.382426016032696]
2026-01-17 13:27:33,062 : worker.worker : DEBUG : Step 109985, finished rewards -33.90, envs finished 2
2026-01-17 13:27:33,169 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:27:33,186 : worker.worker : INFO : Step 110000, Avg Reward 6.7612, Max Reward 40.8307, Loss [5.50613859]
2026-01-17 13:27:33,492 : agent.on_policy : DEBUG : Mean Losses: [2.8950223326683044]
2026-01-17 13:27:33,510 : worker.worker : DEBUG : Step 110020, finished rewards 4.69, envs finished 1
2026-01-17 13:27:33,533 : worker.worker : DEBUG : Step 110024, finished rewards -6.68, envs finished 1
2026-01-17 13:27:33,545 : worker.worker : DEBUG : Step 110025, finished rewards 25.22, envs finished 1
2026-01-17 13:27:33,751 : agent.on_policy : DEBUG : Mean Losses: [4.8693838976323605]
2026-01-17 13:27:33,805 : worker.worker : DEBUG : Step 110061, finished rewards 22.97, envs finished 1
2026-01-17 13:27:33,814 : worker.worker : DEBUG : Step 110063, finished rewards 28.02, envs finished 1
2026-01-17 13:27:33,868 : worker.worker : DEBUG : Step 110077, finished rewards 24.76, envs finished 1
2026-01-17 13:27:33,986 : agent.on_policy : DEBUG : Mean Losses: [8.979585610330105]
2026-01-17 13:27:34,105 : worker.worker : DEBUG : Step 110100, finished rewards -5.15, envs finished 1
2026-01-17 13:27:34,125 : worker.worker : DEBUG : Step 110104, finished rewards 2.81, envs finished 1
2026-01-17 13:27:34,326 : agent.on_policy : DEBUG : Mean Losses: [5.714156959205866]
2026-01-17 13:27:34,369 : worker.worker : DEBUG : Step 110122, finished rewards 18.27, envs finished 1
2026-01-17 13:27:34,400 : worker.worker : DEBUG : Step 110130, finished rewards 14.59, envs finished 1
2026-01-17 13:27:34,493 : agent.on_policy : DEBUG : Mean Losses: [6.494461277499795]
2026-01-17 13:27:34,518 : worker.worker : DEBUG : Step 110150, finished rewards 27.31, envs finished 1
2026-01-17 13:27:34,536 : worker.worker : DEBUG : Step 110153, finished rewards 26.63, envs finished 1
2026-01-17 13:27:34,618 : worker.worker : DEBUG : Step 110159, finished rewards -4.95, envs finished 1
2026-01-17 13:27:34,791 : agent.on_policy : DEBUG : Mean Losses: [5.775812853127718]
2026-01-17 13:27:34,856 : worker.worker : DEBUG : Step 110195, finished rewards 25.25, envs finished 1
2026-01-17 13:27:34,873 : worker.worker : DEBUG : Step 110199, finished rewards 15.94, envs finished 1
2026-01-17 13:27:35,004 : agent.on_policy : DEBUG : Mean Losses: [5.848380345851183]
2026-01-17 13:27:35,145 : worker.worker : DEBUG : Step 110234, finished rewards 9.36, envs finished 1
2026-01-17 13:27:35,209 : agent.on_policy : DEBUG : Mean Losses: [3.876196041703224]
2026-01-17 13:27:35,216 : worker.worker : DEBUG : Step 110242, finished rewards 24.72, envs finished 1
2026-01-17 13:27:35,270 : worker.worker : DEBUG : Step 110256, finished rewards 20.71, envs finished 1
2026-01-17 13:27:35,375 : worker.worker : DEBUG : Step 110269, finished rewards 6.30, envs finished 1
2026-01-17 13:27:35,480 : agent.on_policy : DEBUG : Mean Losses: [8.106426380574703]
2026-01-17 13:27:35,549 : worker.worker : DEBUG : Step 110284, finished rewards -19.42, envs finished 1
2026-01-17 13:27:35,652 : worker.worker : DEBUG : Step 110299, finished rewards 18.64, envs finished 1
2026-01-17 13:27:35,758 : agent.on_policy : DEBUG : Mean Losses: [5.248841047286987]
2026-01-17 13:27:35,886 : worker.worker : DEBUG : Step 110331, finished rewards 6.01, envs finished 2
2026-01-17 13:27:35,998 : agent.on_policy : DEBUG : Mean Losses: [5.584296248853207]
2026-01-17 13:27:36,012 : worker.worker : DEBUG : Step 110340, finished rewards 30.25, envs finished 1
2026-01-17 13:27:36,134 : worker.worker : DEBUG : Step 110361, finished rewards 4.26, envs finished 1
2026-01-17 13:27:36,249 : agent.on_policy : DEBUG : Mean Losses: [5.088873954489827]
2026-01-17 13:27:36,282 : worker.worker : DEBUG : Step 110377, finished rewards 23.88, envs finished 1
2026-01-17 13:27:36,363 : worker.worker : DEBUG : Step 110389, finished rewards 27.12, envs finished 1
2026-01-17 13:27:36,518 : agent.on_policy : DEBUG : Mean Losses: [5.721858710050583]
2026-01-17 13:27:36,560 : worker.worker : DEBUG : Step 110407, finished rewards -5.02, envs finished 1
2026-01-17 13:27:36,902 : agent.on_policy : DEBUG : Mean Losses: [3.1483594439923763]
2026-01-17 13:27:36,955 : worker.worker : DEBUG : Step 110437, finished rewards 14.66, envs finished 1
2026-01-17 13:27:36,315 : worker.worker : DEBUG : Step 110460, finished rewards 12.79, envs finished 2
2026-01-17 13:27:36,321 : worker.worker : DEBUG : Step 110461, finished rewards -192.21, envs finished 1
2026-01-17 13:27:36,389 : agent.on_policy : DEBUG : Mean Losses: [10.689147278666496]
2026-01-17 13:27:36,440 : worker.worker : DEBUG : Step 110480, finished rewards -13.31, envs finished 1
2026-01-17 13:27:36,511 : worker.worker : DEBUG : Step 110491, finished rewards 30.44, envs finished 1
2026-01-17 13:27:36,597 : agent.on_policy : DEBUG : Mean Losses: [6.487504202872515]
2026-01-17 13:27:36,651 : worker.worker : DEBUG : Step 110505, finished rewards 5.71, envs finished 1
2026-01-17 13:27:36,703 : worker.worker : DEBUG : Step 110520, finished rewards -23.52, envs finished 1
2026-01-17 13:27:36,820 : agent.on_policy : DEBUG : Mean Losses: [4.417581276036799]
2026-01-17 13:27:36,907 : worker.worker : DEBUG : Step 110544, finished rewards 30.76, envs finished 1
2026-01-17 13:27:36,971 : worker.worker : DEBUG : Step 110556, finished rewards 2.59, envs finished 1
2026-01-17 13:27:37,112 : agent.on_policy : DEBUG : Mean Losses: [6.223043512552977]
2026-01-17 13:27:37,309 : agent.on_policy : DEBUG : Mean Losses: [4.483765959739685]
2026-01-17 13:27:37,365 : worker.worker : DEBUG : Step 110604, finished rewards -8.95, envs finished 1
2026-01-17 13:27:37,385 : worker.worker : DEBUG : Step 110607, finished rewards -0.08, envs finished 2
2026-01-17 13:27:37,417 : worker.worker : DEBUG : Step 110612, finished rewards -3.16, envs finished 1
2026-01-17 13:27:37,551 : agent.on_policy : DEBUG : Mean Losses: [10.631649851799011]
2026-01-17 13:27:37,567 : worker.worker : DEBUG : Step 110627, finished rewards -7.59, envs finished 1
2026-01-17 13:27:37,887 : agent.on_policy : DEBUG : Mean Losses: [3.346540942788124]
2026-01-17 13:27:37,899 : worker.worker : DEBUG : Step 110659, finished rewards 9.49, envs finished 1
2026-01-17 13:27:38,129 : agent.on_policy : DEBUG : Mean Losses: [3.3830552101135254]
2026-01-17 13:27:38,144 : worker.worker : DEBUG : Step 110691, finished rewards -34.61, envs finished 1
2026-01-17 13:27:38,228 : worker.worker : DEBUG : Step 110714, finished rewards 10.91, envs finished 1
2026-01-17 13:27:38,311 : agent.on_policy : DEBUG : Mean Losses: [5.522345997393131]
2026-01-17 13:27:38,332 : worker.worker : DEBUG : Step 110722, finished rewards 22.64, envs finished 1
2026-01-17 13:27:38,363 : worker.worker : DEBUG : Step 110728, finished rewards 2.35, envs finished 2
2026-01-17 13:27:38,485 : worker.worker : DEBUG : Step 110749, finished rewards -4.35, envs finished 1
2026-01-17 13:27:38,578 : agent.on_policy : DEBUG : Mean Losses: [6.059310868382454]
2026-01-17 13:27:38,583 : worker.worker : DEBUG : Step 110753, finished rewards 22.81, envs finished 1
2026-01-17 13:27:38,800 : agent.on_policy : DEBUG : Mean Losses: [2.8079201243817806]
2026-01-17 13:27:38,858 : worker.worker : DEBUG : Step 110801, finished rewards 13.28, envs finished 1
2026-01-17 13:27:38,870 : worker.worker : DEBUG : Step 110804, finished rewards 36.52, envs finished 1
2026-01-17 13:27:38,914 : worker.worker : DEBUG : Step 110813, finished rewards 25.58, envs finished 1
2026-01-17 13:27:39,112 : agent.on_policy : DEBUG : Mean Losses: [9.758126616477966]
2026-01-17 13:27:39,130 : worker.worker : DEBUG : Step 110817, finished rewards -84.45, envs finished 1
2026-01-17 13:27:39,187 : worker.worker : DEBUG : Step 110821, finished rewards 23.76, envs finished 1
2026-01-17 13:27:39,239 : worker.worker : DEBUG : Step 110832, finished rewards 3.79, envs finished 1
2026-01-17 13:27:39,331 : worker.worker : DEBUG : Step 110845, finished rewards 20.80, envs finished 1
2026-01-17 13:27:39,459 : agent.on_policy : DEBUG : Mean Losses: [6.864904974587262]
2026-01-17 13:27:39,589 : worker.worker : DEBUG : Step 110876, finished rewards -0.46, envs finished 1
2026-01-17 13:27:39,695 : agent.on_policy : DEBUG : Mean Losses: [2.6165444552898407]
2026-01-17 13:27:39,810 : worker.worker : DEBUG : Step 110898, finished rewards 23.24, envs finished 1
2026-01-17 13:27:39,819 : worker.worker : DEBUG : Step 110899, finished rewards 21.26, envs finished 1
2026-01-17 13:27:39,852 : worker.worker : DEBUG : Step 110904, finished rewards 26.05, envs finished 1
2026-01-17 13:27:39,976 : agent.on_policy : DEBUG : Mean Losses: [8.624793399125338]
2026-01-17 13:27:40,068 : worker.worker : DEBUG : Step 110927, finished rewards 13.48, envs finished 1
2026-01-17 13:27:40,152 : worker.worker : DEBUG : Step 110941, finished rewards 20.88, envs finished 1
2026-01-17 13:27:40,245 : agent.on_policy : DEBUG : Mean Losses: [6.594131950289011]
2026-01-17 13:27:40,286 : worker.worker : DEBUG : Step 110948, finished rewards 6.71, envs finished 1
2026-01-17 13:27:40,375 : worker.worker : DEBUG : Step 110958, finished rewards 31.32, envs finished 1
2026-01-17 13:27:40,573 : agent.on_policy : DEBUG : Mean Losses: [4.868464270606637]
2026-01-17 13:27:40,638 : worker.worker : DEBUG : Step 110984, finished rewards 29.22, envs finished 1
2026-01-17 13:27:40,654 : worker.worker : DEBUG : Step 110986, finished rewards 27.42, envs finished 1
2026-01-17 13:27:40,715 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:27:40,891 : agent.on_policy : DEBUG : Mean Losses: [5.8243244253098965]
2026-01-17 13:27:40,901 : worker.worker : DEBUG : Step 111009, finished rewards -36.73, envs finished 1
2026-01-17 13:27:40,936 : worker.worker : DEBUG : Step 111014, finished rewards 10.46, envs finished 1
2026-01-17 13:27:40,961 : worker.worker : DEBUG : Step 111019, finished rewards 36.36, envs finished 1
2026-01-17 13:27:41,095 : agent.on_policy : DEBUG : Mean Losses: [4.8453673124313354]
2026-01-17 13:27:41,418 : agent.on_policy : DEBUG : Mean Losses: [3.1291223913431168]
2026-01-17 13:27:41,424 : worker.worker : DEBUG : Step 111073, finished rewards 5.23, envs finished 2
2026-01-17 13:27:41,429 : worker.worker : DEBUG : Step 111074, finished rewards -1.85, envs finished 1
2026-01-17 13:27:41,512 : worker.worker : DEBUG : Step 111098, finished rewards 30.35, envs finished 1
2026-01-17 13:27:41,530 : worker.worker : DEBUG : Step 111102, finished rewards 24.19, envs finished 1
2026-01-17 13:27:41,628 : agent.on_policy : DEBUG : Mean Losses: [10.232942968606949]
2026-01-17 13:27:41,731 : worker.worker : DEBUG : Step 111118, finished rewards -21.50, envs finished 1
2026-01-17 13:27:41,838 : worker.worker : DEBUG : Step 111132, finished rewards -9.82, envs finished 1
2026-01-17 13:27:41,990 : agent.on_policy : DEBUG : Mean Losses: [5.683351702988148]
2026-01-17 13:27:42,073 : worker.worker : DEBUG : Step 111148, finished rewards -4.95, envs finished 1
2026-01-17 13:27:42,085 : worker.worker : DEBUG : Step 111149, finished rewards 38.54, envs finished 1
2026-01-17 13:27:42,206 : worker.worker : DEBUG : Step 111164, finished rewards 25.00, envs finished 1
2026-01-17 13:27:42,338 : agent.on_policy : DEBUG : Mean Losses: [7.4333724565804005]
2026-01-17 13:27:42,442 : worker.worker : DEBUG : Step 111181, finished rewards 30.79, envs finished 1
2026-01-17 13:27:42,668 : agent.on_policy : DEBUG : Mean Losses: [4.577170982956886]
2026-01-17 13:27:42,673 : worker.worker : DEBUG : Step 111201, finished rewards 31.24, envs finished 2
2026-01-17 13:27:42,679 : worker.worker : DEBUG : Step 111202, finished rewards -3.39, envs finished 1
2026-01-17 13:27:42,728 : worker.worker : DEBUG : Step 111212, finished rewards 23.75, envs finished 1
2026-01-17 13:27:42,942 : agent.on_policy : DEBUG : Mean Losses: [4.578202534466982]
2026-01-17 13:27:43,163 : agent.on_policy : DEBUG : Mean Losses: [2.5994925647974014]
2026-01-17 13:27:43,208 : worker.worker : DEBUG : Step 111275, finished rewards 12.59, envs finished 2
2026-01-17 13:27:43,330 : agent.on_policy : DEBUG : Mean Losses: [6.663969397544861]
2026-01-17 13:27:43,338 : worker.worker : DEBUG : Step 111297, finished rewards 22.96, envs finished 1
2026-01-17 13:27:43,404 : worker.worker : DEBUG : Step 111305, finished rewards -14.76, envs finished 1
2026-01-17 13:27:43,446 : worker.worker : DEBUG : Step 111313, finished rewards -13.31, envs finished 1
2026-01-17 13:27:43,465 : worker.worker : DEBUG : Step 111317, finished rewards 10.79, envs finished 1
2026-01-17 13:27:43,605 : agent.on_policy : DEBUG : Mean Losses: [6.992668431252241]
2026-01-17 13:27:43,607 : worker.worker : DEBUG : Step 111328, finished rewards 7.96, envs finished 1
2026-01-17 13:27:43,799 : agent.on_policy : DEBUG : Mean Losses: [3.114362120628357]
2026-01-17 13:27:43,849 : worker.worker : DEBUG : Step 111371, finished rewards -28.67, envs finished 1
2026-01-17 13:27:44,020 : agent.on_policy : DEBUG : Mean Losses: [4.659025475382805]
2026-01-17 13:27:44,048 : worker.worker : DEBUG : Step 111401, finished rewards -0.58, envs finished 1
2026-01-17 13:27:44,056 : worker.worker : DEBUG : Step 111403, finished rewards 25.87, envs finished 1
2026-01-17 13:27:44,083 : worker.worker : DEBUG : Step 111408, finished rewards 11.59, envs finished 1
2026-01-17 13:27:44,117 : worker.worker : DEBUG : Step 111415, finished rewards 12.93, envs finished 1
2026-01-17 13:27:44,146 : worker.worker : DEBUG : Step 111421, finished rewards -12.44, envs finished 1
2026-01-17 13:27:44,207 : agent.on_policy : DEBUG : Mean Losses: [11.138351172208786]
2026-01-17 13:27:44,355 : worker.worker : DEBUG : Step 111452, finished rewards 5.48, envs finished 1
2026-01-17 13:27:44,427 : agent.on_policy : DEBUG : Mean Losses: [3.0578649416565895]
2026-01-17 13:27:44,552 : worker.worker : DEBUG : Step 111484, finished rewards -12.94, envs finished 1
2026-01-17 13:27:44,559 : worker.worker : DEBUG : Step 111485, finished rewards 30.40, envs finished 1
2026-01-17 13:27:44,621 : agent.on_policy : DEBUG : Mean Losses: [6.624405570328236]
2026-01-17 13:27:44,653 : worker.worker : DEBUG : Step 111497, finished rewards 36.78, envs finished 1
2026-01-17 13:27:44,657 : worker.worker : DEBUG : Step 111498, finished rewards 24.03, envs finished 1
2026-01-17 13:27:44,725 : worker.worker : DEBUG : Step 111510, finished rewards 21.85, envs finished 1
2026-01-17 13:27:44,907 : agent.on_policy : DEBUG : Mean Losses: [7.214037589728832]
2026-01-17 13:27:44,964 : worker.worker : DEBUG : Step 111539, finished rewards 5.82, envs finished 1
2026-01-17 13:27:44,985 : worker.worker : DEBUG : Step 111543, finished rewards -31.10, envs finished 1
2026-01-17 13:27:45,156 : agent.on_policy : DEBUG : Mean Losses: [5.392503637820482]
2026-01-17 13:27:45,244 : worker.worker : DEBUG : Step 111562, finished rewards 34.04, envs finished 1
2026-01-17 13:27:45,332 : worker.worker : DEBUG : Step 111574, finished rewards 1.84, envs finished 1
2026-01-17 13:27:45,510 : agent.on_policy : DEBUG : Mean Losses: [4.9443136136978865]
2026-01-17 13:27:45,552 : worker.worker : DEBUG : Step 111595, finished rewards 11.60, envs finished 1
2026-01-17 13:27:45,593 : worker.worker : DEBUG : Step 111606, finished rewards 14.73, envs finished 1
2026-01-17 13:27:45,629 : worker.worker : DEBUG : Step 111615, finished rewards 36.52, envs finished 1
2026-01-17 13:27:45,681 : agent.on_policy : DEBUG : Mean Losses: [8.058663614094257]
2026-01-17 13:27:45,682 : worker.worker : DEBUG : Step 111616, finished rewards 7.13, envs finished 1
2026-01-17 13:27:45,687 : worker.worker : DEBUG : Step 111617, finished rewards 14.59, envs finished 1
2026-01-17 13:27:45,704 : worker.worker : DEBUG : Step 111619, finished rewards 36.34, envs finished 1
2026-01-17 13:27:45,930 : agent.on_policy : DEBUG : Mean Losses: [2.3900437839329243]
2026-01-17 13:27:46,028 : worker.worker : DEBUG : Step 111678, finished rewards 5.81, envs finished 1
2026-01-17 13:27:46,134 : agent.on_policy : DEBUG : Mean Losses: [3.3652468360960484]
2026-01-17 13:27:46,225 : worker.worker : DEBUG : Step 111693, finished rewards 36.26, envs finished 1
2026-01-17 13:27:46,304 : worker.worker : DEBUG : Step 111701, finished rewards 15.14, envs finished 1
2026-01-17 13:27:46,370 : worker.worker : DEBUG : Step 111706, finished rewards 0.05, envs finished 1
2026-01-17 13:27:46,376 : worker.worker : DEBUG : Step 111707, finished rewards 24.83, envs finished 1
2026-01-17 13:27:46,540 : agent.on_policy : DEBUG : Mean Losses: [11.156202301383018]
2026-01-17 13:27:46,555 : worker.worker : DEBUG : Step 111715, finished rewards 21.59, envs finished 1
2026-01-17 13:27:46,681 : worker.worker : DEBUG : Step 111740, finished rewards -4.17, envs finished 1
2026-01-17 13:27:46,788 : agent.on_policy : DEBUG : Mean Losses: [4.525344122201204]
2026-01-17 13:27:47,001 : agent.on_policy : DEBUG : Mean Losses: [1.8168969042599201]
2026-01-17 13:27:47,037 : worker.worker : DEBUG : Step 111786, finished rewards 29.44, envs finished 1
2026-01-17 13:27:47,153 : agent.on_policy : DEBUG : Mean Losses: [4.692188262939453]
2026-01-17 13:27:47,185 : worker.worker : DEBUG : Step 111814, finished rewards 20.65, envs finished 1
2026-01-17 13:27:47,230 : worker.worker : DEBUG : Step 111818, finished rewards -46.47, envs finished 1
2026-01-17 13:27:47,256 : worker.worker : DEBUG : Step 111823, finished rewards -4.79, envs finished 1
2026-01-17 13:27:47,283 : worker.worker : DEBUG : Step 111828, finished rewards -13.84, envs finished 1
2026-01-17 13:27:47,376 : agent.on_policy : DEBUG : Mean Losses: [8.10388246923685]
2026-01-17 13:27:47,397 : worker.worker : DEBUG : Step 111846, finished rewards -13.18, envs finished 1
2026-01-17 13:27:47,503 : worker.worker : DEBUG : Step 111862, finished rewards 6.04, envs finished 1
2026-01-17 13:27:47,526 : worker.worker : DEBUG : Step 111866, finished rewards -19.06, envs finished 1
2026-01-17 13:27:47,661 : agent.on_policy : DEBUG : Mean Losses: [5.218546226620674]
2026-01-17 13:27:47,844 : agent.on_policy : DEBUG : Mean Losses: [1.8414992690086365]
2026-01-17 13:27:47,860 : worker.worker : DEBUG : Step 111908, finished rewards 1.26, envs finished 1
2026-01-17 13:27:47,916 : worker.worker : DEBUG : Step 111922, finished rewards 13.52, envs finished 1
2026-01-17 13:27:47,968 : worker.worker : DEBUG : Step 111934, finished rewards 11.07, envs finished 1
2026-01-17 13:27:48,072 : agent.on_policy : DEBUG : Mean Losses: [7.176953360438347]
2026-01-17 13:27:48,080 : worker.worker : DEBUG : Step 111938, finished rewards 14.29, envs finished 1
2026-01-17 13:27:48,119 : worker.worker : DEBUG : Step 111946, finished rewards 30.53, envs finished 1
2026-01-17 13:27:48,223 : worker.worker : DEBUG : Step 111963, finished rewards -9.02, envs finished 1
2026-01-17 13:27:48,370 : agent.on_policy : DEBUG : Mean Losses: [5.517517047002912]
2026-01-17 13:27:48,391 : worker.worker : DEBUG : Step 111974, finished rewards -1.01, envs finished 1
2026-01-17 13:27:48,448 : worker.worker : DEBUG : Step 111981, finished rewards 7.32, envs finished 1
2026-01-17 13:27:48,519 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:27:48,614 : agent.on_policy : DEBUG : Mean Losses: [3.5940468348562717]
2026-01-17 13:27:48,690 : worker.worker : DEBUG : Step 112015, finished rewards 14.22, envs finished 1
2026-01-17 13:27:48,774 : worker.worker : DEBUG : Step 112030, finished rewards 22.42, envs finished 1
2026-01-17 13:27:48,854 : agent.on_policy : DEBUG : Mean Losses: [6.168539065867662]
2026-01-17 13:27:48,859 : worker.worker : DEBUG : Step 112033, finished rewards 22.81, envs finished 1
2026-01-17 13:27:48,902 : worker.worker : DEBUG : Step 112044, finished rewards 19.51, envs finished 1
2026-01-17 13:27:49,015 : worker.worker : DEBUG : Step 112057, finished rewards -7.32, envs finished 1
2026-01-17 13:27:49,054 : worker.worker : DEBUG : Step 112062, finished rewards 20.83, envs finished 1
2026-01-17 13:27:49,217 : agent.on_policy : DEBUG : Mean Losses: [7.967093553394079]
2026-01-17 13:27:49,565 : agent.on_policy : DEBUG : Mean Losses: [2.087043199688196]
2026-01-17 13:27:49,622 : worker.worker : DEBUG : Step 112112, finished rewards -5.31, envs finished 1
2026-01-17 13:27:49,633 : worker.worker : DEBUG : Step 112114, finished rewards 32.50, envs finished 1
2026-01-17 13:27:49,657 : worker.worker : DEBUG : Step 112120, finished rewards 38.01, envs finished 1
2026-01-17 13:27:49,669 : worker.worker : DEBUG : Step 112122, finished rewards 24.47, envs finished 1
2026-01-17 13:27:49,684 : worker.worker : DEBUG : Step 112125, finished rewards -14.23, envs finished 1
2026-01-17 13:27:49,824 : agent.on_policy : DEBUG : Mean Losses: [12.314531426876783]
2026-01-17 13:27:49,943 : worker.worker : DEBUG : Step 112154, finished rewards 24.45, envs finished 1
2026-01-17 13:27:50,114 : agent.on_policy : DEBUG : Mean Losses: [4.765240769833326]
2026-01-17 13:27:50,356 : agent.on_policy : DEBUG : Mean Losses: [3.6710401605814695]
2026-01-17 13:27:50,417 : worker.worker : DEBUG : Step 112210, finished rewards -21.27, envs finished 1
2026-01-17 13:27:50,430 : worker.worker : DEBUG : Step 112212, finished rewards 22.10, envs finished 2
2026-01-17 13:27:50,461 : worker.worker : DEBUG : Step 112218, finished rewards 16.17, envs finished 1
2026-01-17 13:27:50,475 : worker.worker : DEBUG : Step 112221, finished rewards 18.21, envs finished 1
2026-01-17 13:27:50,584 : agent.on_policy : DEBUG : Mean Losses: [13.92600629478693]
2026-01-17 13:27:50,699 : worker.worker : DEBUG : Step 112246, finished rewards 24.37, envs finished 1
2026-01-17 13:27:50,729 : worker.worker : DEBUG : Step 112252, finished rewards -83.86, envs finished 1
2026-01-17 13:27:50,854 : agent.on_policy : DEBUG : Mean Losses: [5.310580357909203]
2026-01-17 13:27:51,001 : worker.worker : DEBUG : Step 112281, finished rewards -22.65, envs finished 1
2026-01-17 13:27:51,075 : agent.on_policy : DEBUG : Mean Losses: [2.5652126371860504]
2026-01-17 13:27:51,166 : worker.worker : DEBUG : Step 112308, finished rewards 20.25, envs finished 1
2026-01-17 13:27:51,270 : agent.on_policy : DEBUG : Mean Losses: [6.102710336446762]
2026-01-17 13:27:51,275 : worker.worker : DEBUG : Step 112321, finished rewards 11.29, envs finished 1
2026-01-17 13:27:51,436 : worker.worker : DEBUG : Step 112347, finished rewards -11.51, envs finished 1
2026-01-17 13:27:51,505 : agent.on_policy : DEBUG : Mean Losses: [4.950070716440678]
2026-01-17 13:27:51,529 : worker.worker : DEBUG : Step 112358, finished rewards 12.45, envs finished 1
2026-01-17 13:27:51,719 : agent.on_policy : DEBUG : Mean Losses: [3.6466563418507576]
2026-01-17 13:27:51,727 : worker.worker : DEBUG : Step 112386, finished rewards -25.54, envs finished 1
2026-01-17 13:27:51,761 : worker.worker : DEBUG : Step 112394, finished rewards 8.24, envs finished 1
2026-01-17 13:27:51,836 : worker.worker : DEBUG : Step 112415, finished rewards -21.88, envs finished 1
2026-01-17 13:27:51,883 : agent.on_policy : DEBUG : Mean Losses: [4.654164660722017]
2026-01-17 13:27:51,885 : worker.worker : DEBUG : Step 112416, finished rewards -51.10, envs finished 1
2026-01-17 13:27:51,951 : worker.worker : DEBUG : Step 112423, finished rewards 7.13, envs finished 1
2026-01-17 13:27:52,096 : worker.worker : DEBUG : Step 112437, finished rewards 24.80, envs finished 1
2026-01-17 13:27:52,351 : agent.on_policy : DEBUG : Mean Losses: [5.7390823140740395]
2026-01-17 13:27:52,387 : worker.worker : DEBUG : Step 112452, finished rewards -4.83, envs finished 1
2026-01-17 13:27:52,651 : agent.on_policy : DEBUG : Mean Losses: [1.807414535433054]
2026-01-17 13:27:52,668 : worker.worker : DEBUG : Step 112483, finished rewards 21.63, envs finished 1
2026-01-17 13:27:52,687 : worker.worker : DEBUG : Step 112487, finished rewards 23.49, envs finished 1
2026-01-17 13:27:52,742 : worker.worker : DEBUG : Step 112499, finished rewards -8.77, envs finished 1
2026-01-17 13:27:52,793 : worker.worker : DEBUG : Step 112508, finished rewards 23.83, envs finished 1
2026-01-17 13:27:52,922 : agent.on_policy : DEBUG : Mean Losses: [7.663023270666599]
2026-01-17 13:27:53,025 : worker.worker : DEBUG : Step 112523, finished rewards 18.13, envs finished 1
2026-01-17 13:27:53,047 : worker.worker : DEBUG : Step 112527, finished rewards 10.27, envs finished 1
2026-01-17 13:27:53,127 : worker.worker : DEBUG : Step 112535, finished rewards 21.13, envs finished 1
2026-01-17 13:27:53,294 : agent.on_policy : DEBUG : Mean Losses: [7.449481200426817]
2026-01-17 13:27:53,504 : agent.on_policy : DEBUG : Mean Losses: [1.6429384909570217]
2026-01-17 13:27:53,536 : worker.worker : DEBUG : Step 112584, finished rewards 16.71, envs finished 1
2026-01-17 13:27:53,586 : worker.worker : DEBUG : Step 112594, finished rewards 13.90, envs finished 1
2026-01-17 13:27:53,684 : agent.on_policy : DEBUG : Mean Losses: [6.124037764966488]
2026-01-17 13:27:53,718 : worker.worker : DEBUG : Step 112617, finished rewards 26.18, envs finished 1
2026-01-17 13:27:53,785 : worker.worker : DEBUG : Step 112624, finished rewards 17.53, envs finished 1
2026-01-17 13:27:53,848 : worker.worker : DEBUG : Step 112639, finished rewards -46.55, envs finished 1
2026-01-17 13:27:53,950 : agent.on_policy : DEBUG : Mean Losses: [9.024658039212227]
2026-01-17 13:27:54,090 : worker.worker : DEBUG : Step 112663, finished rewards -22.97, envs finished 1
2026-01-17 13:27:54,170 : agent.on_policy : DEBUG : Mean Losses: [3.403956290334463]
2026-01-17 13:27:54,196 : worker.worker : DEBUG : Step 112678, finished rewards -21.79, envs finished 1
2026-01-17 13:27:54,231 : worker.worker : DEBUG : Step 112686, finished rewards -17.36, envs finished 1
2026-01-17 13:27:54,419 : agent.on_policy : DEBUG : Mean Losses: [4.587524067610502]
2026-01-17 13:27:54,544 : worker.worker : DEBUG : Step 112715, finished rewards 26.39, envs finished 1
2026-01-17 13:27:54,643 : worker.worker : DEBUG : Step 112726, finished rewards -8.28, envs finished 1
2026-01-17 13:27:54,683 : worker.worker : DEBUG : Step 112731, finished rewards 24.41, envs finished 1
2026-01-17 13:27:54,799 : agent.on_policy : DEBUG : Mean Losses: [8.013092495501041]
2026-01-17 13:27:54,806 : worker.worker : DEBUG : Step 112737, finished rewards -3.88, envs finished 2
2026-01-17 13:27:55,005 : agent.on_policy : DEBUG : Mean Losses: [2.0566969513893127]
2026-01-17 13:27:55,046 : worker.worker : DEBUG : Step 112780, finished rewards 22.44, envs finished 1
2026-01-17 13:27:55,076 : worker.worker : DEBUG : Step 112787, finished rewards 2.42, envs finished 1
2026-01-17 13:27:55,170 : agent.on_policy : DEBUG : Mean Losses: [5.407726816833019]
2026-01-17 13:27:55,216 : worker.worker : DEBUG : Step 112809, finished rewards 30.67, envs finished 1
2026-01-17 13:27:55,249 : worker.worker : DEBUG : Step 112812, finished rewards 31.36, envs finished 1
2026-01-17 13:27:55,347 : worker.worker : DEBUG : Step 112826, finished rewards 26.94, envs finished 1
2026-01-17 13:27:55,493 : agent.on_policy : DEBUG : Mean Losses: [8.734674092382193]
2026-01-17 13:27:55,503 : worker.worker : DEBUG : Step 112834, finished rewards 6.53, envs finished 1
2026-01-17 13:27:55,550 : worker.worker : DEBUG : Step 112845, finished rewards 12.67, envs finished 1
2026-01-17 13:27:55,703 : agent.on_policy : DEBUG : Mean Losses: [3.759749084711075]
2026-01-17 13:27:55,761 : worker.worker : DEBUG : Step 112873, finished rewards 23.53, envs finished 1
2026-01-17 13:27:55,773 : worker.worker : DEBUG : Step 112874, finished rewards -43.50, envs finished 1
2026-01-17 13:27:55,832 : worker.worker : DEBUG : Step 112889, finished rewards 36.70, envs finished 1
2026-01-17 13:27:55,943 : agent.on_policy : DEBUG : Mean Losses: [7.808872617781162]
2026-01-17 13:27:55,959 : worker.worker : DEBUG : Step 112900, finished rewards 25.71, envs finished 1
2026-01-17 13:27:56,080 : worker.worker : DEBUG : Step 112919, finished rewards 23.50, envs finished 1
2026-01-17 13:27:56,142 : worker.worker : DEBUG : Step 112925, finished rewards 2.61, envs finished 1
2026-01-17 13:27:56,232 : agent.on_policy : DEBUG : Mean Losses: [5.407849807292223]
2026-01-17 13:27:56,514 : agent.on_policy : DEBUG : Mean Losses: [2.73526319488883]
2026-01-17 13:27:56,577 : worker.worker : DEBUG : Step 112966, finished rewards 24.69, envs finished 1
2026-01-17 13:27:56,609 : worker.worker : DEBUG : Step 112972, finished rewards -11.32, envs finished 1
2026-01-17 13:27:56,741 : agent.on_policy : DEBUG : Mean Losses: [5.482461929321289]
2026-01-17 13:27:56,822 : worker.worker : DEBUG : Step 112998, finished rewards -4.79, envs finished 1
2026-01-17 13:27:56,824 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:27:56,865 : worker.worker : DEBUG : Step 113004, finished rewards 8.57, envs finished 1
2026-01-17 13:27:56,929 : worker.worker : DEBUG : Step 113010, finished rewards 25.89, envs finished 1
2026-01-17 13:27:56,957 : worker.worker : DEBUG : Step 113014, finished rewards 26.97, envs finished 1
2026-01-17 13:27:57,106 : agent.on_policy : DEBUG : Mean Losses: [8.616346906870604]
2026-01-17 13:27:57,112 : worker.worker : DEBUG : Step 113025, finished rewards 2.52, envs finished 1
2026-01-17 13:27:57,132 : worker.worker : DEBUG : Step 113030, finished rewards -22.87, envs finished 1
2026-01-17 13:27:57,267 : agent.on_policy : DEBUG : Mean Losses: [2.3581301365047693]
2026-01-17 13:27:57,349 : worker.worker : DEBUG : Step 113067, finished rewards 18.28, envs finished 1
2026-01-17 13:27:57,567 : agent.on_policy : DEBUG : Mean Losses: [3.26266573369503]
2026-01-17 13:27:57,601 : worker.worker : DEBUG : Step 113096, finished rewards 24.63, envs finished 1
2026-01-17 13:27:57,663 : worker.worker : DEBUG : Step 113108, finished rewards 22.94, envs finished 1
2026-01-17 13:27:57,703 : worker.worker : DEBUG : Step 113116, finished rewards 8.31, envs finished 1
2026-01-17 13:27:57,713 : worker.worker : DEBUG : Step 113118, finished rewards -13.20, envs finished 1
2026-01-17 13:27:57,822 : agent.on_policy : DEBUG : Mean Losses: [9.7237389087677]
2026-01-17 13:27:57,833 : worker.worker : DEBUG : Step 113122, finished rewards 25.55, envs finished 1
2026-01-17 13:27:57,964 : worker.worker : DEBUG : Step 113144, finished rewards -3.87, envs finished 1
2026-01-17 13:27:57,979 : worker.worker : DEBUG : Step 113146, finished rewards 5.65, envs finished 1
2026-01-17 13:27:58,092 : agent.on_policy : DEBUG : Mean Losses: [5.211242381483316]
2026-01-17 13:27:58,282 : agent.on_policy : DEBUG : Mean Losses: [1.828429862856865]
2026-01-17 13:27:58,353 : worker.worker : DEBUG : Step 113206, finished rewards 20.69, envs finished 1
2026-01-17 13:27:58,360 : worker.worker : DEBUG : Step 113207, finished rewards 30.18, envs finished 1
2026-01-17 13:27:58,376 : worker.worker : DEBUG : Step 113210, finished rewards 6.22, envs finished 1
2026-01-17 13:27:58,394 : worker.worker : DEBUG : Step 113213, finished rewards 20.03, envs finished 1
2026-01-17 13:27:58,409 : worker.worker : DEBUG : Step 113215, finished rewards -17.41, envs finished 1
2026-01-17 13:27:58,534 : agent.on_policy : DEBUG : Mean Losses: [12.46192629635334]
2026-01-17 13:27:58,554 : worker.worker : DEBUG : Step 113220, finished rewards 16.17, envs finished 1
2026-01-17 13:27:58,651 : worker.worker : DEBUG : Step 113238, finished rewards 24.68, envs finished 1
2026-01-17 13:27:58,781 : agent.on_policy : DEBUG : Mean Losses: [3.631929174531251]
2026-01-17 13:27:59,009 : agent.on_policy : DEBUG : Mean Losses: [1.555549819022417]
2026-01-17 13:27:59,015 : worker.worker : DEBUG : Step 113281, finished rewards -9.71, envs finished 1
2026-01-17 13:27:59,202 : agent.on_policy : DEBUG : Mean Losses: [3.402720645070076]
2026-01-17 13:27:59,229 : worker.worker : DEBUG : Step 113318, finished rewards 15.77, envs finished 1
2026-01-17 13:27:59,235 : worker.worker : DEBUG : Step 113319, finished rewards 18.48, envs finished 1
2026-01-17 13:27:59,244 : worker.worker : DEBUG : Step 113320, finished rewards 13.07, envs finished 1
2026-01-17 13:27:59,277 : worker.worker : DEBUG : Step 113327, finished rewards 4.37, envs finished 1
2026-01-17 13:27:59,300 : worker.worker : DEBUG : Step 113332, finished rewards 2.87, envs finished 1
2026-01-17 13:27:59,319 : worker.worker : DEBUG : Step 113336, finished rewards -3.59, envs finished 1
2026-01-17 13:27:59,407 : agent.on_policy : DEBUG : Mean Losses: [10.813721105456352]
2026-01-17 13:27:59,414 : worker.worker : DEBUG : Step 113345, finished rewards 13.89, envs finished 1
2026-01-17 13:27:59,756 : agent.on_policy : DEBUG : Mean Losses: [1.1677806749939919]
2026-01-17 13:27:59,902 : worker.worker : DEBUG : Step 113407, finished rewards -1.45, envs finished 1
2026-01-17 13:28:00,000 : agent.on_policy : DEBUG : Mean Losses: [3.0277018547058105]
2026-01-17 13:28:00,025 : worker.worker : DEBUG : Step 113414, finished rewards 22.38, envs finished 1
2026-01-17 13:28:00,058 : worker.worker : DEBUG : Step 113418, finished rewards 18.99, envs finished 1
2026-01-17 13:28:00,187 : worker.worker : DEBUG : Step 113438, finished rewards 2.75, envs finished 1
2026-01-17 13:28:00,291 : agent.on_policy : DEBUG : Mean Losses: [7.191521920263767]
2026-01-17 13:28:00,386 : worker.worker : DEBUG : Step 113457, finished rewards 3.55, envs finished 1
2026-01-17 13:28:00,459 : worker.worker : DEBUG : Step 113469, finished rewards 7.29, envs finished 1
2026-01-17 13:28:00,497 : worker.worker : DEBUG : Step 113471, finished rewards -8.80, envs finished 1
2026-01-17 13:28:00,631 : agent.on_policy : DEBUG : Mean Losses: [5.438176341354847]
2026-01-17 13:28:00,746 : worker.worker : DEBUG : Step 113487, finished rewards -20.90, envs finished 1
2026-01-17 13:28:00,907 : agent.on_policy : DEBUG : Mean Losses: [2.957731232047081]
2026-01-17 13:28:00,941 : worker.worker : DEBUG : Step 113514, finished rewards 17.20, envs finished 1
2026-01-17 13:28:00,964 : worker.worker : DEBUG : Step 113520, finished rewards 8.85, envs finished 1
2026-01-17 13:28:01,064 : agent.on_policy : DEBUG : Mean Losses: [4.770838188007474]
2026-01-17 13:28:01,115 : worker.worker : DEBUG : Step 113547, finished rewards 36.08, envs finished 1
2026-01-17 13:28:01,311 : worker.worker : DEBUG : Step 113566, finished rewards -12.02, envs finished 1
2026-01-17 13:28:01,390 : agent.on_policy : DEBUG : Mean Losses: [5.636276423931122]
2026-01-17 13:28:01,409 : worker.worker : DEBUG : Step 113569, finished rewards 8.66, envs finished 1
2026-01-17 13:28:01,426 : worker.worker : DEBUG : Step 113571, finished rewards -1.68, envs finished 1
2026-01-17 13:28:01,499 : worker.worker : DEBUG : Step 113579, finished rewards 23.81, envs finished 1
2026-01-17 13:28:01,716 : agent.on_policy : DEBUG : Mean Losses: [4.87699493765831]
2026-01-17 13:28:01,752 : worker.worker : DEBUG : Step 113609, finished rewards 0.54, envs finished 1
2026-01-17 13:28:01,889 : agent.on_policy : DEBUG : Mean Losses: [2.4037025049328804]
2026-01-17 13:28:01,910 : worker.worker : DEBUG : Step 113634, finished rewards 9.08, envs finished 1
2026-01-17 13:28:01,955 : worker.worker : DEBUG : Step 113640, finished rewards -1.92, envs finished 1
2026-01-17 13:28:02,090 : worker.worker : DEBUG : Step 113661, finished rewards 7.22, envs finished 1
2026-01-17 13:28:02,238 : agent.on_policy : DEBUG : Mean Losses: [5.960354894399643]
2026-01-17 13:28:02,305 : worker.worker : DEBUG : Step 113673, finished rewards 21.98, envs finished 1
2026-01-17 13:28:02,379 : worker.worker : DEBUG : Step 113690, finished rewards 1.69, envs finished 1
2026-01-17 13:28:02,391 : worker.worker : DEBUG : Step 113691, finished rewards 0.76, envs finished 1
2026-01-17 13:28:02,515 : agent.on_policy : DEBUG : Mean Losses: [6.774293325841427]
2026-01-17 13:28:02,657 : worker.worker : DEBUG : Step 113711, finished rewards -7.52, envs finished 1
2026-01-17 13:28:02,887 : agent.on_policy : DEBUG : Mean Losses: [2.9026062209159136]
2026-01-17 13:28:02,889 : worker.worker : DEBUG : Step 113728, finished rewards 6.66, envs finished 1
2026-01-17 13:28:03,123 : agent.on_policy : DEBUG : Mean Losses: [2.747954249382019]
2026-01-17 13:28:03,173 : worker.worker : DEBUG : Step 113770, finished rewards 10.90, envs finished 1
2026-01-17 13:28:03,214 : worker.worker : DEBUG : Step 113777, finished rewards -13.73, envs finished 1
2026-01-17 13:28:03,389 : agent.on_policy : DEBUG : Mean Losses: [6.87492673099041]
2026-01-17 13:28:03,427 : worker.worker : DEBUG : Step 113796, finished rewards 13.68, envs finished 1
2026-01-17 13:28:03,646 : agent.on_policy : DEBUG : Mean Losses: [4.129284296184778]
2026-01-17 13:28:03,677 : worker.worker : DEBUG : Step 113830, finished rewards -21.96, envs finished 1
2026-01-17 13:28:03,688 : worker.worker : DEBUG : Step 113832, finished rewards 15.40, envs finished 1
2026-01-17 13:28:03,741 : worker.worker : DEBUG : Step 113844, finished rewards -19.42, envs finished 1
2026-01-17 13:28:03,757 : worker.worker : DEBUG : Step 113847, finished rewards -3.27, envs finished 1
2026-01-17 13:28:03,889 : agent.on_policy : DEBUG : Mean Losses: [7.957595460116863]
2026-01-17 13:28:03,983 : worker.worker : DEBUG : Step 113879, finished rewards 18.84, envs finished 1
2026-01-17 13:28:04,125 : agent.on_policy : DEBUG : Mean Losses: [3.2209151051938534]
2026-01-17 13:28:04,155 : worker.worker : DEBUG : Step 113895, finished rewards -38.40, envs finished 2
2026-01-17 13:28:04,322 : agent.on_policy : DEBUG : Mean Losses: [4.541274957358837]
2026-01-17 13:28:04,360 : worker.worker : DEBUG : Step 113923, finished rewards -9.25, envs finished 1
2026-01-17 13:28:04,392 : worker.worker : DEBUG : Step 113927, finished rewards 22.59, envs finished 1
2026-01-17 13:28:04,479 : worker.worker : DEBUG : Step 113945, finished rewards 18.12, envs finished 1
2026-01-17 13:28:04,591 : agent.on_policy : DEBUG : Mean Losses: [5.932985607534647]
2026-01-17 13:28:04,661 : worker.worker : DEBUG : Step 113961, finished rewards 8.91, envs finished 1
2026-01-17 13:28:04,786 : worker.worker : DEBUG : Step 113979, finished rewards 31.00, envs finished 1
2026-01-17 13:28:04,801 : worker.worker : DEBUG : Step 113982, finished rewards -17.42, envs finished 1
2026-01-17 13:28:04,857 : agent.on_policy : DEBUG : Mean Losses: [6.7644565384835005]
2026-01-17 13:28:04,903 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:28:05,003 : worker.worker : DEBUG : Step 114015, finished rewards -2.23, envs finished 1
2026-01-17 13:28:05,097 : agent.on_policy : DEBUG : Mean Losses: [3.2301893942058086]
2026-01-17 13:28:05,113 : worker.worker : DEBUG : Step 114019, finished rewards 23.53, envs finished 1
2026-01-17 13:28:05,223 : worker.worker : DEBUG : Step 114033, finished rewards -10.08, envs finished 1
2026-01-17 13:28:05,289 : worker.worker : DEBUG : Step 114041, finished rewards 7.29, envs finished 1
2026-01-17 13:28:05,442 : agent.on_policy : DEBUG : Mean Losses: [6.4234147211536765]
2026-01-17 13:28:05,471 : worker.worker : DEBUG : Step 114054, finished rewards 38.38, envs finished 1
2026-01-17 13:28:05,485 : worker.worker : DEBUG : Step 114057, finished rewards 7.87, envs finished 1
2026-01-17 13:28:05,701 : agent.on_policy : DEBUG : Mean Losses: [5.451571046374738]
2026-01-17 13:28:05,827 : worker.worker : DEBUG : Step 114110, finished rewards -9.26, envs finished 1
2026-01-17 13:28:05,940 : agent.on_policy : DEBUG : Mean Losses: [3.311851866543293]
2026-01-17 13:28:05,943 : worker.worker : DEBUG : Step 114112, finished rewards 21.82, envs finished 1
2026-01-17 13:28:05,970 : worker.worker : DEBUG : Step 114116, finished rewards 21.70, envs finished 1
2026-01-17 13:28:06,140 : worker.worker : DEBUG : Step 114141, finished rewards 30.15, envs finished 1
2026-01-17 13:28:05,601 : agent.on_policy : DEBUG : Mean Losses: [5.6409475626423955]
2026-01-17 13:28:05,669 : worker.worker : DEBUG : Step 114153, finished rewards 5.66, envs finished 1
2026-01-17 13:28:05,693 : worker.worker : DEBUG : Step 114159, finished rewards 7.05, envs finished 1
2026-01-17 13:28:05,737 : worker.worker : DEBUG : Step 114168, finished rewards -25.47, envs finished 1
2026-01-17 13:28:05,914 : agent.on_policy : DEBUG : Mean Losses: [7.42062359303236]
2026-01-17 13:28:06,004 : worker.worker : DEBUG : Step 114196, finished rewards 30.38, envs finished 1
2026-01-17 13:28:06,047 : worker.worker : DEBUG : Step 114207, finished rewards 25.18, envs finished 1
2026-01-17 13:28:06,155 : agent.on_policy : DEBUG : Mean Losses: [7.342170334421098]
2026-01-17 13:28:06,358 : agent.on_policy : DEBUG : Mean Losses: [2.8931593522429466]
2026-01-17 13:28:06,364 : worker.worker : DEBUG : Step 114241, finished rewards -33.87, envs finished 1
2026-01-17 13:28:06,392 : worker.worker : DEBUG : Step 114248, finished rewards -5.27, envs finished 1
2026-01-17 13:28:06,425 : worker.worker : DEBUG : Step 114256, finished rewards 21.67, envs finished 1
2026-01-17 13:28:06,462 : worker.worker : DEBUG : Step 114264, finished rewards 3.58, envs finished 1
2026-01-17 13:28:06,470 : worker.worker : DEBUG : Step 114265, finished rewards 10.37, envs finished 1
2026-01-17 13:28:06,552 : agent.on_policy : DEBUG : Mean Losses: [7.642783083021641]
2026-01-17 13:28:06,589 : worker.worker : DEBUG : Step 114284, finished rewards 36.74, envs finished 1
2026-01-17 13:28:06,688 : worker.worker : DEBUG : Step 114297, finished rewards 17.09, envs finished 1
2026-01-17 13:28:06,904 : agent.on_policy : DEBUG : Mean Losses: [7.023210160434246]
2026-01-17 13:28:06,976 : worker.worker : DEBUG : Step 114317, finished rewards -10.71, envs finished 1
2026-01-17 13:28:07,158 : agent.on_policy : DEBUG : Mean Losses: [2.708815809339285]
2026-01-17 13:28:07,248 : worker.worker : DEBUG : Step 114362, finished rewards 9.01, envs finished 1
2026-01-17 13:28:07,366 : agent.on_policy : DEBUG : Mean Losses: [5.211767561733723]
2026-01-17 13:28:07,373 : worker.worker : DEBUG : Step 114369, finished rewards 13.93, envs finished 1
2026-01-17 13:28:07,429 : worker.worker : DEBUG : Step 114374, finished rewards 4.64, envs finished 1
2026-01-17 13:28:07,473 : worker.worker : DEBUG : Step 114381, finished rewards -8.86, envs finished 1
2026-01-17 13:28:07,603 : worker.worker : DEBUG : Step 114398, finished rewards -8.77, envs finished 1
2026-01-17 13:28:07,703 : agent.on_policy : DEBUG : Mean Losses: [7.081287994980812]
2026-01-17 13:28:07,923 : agent.on_policy : DEBUG : Mean Losses: [2.1199815459549427]
2026-01-17 13:28:07,991 : worker.worker : DEBUG : Step 114450, finished rewards -6.06, envs finished 1
2026-01-17 13:28:08,005 : worker.worker : DEBUG : Step 114453, finished rewards -23.58, envs finished 1
2026-01-17 13:28:08,052 : worker.worker : DEBUG : Step 114463, finished rewards -19.70, envs finished 1
2026-01-17 13:28:08,169 : agent.on_policy : DEBUG : Mean Losses: [7.4793107360601425]
2026-01-17 13:28:08,253 : worker.worker : DEBUG : Step 114475, finished rewards 11.46, envs finished 1
2026-01-17 13:28:08,456 : agent.on_policy : DEBUG : Mean Losses: [3.6936015188694]
2026-01-17 13:28:08,459 : worker.worker : DEBUG : Step 114496, finished rewards 2.13, envs finished 1
2026-01-17 13:28:08,529 : worker.worker : DEBUG : Step 114512, finished rewards -4.59, envs finished 1
2026-01-17 13:28:08,557 : worker.worker : DEBUG : Step 114518, finished rewards 3.56, envs finished 1
2026-01-17 13:28:08,702 : agent.on_policy : DEBUG : Mean Losses: [5.302906662225723]
2026-01-17 13:28:08,764 : worker.worker : DEBUG : Step 114548, finished rewards 19.32, envs finished 1
2026-01-17 13:28:08,794 : worker.worker : DEBUG : Step 114554, finished rewards 25.51, envs finished 1
2026-01-17 13:28:08,915 : agent.on_policy : DEBUG : Mean Losses: [8.694916855543852]
2026-01-17 13:28:08,925 : worker.worker : DEBUG : Step 114561, finished rewards -49.75, envs finished 1
2026-01-17 13:28:09,192 : worker.worker : DEBUG : Step 114587, finished rewards 9.33, envs finished 1
2026-01-17 13:28:09,393 : agent.on_policy : DEBUG : Mean Losses: [4.021926295012236]
2026-01-17 13:28:09,463 : worker.worker : DEBUG : Step 114598, finished rewards 28.92, envs finished 1
2026-01-17 13:28:09,542 : worker.worker : DEBUG : Step 114614, finished rewards 21.70, envs finished 1
2026-01-17 13:28:09,657 : agent.on_policy : DEBUG : Mean Losses: [5.705861635506153]
2026-01-17 13:28:09,778 : worker.worker : DEBUG : Step 114646, finished rewards 30.07, envs finished 1
2026-01-17 13:28:09,794 : worker.worker : DEBUG : Step 114649, finished rewards 17.07, envs finished 1
2026-01-17 13:28:10,028 : agent.on_policy : DEBUG : Mean Losses: [8.861320942640305]
2026-01-17 13:28:10,061 : worker.worker : DEBUG : Step 114657, finished rewards 42.75, envs finished 1
2026-01-17 13:28:10,125 : worker.worker : DEBUG : Step 114668, finished rewards 8.19, envs finished 1
2026-01-17 13:28:10,313 : agent.on_policy : DEBUG : Mean Losses: [4.670013166964054]
2026-01-17 13:28:10,370 : worker.worker : DEBUG : Step 114703, finished rewards -87.86, envs finished 1
2026-01-17 13:28:10,379 : worker.worker : DEBUG : Step 114704, finished rewards 14.86, envs finished 1
2026-01-17 13:28:10,560 : agent.on_policy : DEBUG : Mean Losses: [5.617655649781227]
2026-01-17 13:28:10,763 : agent.on_policy : DEBUG : Mean Losses: [4.193081378936768]
2026-01-17 13:28:10,767 : worker.worker : DEBUG : Step 114752, finished rewards -12.77, envs finished 1
2026-01-17 13:28:10,794 : worker.worker : DEBUG : Step 114756, finished rewards 11.22, envs finished 1
2026-01-17 13:28:10,843 : worker.worker : DEBUG : Step 114767, finished rewards 6.30, envs finished 1
2026-01-17 13:28:10,858 : worker.worker : DEBUG : Step 114769, finished rewards -20.28, envs finished 1
2026-01-17 13:28:10,923 : worker.worker : DEBUG : Step 114782, finished rewards 8.24, envs finished 1
2026-01-17 13:28:11,020 : agent.on_policy : DEBUG : Mean Losses: [9.156349778175354]
2026-01-17 13:28:11,163 : worker.worker : DEBUG : Step 114802, finished rewards 20.33, envs finished 1
2026-01-17 13:28:11,214 : worker.worker : DEBUG : Step 114805, finished rewards -14.90, envs finished 1
2026-01-17 13:28:11,232 : worker.worker : DEBUG : Step 114807, finished rewards 16.16, envs finished 1
2026-01-17 13:28:11,370 : agent.on_policy : DEBUG : Mean Losses: [5.693502681329846]
2026-01-17 13:28:11,581 : agent.on_policy : DEBUG : Mean Losses: [1.2284159995615482]
2026-01-17 13:28:11,604 : worker.worker : DEBUG : Step 114852, finished rewards 30.50, envs finished 1
2026-01-17 13:28:11,623 : worker.worker : DEBUG : Step 114855, finished rewards 26.39, envs finished 1
2026-01-17 13:28:11,639 : worker.worker : DEBUG : Step 114857, finished rewards 38.31, envs finished 1
2026-01-17 13:28:11,681 : worker.worker : DEBUG : Step 114866, finished rewards 12.53, envs finished 1
2026-01-17 13:28:11,708 : worker.worker : DEBUG : Step 114872, finished rewards 3.67, envs finished 1
2026-01-17 13:28:11,809 : agent.on_policy : DEBUG : Mean Losses: [8.016101248562336]
2026-01-17 13:28:12,114 : agent.on_policy : DEBUG : Mean Losses: [1.9460527785122395]
2026-01-17 13:28:12,148 : worker.worker : DEBUG : Step 114919, finished rewards 10.12, envs finished 1
2026-01-17 13:28:12,182 : worker.worker : DEBUG : Step 114926, finished rewards 3.37, envs finished 1
2026-01-17 13:28:12,212 : worker.worker : DEBUG : Step 114931, finished rewards 37.19, envs finished 1
2026-01-17 13:28:12,261 : worker.worker : DEBUG : Step 114943, finished rewards 30.84, envs finished 1
2026-01-17 13:28:12,316 : agent.on_policy : DEBUG : Mean Losses: [9.665542632341385]
2026-01-17 13:28:12,323 : worker.worker : DEBUG : Step 114945, finished rewards -10.35, envs finished 1
2026-01-17 13:28:12,417 : worker.worker : DEBUG : Step 114969, finished rewards 5.36, envs finished 1
2026-01-17 13:28:12,561 : agent.on_policy : DEBUG : Mean Losses: [3.634705430828035]
2026-01-17 13:28:12,595 : worker.worker : DEBUG : Step 114978, finished rewards 15.53, envs finished 1
2026-01-17 13:28:12,700 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:28:12,714 : worker.worker : INFO : Step 115000, Avg Reward 7.3455, Max Reward 42.7496, Loss [5.51984981]
2026-01-17 13:28:12,877 : agent.on_policy : DEBUG : Mean Losses: [3.3269044384360313]
2026-01-17 13:28:12,997 : worker.worker : DEBUG : Step 115034, finished rewards 25.68, envs finished 1
2026-01-17 13:28:13,045 : worker.worker : DEBUG : Step 115039, finished rewards -18.21, envs finished 1
2026-01-17 13:28:13,240 : agent.on_policy : DEBUG : Mean Losses: [5.786574587225914]
2026-01-17 13:28:13,378 : worker.worker : DEBUG : Step 115057, finished rewards -6.10, envs finished 1
2026-01-17 13:28:13,471 : worker.worker : DEBUG : Step 115065, finished rewards 0.75, envs finished 1
2026-01-17 13:28:13,481 : worker.worker : DEBUG : Step 115066, finished rewards 6.77, envs finished 2
2026-01-17 13:28:13,642 : agent.on_policy : DEBUG : Mean Losses: [9.790837429463863]
2026-01-17 13:28:13,659 : worker.worker : DEBUG : Step 115075, finished rewards 20.70, envs finished 1
2026-01-17 13:28:13,691 : worker.worker : DEBUG : Step 115080, finished rewards -25.96, envs finished 1
2026-01-17 13:28:13,886 : agent.on_policy : DEBUG : Mean Losses: [2.4397204760462046]
2026-01-17 13:28:14,064 : agent.on_policy : DEBUG : Mean Losses: [1.601300373673439]
2026-01-17 13:28:14,078 : worker.worker : DEBUG : Step 115139, finished rewards 12.27, envs finished 1
2026-01-17 13:28:14,144 : worker.worker : DEBUG : Step 115154, finished rewards 26.68, envs finished 1
2026-01-17 13:28:14,159 : worker.worker : DEBUG : Step 115157, finished rewards 23.63, envs finished 1
2026-01-17 13:28:14,302 : agent.on_policy : DEBUG : Mean Losses: [8.509638845920563]
2026-01-17 13:28:14,307 : worker.worker : DEBUG : Step 115169, finished rewards -1.25, envs finished 1
2026-01-17 13:28:14,334 : worker.worker : DEBUG : Step 115175, finished rewards 20.35, envs finished 1
2026-01-17 13:28:14,352 : worker.worker : DEBUG : Step 115177, finished rewards 22.03, envs finished 1
2026-01-17 13:28:14,601 : agent.on_policy : DEBUG : Mean Losses: [4.721593838185072]
2026-01-17 13:28:14,696 : worker.worker : DEBUG : Step 115222, finished rewards -19.00, envs finished 1
2026-01-17 13:28:14,858 : agent.on_policy : DEBUG : Mean Losses: [4.639560103416443]
2026-01-17 13:28:14,885 : worker.worker : DEBUG : Step 115238, finished rewards -30.76, envs finished 1
2026-01-17 13:28:14,998 : worker.worker : DEBUG : Step 115254, finished rewards 21.22, envs finished 1
2026-01-17 13:28:15,049 : worker.worker : DEBUG : Step 115261, finished rewards 24.37, envs finished 1
2026-01-17 13:28:15,230 : agent.on_policy : DEBUG : Mean Losses: [8.36463388800621]
2026-01-17 13:28:15,415 : worker.worker : DEBUG : Step 115293, finished rewards -11.82, envs finished 1
2026-01-17 13:28:15,428 : worker.worker : DEBUG : Step 115295, finished rewards -20.64, envs finished 1
2026-01-17 13:28:15,506 : agent.on_policy : DEBUG : Mean Losses: [6.294747442007065]
2026-01-17 13:28:15,659 : worker.worker : DEBUG : Step 115318, finished rewards -0.55, envs finished 1
2026-01-17 13:28:15,691 : worker.worker : DEBUG : Step 115320, finished rewards 21.09, envs finished 1
2026-01-17 13:28:15,709 : worker.worker : DEBUG : Step 115321, finished rewards -17.45, envs finished 1
2026-01-17 13:28:15,825 : agent.on_policy : DEBUG : Mean Losses: [6.617463992908597]
2026-01-17 13:28:15,924 : worker.worker : DEBUG : Step 115338, finished rewards 18.95, envs finished 1
2026-01-17 13:28:16,091 : worker.worker : DEBUG : Step 115357, finished rewards 20.31, envs finished 1
2026-01-17 13:28:16,211 : agent.on_policy : DEBUG : Mean Losses: [4.578362133353949]
2026-01-17 13:28:16,330 : worker.worker : DEBUG : Step 115376, finished rewards 1.23, envs finished 1
2026-01-17 13:28:16,625 : agent.on_policy : DEBUG : Mean Losses: [3.4676979556679726]
2026-01-17 13:28:16,684 : worker.worker : DEBUG : Step 115404, finished rewards 29.93, envs finished 1
2026-01-17 13:28:16,772 : worker.worker : DEBUG : Step 115422, finished rewards 8.21, envs finished 1
2026-01-17 13:28:16,889 : agent.on_policy : DEBUG : Mean Losses: [5.137885473668575]
2026-01-17 13:28:16,895 : worker.worker : DEBUG : Step 115425, finished rewards -6.66, envs finished 1
2026-01-17 13:28:17,034 : worker.worker : DEBUG : Step 115447, finished rewards -6.07, envs finished 1
2026-01-17 13:28:17,070 : worker.worker : DEBUG : Step 115453, finished rewards -4.69, envs finished 1
2026-01-17 13:28:17,156 : agent.on_policy : DEBUG : Mean Losses: [5.1494412533938885]
2026-01-17 13:28:17,189 : worker.worker : DEBUG : Step 115465, finished rewards -3.98, envs finished 1
2026-01-17 13:28:17,215 : worker.worker : DEBUG : Step 115470, finished rewards 23.59, envs finished 1
2026-01-17 13:28:17,257 : worker.worker : DEBUG : Step 115473, finished rewards 6.72, envs finished 1
2026-01-17 13:28:17,458 : agent.on_policy : DEBUG : Mean Losses: [5.077163303270936]
2026-01-17 13:28:17,563 : worker.worker : DEBUG : Step 115506, finished rewards 29.62, envs finished 1
2026-01-17 13:28:17,783 : agent.on_policy : DEBUG : Mean Losses: [3.530451714992523]
2026-01-17 13:28:17,800 : worker.worker : DEBUG : Step 115523, finished rewards 21.18, envs finished 1
2026-01-17 13:28:17,842 : worker.worker : DEBUG : Step 115530, finished rewards 31.08, envs finished 1
2026-01-17 13:28:17,874 : worker.worker : DEBUG : Step 115536, finished rewards 30.65, envs finished 1
2026-01-17 13:28:17,936 : worker.worker : DEBUG : Step 115547, finished rewards -6.80, envs finished 1
2026-01-17 13:28:18,012 : agent.on_policy : DEBUG : Mean Losses: [7.225751630961895]
2026-01-17 13:28:18,065 : worker.worker : DEBUG : Step 115557, finished rewards 29.96, envs finished 1
2026-01-17 13:28:18,142 : worker.worker : DEBUG : Step 115577, finished rewards 9.10, envs finished 1
2026-01-17 13:28:18,278 : agent.on_policy : DEBUG : Mean Losses: [4.227688871324062]
2026-01-17 13:28:18,292 : worker.worker : DEBUG : Step 115587, finished rewards 7.69, envs finished 1
2026-01-17 13:28:18,435 : agent.on_policy : DEBUG : Mean Losses: [2.676297441124916]
2026-01-17 13:28:18,437 : worker.worker : DEBUG : Step 115616, finished rewards 11.92, envs finished 1
2026-01-17 13:28:18,502 : worker.worker : DEBUG : Step 115626, finished rewards 21.87, envs finished 1
2026-01-17 13:28:18,680 : agent.on_policy : DEBUG : Mean Losses: [3.654959037899971]
2026-01-17 13:28:18,710 : worker.worker : DEBUG : Step 115656, finished rewards 1.61, envs finished 1
2026-01-17 13:28:18,776 : worker.worker : DEBUG : Step 115674, finished rewards -15.48, envs finished 1
2026-01-17 13:28:18,841 : agent.on_policy : DEBUG : Mean Losses: [4.605804309248924]
2026-01-17 13:28:18,843 : worker.worker : DEBUG : Step 115680, finished rewards 6.41, envs finished 1
2026-01-17 13:28:19,020 : worker.worker : DEBUG : Step 115711, finished rewards 29.66, envs finished 1
2026-01-17 13:28:19,079 : agent.on_policy : DEBUG : Mean Losses: [5.60063199326396]
2026-01-17 13:28:19,124 : worker.worker : DEBUG : Step 115724, finished rewards -13.85, envs finished 2
2026-01-17 13:28:19,224 : worker.worker : DEBUG : Step 115741, finished rewards 29.66, envs finished 1
2026-01-17 13:28:19,430 : agent.on_policy : DEBUG : Mean Losses: [9.089708052575588]
2026-01-17 13:28:19,563 : worker.worker : DEBUG : Step 115755, finished rewards -37.35, envs finished 1
2026-01-17 13:28:19,606 : worker.worker : DEBUG : Step 115758, finished rewards -33.20, envs finished 1
2026-01-17 13:28:19,774 : worker.worker : DEBUG : Step 115773, finished rewards 23.52, envs finished 1
2026-01-17 13:28:19,899 : agent.on_policy : DEBUG : Mean Losses: [5.695273227989674]
2026-01-17 13:28:19,997 : worker.worker : DEBUG : Step 115790, finished rewards 7.08, envs finished 1
2026-01-17 13:28:20,157 : agent.on_policy : DEBUG : Mean Losses: [2.8255953304469585]
2026-01-17 13:28:20,209 : worker.worker : DEBUG : Step 115823, finished rewards 20.10, envs finished 1
2026-01-17 13:28:20,260 : worker.worker : DEBUG : Step 115838, finished rewards 21.18, envs finished 1
2026-01-17 13:28:20,378 : agent.on_policy : DEBUG : Mean Losses: [5.818385094404221]
2026-01-17 13:28:20,394 : worker.worker : DEBUG : Step 115843, finished rewards 29.18, envs finished 1
2026-01-17 13:28:20,444 : worker.worker : DEBUG : Step 115855, finished rewards 0.81, envs finished 1
2026-01-17 13:28:20,449 : worker.worker : DEBUG : Step 115856, finished rewards 30.82, envs finished 1
2026-01-17 13:28:20,595 : agent.on_policy : DEBUG : Mean Losses: [6.83355101197958]
2026-01-17 13:28:20,661 : worker.worker : DEBUG : Step 115887, finished rewards -23.65, envs finished 1
2026-01-17 13:28:20,672 : worker.worker : DEBUG : Step 115890, finished rewards -4.69, envs finished 1
2026-01-17 13:28:20,846 : agent.on_policy : DEBUG : Mean Losses: [4.569206543266773]
2026-01-17 13:28:20,853 : worker.worker : DEBUG : Step 115906, finished rewards 5.90, envs finished 1
2026-01-17 13:28:21,060 : agent.on_policy : DEBUG : Mean Losses: [2.5844447389245033]
2026-01-17 13:28:21,061 : worker.worker : DEBUG : Step 115936, finished rewards 22.99, envs finished 1
2026-01-17 13:28:21,184 : worker.worker : DEBUG : Step 115965, finished rewards -9.95, envs finished 1
2026-01-17 13:28:21,308 : agent.on_policy : DEBUG : Mean Losses: [4.050697527825832]
2026-01-17 13:28:21,316 : worker.worker : DEBUG : Step 115969, finished rewards 8.08, envs finished 1
2026-01-17 13:28:21,342 : worker.worker : DEBUG : Step 115972, finished rewards 6.31, envs finished 1
2026-01-17 13:28:21,416 : worker.worker : DEBUG : Step 115981, finished rewards -15.25, envs finished 1
2026-01-17 13:28:21,494 : worker.worker : DEBUG : Step 115996, finished rewards 11.34, envs finished 1
2026-01-17 13:28:21,527 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:28:21,614 : agent.on_policy : DEBUG : Mean Losses: [6.147424794733524]
2026-01-17 13:28:21,620 : worker.worker : DEBUG : Step 116001, finished rewards 10.38, envs finished 1
2026-01-17 13:28:21,765 : worker.worker : DEBUG : Step 116021, finished rewards 5.77, envs finished 1
2026-01-17 13:28:21,894 : agent.on_policy : DEBUG : Mean Losses: [3.8251967430114746]
2026-01-17 13:28:21,964 : worker.worker : DEBUG : Step 116043, finished rewards 12.50, envs finished 1
2026-01-17 13:28:22,014 : worker.worker : DEBUG : Step 116055, finished rewards 28.49, envs finished 1
2026-01-17 13:28:22,213 : agent.on_policy : DEBUG : Mean Losses: [5.5880209393799305]
2026-01-17 13:28:22,241 : worker.worker : DEBUG : Step 116070, finished rewards 13.01, envs finished 1
2026-01-17 13:28:22,264 : worker.worker : DEBUG : Step 116074, finished rewards 23.63, envs finished 1
2026-01-17 13:28:22,448 : agent.on_policy : DEBUG : Mean Losses: [5.717572882771492]
2026-01-17 13:28:22,544 : worker.worker : DEBUG : Step 116122, finished rewards 0.30, envs finished 1
2026-01-17 13:28:22,663 : agent.on_policy : DEBUG : Mean Losses: [4.754253730177879]
2026-01-17 13:28:22,744 : worker.worker : DEBUG : Step 116139, finished rewards 30.19, envs finished 1
2026-01-17 13:28:22,753 : worker.worker : DEBUG : Step 116140, finished rewards 21.36, envs finished 1
2026-01-17 13:28:22,847 : worker.worker : DEBUG : Step 116147, finished rewards -0.21, envs finished 1
2026-01-17 13:28:22,886 : worker.worker : DEBUG : Step 116152, finished rewards -38.19, envs finished 1
2026-01-17 13:28:22,962 : worker.worker : DEBUG : Step 116159, finished rewards 29.38, envs finished 1
2026-01-17 13:28:23,095 : agent.on_policy : DEBUG : Mean Losses: [12.331030189990997]
2026-01-17 13:28:23,178 : worker.worker : DEBUG : Step 116178, finished rewards 12.35, envs finished 1
2026-01-17 13:28:23,185 : worker.worker : DEBUG : Step 116180, finished rewards -28.08, envs finished 1
2026-01-17 13:28:23,362 : agent.on_policy : DEBUG : Mean Losses: [3.9306289441883564]
2026-01-17 13:28:23,466 : worker.worker : DEBUG : Step 116223, finished rewards 17.63, envs finished 1
2026-01-17 13:28:23,553 : agent.on_policy : DEBUG : Mean Losses: [3.323396150022745]
2026-01-17 13:28:23,610 : worker.worker : DEBUG : Step 116239, finished rewards 23.06, envs finished 1
2026-01-17 13:28:23,731 : worker.worker : DEBUG : Step 116255, finished rewards 6.24, envs finished 1
2026-01-17 13:28:23,811 : agent.on_policy : DEBUG : Mean Losses: [5.48759288340807]
2026-01-17 13:28:23,900 : worker.worker : DEBUG : Step 116275, finished rewards 6.46, envs finished 1
2026-01-17 13:28:23,952 : worker.worker : DEBUG : Step 116282, finished rewards 1.70, envs finished 1
2026-01-17 13:28:24,010 : worker.worker : DEBUG : Step 116286, finished rewards 11.34, envs finished 1
2026-01-17 13:28:24,209 : agent.on_policy : DEBUG : Mean Losses: [6.2978831604123116]
2026-01-17 13:28:24,246 : worker.worker : DEBUG : Step 116292, finished rewards 9.71, envs finished 1
2026-01-17 13:28:24,254 : worker.worker : DEBUG : Step 116293, finished rewards -19.59, envs finished 1
2026-01-17 13:28:24,477 : agent.on_policy : DEBUG : Mean Losses: [2.5856218729168177]
2026-01-17 13:28:24,577 : worker.worker : DEBUG : Step 116348, finished rewards 0.41, envs finished 1
2026-01-17 13:28:24,694 : agent.on_policy : DEBUG : Mean Losses: [3.226033601909876]
2026-01-17 13:28:24,796 : worker.worker : DEBUG : Step 116368, finished rewards 8.80, envs finished 1
2026-01-17 13:28:24,843 : worker.worker : DEBUG : Step 116377, finished rewards 16.36, envs finished 1
2026-01-17 13:28:24,879 : worker.worker : DEBUG : Step 116379, finished rewards 21.03, envs finished 1
2026-01-17 13:28:24,951 : agent.on_policy : DEBUG : Mean Losses: [7.829911679029465]
2026-01-17 13:28:24,976 : worker.worker : DEBUG : Step 116389, finished rewards 21.19, envs finished 1
2026-01-17 13:28:24,994 : worker.worker : DEBUG : Step 116393, finished rewards 18.09, envs finished 1
2026-01-17 13:28:25,180 : agent.on_policy : DEBUG : Mean Losses: [4.94204883929342]
2026-01-17 13:28:25,191 : worker.worker : DEBUG : Step 116419, finished rewards -35.19, envs finished 1
2026-01-17 13:28:25,431 : agent.on_policy : DEBUG : Mean Losses: [3.1929059997200966]
2026-01-17 13:28:25,483 : worker.worker : DEBUG : Step 116462, finished rewards -38.98, envs finished 1
2026-01-17 13:28:25,535 : worker.worker : DEBUG : Step 116475, finished rewards 20.30, envs finished 1
2026-01-17 13:28:25,661 : agent.on_policy : DEBUG : Mean Losses: [5.747894395142794]
2026-01-17 13:28:25,698 : worker.worker : DEBUG : Step 116485, finished rewards 4.06, envs finished 1
2026-01-17 13:28:25,750 : worker.worker : DEBUG : Step 116490, finished rewards -7.97, envs finished 1
2026-01-17 13:28:25,835 : worker.worker : DEBUG : Step 116509, finished rewards 6.62, envs finished 1
2026-01-17 13:28:25,962 : agent.on_policy : DEBUG : Mean Losses: [7.726310513913631]
2026-01-17 13:28:26,071 : worker.worker : DEBUG : Step 116527, finished rewards -15.13, envs finished 1
2026-01-17 13:28:26,101 : worker.worker : DEBUG : Step 116528, finished rewards 12.80, envs finished 1
2026-01-17 13:28:26,311 : agent.on_policy : DEBUG : Mean Losses: [5.4662665873765945]
2026-01-17 13:28:26,317 : worker.worker : DEBUG : Step 116545, finished rewards -9.72, envs finished 1
2026-01-17 13:28:26,475 : worker.worker : DEBUG : Step 116573, finished rewards 17.75, envs finished 1
2026-01-17 13:28:26,533 : agent.on_policy : DEBUG : Mean Losses: [3.9194309525191784]
2026-01-17 13:28:26,552 : worker.worker : DEBUG : Step 116581, finished rewards 5.06, envs finished 1
2026-01-17 13:28:26,557 : worker.worker : DEBUG : Step 116582, finished rewards 20.89, envs finished 1
2026-01-17 13:28:26,758 : agent.on_policy : DEBUG : Mean Losses: [4.017697213217616]
2026-01-17 13:28:26,763 : worker.worker : DEBUG : Step 116609, finished rewards 4.28, envs finished 1
2026-01-17 13:28:26,833 : worker.worker : DEBUG : Step 116627, finished rewards 21.27, envs finished 1
2026-01-17 13:28:26,846 : worker.worker : DEBUG : Step 116630, finished rewards 2.82, envs finished 1
2026-01-17 13:28:26,993 : agent.on_policy : DEBUG : Mean Losses: [6.415008418262005]
2026-01-17 13:28:27,074 : worker.worker : DEBUG : Step 116662, finished rewards 7.22, envs finished 1
2026-01-17 13:28:27,206 : agent.on_policy : DEBUG : Mean Losses: [3.192660955712199]
2026-01-17 13:28:27,228 : worker.worker : DEBUG : Step 116676, finished rewards 22.00, envs finished 1
2026-01-17 13:28:27,308 : worker.worker : DEBUG : Step 116687, finished rewards 14.51, envs finished 1
2026-01-17 13:28:27,329 : worker.worker : DEBUG : Step 116691, finished rewards -27.72, envs finished 1
2026-01-17 13:28:27,385 : worker.worker : DEBUG : Step 116701, finished rewards 14.57, envs finished 2
2026-01-17 13:28:27,585 : agent.on_policy : DEBUG : Mean Losses: [8.187391694635153]
2026-01-17 13:28:27,691 : worker.worker : DEBUG : Step 116722, finished rewards 25.35, envs finished 1
2026-01-17 13:28:27,861 : agent.on_policy : DEBUG : Mean Losses: [3.243858297355473]
2026-01-17 13:28:27,941 : worker.worker : DEBUG : Step 116753, finished rewards -0.56, envs finished 1
2026-01-17 13:28:28,151 : agent.on_policy : DEBUG : Mean Losses: [4.113202253356576]
2026-01-17 13:28:28,167 : worker.worker : DEBUG : Step 116773, finished rewards 10.42, envs finished 1
2026-01-17 13:28:28,178 : worker.worker : DEBUG : Step 116776, finished rewards 38.40, envs finished 2
2026-01-17 13:28:28,239 : worker.worker : DEBUG : Step 116788, finished rewards 18.83, envs finished 1
2026-01-17 13:28:28,259 : worker.worker : DEBUG : Step 116792, finished rewards 9.21, envs finished 1
2026-01-17 13:28:28,388 : agent.on_policy : DEBUG : Mean Losses: [8.41016056202352]
2026-01-17 13:28:28,494 : worker.worker : DEBUG : Step 116819, finished rewards -3.56, envs finished 1
2026-01-17 13:28:28,659 : agent.on_policy : DEBUG : Mean Losses: [3.1380224898457527]
2026-01-17 13:28:28,759 : worker.worker : DEBUG : Step 116849, finished rewards 22.40, envs finished 1
2026-01-17 13:28:28,923 : agent.on_policy : DEBUG : Mean Losses: [4.377509366720915]
2026-01-17 13:28:28,944 : worker.worker : DEBUG : Step 116871, finished rewards 21.67, envs finished 1
2026-01-17 13:28:28,976 : worker.worker : DEBUG : Step 116878, finished rewards 15.79, envs finished 1
2026-01-17 13:28:28,993 : worker.worker : DEBUG : Step 116882, finished rewards -21.06, envs finished 1
2026-01-17 13:28:29,012 : worker.worker : DEBUG : Step 116886, finished rewards 21.40, envs finished 1
2026-01-17 13:28:29,104 : agent.on_policy : DEBUG : Mean Losses: [7.966476283967495]
2026-01-17 13:28:29,247 : worker.worker : DEBUG : Step 116923, finished rewards -16.69, envs finished 1
2026-01-17 13:28:29,434 : agent.on_policy : DEBUG : Mean Losses: [3.78682311065495]
2026-01-17 13:28:29,449 : worker.worker : DEBUG : Step 116931, finished rewards -10.70, envs finished 1
2026-01-17 13:28:29,581 : worker.worker : DEBUG : Step 116947, finished rewards -2.16, envs finished 1
2026-01-17 13:28:29,860 : agent.on_policy : DEBUG : Mean Losses: [3.7635882273316383]
2026-01-17 13:28:29,902 : worker.worker : DEBUG : Step 116968, finished rewards 28.15, envs finished 1
2026-01-17 13:28:29,953 : worker.worker : DEBUG : Step 116978, finished rewards -1.75, envs finished 1
2026-01-17 13:28:29,968 : worker.worker : DEBUG : Step 116982, finished rewards 16.32, envs finished 1
2026-01-17 13:28:30,007 : worker.worker : DEBUG : Step 116990, finished rewards 13.09, envs finished 1
2026-01-17 13:28:30,116 : agent.on_policy : DEBUG : Mean Losses: [8.829650811851025]
2026-01-17 13:28:30,125 : worker.worker : DEBUG : Step 116993, finished rewards 4.86, envs finished 1
2026-01-17 13:28:30,151 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:28:30,382 : agent.on_policy : DEBUG : Mean Losses: [1.694766040891409]
2026-01-17 13:28:30,462 : worker.worker : DEBUG : Step 117047, finished rewards 5.55, envs finished 1
2026-01-17 13:28:30,478 : worker.worker : DEBUG : Step 117052, finished rewards -5.67, envs finished 1
2026-01-17 13:28:30,592 : agent.on_policy : DEBUG : Mean Losses: [5.453248232603073]
2026-01-17 13:28:30,693 : worker.worker : DEBUG : Step 117070, finished rewards 26.22, envs finished 1
2026-01-17 13:28:30,878 : agent.on_policy : DEBUG : Mean Losses: [6.4414356760680676]
2026-01-17 13:28:30,904 : worker.worker : DEBUG : Step 117095, finished rewards 5.09, envs finished 1
2026-01-17 13:28:30,919 : worker.worker : DEBUG : Step 117099, finished rewards -22.35, envs finished 1
2026-01-17 13:28:30,966 : worker.worker : DEBUG : Step 117105, finished rewards 6.30, envs finished 1
2026-01-17 13:28:31,043 : worker.worker : DEBUG : Step 117118, finished rewards 2.32, envs finished 1
2026-01-17 13:28:31,182 : agent.on_policy : DEBUG : Mean Losses: [7.505736298859119]
2026-01-17 13:28:31,373 : worker.worker : DEBUG : Step 117145, finished rewards 23.74, envs finished 1
2026-01-17 13:28:31,468 : agent.on_policy : DEBUG : Mean Losses: [3.5124038932844996]
2026-01-17 13:28:31,630 : worker.worker : DEBUG : Step 117178, finished rewards 11.70, envs finished 1
2026-01-17 13:28:31,766 : agent.on_policy : DEBUG : Mean Losses: [4.26452074944973]
2026-01-17 13:28:31,806 : worker.worker : DEBUG : Step 117191, finished rewards -7.14, envs finished 1
2026-01-17 13:28:31,836 : worker.worker : DEBUG : Step 117197, finished rewards 24.52, envs finished 1
2026-01-17 13:28:31,982 : agent.on_policy : DEBUG : Mean Losses: [5.73946812748909]
2026-01-17 13:28:32,017 : worker.worker : DEBUG : Step 117218, finished rewards -72.73, envs finished 1
2026-01-17 13:28:32,084 : worker.worker : DEBUG : Step 117230, finished rewards -5.55, envs finished 2
2026-01-17 13:28:32,174 : worker.worker : DEBUG : Step 117242, finished rewards 22.02, envs finished 1
2026-01-17 13:28:32,272 : agent.on_policy : DEBUG : Mean Losses: [7.748482622206211]
2026-01-17 13:28:32,301 : worker.worker : DEBUG : Step 117254, finished rewards -5.25, envs finished 1
2026-01-17 13:28:32,454 : worker.worker : DEBUG : Step 117279, finished rewards 31.92, envs finished 1
2026-01-17 13:28:32,530 : agent.on_policy : DEBUG : Mean Losses: [4.475180646404624]
2026-01-17 13:28:32,563 : worker.worker : DEBUG : Step 117287, finished rewards 22.17, envs finished 1
2026-01-17 13:28:32,878 : agent.on_policy : DEBUG : Mean Losses: [2.728145470842719]
2026-01-17 13:28:32,931 : worker.worker : DEBUG : Step 117326, finished rewards 11.82, envs finished 1
2026-01-17 13:28:32,971 : worker.worker : DEBUG : Step 117336, finished rewards -24.27, envs finished 1
2026-01-17 13:28:33,143 : agent.on_policy : DEBUG : Mean Losses: [5.690063267946243]
2026-01-17 13:28:33,232 : worker.worker : DEBUG : Step 117355, finished rewards 17.90, envs finished 1
2026-01-17 13:28:33,250 : worker.worker : DEBUG : Step 117357, finished rewards 0.30, envs finished 1
2026-01-17 13:28:33,368 : worker.worker : DEBUG : Step 117370, finished rewards 14.55, envs finished 2
2026-01-17 13:28:33,525 : agent.on_policy : DEBUG : Mean Losses: [10.640992879867554]
2026-01-17 13:28:33,756 : agent.on_policy : DEBUG : Mean Losses: [2.91226926445961]
2026-01-17 13:28:33,765 : worker.worker : DEBUG : Step 117410, finished rewards 30.38, envs finished 1
2026-01-17 13:28:33,787 : worker.worker : DEBUG : Step 117416, finished rewards -47.73, envs finished 1
2026-01-17 13:28:33,820 : worker.worker : DEBUG : Step 117424, finished rewards -12.42, envs finished 1
2026-01-17 13:28:33,925 : agent.on_policy : DEBUG : Mean Losses: [6.654410131275654]
2026-01-17 13:28:33,954 : worker.worker : DEBUG : Step 117447, finished rewards 26.59, envs finished 1
2026-01-17 13:28:34,025 : worker.worker : DEBUG : Step 117453, finished rewards 30.73, envs finished 1
2026-01-17 13:28:34,069 : worker.worker : DEBUG : Step 117460, finished rewards 26.95, envs finished 1
2026-01-17 13:28:34,168 : worker.worker : DEBUG : Step 117471, finished rewards -7.18, envs finished 1
2026-01-17 13:28:34,276 : agent.on_policy : DEBUG : Mean Losses: [7.935943443328142]
2026-01-17 13:28:34,290 : worker.worker : DEBUG : Step 117475, finished rewards 3.32, envs finished 1
2026-01-17 13:28:34,543 : agent.on_policy : DEBUG : Mean Losses: [2.2950884141027927]
2026-01-17 13:28:34,619 : worker.worker : DEBUG : Step 117527, finished rewards 33.02, envs finished 1
2026-01-17 13:28:34,747 : agent.on_policy : DEBUG : Mean Losses: [5.179156668484211]
2026-01-17 13:28:34,783 : worker.worker : DEBUG : Step 117542, finished rewards -8.55, envs finished 1
2026-01-17 13:28:34,809 : worker.worker : DEBUG : Step 117544, finished rewards 4.95, envs finished 1
2026-01-17 13:28:34,949 : worker.worker : DEBUG : Step 117555, finished rewards 18.61, envs finished 1
2026-01-17 13:28:34,995 : worker.worker : DEBUG : Step 117561, finished rewards -10.10, envs finished 1
2026-01-17 13:28:35,106 : agent.on_policy : DEBUG : Mean Losses: [7.1347982957959175]
2026-01-17 13:28:35,216 : worker.worker : DEBUG : Step 117586, finished rewards -1.77, envs finished 1
2026-01-17 13:28:35,364 : agent.on_policy : DEBUG : Mean Losses: [3.114113003015518]
2026-01-17 13:28:35,442 : worker.worker : DEBUG : Step 117624, finished rewards 21.33, envs finished 1
2026-01-17 13:28:35,213 : agent.on_policy : DEBUG : Mean Losses: [5.4884401969611645]
2026-01-17 13:28:35,216 : worker.worker : DEBUG : Step 117632, finished rewards -28.67, envs finished 1
2026-01-17 13:28:35,249 : worker.worker : DEBUG : Step 117638, finished rewards 21.93, envs finished 1
2026-01-17 13:28:35,308 : worker.worker : DEBUG : Step 117652, finished rewards -41.74, envs finished 1
2026-01-17 13:28:35,358 : worker.worker : DEBUG : Step 117663, finished rewards 4.74, envs finished 1
2026-01-17 13:28:35,486 : agent.on_policy : DEBUG : Mean Losses: [6.907276384532452]
2026-01-17 13:28:35,571 : worker.worker : DEBUG : Step 117676, finished rewards 7.33, envs finished 1
2026-01-17 13:28:35,596 : worker.worker : DEBUG : Step 117681, finished rewards 23.14, envs finished 1
2026-01-17 13:28:35,698 : worker.worker : DEBUG : Step 117692, finished rewards -4.91, envs finished 1
2026-01-17 13:28:35,806 : agent.on_policy : DEBUG : Mean Losses: [6.880604669451714]
2026-01-17 13:28:36,006 : agent.on_policy : DEBUG : Mean Losses: [1.4132630676031113]
2026-01-17 13:28:36,049 : worker.worker : DEBUG : Step 117741, finished rewards 5.71, envs finished 1
2026-01-17 13:28:36,058 : worker.worker : DEBUG : Step 117743, finished rewards 7.76, envs finished 1
2026-01-17 13:28:36,166 : agent.on_policy : DEBUG : Mean Losses: [5.00923565775156]
2026-01-17 13:28:36,175 : worker.worker : DEBUG : Step 117762, finished rewards 1.14, envs finished 1
2026-01-17 13:28:36,269 : worker.worker : DEBUG : Step 117773, finished rewards 23.81, envs finished 1
2026-01-17 13:28:36,277 : worker.worker : DEBUG : Step 117774, finished rewards 1.18, envs finished 1
2026-01-17 13:28:36,464 : agent.on_policy : DEBUG : Mean Losses: [5.829282663762569]
2026-01-17 13:28:36,466 : worker.worker : DEBUG : Step 117792, finished rewards 1.64, envs finished 2
2026-01-17 13:28:36,605 : agent.on_policy : DEBUG : Mean Losses: [2.90829161927104]
2026-01-17 13:28:36,665 : worker.worker : DEBUG : Step 117830, finished rewards 27.84, envs finished 1
2026-01-17 13:28:36,715 : worker.worker : DEBUG : Step 117842, finished rewards 21.02, envs finished 1
2026-01-17 13:28:36,749 : worker.worker : DEBUG : Step 117849, finished rewards -24.72, envs finished 1
2026-01-17 13:28:36,860 : agent.on_policy : DEBUG : Mean Losses: [5.930611167103052]
2026-01-17 13:28:36,880 : worker.worker : DEBUG : Step 117861, finished rewards 21.18, envs finished 1
2026-01-17 13:28:36,921 : worker.worker : DEBUG : Step 117864, finished rewards 26.73, envs finished 1
2026-01-17 13:28:37,008 : worker.worker : DEBUG : Step 117878, finished rewards 13.61, envs finished 1
2026-01-17 13:28:37,042 : worker.worker : DEBUG : Step 117884, finished rewards 24.46, envs finished 1
2026-01-17 13:28:37,147 : agent.on_policy : DEBUG : Mean Losses: [7.521522451192141]
2026-01-17 13:28:37,343 : agent.on_policy : DEBUG : Mean Losses: [2.5810156110674143]
2026-01-17 13:28:37,365 : worker.worker : DEBUG : Step 117927, finished rewards 29.10, envs finished 1
2026-01-17 13:28:37,410 : worker.worker : DEBUG : Step 117939, finished rewards -12.35, envs finished 1
2026-01-17 13:28:37,493 : agent.on_policy : DEBUG : Mean Losses: [6.283719636499882]
2026-01-17 13:28:37,530 : worker.worker : DEBUG : Step 117962, finished rewards -5.49, envs finished 1
2026-01-17 13:28:37,628 : worker.worker : DEBUG : Step 117975, finished rewards 22.20, envs finished 1
2026-01-17 13:28:37,646 : worker.worker : DEBUG : Step 117978, finished rewards 5.66, envs finished 1
2026-01-17 13:28:37,670 : worker.worker : DEBUG : Step 117982, finished rewards 19.76, envs finished 1
2026-01-17 13:28:37,770 : agent.on_policy : DEBUG : Mean Losses: [9.79034479893744]
2026-01-17 13:28:37,772 : worker.worker : DEBUG : Step 117984, finished rewards -6.52, envs finished 1
2026-01-17 13:28:37,790 : worker.worker : DEBUG : Step 117988, finished rewards 1.83, envs finished 1
2026-01-17 13:28:37,866 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:28:38,017 : agent.on_policy : DEBUG : Mean Losses: [1.9946460984647274]
2026-01-17 13:28:38,069 : worker.worker : DEBUG : Step 118030, finished rewards 24.47, envs finished 1
2026-01-17 13:28:38,110 : worker.worker : DEBUG : Step 118041, finished rewards 8.42, envs finished 1
2026-01-17 13:28:38,229 : agent.on_policy : DEBUG : Mean Losses: [4.585205513983965]
2026-01-17 13:28:38,331 : worker.worker : DEBUG : Step 118064, finished rewards 16.72, envs finished 1
2026-01-17 13:28:38,510 : agent.on_policy : DEBUG : Mean Losses: [4.85269589908421]
2026-01-17 13:28:38,529 : worker.worker : DEBUG : Step 118084, finished rewards 12.52, envs finished 1
2026-01-17 13:28:38,680 : agent.on_policy : DEBUG : Mean Losses: [3.569714989513159]
2026-01-17 13:28:38,726 : worker.worker : DEBUG : Step 118119, finished rewards -9.42, envs finished 1
2026-01-17 13:28:38,748 : worker.worker : DEBUG : Step 118123, finished rewards -10.26, envs finished 1
2026-01-17 13:28:38,805 : worker.worker : DEBUG : Step 118137, finished rewards -22.51, envs finished 1
2026-01-17 13:28:38,893 : agent.on_policy : DEBUG : Mean Losses: [5.586192488670349]
2026-01-17 13:28:38,937 : worker.worker : DEBUG : Step 118148, finished rewards 6.35, envs finished 1
2026-01-17 13:28:38,976 : worker.worker : DEBUG : Step 118157, finished rewards 5.92, envs finished 1
2026-01-17 13:28:39,015 : worker.worker : DEBUG : Step 118168, finished rewards -34.72, envs finished 1
2026-01-17 13:28:39,089 : agent.on_policy : DEBUG : Mean Losses: [4.729560993611813]
2026-01-17 13:28:39,113 : worker.worker : DEBUG : Step 118182, finished rewards 6.31, envs finished 1
2026-01-17 13:28:39,625 : agent.on_policy : DEBUG : Mean Losses: [2.6652428582310677]
2026-01-17 13:28:39,661 : worker.worker : DEBUG : Step 118216, finished rewards -3.43, envs finished 1
2026-01-17 13:28:39,844 : agent.on_policy : DEBUG : Mean Losses: [4.734678439795971]
2026-01-17 13:28:39,857 : worker.worker : DEBUG : Step 118242, finished rewards 5.49, envs finished 1
2026-01-17 13:28:39,911 : worker.worker : DEBUG : Step 118254, finished rewards 21.82, envs finished 1
2026-01-17 13:28:39,952 : worker.worker : DEBUG : Step 118264, finished rewards 21.68, envs finished 1
2026-01-17 13:28:40,068 : agent.on_policy : DEBUG : Mean Losses: [7.885827004909515]
2026-01-17 13:28:40,154 : worker.worker : DEBUG : Step 118282, finished rewards -11.18, envs finished 1
2026-01-17 13:28:40,218 : worker.worker : DEBUG : Step 118286, finished rewards 40.54, envs finished 1
2026-01-17 13:28:40,229 : worker.worker : DEBUG : Step 118287, finished rewards -26.03, envs finished 1
2026-01-17 13:28:40,314 : worker.worker : DEBUG : Step 118295, finished rewards -5.68, envs finished 1
2026-01-17 13:28:40,465 : agent.on_policy : DEBUG : Mean Losses: [8.467738717794418]
2026-01-17 13:28:40,488 : worker.worker : DEBUG : Step 118312, finished rewards -4.01, envs finished 1
2026-01-17 13:28:40,602 : worker.worker : DEBUG : Step 118335, finished rewards 31.75, envs finished 1
2026-01-17 13:28:40,751 : agent.on_policy : DEBUG : Mean Losses: [4.555015701800585]
2026-01-17 13:28:40,816 : worker.worker : DEBUG : Step 118354, finished rewards 41.93, envs finished 1
2026-01-17 13:28:40,844 : worker.worker : DEBUG : Step 118360, finished rewards 4.20, envs finished 1
2026-01-17 13:28:40,873 : worker.worker : DEBUG : Step 118367, finished rewards 15.92, envs finished 1
2026-01-17 13:28:40,969 : agent.on_policy : DEBUG : Mean Losses: [7.479074578732252]
2026-01-17 13:28:40,975 : worker.worker : DEBUG : Step 118369, finished rewards 31.53, envs finished 1
2026-01-17 13:28:41,182 : agent.on_policy : DEBUG : Mean Losses: [2.8516243156045675]
2026-01-17 13:28:41,199 : worker.worker : DEBUG : Step 118405, finished rewards 25.55, envs finished 1
2026-01-17 13:28:41,219 : worker.worker : DEBUG : Step 118410, finished rewards -1.95, envs finished 1
2026-01-17 13:28:41,250 : worker.worker : DEBUG : Step 118418, finished rewards 2.72, envs finished 1
2026-01-17 13:28:41,367 : agent.on_policy : DEBUG : Mean Losses: [6.391731351613998]
2026-01-17 13:28:41,557 : agent.on_policy : DEBUG : Mean Losses: [2.691468521952629]
2026-01-17 13:28:41,576 : worker.worker : DEBUG : Step 118469, finished rewards -8.83, envs finished 1
2026-01-17 13:28:41,589 : worker.worker : DEBUG : Step 118471, finished rewards 10.07, envs finished 1
2026-01-17 13:28:41,713 : agent.on_policy : DEBUG : Mean Losses: [6.14979587495327]
2026-01-17 13:28:41,766 : worker.worker : DEBUG : Step 118502, finished rewards -5.96, envs finished 1
2026-01-17 13:28:41,785 : worker.worker : DEBUG : Step 118506, finished rewards 20.16, envs finished 2
2026-01-17 13:28:41,808 : worker.worker : DEBUG : Step 118510, finished rewards -6.37, envs finished 1
2026-01-17 13:28:41,967 : agent.on_policy : DEBUG : Mean Losses: [8.152062773704529]
2026-01-17 13:28:42,072 : worker.worker : DEBUG : Step 118555, finished rewards -46.56, envs finished 1
2026-01-17 13:28:42,219 : agent.on_policy : DEBUG : Mean Losses: [3.6742005087435246]
2026-01-17 13:28:42,535 : agent.on_policy : DEBUG : Mean Losses: [3.6635781936347485]
2026-01-17 13:28:42,541 : worker.worker : DEBUG : Step 118592, finished rewards 2.30, envs finished 1
2026-01-17 13:28:42,586 : worker.worker : DEBUG : Step 118598, finished rewards 23.26, envs finished 1
2026-01-17 13:28:42,671 : worker.worker : DEBUG : Step 118614, finished rewards 14.75, envs finished 1
2026-01-17 13:28:42,713 : worker.worker : DEBUG : Step 118621, finished rewards -7.50, envs finished 1
2026-01-17 13:28:42,848 : agent.on_policy : DEBUG : Mean Losses: [7.320680022239685]
2026-01-17 13:28:42,859 : worker.worker : DEBUG : Step 118625, finished rewards 6.37, envs finished 1
2026-01-17 13:28:42,970 : worker.worker : DEBUG : Step 118644, finished rewards -13.23, envs finished 1
2026-01-17 13:28:43,142 : agent.on_policy : DEBUG : Mean Losses: [4.71528247371316]
2026-01-17 13:28:43,196 : worker.worker : DEBUG : Step 118667, finished rewards -91.72, envs finished 1
2026-01-17 13:28:43,371 : agent.on_policy : DEBUG : Mean Losses: [3.026152230799198]
2026-01-17 13:28:43,377 : worker.worker : DEBUG : Step 118689, finished rewards -5.30, envs finished 1
2026-01-17 13:28:43,444 : worker.worker : DEBUG : Step 118705, finished rewards 26.58, envs finished 1
2026-01-17 13:28:43,606 : agent.on_policy : DEBUG : Mean Losses: [4.825131211429834]
2026-01-17 13:28:43,621 : worker.worker : DEBUG : Step 118723, finished rewards 8.70, envs finished 2
2026-01-17 13:28:43,645 : worker.worker : DEBUG : Step 118729, finished rewards 14.59, envs finished 1
2026-01-17 13:28:43,654 : worker.worker : DEBUG : Step 118730, finished rewards -3.68, envs finished 1
2026-01-17 13:28:43,735 : worker.worker : DEBUG : Step 118751, finished rewards 31.91, envs finished 1
2026-01-17 13:28:43,796 : agent.on_policy : DEBUG : Mean Losses: [8.191660036332905]
2026-01-17 13:28:43,922 : worker.worker : DEBUG : Step 118766, finished rewards 18.59, envs finished 2
2026-01-17 13:28:44,069 : agent.on_policy : DEBUG : Mean Losses: [4.843050209805369]
2026-01-17 13:28:44,201 : worker.worker : DEBUG : Step 118805, finished rewards 36.67, envs finished 1
2026-01-17 13:28:44,328 : agent.on_policy : DEBUG : Mean Losses: [4.3482758942991495]
2026-01-17 13:28:44,470 : worker.worker : DEBUG : Step 118846, finished rewards 1.19, envs finished 1
2026-01-17 13:28:44,519 : agent.on_policy : DEBUG : Mean Losses: [4.28046116605401]
2026-01-17 13:28:44,530 : worker.worker : DEBUG : Step 118850, finished rewards 5.03, envs finished 2
2026-01-17 13:28:44,544 : worker.worker : DEBUG : Step 118852, finished rewards 1.12, envs finished 1
2026-01-17 13:28:44,581 : worker.worker : DEBUG : Step 118861, finished rewards 25.18, envs finished 1
2026-01-17 13:28:44,587 : worker.worker : DEBUG : Step 118862, finished rewards -11.41, envs finished 1
2026-01-17 13:28:44,643 : worker.worker : DEBUG : Step 118875, finished rewards 15.03, envs finished 1
2026-01-17 13:28:44,710 : agent.on_policy : DEBUG : Mean Losses: [6.926677661947906]
2026-01-17 13:28:44,891 : agent.on_policy : DEBUG : Mean Losses: [0.9657774269580841]
2026-01-17 13:28:44,917 : worker.worker : DEBUG : Step 118919, finished rewards 42.01, envs finished 1
2026-01-17 13:28:44,978 : worker.worker : DEBUG : Step 118936, finished rewards 27.06, envs finished 1
2026-01-17 13:28:45,003 : worker.worker : DEBUG : Step 118941, finished rewards -1.28, envs finished 1
2026-01-17 13:28:45,014 : worker.worker : DEBUG : Step 118943, finished rewards 24.68, envs finished 1
2026-01-17 13:28:45,110 : agent.on_policy : DEBUG : Mean Losses: [8.207998931407928]
2026-01-17 13:28:45,236 : worker.worker : DEBUG : Step 118966, finished rewards 25.86, envs finished 1
2026-01-17 13:28:45,401 : agent.on_policy : DEBUG : Mean Losses: [4.614619156811386]
2026-01-17 13:28:45,404 : worker.worker : DEBUG : Step 118976, finished rewards 4.28, envs finished 1
2026-01-17 13:28:45,445 : worker.worker : DEBUG : Step 118985, finished rewards 5.94, envs finished 1
2026-01-17 13:28:45,459 : worker.worker : DEBUG : Step 118987, finished rewards -0.88, envs finished 1
2026-01-17 13:28:45,504 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:28:45,582 : agent.on_policy : DEBUG : Mean Losses: [4.238307803869247]
2026-01-17 13:28:45,876 : agent.on_policy : DEBUG : Mean Losses: [2.7320685014128685]
2026-01-17 13:28:45,898 : worker.worker : DEBUG : Step 119046, finished rewards 3.37, envs finished 1
2026-01-17 13:28:45,955 : worker.worker : DEBUG : Step 119060, finished rewards 30.31, envs finished 1
2026-01-17 13:28:45,963 : worker.worker : DEBUG : Step 119061, finished rewards -2.86, envs finished 1
2026-01-17 13:28:45,970 : worker.worker : DEBUG : Step 119062, finished rewards 22.34, envs finished 1
2026-01-17 13:28:46,012 : worker.worker : DEBUG : Step 119071, finished rewards 30.31, envs finished 1
2026-01-17 13:28:46,130 : agent.on_policy : DEBUG : Mean Losses: [11.492723140865564]
2026-01-17 13:28:46,134 : worker.worker : DEBUG : Step 119072, finished rewards -0.16, envs finished 1
2026-01-17 13:28:46,149 : worker.worker : DEBUG : Step 119075, finished rewards -4.33, envs finished 1
2026-01-17 13:28:46,268 : worker.worker : DEBUG : Step 119095, finished rewards 13.85, envs finished 1
2026-01-17 13:28:46,393 : agent.on_policy : DEBUG : Mean Losses: [2.9234808925539255]
2026-01-17 13:28:46,593 : agent.on_policy : DEBUG : Mean Losses: [1.0119661018252373]
2026-01-17 13:28:46,663 : worker.worker : DEBUG : Step 119157, finished rewards 31.38, envs finished 1
2026-01-17 13:28:46,807 : agent.on_policy : DEBUG : Mean Losses: [6.753468036651611]
2026-01-17 13:28:46,829 : worker.worker : DEBUG : Step 119173, finished rewards 9.22, envs finished 1
2026-01-17 13:28:46,846 : worker.worker : DEBUG : Step 119177, finished rewards 5.31, envs finished 1
2026-01-17 13:28:46,873 : worker.worker : DEBUG : Step 119182, finished rewards -7.75, envs finished 1
2026-01-17 13:28:46,917 : worker.worker : DEBUG : Step 119192, finished rewards 3.56, envs finished 1
2026-01-17 13:28:46,989 : agent.on_policy : DEBUG : Mean Losses: [9.066657483577728]
2026-01-17 13:28:47,131 : worker.worker : DEBUG : Step 119231, finished rewards -1.75, envs finished 1
2026-01-17 13:28:47,184 : agent.on_policy : DEBUG : Mean Losses: [3.2510930243879557]
2026-01-17 13:28:47,258 : worker.worker : DEBUG : Step 119253, finished rewards -37.59, envs finished 1
2026-01-17 13:28:47,395 : agent.on_policy : DEBUG : Mean Losses: [4.269273042678833]
2026-01-17 13:28:47,427 : worker.worker : DEBUG : Step 119273, finished rewards -45.47, envs finished 1
2026-01-17 13:28:47,466 : worker.worker : DEBUG : Step 119283, finished rewards 0.81, envs finished 1
2026-01-17 13:28:47,572 : agent.on_policy : DEBUG : Mean Losses: [6.636425957083702]
2026-01-17 13:28:47,579 : worker.worker : DEBUG : Step 119297, finished rewards 6.78, envs finished 1
2026-01-17 13:28:47,794 : agent.on_policy : DEBUG : Mean Losses: [2.6672609774395823]
2026-01-17 13:28:47,841 : worker.worker : DEBUG : Step 119341, finished rewards -20.32, envs finished 1
2026-01-17 13:28:47,861 : worker.worker : DEBUG : Step 119346, finished rewards -30.29, envs finished 1
2026-01-17 13:28:47,886 : worker.worker : DEBUG : Step 119351, finished rewards 3.13, envs finished 1
2026-01-17 13:28:47,926 : worker.worker : DEBUG : Step 119359, finished rewards -31.63, envs finished 1
2026-01-17 13:28:47,986 : agent.on_policy : DEBUG : Mean Losses: [7.115317724645138]
2026-01-17 13:28:48,058 : worker.worker : DEBUG : Step 119379, finished rewards 20.18, envs finished 1
2026-01-17 13:28:48,074 : worker.worker : DEBUG : Step 119381, finished rewards -1.62, envs finished 1
2026-01-17 13:28:48,202 : agent.on_policy : DEBUG : Mean Losses: [6.285267643630505]
2026-01-17 13:28:48,350 : worker.worker : DEBUG : Step 119418, finished rewards -15.44, envs finished 1
2026-01-17 13:28:48,427 : agent.on_policy : DEBUG : Mean Losses: [3.6006571501493454]
2026-01-17 13:28:48,473 : worker.worker : DEBUG : Step 119435, finished rewards 36.04, envs finished 1
2026-01-17 13:28:48,492 : worker.worker : DEBUG : Step 119438, finished rewards 23.18, envs finished 1
2026-01-17 13:28:48,513 : worker.worker : DEBUG : Step 119439, finished rewards -13.70, envs finished 1
2026-01-17 13:28:48,546 : worker.worker : DEBUG : Step 119442, finished rewards 18.27, envs finished 1
2026-01-17 13:28:48,650 : agent.on_policy : DEBUG : Mean Losses: [9.057789504528046]
2026-01-17 13:28:48,778 : worker.worker : DEBUG : Step 119475, finished rewards 22.12, envs finished 1
2026-01-17 13:28:48,854 : worker.worker : DEBUG : Step 119484, finished rewards 4.60, envs finished 1
2026-01-17 13:28:48,943 : agent.on_policy : DEBUG : Mean Losses: [5.0740910694003105]
2026-01-17 13:28:49,082 : worker.worker : DEBUG : Step 119512, finished rewards -4.26, envs finished 1
2026-01-17 13:28:49,305 : agent.on_policy : DEBUG : Mean Losses: [2.6983545757830143]
2026-01-17 13:28:49,354 : worker.worker : DEBUG : Step 119533, finished rewards 23.26, envs finished 1
2026-01-17 13:28:49,437 : worker.worker : DEBUG : Step 119538, finished rewards 3.62, envs finished 1
2026-01-17 13:28:49,690 : agent.on_policy : DEBUG : Mean Losses: [6.222806178033352]
2026-01-17 13:28:49,728 : worker.worker : DEBUG : Step 119563, finished rewards 26.31, envs finished 1
2026-01-17 13:28:49,759 : worker.worker : DEBUG : Step 119570, finished rewards -5.03, envs finished 1
2026-01-17 13:28:49,775 : worker.worker : DEBUG : Step 119573, finished rewards -7.92, envs finished 2
2026-01-17 13:28:49,897 : agent.on_policy : DEBUG : Mean Losses: [7.771693594753742]
2026-01-17 13:28:50,080 : worker.worker : DEBUG : Step 119615, finished rewards -7.23, envs finished 1
2026-01-17 13:28:50,133 : agent.on_policy : DEBUG : Mean Losses: [2.8837406374514103]
2026-01-17 13:28:50,208 : worker.worker : DEBUG : Step 119639, finished rewards 18.03, envs finished 1
2026-01-17 13:28:50,355 : agent.on_policy : DEBUG : Mean Losses: [4.148067843168974]
2026-01-17 13:28:50,382 : worker.worker : DEBUG : Step 119655, finished rewards 1.99, envs finished 1
2026-01-17 13:28:50,428 : worker.worker : DEBUG : Step 119665, finished rewards -17.54, envs finished 1
2026-01-17 13:28:50,527 : agent.on_policy : DEBUG : Mean Losses: [5.91329887509346]
2026-01-17 13:28:50,570 : worker.worker : DEBUG : Step 119689, finished rewards 13.09, envs finished 1
2026-01-17 13:28:50,598 : worker.worker : DEBUG : Step 119690, finished rewards 0.42, envs finished 1
2026-01-17 13:28:50,688 : worker.worker : DEBUG : Step 119709, finished rewards 5.93, envs finished 1
2026-01-17 13:28:50,779 : agent.on_policy : DEBUG : Mean Losses: [6.186730854213238]
2026-01-17 13:28:50,832 : worker.worker : DEBUG : Step 119715, finished rewards -11.69, envs finished 1
2026-01-17 13:28:50,896 : worker.worker : DEBUG : Step 119721, finished rewards 31.27, envs finished 1
2026-01-17 13:28:51,081 : agent.on_policy : DEBUG : Mean Losses: [4.418040482327342]
2026-01-17 13:28:51,088 : worker.worker : DEBUG : Step 119745, finished rewards 0.53, envs finished 1
2026-01-17 13:28:51,098 : worker.worker : DEBUG : Step 119747, finished rewards 26.32, envs finished 1
2026-01-17 13:28:51,165 : worker.worker : DEBUG : Step 119761, finished rewards 21.63, envs finished 1
2026-01-17 13:28:51,298 : agent.on_policy : DEBUG : Mean Losses: [4.430474676191807]
2026-01-17 13:28:51,315 : worker.worker : DEBUG : Step 119779, finished rewards 26.90, envs finished 1
2026-01-17 13:28:51,395 : worker.worker : DEBUG : Step 119801, finished rewards 9.73, envs finished 1
2026-01-17 13:28:51,521 : agent.on_policy : DEBUG : Mean Losses: [4.4428244680166245]
2026-01-17 13:28:51,724 : agent.on_policy : DEBUG : Mean Losses: [2.1156772933900356]
2026-01-17 13:28:51,735 : worker.worker : DEBUG : Step 119843, finished rewards -5.26, envs finished 1
2026-01-17 13:28:51,754 : worker.worker : DEBUG : Step 119847, finished rewards 3.01, envs finished 1
2026-01-17 13:28:51,797 : worker.worker : DEBUG : Step 119858, finished rewards 21.68, envs finished 1
2026-01-17 13:28:51,808 : worker.worker : DEBUG : Step 119859, finished rewards -9.84, envs finished 1
2026-01-17 13:28:51,854 : worker.worker : DEBUG : Step 119870, finished rewards 2.42, envs finished 1
2026-01-17 13:28:51,911 : agent.on_policy : DEBUG : Mean Losses: [8.760647788643837]
2026-01-17 13:28:52,051 : worker.worker : DEBUG : Step 119898, finished rewards 4.67, envs finished 1
2026-01-17 13:28:52,160 : agent.on_policy : DEBUG : Mean Losses: [3.031088763847947]
2026-01-17 13:28:52,246 : worker.worker : DEBUG : Step 119913, finished rewards -28.58, envs finished 1
2026-01-17 13:28:52,487 : agent.on_policy : DEBUG : Mean Losses: [3.1982047706842422]
2026-01-17 13:28:52,491 : worker.worker : DEBUG : Step 119936, finished rewards 23.68, envs finished 1
2026-01-17 13:28:52,498 : worker.worker : DEBUG : Step 119937, finished rewards 26.47, envs finished 1
2026-01-17 13:28:52,526 : worker.worker : DEBUG : Step 119940, finished rewards 31.62, envs finished 1
2026-01-17 13:28:52,544 : worker.worker : DEBUG : Step 119942, finished rewards -1.18, envs finished 1
2026-01-17 13:28:52,643 : worker.worker : DEBUG : Step 119963, finished rewards 25.07, envs finished 1
2026-01-17 13:28:52,774 : agent.on_policy : DEBUG : Mean Losses: [5.987111886963248]
2026-01-17 13:28:52,976 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:28:53,040 : agent.on_policy : DEBUG : Mean Losses: [1.5629225187003613]
2026-01-17 13:28:53,047 : worker.worker : INFO : Step 120000, Avg Reward 6.2083, Max Reward 42.0139, Loss [5.1880932]
2026-01-17 13:28:53,203 : worker.worker : DEBUG : Step 120015, finished rewards 7.57, envs finished 1
2026-01-17 13:28:53,241 : worker.worker : DEBUG : Step 120020, finished rewards -10.92, envs finished 1
2026-01-17 13:28:53,352 : worker.worker : DEBUG : Step 120028, finished rewards 8.51, envs finished 1
2026-01-17 13:28:53,383 : worker.worker : DEBUG : Step 120031, finished rewards 25.92, envs finished 1
2026-01-17 13:28:53,494 : agent.on_policy : DEBUG : Mean Losses: [8.015773244202137]
2026-01-17 13:28:53,500 : worker.worker : DEBUG : Step 120034, finished rewards 23.36, envs finished 1
2026-01-17 13:28:53,627 : worker.worker : DEBUG : Step 120055, finished rewards 16.52, envs finished 2
2026-01-17 13:28:53,747 : agent.on_policy : DEBUG : Mean Losses: [5.617434598505497]
2026-01-17 13:28:53,831 : worker.worker : DEBUG : Step 120076, finished rewards -6.05, envs finished 1
2026-01-17 13:28:54,000 : agent.on_policy : DEBUG : Mean Losses: [2.994573323056102]
2026-01-17 13:28:54,204 : agent.on_policy : DEBUG : Mean Losses: [2.2749432176351547]
2026-01-17 13:28:54,242 : worker.worker : DEBUG : Step 120136, finished rewards 10.37, envs finished 1
2026-01-17 13:28:54,287 : worker.worker : DEBUG : Step 120143, finished rewards 26.20, envs finished 1
2026-01-17 13:28:54,339 : worker.worker : DEBUG : Step 120152, finished rewards 10.07, envs finished 1
2026-01-17 13:28:54,474 : agent.on_policy : DEBUG : Mean Losses: [9.095905005931854]
2026-01-17 13:28:54,480 : worker.worker : DEBUG : Step 120161, finished rewards -2.60, envs finished 2
2026-01-17 13:28:54,514 : worker.worker : DEBUG : Step 120167, finished rewards -13.32, envs finished 1
2026-01-17 13:28:54,552 : worker.worker : DEBUG : Step 120175, finished rewards 5.59, envs finished 1
2026-01-17 13:28:54,659 : agent.on_policy : DEBUG : Mean Losses: [4.264580607414246]
2026-01-17 13:28:54,784 : worker.worker : DEBUG : Step 120218, finished rewards -10.60, envs finished 1
2026-01-17 13:28:54,790 : worker.worker : DEBUG : Step 120219, finished rewards 30.48, envs finished 1
2026-01-17 13:28:54,910 : agent.on_policy : DEBUG : Mean Losses: [4.409256435930729]
2026-01-17 13:28:54,911 : worker.worker : DEBUG : Step 120224, finished rewards 31.52, envs finished 1
2026-01-17 13:28:54,990 : worker.worker : DEBUG : Step 120235, finished rewards 30.43, envs finished 1
2026-01-17 13:28:55,027 : worker.worker : DEBUG : Step 120243, finished rewards 30.96, envs finished 1
2026-01-17 13:28:55,090 : worker.worker : DEBUG : Step 120252, finished rewards 36.71, envs finished 1
2026-01-17 13:28:55,192 : agent.on_policy : DEBUG : Mean Losses: [8.445029877126217]
2026-01-17 13:28:55,342 : worker.worker : DEBUG : Step 120282, finished rewards 3.77, envs finished 1
2026-01-17 13:28:55,468 : agent.on_policy : DEBUG : Mean Losses: [2.6049087587743998]
2026-01-17 13:28:55,580 : worker.worker : DEBUG : Step 120307, finished rewards 25.78, envs finished 1
2026-01-17 13:28:55,724 : agent.on_policy : DEBUG : Mean Losses: [3.9617917239665985]
2026-01-17 13:28:55,747 : worker.worker : DEBUG : Step 120326, finished rewards -22.77, envs finished 1
2026-01-17 13:28:55,804 : worker.worker : DEBUG : Step 120342, finished rewards 13.62, envs finished 1
2026-01-17 13:28:55,825 : worker.worker : DEBUG : Step 120347, finished rewards -2.87, envs finished 1
2026-01-17 13:28:55,913 : agent.on_policy : DEBUG : Mean Losses: [6.708062758669257]
2026-01-17 13:28:55,997 : worker.worker : DEBUG : Step 120368, finished rewards -2.32, envs finished 1
2026-01-17 13:28:56,001 : worker.worker : DEBUG : Step 120369, finished rewards -18.00, envs finished 1
2026-01-17 13:28:56,152 : agent.on_policy : DEBUG : Mean Losses: [5.672134768217802]
2026-01-17 13:28:56,172 : worker.worker : DEBUG : Step 120390, finished rewards -9.05, envs finished 1
2026-01-17 13:28:56,243 : worker.worker : DEBUG : Step 120410, finished rewards 1.73, envs finished 1
2026-01-17 13:28:56,387 : agent.on_policy : DEBUG : Mean Losses: [3.8414825405925512]
2026-01-17 13:28:56,397 : worker.worker : DEBUG : Step 120418, finished rewards 9.80, envs finished 1
2026-01-17 13:28:56,652 : agent.on_policy : DEBUG : Mean Losses: [2.2222853377461433]
2026-01-17 13:28:56,692 : worker.worker : DEBUG : Step 120457, finished rewards 10.83, envs finished 1
2026-01-17 13:28:56,713 : worker.worker : DEBUG : Step 120462, finished rewards -1.21, envs finished 1
2026-01-17 13:28:56,730 : worker.worker : DEBUG : Step 120466, finished rewards 3.41, envs finished 1
2026-01-17 13:28:56,844 : agent.on_policy : DEBUG : Mean Losses: [6.208230651915073]
2026-01-17 13:28:56,944 : worker.worker : DEBUG : Step 120497, finished rewards -3.76, envs finished 1
2026-01-17 13:28:56,964 : worker.worker : DEBUG : Step 120501, finished rewards 24.58, envs finished 1
2026-01-17 13:28:56,977 : worker.worker : DEBUG : Step 120503, finished rewards 29.79, envs finished 1
2026-01-17 13:28:56,991 : worker.worker : DEBUG : Step 120505, finished rewards 7.36, envs finished 1
2026-01-17 13:28:57,111 : agent.on_policy : DEBUG : Mean Losses: [9.834889650344849]
2026-01-17 13:28:57,115 : worker.worker : DEBUG : Step 120513, finished rewards -14.54, envs finished 1
2026-01-17 13:28:57,329 : agent.on_policy : DEBUG : Mean Losses: [1.5140036810189486]
2026-01-17 13:28:57,422 : worker.worker : DEBUG : Step 120573, finished rewards 36.60, envs finished 1
2026-01-17 13:28:57,523 : agent.on_policy : DEBUG : Mean Losses: [4.948561578989029]
2026-01-17 13:28:57,546 : worker.worker : DEBUG : Step 120580, finished rewards 1.85, envs finished 1
2026-01-17 13:28:57,624 : worker.worker : DEBUG : Step 120587, finished rewards 31.79, envs finished 1
2026-01-17 13:28:57,645 : worker.worker : DEBUG : Step 120592, finished rewards -1.55, envs finished 1
2026-01-17 13:28:57,791 : agent.on_policy : DEBUG : Mean Losses: [8.52519491687417]
2026-01-17 13:28:57,816 : worker.worker : DEBUG : Step 120614, finished rewards 10.92, envs finished 1
2026-01-17 13:28:57,853 : worker.worker : DEBUG : Step 120624, finished rewards 4.88, envs finished 1
2026-01-17 13:28:57,958 : agent.on_policy : DEBUG : Mean Losses: [4.777728237211704]
2026-01-17 13:28:57,975 : worker.worker : DEBUG : Step 120644, finished rewards -3.16, envs finished 1
2026-01-17 13:28:58,091 : worker.worker : DEBUG : Step 120660, finished rewards -34.56, envs finished 1
2026-01-17 13:28:58,154 : worker.worker : DEBUG : Step 120666, finished rewards 25.57, envs finished 1
2026-01-17 13:28:58,328 : agent.on_policy : DEBUG : Mean Losses: [6.753855973482132]
2026-01-17 13:28:58,427 : worker.worker : DEBUG : Step 120688, finished rewards 17.67, envs finished 1
2026-01-17 13:28:58,436 : worker.worker : DEBUG : Step 120690, finished rewards 18.81, envs finished 1
2026-01-17 13:28:58,593 : agent.on_policy : DEBUG : Mean Losses: [5.300738736987114]
2026-01-17 13:28:58,665 : worker.worker : DEBUG : Step 120725, finished rewards -14.07, envs finished 1
2026-01-17 13:28:58,901 : agent.on_policy : DEBUG : Mean Losses: [5.061715083196759]
2026-01-17 13:28:58,903 : worker.worker : DEBUG : Step 120736, finished rewards 37.82, envs finished 1
2026-01-17 13:28:58,967 : worker.worker : DEBUG : Step 120751, finished rewards 28.89, envs finished 1
2026-01-17 13:28:58,994 : worker.worker : DEBUG : Step 120758, finished rewards 7.51, envs finished 1
2026-01-17 13:28:59,007 : worker.worker : DEBUG : Step 120761, finished rewards -8.67, envs finished 1
2026-01-17 13:28:59,124 : agent.on_policy : DEBUG : Mean Losses: [7.429367857053876]
2026-01-17 13:28:59,129 : worker.worker : DEBUG : Step 120769, finished rewards 32.55, envs finished 1
2026-01-17 13:28:59,133 : worker.worker : DEBUG : Step 120770, finished rewards -24.34, envs finished 1
2026-01-17 13:28:59,314 : agent.on_policy : DEBUG : Mean Losses: [1.7431697370484471]
2026-01-17 13:28:59,342 : worker.worker : DEBUG : Step 120807, finished rewards 7.10, envs finished 1
2026-01-17 13:28:59,380 : worker.worker : DEBUG : Step 120817, finished rewards 24.53, envs finished 1
2026-01-17 13:28:59,418 : worker.worker : DEBUG : Step 120826, finished rewards 26.71, envs finished 1
2026-01-17 13:28:59,486 : agent.on_policy : DEBUG : Mean Losses: [6.791670249775052]
2026-01-17 13:28:59,636 : worker.worker : DEBUG : Step 120858, finished rewards 20.94, envs finished 1
2026-01-17 13:28:59,649 : worker.worker : DEBUG : Step 120860, finished rewards 25.10, envs finished 1
2026-01-17 13:28:59,904 : agent.on_policy : DEBUG : Mean Losses: [6.871825214475393]
2026-01-17 13:28:59,962 : worker.worker : DEBUG : Step 120879, finished rewards 11.24, envs finished 1
2026-01-17 13:29:00,002 : worker.worker : DEBUG : Step 120890, finished rewards -2.53, envs finished 1
2026-01-17 13:29:00,112 : agent.on_policy : DEBUG : Mean Losses: [5.305101735517383]
2026-01-17 13:29:00,215 : worker.worker : DEBUG : Step 120914, finished rewards -20.18, envs finished 1
2026-01-17 13:29:00,272 : worker.worker : DEBUG : Step 120924, finished rewards 20.80, envs finished 1
2026-01-17 13:29:00,408 : agent.on_policy : DEBUG : Mean Losses: [6.645485965535045]
2026-01-17 13:29:00,442 : worker.worker : DEBUG : Step 120935, finished rewards 35.70, envs finished 1
2026-01-17 13:29:00,448 : worker.worker : DEBUG : Step 120936, finished rewards -0.62, envs finished 1
2026-01-17 13:29:00,643 : agent.on_policy : DEBUG : Mean Losses: [4.734019074589014]
2026-01-17 13:29:00,669 : worker.worker : DEBUG : Step 120966, finished rewards -20.37, envs finished 1
2026-01-17 13:29:00,796 : agent.on_policy : DEBUG : Mean Losses: [3.4403398111462593]
2026-01-17 13:29:00,850 : worker.worker : DEBUG : Step 120997, finished rewards 5.90, envs finished 1
2026-01-17 13:29:00,867 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:29:00,880 : worker.worker : DEBUG : Step 121001, finished rewards -11.75, envs finished 1
2026-01-17 13:29:00,905 : worker.worker : DEBUG : Step 121007, finished rewards 24.78, envs finished 1
2026-01-17 13:29:01,002 : worker.worker : DEBUG : Step 121020, finished rewards 22.36, envs finished 1
2026-01-17 13:29:01,129 : agent.on_policy : DEBUG : Mean Losses: [7.914062216877937]
2026-01-17 13:29:01,350 : agent.on_policy : DEBUG : Mean Losses: [3.068969238549471]
2026-01-17 13:29:01,356 : worker.worker : DEBUG : Step 121057, finished rewards -22.92, envs finished 1
2026-01-17 13:29:01,416 : worker.worker : DEBUG : Step 121072, finished rewards -4.58, envs finished 1
2026-01-17 13:29:01,423 : worker.worker : DEBUG : Step 121074, finished rewards -6.72, envs finished 1
2026-01-17 13:29:01,468 : worker.worker : DEBUG : Step 121083, finished rewards 6.32, envs finished 1
2026-01-17 13:29:01,582 : agent.on_policy : DEBUG : Mean Losses: [7.326683513820171]
2026-01-17 13:29:01,603 : worker.worker : DEBUG : Step 121094, finished rewards 28.59, envs finished 1
2026-01-17 13:29:01,677 : worker.worker : DEBUG : Step 121100, finished rewards 18.63, envs finished 1
2026-01-17 13:29:01,732 : worker.worker : DEBUG : Step 121112, finished rewards 25.06, envs finished 1
2026-01-17 13:29:01,856 : agent.on_policy : DEBUG : Mean Losses: [7.3571206871420145]
2026-01-17 13:29:01,902 : worker.worker : DEBUG : Step 121126, finished rewards 2.00, envs finished 1
2026-01-17 13:29:02,070 : agent.on_policy : DEBUG : Mean Losses: [2.566140854731202]
2026-01-17 13:29:02,073 : worker.worker : DEBUG : Step 121152, finished rewards 35.48, envs finished 1
2026-01-17 13:29:02,116 : worker.worker : DEBUG : Step 121158, finished rewards 17.27, envs finished 1
2026-01-17 13:29:02,147 : worker.worker : DEBUG : Step 121164, finished rewards 23.01, envs finished 1
2026-01-17 13:29:02,259 : agent.on_policy : DEBUG : Mean Losses: [4.635230961255729]
2026-01-17 13:29:02,413 : worker.worker : DEBUG : Step 121205, finished rewards 14.41, envs finished 1
2026-01-17 13:29:02,654 : agent.on_policy : DEBUG : Mean Losses: [3.612152986228466]
2026-01-17 13:29:02,679 : worker.worker : DEBUG : Step 121221, finished rewards -4.63, envs finished 1
2026-01-17 13:29:02,698 : worker.worker : DEBUG : Step 121224, finished rewards -0.23, envs finished 1
2026-01-17 13:29:02,793 : worker.worker : DEBUG : Step 121243, finished rewards -2.62, envs finished 1
2026-01-17 13:29:02,803 : worker.worker : DEBUG : Step 121245, finished rewards 25.21, envs finished 1
2026-01-17 13:29:02,912 : agent.on_policy : DEBUG : Mean Losses: [6.973191499710083]
2026-01-17 13:29:02,914 : worker.worker : DEBUG : Step 121248, finished rewards 3.41, envs finished 1
2026-01-17 13:29:03,203 : agent.on_policy : DEBUG : Mean Losses: [1.815204430371523]
2026-01-17 13:29:03,225 : worker.worker : DEBUG : Step 121286, finished rewards -3.65, envs finished 1
2026-01-17 13:29:03,310 : worker.worker : DEBUG : Step 121305, finished rewards 19.49, envs finished 1
2026-01-17 13:29:03,343 : worker.worker : DEBUG : Step 121311, finished rewards -7.71, envs finished 1
2026-01-17 13:29:03,456 : agent.on_policy : DEBUG : Mean Losses: [5.066176429390907]
2026-01-17 13:29:03,635 : worker.worker : DEBUG : Step 121335, finished rewards 23.48, envs finished 1
2026-01-17 13:29:03,735 : agent.on_policy : DEBUG : Mean Losses: [3.9986058846116066]
2026-01-17 13:29:03,759 : worker.worker : DEBUG : Step 121351, finished rewards -1.21, envs finished 1
2026-01-17 13:29:03,766 : worker.worker : DEBUG : Step 121353, finished rewards 14.65, envs finished 1
2026-01-17 13:29:03,956 : agent.on_policy : DEBUG : Mean Losses: [5.01969102025032]
2026-01-17 13:29:04,034 : worker.worker : DEBUG : Step 121400, finished rewards -21.30, envs finished 1
2026-01-17 13:29:04,048 : worker.worker : DEBUG : Step 121403, finished rewards 24.98, envs finished 1
2026-01-17 13:29:04,163 : agent.on_policy : DEBUG : Mean Losses: [5.554682619869709]
2026-01-17 13:29:04,166 : worker.worker : DEBUG : Step 121408, finished rewards -52.41, envs finished 1
2026-01-17 13:29:04,250 : worker.worker : DEBUG : Step 121420, finished rewards 8.26, envs finished 1
2026-01-17 13:29:04,335 : worker.worker : DEBUG : Step 121435, finished rewards 17.79, envs finished 1
2026-01-17 13:29:04,455 : agent.on_policy : DEBUG : Mean Losses: [5.549325322732329]
2026-01-17 13:29:04,487 : worker.worker : DEBUG : Step 121444, finished rewards -16.26, envs finished 1
2026-01-17 13:29:04,594 : worker.worker : DEBUG : Step 121457, finished rewards 15.23, envs finished 1
2026-01-17 13:29:04,760 : agent.on_policy : DEBUG : Mean Losses: [4.446289788931608]
2026-01-17 13:29:04,762 : worker.worker : DEBUG : Step 121472, finished rewards -1.54, envs finished 1
2026-01-17 13:29:04,852 : worker.worker : DEBUG : Step 121496, finished rewards 23.68, envs finished 1
2026-01-17 13:29:04,965 : agent.on_policy : DEBUG : Mean Losses: [4.514239948242903]
2026-01-17 13:29:04,976 : worker.worker : DEBUG : Step 121506, finished rewards 20.20, envs finished 1
2026-01-17 13:29:05,061 : worker.worker : DEBUG : Step 121516, finished rewards 21.02, envs finished 1
2026-01-17 13:29:04,419 : agent.on_policy : DEBUG : Mean Losses: [5.312471274286509]
2026-01-17 13:29:04,429 : worker.worker : DEBUG : Step 121538, finished rewards -4.60, envs finished 1
2026-01-17 13:29:04,445 : worker.worker : DEBUG : Step 121541, finished rewards 14.59, envs finished 1
2026-01-17 13:29:04,451 : worker.worker : DEBUG : Step 121542, finished rewards 21.38, envs finished 1
2026-01-17 13:29:04,512 : worker.worker : DEBUG : Step 121557, finished rewards 18.46, envs finished 1
2026-01-17 13:29:04,610 : agent.on_policy : DEBUG : Mean Losses: [5.592436050996184]
2026-01-17 13:29:04,712 : worker.worker : DEBUG : Step 121590, finished rewards 23.11, envs finished 1
2026-01-17 13:29:04,836 : agent.on_policy : DEBUG : Mean Losses: [4.374580681324005]
2026-01-17 13:29:04,939 : worker.worker : DEBUG : Step 121617, finished rewards 16.51, envs finished 1
2026-01-17 13:29:04,960 : worker.worker : DEBUG : Step 121621, finished rewards 7.96, envs finished 1
2026-01-17 13:29:05,205 : agent.on_policy : DEBUG : Mean Losses: [6.071634851396084]
2026-01-17 13:29:05,213 : worker.worker : DEBUG : Step 121632, finished rewards 26.04, envs finished 1
2026-01-17 13:29:05,270 : worker.worker : DEBUG : Step 121638, finished rewards -8.68, envs finished 2
2026-01-17 13:29:05,451 : agent.on_policy : DEBUG : Mean Losses: [4.4169284757226706]
2026-01-17 13:29:05,458 : worker.worker : DEBUG : Step 121666, finished rewards 36.92, envs finished 1
2026-01-17 13:29:05,483 : worker.worker : DEBUG : Step 121671, finished rewards 4.26, envs finished 1
2026-01-17 13:29:05,511 : worker.worker : DEBUG : Step 121675, finished rewards 5.44, envs finished 1
2026-01-17 13:29:05,651 : agent.on_policy : DEBUG : Mean Losses: [4.144173331558704]
2026-01-17 13:29:05,701 : worker.worker : DEBUG : Step 121700, finished rewards 30.90, envs finished 1
2026-01-17 13:29:05,902 : agent.on_policy : DEBUG : Mean Losses: [3.238901808857918]
2026-01-17 13:29:05,937 : worker.worker : DEBUG : Step 121737, finished rewards 15.74, envs finished 1
2026-01-17 13:29:05,942 : worker.worker : DEBUG : Step 121738, finished rewards 6.67, envs finished 1
2026-01-17 13:29:06,073 : agent.on_policy : DEBUG : Mean Losses: [5.865580081939697]
2026-01-17 13:29:06,176 : worker.worker : DEBUG : Step 121778, finished rewards -11.26, envs finished 1
2026-01-17 13:29:06,203 : worker.worker : DEBUG : Step 121784, finished rewards 5.48, envs finished 1
2026-01-17 13:29:06,249 : worker.worker : DEBUG : Step 121788, finished rewards -11.66, envs finished 1
2026-01-17 13:29:06,341 : agent.on_policy : DEBUG : Mean Losses: [8.252476684749126]
2026-01-17 13:29:06,371 : worker.worker : DEBUG : Step 121800, finished rewards -0.95, envs finished 1
2026-01-17 13:29:06,562 : agent.on_policy : DEBUG : Mean Losses: [3.466359678655863]
2026-01-17 13:29:06,563 : worker.worker : DEBUG : Step 121824, finished rewards -13.06, envs finished 1
2026-01-17 13:29:06,571 : worker.worker : DEBUG : Step 121826, finished rewards -0.68, envs finished 1
2026-01-17 13:29:06,662 : worker.worker : DEBUG : Step 121853, finished rewards 4.95, envs finished 1
2026-01-17 13:29:06,737 : agent.on_policy : DEBUG : Mean Losses: [4.04248196259141]
2026-01-17 13:29:06,863 : worker.worker : DEBUG : Step 121870, finished rewards 24.52, envs finished 1
2026-01-17 13:29:06,959 : worker.worker : DEBUG : Step 121879, finished rewards -11.62, envs finished 1
2026-01-17 13:29:07,130 : agent.on_policy : DEBUG : Mean Losses: [5.934492846950889]
2026-01-17 13:29:07,156 : worker.worker : DEBUG : Step 121894, finished rewards 22.92, envs finished 1
2026-01-17 13:29:07,239 : worker.worker : DEBUG : Step 121919, finished rewards 24.89, envs finished 1
2026-01-17 13:29:07,300 : agent.on_policy : DEBUG : Mean Losses: [5.482056119479239]
2026-01-17 13:29:07,304 : worker.worker : DEBUG : Step 121920, finished rewards -8.29, envs finished 1
2026-01-17 13:29:07,354 : worker.worker : DEBUG : Step 121925, finished rewards -6.93, envs finished 1
2026-01-17 13:29:07,504 : worker.worker : DEBUG : Step 121942, finished rewards 4.42, envs finished 1
2026-01-17 13:29:07,525 : worker.worker : DEBUG : Step 121944, finished rewards 25.31, envs finished 1
2026-01-17 13:29:07,651 : agent.on_policy : DEBUG : Mean Losses: [5.912751525640488]
2026-01-17 13:29:07,778 : worker.worker : DEBUG : Step 121975, finished rewards 14.76, envs finished 1
2026-01-17 13:29:07,925 : agent.on_policy : DEBUG : Mean Losses: [3.040004950016737]
2026-01-17 13:29:07,953 : worker.worker : DEBUG : Step 121993, finished rewards 20.09, envs finished 1
2026-01-17 13:29:07,960 : worker.worker : DEBUG : Step 121995, finished rewards 10.51, envs finished 1
2026-01-17 13:29:07,973 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:29:08,009 : worker.worker : DEBUG : Step 122005, finished rewards 29.80, envs finished 1
2026-01-17 13:29:08,098 : agent.on_policy : DEBUG : Mean Losses: [6.29737239331007]
2026-01-17 13:29:08,110 : worker.worker : DEBUG : Step 122019, finished rewards 17.45, envs finished 1
2026-01-17 13:29:08,152 : worker.worker : DEBUG : Step 122027, finished rewards 30.58, envs finished 1
2026-01-17 13:29:08,268 : worker.worker : DEBUG : Step 122043, finished rewards 17.85, envs finished 1
2026-01-17 13:29:08,469 : agent.on_policy : DEBUG : Mean Losses: [6.424485262483358]
2026-01-17 13:29:08,497 : worker.worker : DEBUG : Step 122054, finished rewards -1.35, envs finished 1
2026-01-17 13:29:08,524 : worker.worker : DEBUG : Step 122058, finished rewards 30.96, envs finished 1
2026-01-17 13:29:08,628 : worker.worker : DEBUG : Step 122078, finished rewards 30.84, envs finished 1
2026-01-17 13:29:08,742 : agent.on_policy : DEBUG : Mean Losses: [7.617192968726158]
2026-01-17 13:29:08,897 : worker.worker : DEBUG : Step 122102, finished rewards 21.55, envs finished 1
2026-01-17 13:29:08,923 : worker.worker : DEBUG : Step 122108, finished rewards 6.64, envs finished 1
2026-01-17 13:29:08,984 : agent.on_policy : DEBUG : Mean Losses: [4.9980946481227875]
2026-01-17 13:29:09,082 : worker.worker : DEBUG : Step 122125, finished rewards 14.98, envs finished 1
2026-01-17 13:29:09,172 : worker.worker : DEBUG : Step 122134, finished rewards 25.31, envs finished 1
2026-01-17 13:29:09,302 : worker.worker : DEBUG : Step 122142, finished rewards 28.64, envs finished 1
2026-01-17 13:29:09,385 : agent.on_policy : DEBUG : Mean Losses: [7.848056904040277]
2026-01-17 13:29:09,594 : worker.worker : DEBUG : Step 122174, finished rewards 6.35, envs finished 1
2026-01-17 13:29:09,650 : agent.on_policy : DEBUG : Mean Losses: [3.7995222341269255]
2026-01-17 13:29:09,690 : worker.worker : DEBUG : Step 122185, finished rewards 10.24, envs finished 1
2026-01-17 13:29:09,910 : agent.on_policy : DEBUG : Mean Losses: [5.0595613196492195]
2026-01-17 13:29:09,952 : worker.worker : DEBUG : Step 122220, finished rewards -31.80, envs finished 1
2026-01-17 13:29:09,988 : worker.worker : DEBUG : Step 122229, finished rewards -2.74, envs finished 1
2026-01-17 13:29:10,027 : worker.worker : DEBUG : Step 122238, finished rewards 22.00, envs finished 1
2026-01-17 13:29:10,091 : agent.on_policy : DEBUG : Mean Losses: [7.75067550688982]
2026-01-17 13:29:10,102 : worker.worker : DEBUG : Step 122242, finished rewards -6.31, envs finished 1
2026-01-17 13:29:10,175 : worker.worker : DEBUG : Step 122258, finished rewards -0.48, envs finished 1
2026-01-17 13:29:10,249 : worker.worker : DEBUG : Step 122267, finished rewards 23.28, envs finished 1
2026-01-17 13:29:10,361 : agent.on_policy : DEBUG : Mean Losses: [5.608707025647163]
2026-01-17 13:29:10,589 : agent.on_policy : DEBUG : Mean Losses: [1.921065179631114]
2026-01-17 13:29:10,612 : worker.worker : DEBUG : Step 122309, finished rewards -1.09, envs finished 1
2026-01-17 13:29:10,628 : worker.worker : DEBUG : Step 122312, finished rewards -43.54, envs finished 1
2026-01-17 13:29:10,709 : worker.worker : DEBUG : Step 122335, finished rewards 7.41, envs finished 1
2026-01-17 13:29:10,770 : agent.on_policy : DEBUG : Mean Losses: [6.402432914823294]
2026-01-17 13:29:10,803 : worker.worker : DEBUG : Step 122338, finished rewards 22.07, envs finished 1
2026-01-17 13:29:10,989 : worker.worker : DEBUG : Step 122363, finished rewards -7.78, envs finished 1
2026-01-17 13:29:10,998 : worker.worker : DEBUG : Step 122364, finished rewards -2.21, envs finished 1
2026-01-17 13:29:11,022 : worker.worker : DEBUG : Step 122366, finished rewards 20.55, envs finished 1
2026-01-17 13:29:11,134 : agent.on_policy : DEBUG : Mean Losses: [6.712426967918873]
2026-01-17 13:29:11,272 : worker.worker : DEBUG : Step 122390, finished rewards -6.06, envs finished 1
2026-01-17 13:29:11,367 : agent.on_policy : DEBUG : Mean Losses: [2.565319871529937]
2026-01-17 13:29:11,383 : worker.worker : DEBUG : Step 122403, finished rewards 24.22, envs finished 1
2026-01-17 13:29:11,551 : worker.worker : DEBUG : Step 122425, finished rewards 7.97, envs finished 1
2026-01-17 13:29:11,576 : worker.worker : DEBUG : Step 122431, finished rewards 23.77, envs finished 1
2026-01-17 13:29:11,628 : agent.on_policy : DEBUG : Mean Losses: [5.28601661324501]
2026-01-17 13:29:11,751 : worker.worker : DEBUG : Step 122461, finished rewards 19.79, envs finished 1
2026-01-17 13:29:11,829 : agent.on_policy : DEBUG : Mean Losses: [4.276994636282325]
2026-01-17 13:29:11,870 : worker.worker : DEBUG : Step 122476, finished rewards 7.45, envs finished 1
2026-01-17 13:29:11,893 : worker.worker : DEBUG : Step 122480, finished rewards 25.35, envs finished 1
2026-01-17 13:29:12,129 : agent.on_policy : DEBUG : Mean Losses: [7.303426705300808]
2026-01-17 13:29:12,143 : worker.worker : DEBUG : Step 122499, finished rewards -32.97, envs finished 1
2026-01-17 13:29:12,154 : worker.worker : DEBUG : Step 122501, finished rewards 37.53, envs finished 1
2026-01-17 13:29:12,215 : worker.worker : DEBUG : Step 122515, finished rewards -15.51, envs finished 1
2026-01-17 13:29:12,220 : worker.worker : DEBUG : Step 122516, finished rewards 10.31, envs finished 1
2026-01-17 13:29:12,400 : agent.on_policy : DEBUG : Mean Losses: [7.551992505788803]
2026-01-17 13:29:12,702 : agent.on_policy : DEBUG : Mean Losses: [1.2107400838285685]
2026-01-17 13:29:12,725 : worker.worker : DEBUG : Step 122566, finished rewards -8.71, envs finished 1
2026-01-17 13:29:12,832 : worker.worker : DEBUG : Step 122591, finished rewards 25.92, envs finished 1
2026-01-17 13:29:12,966 : agent.on_policy : DEBUG : Mean Losses: [6.231241777539253]
2026-01-17 13:29:13,044 : worker.worker : DEBUG : Step 122605, finished rewards -6.03, envs finished 1
2026-01-17 13:29:13,058 : worker.worker : DEBUG : Step 122608, finished rewards -15.34, envs finished 1
2026-01-17 13:29:13,125 : worker.worker : DEBUG : Step 122617, finished rewards 5.64, envs finished 1
2026-01-17 13:29:13,186 : worker.worker : DEBUG : Step 122623, finished rewards 10.34, envs finished 1
2026-01-17 13:29:13,264 : agent.on_policy : DEBUG : Mean Losses: [8.425358578562737]
2026-01-17 13:29:13,321 : worker.worker : DEBUG : Step 122629, finished rewards -18.26, envs finished 1
2026-01-17 13:29:13,515 : agent.on_policy : DEBUG : Mean Losses: [3.1434222953394055]
2026-01-17 13:29:13,533 : worker.worker : DEBUG : Step 122661, finished rewards -16.75, envs finished 1
2026-01-17 13:29:13,693 : agent.on_policy : DEBUG : Mean Losses: [2.7806978560984135]
2026-01-17 13:29:13,769 : worker.worker : DEBUG : Step 122700, finished rewards -5.30, envs finished 1
2026-01-17 13:29:13,932 : agent.on_policy : DEBUG : Mean Losses: [4.448739171028137]
2026-01-17 13:29:13,935 : worker.worker : DEBUG : Step 122720, finished rewards -0.66, envs finished 1
2026-01-17 13:29:13,993 : worker.worker : DEBUG : Step 122734, finished rewards 12.39, envs finished 1
2026-01-17 13:29:13,997 : worker.worker : DEBUG : Step 122735, finished rewards -3.90, envs finished 1
2026-01-17 13:29:14,034 : worker.worker : DEBUG : Step 122744, finished rewards 5.82, envs finished 1
2026-01-17 13:29:14,156 : agent.on_policy : DEBUG : Mean Losses: [7.785948731005192]
2026-01-17 13:29:14,164 : worker.worker : DEBUG : Step 122753, finished rewards -8.82, envs finished 1
2026-01-17 13:29:14,217 : worker.worker : DEBUG : Step 122758, finished rewards 19.28, envs finished 1
2026-01-17 13:29:14,286 : worker.worker : DEBUG : Step 122772, finished rewards -26.63, envs finished 1
2026-01-17 13:29:14,433 : agent.on_policy : DEBUG : Mean Losses: [4.272993233054876]
2026-01-17 13:29:14,437 : worker.worker : DEBUG : Step 122784, finished rewards 30.45, envs finished 1
2026-01-17 13:29:14,633 : agent.on_policy : DEBUG : Mean Losses: [1.884048342704773]
2026-01-17 13:29:14,649 : worker.worker : DEBUG : Step 122818, finished rewards 30.81, envs finished 1
2026-01-17 13:29:14,813 : worker.worker : DEBUG : Step 122835, finished rewards 18.14, envs finished 1
2026-01-17 13:29:14,928 : worker.worker : DEBUG : Step 122844, finished rewards 2.14, envs finished 1
2026-01-17 13:29:15,058 : agent.on_policy : DEBUG : Mean Losses: [6.633183911442757]
2026-01-17 13:29:15,155 : worker.worker : DEBUG : Step 122860, finished rewards 7.54, envs finished 1
2026-01-17 13:29:15,221 : worker.worker : DEBUG : Step 122868, finished rewards 23.45, envs finished 1
2026-01-17 13:29:15,265 : worker.worker : DEBUG : Step 122871, finished rewards 7.83, envs finished 1
2026-01-17 13:29:15,441 : agent.on_policy : DEBUG : Mean Losses: [5.532361648976803]
2026-01-17 13:29:15,486 : worker.worker : DEBUG : Step 122885, finished rewards -1.76, envs finished 1
2026-01-17 13:29:15,507 : worker.worker : DEBUG : Step 122886, finished rewards 17.12, envs finished 1
2026-01-17 13:29:15,693 : agent.on_policy : DEBUG : Mean Losses: [3.339656791649759]
2026-01-17 13:29:15,779 : worker.worker : DEBUG : Step 122935, finished rewards 7.60, envs finished 1
2026-01-17 13:29:15,801 : worker.worker : DEBUG : Step 122941, finished rewards 22.51, envs finished 1
2026-01-17 13:29:15,910 : agent.on_policy : DEBUG : Mean Losses: [6.485689774155617]
2026-01-17 13:29:15,941 : worker.worker : DEBUG : Step 122952, finished rewards 24.67, envs finished 1
2026-01-17 13:29:16,011 : worker.worker : DEBUG : Step 122959, finished rewards 4.39, envs finished 1
2026-01-17 13:29:16,041 : worker.worker : DEBUG : Step 122963, finished rewards 37.33, envs finished 1
2026-01-17 13:29:16,197 : agent.on_policy : DEBUG : Mean Losses: [7.308480218052864]
2026-01-17 13:29:16,200 : worker.worker : DEBUG : Step 122976, finished rewards 26.23, envs finished 1
2026-01-17 13:29:16,278 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:29:16,282 : worker.worker : DEBUG : Step 122999, finished rewards 6.86, envs finished 1
2026-01-17 13:29:16,404 : agent.on_policy : DEBUG : Mean Losses: [3.0935174077749252]
2026-01-17 13:29:16,538 : worker.worker : DEBUG : Step 123033, finished rewards 24.60, envs finished 1
2026-01-17 13:29:16,558 : worker.worker : DEBUG : Step 123035, finished rewards 10.78, envs finished 2
2026-01-17 13:29:16,665 : agent.on_policy : DEBUG : Mean Losses: [7.490019664168358]
2026-01-17 13:29:16,806 : worker.worker : DEBUG : Step 123060, finished rewards -1.96, envs finished 1
2026-01-17 13:29:16,821 : worker.worker : DEBUG : Step 123063, finished rewards 19.22, envs finished 1
2026-01-17 13:29:16,846 : worker.worker : DEBUG : Step 123068, finished rewards 24.52, envs finished 1
2026-01-17 13:29:16,904 : agent.on_policy : DEBUG : Mean Losses: [8.12658990547061]
2026-01-17 13:29:16,911 : worker.worker : DEBUG : Step 123073, finished rewards 8.04, envs finished 1
2026-01-17 13:29:17,118 : agent.on_policy : DEBUG : Mean Losses: [1.6410689242184162]
2026-01-17 13:29:17,173 : worker.worker : DEBUG : Step 123120, finished rewards 3.49, envs finished 1
2026-01-17 13:29:17,318 : agent.on_policy : DEBUG : Mean Losses: [3.7152383103966713]
2026-01-17 13:29:17,347 : worker.worker : DEBUG : Step 123142, finished rewards 14.52, envs finished 1
2026-01-17 13:29:17,567 : agent.on_policy : DEBUG : Mean Losses: [5.696806810796261]
2026-01-17 13:29:17,571 : worker.worker : DEBUG : Step 123168, finished rewards 22.16, envs finished 1
2026-01-17 13:29:17,614 : worker.worker : DEBUG : Step 123175, finished rewards -12.19, envs finished 1
2026-01-17 13:29:17,684 : worker.worker : DEBUG : Step 123191, finished rewards 9.80, envs finished 1
2026-01-17 13:29:17,714 : worker.worker : DEBUG : Step 123198, finished rewards -28.38, envs finished 1
2026-01-17 13:29:17,813 : agent.on_policy : DEBUG : Mean Losses: [7.533862620592117]
2026-01-17 13:29:17,855 : worker.worker : DEBUG : Step 123208, finished rewards -17.92, envs finished 1
2026-01-17 13:29:17,898 : worker.worker : DEBUG : Step 123212, finished rewards 23.62, envs finished 1
2026-01-17 13:29:18,080 : agent.on_policy : DEBUG : Mean Losses: [5.029117135331035]
2026-01-17 13:29:18,246 : worker.worker : DEBUG : Step 123261, finished rewards -56.71, envs finished 1
2026-01-17 13:29:18,357 : agent.on_policy : DEBUG : Mean Losses: [2.937859136611223]
2026-01-17 13:29:18,506 : worker.worker : DEBUG : Step 123283, finished rewards 14.59, envs finished 1
2026-01-17 13:29:18,514 : worker.worker : DEBUG : Step 123284, finished rewards 8.38, envs finished 1
2026-01-17 13:29:18,545 : worker.worker : DEBUG : Step 123288, finished rewards 22.01, envs finished 1
2026-01-17 13:29:18,554 : worker.worker : DEBUG : Step 123289, finished rewards 35.93, envs finished 1
2026-01-17 13:29:18,684 : agent.on_policy : DEBUG : Mean Losses: [10.512866083532572]
2026-01-17 13:29:18,724 : worker.worker : DEBUG : Step 123300, finished rewards 17.46, envs finished 1
2026-01-17 13:29:18,965 : agent.on_policy : DEBUG : Mean Losses: [3.4616562305018306]
2026-01-17 13:29:18,983 : worker.worker : DEBUG : Step 123331, finished rewards 5.68, envs finished 1
2026-01-17 13:29:19,021 : worker.worker : DEBUG : Step 123339, finished rewards -44.99, envs finished 1
2026-01-17 13:29:19,222 : agent.on_policy : DEBUG : Mean Losses: [2.8881552517414093]
2026-01-17 13:29:19,244 : worker.worker : DEBUG : Step 123364, finished rewards 16.09, envs finished 1
2026-01-17 13:29:19,272 : worker.worker : DEBUG : Step 123368, finished rewards 29.96, envs finished 1
2026-01-17 13:29:19,334 : worker.worker : DEBUG : Step 123375, finished rewards 38.76, envs finished 1
2026-01-17 13:29:19,510 : worker.worker : DEBUG : Step 123391, finished rewards 16.28, envs finished 1
2026-01-17 13:29:19,665 : agent.on_policy : DEBUG : Mean Losses: [7.452066987752914]
2026-01-17 13:29:19,834 : worker.worker : DEBUG : Step 123417, finished rewards -4.61, envs finished 1
2026-01-17 13:29:20,051 : agent.on_policy : DEBUG : Mean Losses: [4.343339515849948]
2026-01-17 13:29:20,099 : worker.worker : DEBUG : Step 123431, finished rewards -11.43, envs finished 1
2026-01-17 13:29:20,246 : worker.worker : DEBUG : Step 123450, finished rewards 10.37, envs finished 1
2026-01-17 13:29:20,297 : worker.worker : DEBUG : Step 123454, finished rewards 25.34, envs finished 1
2026-01-17 13:29:20,402 : agent.on_policy : DEBUG : Mean Losses: [5.831816118210554]
2026-01-17 13:29:20,488 : worker.worker : DEBUG : Step 123467, finished rewards 23.53, envs finished 1
2026-01-17 13:29:20,593 : worker.worker : DEBUG : Step 123480, finished rewards 9.33, envs finished 1
2026-01-17 13:29:20,751 : agent.on_policy : DEBUG : Mean Losses: [4.557890312746167]
2026-01-17 13:29:20,875 : worker.worker : DEBUG : Step 123506, finished rewards -16.05, envs finished 1
2026-01-17 13:29:20,958 : worker.worker : DEBUG : Step 123516, finished rewards 29.71, envs finished 1
2026-01-17 13:29:21,088 : agent.on_policy : DEBUG : Mean Losses: [5.101877505891025]
2026-01-17 13:29:21,168 : worker.worker : DEBUG : Step 123531, finished rewards -5.27, envs finished 1
2026-01-17 13:29:21,285 : worker.worker : DEBUG : Step 123547, finished rewards -3.78, envs finished 1
2026-01-17 13:29:21,496 : agent.on_policy : DEBUG : Mean Losses: [5.0746034309268]
2026-01-17 13:29:21,529 : worker.worker : DEBUG : Step 123560, finished rewards 23.69, envs finished 1
2026-01-17 13:29:21,592 : worker.worker : DEBUG : Step 123575, finished rewards 41.90, envs finished 1
2026-01-17 13:29:21,733 : agent.on_policy : DEBUG : Mean Losses: [6.459495209157467]
2026-01-17 13:29:21,798 : worker.worker : DEBUG : Step 123591, finished rewards -10.94, envs finished 1
2026-01-17 13:29:21,944 : worker.worker : DEBUG : Step 123607, finished rewards 25.53, envs finished 1
2026-01-17 13:29:22,046 : agent.on_policy : DEBUG : Mean Losses: [5.288286454975605]
2026-01-17 13:29:22,178 : worker.worker : DEBUG : Step 123629, finished rewards -22.75, envs finished 2
2026-01-17 13:29:22,450 : agent.on_policy : DEBUG : Mean Losses: [5.30451238155365]
2026-01-17 13:29:22,470 : worker.worker : DEBUG : Step 123651, finished rewards 25.22, envs finished 1
2026-01-17 13:29:22,587 : worker.worker : DEBUG : Step 123677, finished rewards -18.17, envs finished 1
2026-01-17 13:29:22,702 : agent.on_policy : DEBUG : Mean Losses: [4.277890961617231]
2026-01-17 13:29:22,800 : worker.worker : DEBUG : Step 123695, finished rewards -9.59, envs finished 1
2026-01-17 13:29:22,970 : worker.worker : DEBUG : Step 123711, finished rewards 19.22, envs finished 2
2026-01-17 13:29:23,105 : agent.on_policy : DEBUG : Mean Losses: [6.8578892052173615]
2026-01-17 13:29:23,169 : worker.worker : DEBUG : Step 123725, finished rewards 3.50, envs finished 1
2026-01-17 13:29:23,203 : worker.worker : DEBUG : Step 123731, finished rewards -10.66, envs finished 1
2026-01-17 13:29:23,256 : worker.worker : DEBUG : Step 123741, finished rewards 26.25, envs finished 1
2026-01-17 13:29:23,287 : worker.worker : DEBUG : Step 123742, finished rewards 10.94, envs finished 1
2026-01-17 13:29:23,377 : agent.on_policy : DEBUG : Mean Losses: [7.576451037079096]
2026-01-17 13:29:23,708 : agent.on_policy : DEBUG : Mean Losses: [0.9494911953806877]
2026-01-17 13:29:23,767 : worker.worker : DEBUG : Step 123793, finished rewards 30.97, envs finished 1
2026-01-17 13:29:23,806 : worker.worker : DEBUG : Step 123804, finished rewards 23.47, envs finished 1
2026-01-17 13:29:23,818 : worker.worker : DEBUG : Step 123806, finished rewards 13.48, envs finished 1
2026-01-17 13:29:23,824 : worker.worker : DEBUG : Step 123807, finished rewards -1.13, envs finished 1
2026-01-17 13:29:23,921 : agent.on_policy : DEBUG : Mean Losses: [8.689351379871368]
2026-01-17 13:29:23,947 : worker.worker : DEBUG : Step 123813, finished rewards 31.24, envs finished 1
2026-01-17 13:29:23,956 : worker.worker : DEBUG : Step 123814, finished rewards 26.22, envs finished 1
2026-01-17 13:29:24,086 : worker.worker : DEBUG : Step 123835, finished rewards 24.73, envs finished 1
2026-01-17 13:29:24,212 : agent.on_policy : DEBUG : Mean Losses: [5.481100656092167]
2026-01-17 13:29:24,249 : worker.worker : DEBUG : Step 123845, finished rewards 13.92, envs finished 1
2026-01-17 13:29:24,453 : agent.on_policy : DEBUG : Mean Losses: [2.345187019556761]
2026-01-17 13:29:24,532 : worker.worker : DEBUG : Step 123890, finished rewards 28.67, envs finished 1
2026-01-17 13:29:24,669 : agent.on_policy : DEBUG : Mean Losses: [5.084972500801086]
2026-01-17 13:29:24,679 : worker.worker : DEBUG : Step 123906, finished rewards 24.77, envs finished 1
2026-01-17 13:29:24,734 : worker.worker : DEBUG : Step 123912, finished rewards 3.50, envs finished 1
2026-01-17 13:29:24,918 : agent.on_policy : DEBUG : Mean Losses: [4.663851618766785]
2026-01-17 13:29:24,973 : worker.worker : DEBUG : Step 123952, finished rewards -4.60, envs finished 1
2026-01-17 13:29:24,978 : worker.worker : DEBUG : Step 123953, finished rewards -14.90, envs finished 1
2026-01-17 13:29:25,011 : worker.worker : DEBUG : Step 123962, finished rewards 7.66, envs finished 1
2026-01-17 13:29:25,134 : agent.on_policy : DEBUG : Mean Losses: [6.247820816934109]
2026-01-17 13:29:25,225 : worker.worker : DEBUG : Step 123979, finished rewards -17.16, envs finished 1
2026-01-17 13:29:25,248 : worker.worker : DEBUG : Step 123983, finished rewards -40.19, envs finished 1
2026-01-17 13:29:25,354 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:29:25,510 : agent.on_policy : DEBUG : Mean Losses: [4.442713552154601]
2026-01-17 13:29:25,537 : worker.worker : DEBUG : Step 124003, finished rewards 20.68, envs finished 1
2026-01-17 13:29:25,595 : worker.worker : DEBUG : Step 124009, finished rewards 3.58, envs finished 1
2026-01-17 13:29:25,609 : worker.worker : DEBUG : Step 124011, finished rewards 20.63, envs finished 1
2026-01-17 13:29:25,818 : agent.on_policy : DEBUG : Mean Losses: [4.368385761976242]
2026-01-17 13:29:26,017 : agent.on_policy : DEBUG : Mean Losses: [2.2190981581807137]
2026-01-17 13:29:26,048 : worker.worker : DEBUG : Step 124070, finished rewards 25.31, envs finished 1
2026-01-17 13:29:26,056 : worker.worker : DEBUG : Step 124071, finished rewards 4.18, envs finished 2
2026-01-17 13:29:26,098 : worker.worker : DEBUG : Step 124078, finished rewards 10.87, envs finished 1
2026-01-17 13:29:26,128 : worker.worker : DEBUG : Step 124085, finished rewards 31.38, envs finished 1
2026-01-17 13:29:26,164 : worker.worker : DEBUG : Step 124092, finished rewards 30.86, envs finished 1
2026-01-17 13:29:26,230 : agent.on_policy : DEBUG : Mean Losses: [13.22453436255455]
2026-01-17 13:29:26,424 : agent.on_policy : DEBUG : Mean Losses: [1.203941199928522]
2026-01-17 13:29:26,453 : worker.worker : DEBUG : Step 124136, finished rewards -16.73, envs finished 1
2026-01-17 13:29:26,480 : worker.worker : DEBUG : Step 124141, finished rewards -3.26, envs finished 1
2026-01-17 13:29:26,534 : worker.worker : DEBUG : Step 124152, finished rewards 31.33, envs finished 1
2026-01-17 13:29:26,614 : agent.on_policy : DEBUG : Mean Losses: [5.87652400135994]
2026-01-17 13:29:26,713 : worker.worker : DEBUG : Step 124179, finished rewards 14.12, envs finished 1
2026-01-17 13:29:26,849 : agent.on_policy : DEBUG : Mean Losses: [4.334969654679298]
2026-01-17 13:29:26,853 : worker.worker : DEBUG : Step 124192, finished rewards 11.13, envs finished 1
2026-01-17 13:29:26,929 : worker.worker : DEBUG : Step 124211, finished rewards 36.73, envs finished 1
2026-01-17 13:29:26,947 : worker.worker : DEBUG : Step 124215, finished rewards 1.75, envs finished 1
2026-01-17 13:29:27,079 : agent.on_policy : DEBUG : Mean Losses: [6.685042567551136]
2026-01-17 13:29:27,181 : worker.worker : DEBUG : Step 124241, finished rewards 18.09, envs finished 1
2026-01-17 13:29:27,223 : worker.worker : DEBUG : Step 124250, finished rewards -22.34, envs finished 1
2026-01-17 13:29:27,329 : agent.on_policy : DEBUG : Mean Losses: [5.556568052619696]
2026-01-17 13:29:27,336 : worker.worker : DEBUG : Step 124257, finished rewards 14.04, envs finished 1
2026-01-17 13:29:27,356 : worker.worker : DEBUG : Step 124261, finished rewards -24.56, envs finished 1
2026-01-17 13:29:27,557 : agent.on_policy : DEBUG : Mean Losses: [3.366780087351799]
2026-01-17 13:29:27,616 : worker.worker : DEBUG : Step 124305, finished rewards 7.97, envs finished 1
2026-01-17 13:29:27,651 : worker.worker : DEBUG : Step 124313, finished rewards 19.03, envs finished 1
2026-01-17 13:29:27,796 : agent.on_policy : DEBUG : Mean Losses: [6.084413059055805]
2026-01-17 13:29:27,880 : worker.worker : DEBUG : Step 124345, finished rewards -7.61, envs finished 1
2026-01-17 13:29:27,895 : worker.worker : DEBUG : Step 124348, finished rewards 14.39, envs finished 1
2026-01-17 13:29:28,007 : agent.on_policy : DEBUG : Mean Losses: [5.578022891655564]
2026-01-17 13:29:28,012 : worker.worker : DEBUG : Step 124352, finished rewards 24.49, envs finished 1
2026-01-17 13:29:28,056 : worker.worker : DEBUG : Step 124358, finished rewards -45.48, envs finished 1
2026-01-17 13:29:28,336 : agent.on_policy : DEBUG : Mean Losses: [3.556782066822052]
2026-01-17 13:29:28,371 : worker.worker : DEBUG : Step 124390, finished rewards 36.03, envs finished 1
2026-01-17 13:29:28,431 : worker.worker : DEBUG : Step 124397, finished rewards -15.03, envs finished 1
2026-01-17 13:29:28,491 : worker.worker : DEBUG : Step 124407, finished rewards -15.88, envs finished 1
2026-01-17 13:29:28,562 : worker.worker : DEBUG : Step 124414, finished rewards 14.74, envs finished 1
2026-01-17 13:29:28,738 : agent.on_policy : DEBUG : Mean Losses: [8.34584042057395]
2026-01-17 13:29:29,001 : agent.on_policy : DEBUG : Mean Losses: [1.7396534532308578]
2026-01-17 13:29:29,028 : worker.worker : DEBUG : Step 124456, finished rewards 14.95, envs finished 1
2026-01-17 13:29:29,084 : worker.worker : DEBUG : Step 124470, finished rewards 5.49, envs finished 1
2026-01-17 13:29:29,109 : worker.worker : DEBUG : Step 124476, finished rewards 6.22, envs finished 1
2026-01-17 13:29:29,192 : agent.on_policy : DEBUG : Mean Losses: [6.043676562607288]
2026-01-17 13:29:29,224 : worker.worker : DEBUG : Step 124483, finished rewards -11.25, envs finished 1
2026-01-17 13:29:29,249 : worker.worker : DEBUG : Step 124487, finished rewards 21.51, envs finished 1
2026-01-17 13:29:29,329 : worker.worker : DEBUG : Step 124498, finished rewards 26.54, envs finished 1
2026-01-17 13:29:29,474 : agent.on_policy : DEBUG : Mean Losses: [5.287508787587285]
2026-01-17 13:29:29,478 : worker.worker : DEBUG : Step 124512, finished rewards 19.93, envs finished 1
2026-01-17 13:29:29,566 : worker.worker : DEBUG : Step 124524, finished rewards -0.56, envs finished 1
2026-01-17 13:29:29,917 : agent.on_policy : DEBUG : Mean Losses: [2.460195641964674]
2026-01-17 13:29:29,927 : worker.worker : DEBUG : Step 124546, finished rewards 26.68, envs finished 1
2026-01-17 13:29:29,964 : worker.worker : DEBUG : Step 124552, finished rewards 36.83, envs finished 1
2026-01-17 13:29:30,155 : agent.on_policy : DEBUG : Mean Losses: [4.62794840708375]
2026-01-17 13:29:30,227 : worker.worker : DEBUG : Step 124596, finished rewards 2.13, envs finished 1
2026-01-17 13:29:30,248 : worker.worker : DEBUG : Step 124601, finished rewards 35.78, envs finished 1
2026-01-17 13:29:30,263 : worker.worker : DEBUG : Step 124604, finished rewards 23.58, envs finished 1
2026-01-17 13:29:30,377 : agent.on_policy : DEBUG : Mean Losses: [9.576634585857391]
2026-01-17 13:29:30,456 : worker.worker : DEBUG : Step 124619, finished rewards -1.04, envs finished 2
2026-01-17 13:29:30,575 : worker.worker : DEBUG : Step 124636, finished rewards 30.30, envs finished 1
2026-01-17 13:29:30,705 : agent.on_policy : DEBUG : Mean Losses: [6.103925189003348]
2026-01-17 13:29:30,794 : worker.worker : DEBUG : Step 124649, finished rewards 16.12, envs finished 1
2026-01-17 13:29:30,945 : worker.worker : DEBUG : Step 124667, finished rewards -36.94, envs finished 1
2026-01-17 13:29:31,080 : agent.on_policy : DEBUG : Mean Losses: [4.4675149116665125]
2026-01-17 13:29:31,148 : worker.worker : DEBUG : Step 124693, finished rewards 24.05, envs finished 1
2026-01-17 13:29:31,176 : worker.worker : DEBUG : Step 124700, finished rewards 17.71, envs finished 1
2026-01-17 13:29:31,282 : agent.on_policy : DEBUG : Mean Losses: [6.467674266546965]
2026-01-17 13:29:31,314 : worker.worker : DEBUG : Step 124710, finished rewards 25.15, envs finished 1
2026-01-17 13:29:31,455 : worker.worker : DEBUG : Step 124724, finished rewards 14.32, envs finished 1
2026-01-17 13:29:31,667 : agent.on_policy : DEBUG : Mean Losses: [6.516113851219416]
2026-01-17 13:29:31,786 : worker.worker : DEBUG : Step 124756, finished rewards 5.92, envs finished 1
2026-01-17 13:29:31,812 : worker.worker : DEBUG : Step 124759, finished rewards 10.86, envs finished 1
2026-01-17 13:29:31,878 : worker.worker : DEBUG : Step 124764, finished rewards -24.23, envs finished 1
2026-01-17 13:29:31,942 : agent.on_policy : DEBUG : Mean Losses: [7.637035317718983]
2026-01-17 13:29:32,009 : worker.worker : DEBUG : Step 124775, finished rewards 38.41, envs finished 1
2026-01-17 13:29:32,207 : agent.on_policy : DEBUG : Mean Losses: [3.4145444706082344]
2026-01-17 13:29:32,219 : worker.worker : DEBUG : Step 124802, finished rewards -8.79, envs finished 1
2026-01-17 13:29:32,311 : worker.worker : DEBUG : Step 124822, finished rewards 0.64, envs finished 1
2026-01-17 13:29:32,465 : agent.on_policy : DEBUG : Mean Losses: [3.2014394477009773]
2026-01-17 13:29:32,557 : worker.worker : DEBUG : Step 124844, finished rewards -8.72, envs finished 1
2026-01-17 13:29:32,689 : worker.worker : DEBUG : Step 124857, finished rewards 31.07, envs finished 1
2026-01-17 13:29:32,721 : worker.worker : DEBUG : Step 124861, finished rewards -0.59, envs finished 1
2026-01-17 13:29:32,860 : agent.on_policy : DEBUG : Mean Losses: [8.746543303132057]
2026-01-17 13:29:32,940 : worker.worker : DEBUG : Step 124883, finished rewards 1.59, envs finished 1
2026-01-17 13:29:32,992 : worker.worker : DEBUG : Step 124894, finished rewards 24.52, envs finished 1
2026-01-17 13:29:33,120 : agent.on_policy : DEBUG : Mean Losses: [4.714600943028927]
2026-01-17 13:29:33,144 : worker.worker : DEBUG : Step 124900, finished rewards -7.80, envs finished 1
2026-01-17 13:29:33,269 : worker.worker : DEBUG : Step 124914, finished rewards -20.82, envs finished 1
2026-01-17 13:29:33,465 : agent.on_policy : DEBUG : Mean Losses: [3.8571754842996597]
2026-01-17 13:29:33,498 : worker.worker : DEBUG : Step 124935, finished rewards 24.30, envs finished 1
2026-01-17 13:29:33,586 : worker.worker : DEBUG : Step 124958, finished rewards -5.65, envs finished 1
2026-01-17 13:29:33,677 : agent.on_policy : DEBUG : Mean Losses: [4.653710901737213]
2026-01-17 13:29:33,696 : worker.worker : DEBUG : Step 124960, finished rewards 18.16, envs finished 1
2026-01-17 13:29:33,871 : worker.worker : DEBUG : Step 124986, finished rewards 25.06, envs finished 1
2026-01-17 13:29:33,983 : agent.on_policy : DEBUG : Mean Losses: [5.15754359215498]
2026-01-17 13:29:33,990 : worker.worker : DEBUG : Step 124993, finished rewards 22.65, envs finished 1
2026-01-17 13:29:34,015 : worker.worker : DEBUG : Step 124998, finished rewards -9.35, envs finished 1
2026-01-17 13:29:34,017 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:29:34,067 : worker.worker : INFO : Step 125000, Avg Reward 8.6893, Max Reward 41.8970, Loss [5.26100494]
2026-01-17 13:29:34,211 : agent.on_policy : DEBUG : Mean Losses: [3.2779769115149975]
2026-01-17 13:29:34,247 : worker.worker : DEBUG : Step 125027, finished rewards 27.35, envs finished 1
2026-01-17 13:29:33,642 : worker.worker : DEBUG : Step 125047, finished rewards -2.86, envs finished 1
2026-01-17 13:29:33,757 : worker.worker : DEBUG : Step 125055, finished rewards -26.29, envs finished 1
2026-01-17 13:29:33,850 : agent.on_policy : DEBUG : Mean Losses: [5.5033316146582365]
2026-01-17 13:29:33,893 : worker.worker : DEBUG : Step 125060, finished rewards 20.81, envs finished 1
2026-01-17 13:29:33,997 : worker.worker : DEBUG : Step 125080, finished rewards 3.75, envs finished 1
2026-01-17 13:29:34,118 : agent.on_policy : DEBUG : Mean Losses: [3.735409425571561]
2026-01-17 13:29:34,178 : worker.worker : DEBUG : Step 125096, finished rewards 11.84, envs finished 1
2026-01-17 13:29:34,273 : worker.worker : DEBUG : Step 125108, finished rewards 10.23, envs finished 2
2026-01-17 13:29:34,397 : agent.on_policy : DEBUG : Mean Losses: [6.3830930814146996]
2026-01-17 13:29:34,428 : worker.worker : DEBUG : Step 125126, finished rewards 18.50, envs finished 1
2026-01-17 13:29:34,506 : worker.worker : DEBUG : Step 125136, finished rewards 27.34, envs finished 1
2026-01-17 13:29:34,657 : agent.on_policy : DEBUG : Mean Losses: [4.604863069951534]
2026-01-17 13:29:34,678 : worker.worker : DEBUG : Step 125159, finished rewards 16.24, envs finished 1
2026-01-17 13:29:34,751 : worker.worker : DEBUG : Step 125167, finished rewards 28.46, envs finished 1
2026-01-17 13:29:34,761 : worker.worker : DEBUG : Step 125169, finished rewards 12.89, envs finished 1
2026-01-17 13:29:34,928 : agent.on_policy : DEBUG : Mean Losses: [5.6293694749474525]
2026-01-17 13:29:35,134 : agent.on_policy : DEBUG : Mean Losses: [2.8344769179821014]
2026-01-17 13:29:35,154 : worker.worker : DEBUG : Step 125221, finished rewards 7.68, envs finished 1
2026-01-17 13:29:35,166 : worker.worker : DEBUG : Step 125224, finished rewards -1.02, envs finished 1
2026-01-17 13:29:35,187 : worker.worker : DEBUG : Step 125229, finished rewards 8.97, envs finished 1
2026-01-17 13:29:35,308 : agent.on_policy : DEBUG : Mean Losses: [4.818961038719863]
2026-01-17 13:29:35,321 : worker.worker : DEBUG : Step 125251, finished rewards 24.05, envs finished 1
2026-01-17 13:29:35,377 : worker.worker : DEBUG : Step 125256, finished rewards 7.35, envs finished 1
2026-01-17 13:29:35,385 : worker.worker : DEBUG : Step 125257, finished rewards -4.92, envs finished 1
2026-01-17 13:29:35,404 : worker.worker : DEBUG : Step 125261, finished rewards 22.81, envs finished 1
2026-01-17 13:29:35,431 : worker.worker : DEBUG : Step 125265, finished rewards 22.47, envs finished 1
2026-01-17 13:29:35,610 : agent.on_policy : DEBUG : Mean Losses: [7.371145181357861]
2026-01-17 13:29:35,755 : agent.on_policy : DEBUG : Mean Losses: [1.234007090330124]
2026-01-17 13:29:35,764 : worker.worker : DEBUG : Step 125313, finished rewards 24.38, envs finished 1
2026-01-17 13:29:35,834 : worker.worker : DEBUG : Step 125324, finished rewards 17.68, envs finished 1
2026-01-17 13:29:36,047 : agent.on_policy : DEBUG : Mean Losses: [3.9954349733889103]
2026-01-17 13:29:36,062 : worker.worker : DEBUG : Step 125347, finished rewards 17.93, envs finished 2
2026-01-17 13:29:36,122 : worker.worker : DEBUG : Step 125360, finished rewards 18.75, envs finished 2
2026-01-17 13:29:36,307 : agent.on_policy : DEBUG : Mean Losses: [6.566278353333473]
2026-01-17 13:29:36,309 : worker.worker : DEBUG : Step 125376, finished rewards -1.27, envs finished 1
2026-01-17 13:29:36,341 : worker.worker : DEBUG : Step 125384, finished rewards -1.89, envs finished 1
2026-01-17 13:29:36,467 : agent.on_policy : DEBUG : Mean Losses: [2.0709831323474646]
2026-01-17 13:29:36,629 : worker.worker : DEBUG : Step 125439, finished rewards 1.08, envs finished 1
2026-01-17 13:29:36,677 : agent.on_policy : DEBUG : Mean Losses: [3.0771439857780933]
2026-01-17 13:29:36,678 : worker.worker : DEBUG : Step 125440, finished rewards 23.90, envs finished 1
2026-01-17 13:29:36,721 : worker.worker : DEBUG : Step 125451, finished rewards 26.19, envs finished 1
2026-01-17 13:29:36,834 : agent.on_policy : DEBUG : Mean Losses: [5.801222212612629]
2026-01-17 13:29:36,890 : worker.worker : DEBUG : Step 125482, finished rewards 1.22, envs finished 1
2026-01-17 13:29:36,924 : worker.worker : DEBUG : Step 125487, finished rewards -25.21, envs finished 1
2026-01-17 13:29:37,092 : agent.on_policy : DEBUG : Mean Losses: [4.612497337162495]
2026-01-17 13:29:37,093 : worker.worker : DEBUG : Step 125504, finished rewards -22.55, envs finished 1
2026-01-17 13:29:37,193 : worker.worker : DEBUG : Step 125531, finished rewards -22.99, envs finished 1
2026-01-17 13:29:37,197 : worker.worker : DEBUG : Step 125532, finished rewards 23.19, envs finished 1
2026-01-17 13:29:37,303 : agent.on_policy : DEBUG : Mean Losses: [6.925943408161402]
2026-01-17 13:29:37,324 : worker.worker : DEBUG : Step 125542, finished rewards -21.93, envs finished 1
2026-01-17 13:29:37,330 : worker.worker : DEBUG : Step 125543, finished rewards 24.17, envs finished 1
2026-01-17 13:29:37,535 : agent.on_policy : DEBUG : Mean Losses: [4.248493410646915]
2026-01-17 13:29:37,593 : worker.worker : DEBUG : Step 125584, finished rewards -8.02, envs finished 1
2026-01-17 13:29:37,757 : agent.on_policy : DEBUG : Mean Losses: [4.658787701278925]
2026-01-17 13:29:37,808 : worker.worker : DEBUG : Step 125616, finished rewards -2.33, envs finished 1
2026-01-17 13:29:37,824 : worker.worker : DEBUG : Step 125620, finished rewards -9.02, envs finished 1
2026-01-17 13:29:37,833 : worker.worker : DEBUG : Step 125622, finished rewards 26.90, envs finished 1
2026-01-17 13:29:37,971 : agent.on_policy : DEBUG : Mean Losses: [7.700746119022369]
2026-01-17 13:29:38,198 : agent.on_policy : DEBUG : Mean Losses: [3.607917185872793]
2026-01-17 13:29:38,199 : worker.worker : DEBUG : Step 125664, finished rewards 4.80, envs finished 1
2026-01-17 13:29:38,281 : worker.worker : DEBUG : Step 125683, finished rewards 21.25, envs finished 1
2026-01-17 13:29:38,290 : worker.worker : DEBUG : Step 125685, finished rewards -16.52, envs finished 1
2026-01-17 13:29:38,436 : agent.on_policy : DEBUG : Mean Losses: [6.025155760347843]
2026-01-17 13:29:38,483 : worker.worker : DEBUG : Step 125711, finished rewards -35.27, envs finished 1
2026-01-17 13:29:38,498 : worker.worker : DEBUG : Step 125715, finished rewards 23.67, envs finished 1
2026-01-17 13:29:38,528 : worker.worker : DEBUG : Step 125721, finished rewards 15.22, envs finished 2
2026-01-17 13:29:38,535 : worker.worker : DEBUG : Step 125723, finished rewards -40.23, envs finished 1
2026-01-17 13:29:38,602 : agent.on_policy : DEBUG : Mean Losses: [10.005434483289719]
2026-01-17 13:29:38,805 : agent.on_policy : DEBUG : Mean Losses: [1.396625854074955]
2026-01-17 13:29:38,852 : worker.worker : DEBUG : Step 125775, finished rewards 25.40, envs finished 1
2026-01-17 13:29:38,883 : worker.worker : DEBUG : Step 125783, finished rewards 3.78, envs finished 1
2026-01-17 13:29:38,988 : agent.on_policy : DEBUG : Mean Losses: [5.287894435226917]
2026-01-17 13:29:39,070 : worker.worker : DEBUG : Step 125804, finished rewards 5.60, envs finished 1
2026-01-17 13:29:39,186 : worker.worker : DEBUG : Step 125812, finished rewards 24.70, envs finished 1
2026-01-17 13:29:39,276 : worker.worker : DEBUG : Step 125819, finished rewards 16.01, envs finished 2
2026-01-17 13:29:39,549 : agent.on_policy : DEBUG : Mean Losses: [8.736630149185658]
2026-01-17 13:29:39,586 : worker.worker : DEBUG : Step 125834, finished rewards 5.77, envs finished 1
2026-01-17 13:29:39,615 : worker.worker : DEBUG : Step 125841, finished rewards 4.50, envs finished 1
2026-01-17 13:29:39,730 : agent.on_policy : DEBUG : Mean Losses: [3.5339989941567183]
2026-01-17 13:29:39,931 : agent.on_policy : DEBUG : Mean Losses: [2.4021426662802696]
2026-01-17 13:29:39,963 : worker.worker : DEBUG : Step 125897, finished rewards 15.39, envs finished 2
2026-01-17 13:29:40,084 : agent.on_policy : DEBUG : Mean Losses: [5.528886765241623]
2026-01-17 13:29:40,142 : worker.worker : DEBUG : Step 125928, finished rewards 15.15, envs finished 2
2026-01-17 13:29:40,230 : worker.worker : DEBUG : Step 125946, finished rewards 0.91, envs finished 1
2026-01-17 13:29:40,239 : worker.worker : DEBUG : Step 125948, finished rewards -35.10, envs finished 1
2026-01-17 13:29:40,426 : agent.on_policy : DEBUG : Mean Losses: [8.711100593209267]
2026-01-17 13:29:40,478 : worker.worker : DEBUG : Step 125959, finished rewards -4.12, envs finished 1
2026-01-17 13:29:40,534 : worker.worker : DEBUG : Step 125963, finished rewards 2.36, envs finished 1
2026-01-17 13:29:40,696 : worker.worker : DEBUG : Step 125981, finished rewards 29.61, envs finished 1
2026-01-17 13:29:40,846 : agent.on_policy : DEBUG : Mean Losses: [5.275216843932867]
2026-01-17 13:29:40,887 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:29:40,979 : agent.on_policy : DEBUG : Mean Losses: [2.7905874960124493]
2026-01-17 13:29:40,986 : worker.worker : DEBUG : Step 126018, finished rewards 25.23, envs finished 1
2026-01-17 13:29:41,147 : worker.worker : DEBUG : Step 126043, finished rewards 9.31, envs finished 1
2026-01-17 13:29:41,216 : agent.on_policy : DEBUG : Mean Losses: [5.727918319404125]
2026-01-17 13:29:41,236 : worker.worker : DEBUG : Step 126052, finished rewards -18.64, envs finished 1
2026-01-17 13:29:41,279 : worker.worker : DEBUG : Step 126064, finished rewards 7.09, envs finished 1
2026-01-17 13:29:41,431 : agent.on_policy : DEBUG : Mean Losses: [6.52849899046123]
2026-01-17 13:29:41,435 : worker.worker : DEBUG : Step 126081, finished rewards 17.87, envs finished 1
2026-01-17 13:29:41,449 : worker.worker : DEBUG : Step 126085, finished rewards 2.63, envs finished 1
2026-01-17 13:29:41,488 : worker.worker : DEBUG : Step 126095, finished rewards -13.28, envs finished 1
2026-01-17 13:29:41,588 : agent.on_policy : DEBUG : Mean Losses: [3.7732187965884805]
2026-01-17 13:29:41,685 : worker.worker : DEBUG : Step 126129, finished rewards 35.93, envs finished 1
2026-01-17 13:29:41,715 : worker.worker : DEBUG : Step 126136, finished rewards 7.26, envs finished 1
2026-01-17 13:29:41,834 : agent.on_policy : DEBUG : Mean Losses: [4.6743825897574425]
2026-01-17 13:29:41,908 : worker.worker : DEBUG : Step 126154, finished rewards 9.91, envs finished 1
2026-01-17 13:29:41,989 : worker.worker : DEBUG : Step 126170, finished rewards -49.09, envs finished 1
2026-01-17 13:29:42,192 : agent.on_policy : DEBUG : Mean Losses: [4.816177021712065]
2026-01-17 13:29:42,202 : worker.worker : DEBUG : Step 126177, finished rewards 24.71, envs finished 1
2026-01-17 13:29:42,217 : worker.worker : DEBUG : Step 126179, finished rewards 7.61, envs finished 1
2026-01-17 13:29:42,239 : worker.worker : DEBUG : Step 126181, finished rewards 19.99, envs finished 1
2026-01-17 13:29:42,290 : worker.worker : DEBUG : Step 126189, finished rewards 23.25, envs finished 1
2026-01-17 13:29:42,367 : worker.worker : DEBUG : Step 126203, finished rewards 37.44, envs finished 1
2026-01-17 13:29:42,525 : agent.on_policy : DEBUG : Mean Losses: [7.414211756084114]
2026-01-17 13:29:42,685 : worker.worker : DEBUG : Step 126238, finished rewards 14.77, envs finished 1
2026-01-17 13:29:42,829 : agent.on_policy : DEBUG : Mean Losses: [2.9988532392308116]
2026-01-17 13:29:43,020 : worker.worker : DEBUG : Step 126268, finished rewards 26.21, envs finished 1
2026-01-17 13:29:43,106 : agent.on_policy : DEBUG : Mean Losses: [4.567399553954601]
2026-01-17 13:29:43,123 : worker.worker : DEBUG : Step 126275, finished rewards 5.19, envs finished 1
2026-01-17 13:29:43,204 : worker.worker : DEBUG : Step 126285, finished rewards 22.25, envs finished 1
2026-01-17 13:29:43,261 : worker.worker : DEBUG : Step 126292, finished rewards 10.32, envs finished 1
2026-01-17 13:29:43,329 : worker.worker : DEBUG : Step 126298, finished rewards 6.99, envs finished 1
2026-01-17 13:29:43,356 : worker.worker : DEBUG : Step 126301, finished rewards -4.05, envs finished 1
2026-01-17 13:29:43,424 : agent.on_policy : DEBUG : Mean Losses: [8.704167071729898]
2026-01-17 13:29:43,523 : worker.worker : DEBUG : Step 126319, finished rewards 7.14, envs finished 1
2026-01-17 13:29:43,528 : worker.worker : DEBUG : Step 126320, finished rewards 31.18, envs finished 1
2026-01-17 13:29:43,733 : agent.on_policy : DEBUG : Mean Losses: [3.930176069959998]
2026-01-17 13:29:44,097 : agent.on_policy : DEBUG : Mean Losses: [2.111146304756403]
2026-01-17 13:29:44,272 : worker.worker : DEBUG : Step 126398, finished rewards 21.04, envs finished 1
2026-01-17 13:29:44,372 : agent.on_policy : DEBUG : Mean Losses: [6.2949953973293304]
2026-01-17 13:29:44,441 : worker.worker : DEBUG : Step 126412, finished rewards 23.19, envs finished 1
2026-01-17 13:29:44,463 : worker.worker : DEBUG : Step 126414, finished rewards -2.45, envs finished 1
2026-01-17 13:29:44,527 : worker.worker : DEBUG : Step 126423, finished rewards -16.91, envs finished 1
2026-01-17 13:29:44,585 : worker.worker : DEBUG : Step 126428, finished rewards -27.17, envs finished 1
2026-01-17 13:29:44,703 : agent.on_policy : DEBUG : Mean Losses: [9.461387529969215]
2026-01-17 13:29:44,710 : worker.worker : DEBUG : Step 126433, finished rewards -7.97, envs finished 1
2026-01-17 13:29:44,863 : worker.worker : DEBUG : Step 126452, finished rewards -6.50, envs finished 1
2026-01-17 13:29:44,900 : worker.worker : DEBUG : Step 126459, finished rewards -33.49, envs finished 1
2026-01-17 13:29:44,989 : agent.on_policy : DEBUG : Mean Losses: [4.233916649594903]
2026-01-17 13:29:45,159 : worker.worker : DEBUG : Step 126483, finished rewards 29.58, envs finished 1
2026-01-17 13:29:45,200 : worker.worker : DEBUG : Step 126487, finished rewards 37.28, envs finished 1
2026-01-17 13:29:45,265 : worker.worker : DEBUG : Step 126495, finished rewards 32.49, envs finished 1
2026-01-17 13:29:45,349 : agent.on_policy : DEBUG : Mean Losses: [8.125678298994899]
2026-01-17 13:29:45,566 : worker.worker : DEBUG : Step 126524, finished rewards 25.35, envs finished 1
2026-01-17 13:29:45,657 : agent.on_policy : DEBUG : Mean Losses: [4.660213876515627]
2026-01-17 13:29:45,684 : worker.worker : DEBUG : Step 126534, finished rewards 37.44, envs finished 1
2026-01-17 13:29:45,688 : worker.worker : DEBUG : Step 126535, finished rewards 13.72, envs finished 1
2026-01-17 13:29:45,695 : worker.worker : DEBUG : Step 126536, finished rewards 10.33, envs finished 1
2026-01-17 13:29:45,799 : worker.worker : DEBUG : Step 126550, finished rewards 20.69, envs finished 1
2026-01-17 13:29:45,964 : agent.on_policy : DEBUG : Mean Losses: [6.968034520745277]
2026-01-17 13:29:46,016 : worker.worker : DEBUG : Step 126565, finished rewards 31.51, envs finished 1
2026-01-17 13:29:46,167 : worker.worker : DEBUG : Step 126582, finished rewards 22.56, envs finished 1
2026-01-17 13:29:46,238 : worker.worker : DEBUG : Step 126589, finished rewards 21.99, envs finished 1
2026-01-17 13:29:46,386 : agent.on_policy : DEBUG : Mean Losses: [5.855915434658527]
2026-01-17 13:29:46,510 : worker.worker : DEBUG : Step 126618, finished rewards 42.33, envs finished 1
2026-01-17 13:29:46,630 : agent.on_policy : DEBUG : Mean Losses: [4.710127122700214]
2026-01-17 13:29:46,693 : worker.worker : DEBUG : Step 126632, finished rewards 21.83, envs finished 1
2026-01-17 13:29:46,914 : agent.on_policy : DEBUG : Mean Losses: [4.362745314836502]
2026-01-17 13:29:46,923 : worker.worker : DEBUG : Step 126658, finished rewards 23.84, envs finished 1
2026-01-17 13:29:46,936 : worker.worker : DEBUG : Step 126661, finished rewards -2.09, envs finished 1
2026-01-17 13:29:46,995 : worker.worker : DEBUG : Step 126673, finished rewards -18.70, envs finished 1
2026-01-17 13:29:47,144 : agent.on_policy : DEBUG : Mean Losses: [6.083128795027733]
2026-01-17 13:29:47,148 : worker.worker : DEBUG : Step 126688, finished rewards 40.17, envs finished 1
2026-01-17 13:29:47,172 : worker.worker : DEBUG : Step 126691, finished rewards 17.53, envs finished 1
2026-01-17 13:29:47,272 : worker.worker : DEBUG : Step 126709, finished rewards -17.03, envs finished 1
2026-01-17 13:29:47,280 : worker.worker : DEBUG : Step 126710, finished rewards -0.56, envs finished 1
2026-01-17 13:29:47,476 : agent.on_policy : DEBUG : Mean Losses: [5.105979826301336]
2026-01-17 13:29:47,494 : worker.worker : DEBUG : Step 126724, finished rewards 24.13, envs finished 1
2026-01-17 13:29:47,710 : agent.on_policy : DEBUG : Mean Losses: [2.257942132651806]
2026-01-17 13:29:47,809 : worker.worker : DEBUG : Step 126771, finished rewards 11.83, envs finished 1
2026-01-17 13:29:47,835 : worker.worker : DEBUG : Step 126775, finished rewards 7.91, envs finished 1
2026-01-17 13:29:48,003 : agent.on_policy : DEBUG : Mean Losses: [5.252497889101505]
2026-01-17 13:29:48,017 : worker.worker : DEBUG : Step 126787, finished rewards 17.45, envs finished 1
2026-01-17 13:29:48,129 : worker.worker : DEBUG : Step 126815, finished rewards 24.29, envs finished 1
2026-01-17 13:29:48,247 : agent.on_policy : DEBUG : Mean Losses: [7.239535290747881]
2026-01-17 13:29:48,362 : worker.worker : DEBUG : Step 126832, finished rewards 3.60, envs finished 1
2026-01-17 13:29:48,436 : worker.worker : DEBUG : Step 126840, finished rewards 41.87, envs finished 1
2026-01-17 13:29:48,465 : worker.worker : DEBUG : Step 126843, finished rewards -3.36, envs finished 1
2026-01-17 13:29:48,478 : worker.worker : DEBUG : Step 126845, finished rewards -19.48, envs finished 1
2026-01-17 13:29:48,626 : agent.on_policy : DEBUG : Mean Losses: [9.473980765789747]
2026-01-17 13:29:48,666 : worker.worker : DEBUG : Step 126857, finished rewards -30.98, envs finished 1
2026-01-17 13:29:48,674 : worker.worker : DEBUG : Step 126858, finished rewards 30.87, envs finished 1
2026-01-17 13:29:48,891 : agent.on_policy : DEBUG : Mean Losses: [4.067468345165253]
2026-01-17 13:29:48,905 : worker.worker : DEBUG : Step 126883, finished rewards 22.38, envs finished 1
2026-01-17 13:29:49,125 : agent.on_policy : DEBUG : Mean Losses: [2.1360521093010902]
2026-01-17 13:29:49,199 : worker.worker : DEBUG : Step 126929, finished rewards 21.14, envs finished 1
2026-01-17 13:29:49,288 : worker.worker : DEBUG : Step 126942, finished rewards 21.26, envs finished 1
2026-01-17 13:29:49,334 : worker.worker : DEBUG : Step 126943, finished rewards -1.53, envs finished 1
2026-01-17 13:29:49,592 : agent.on_policy : DEBUG : Mean Losses: [7.138775199651718]
2026-01-17 13:29:49,673 : worker.worker : DEBUG : Step 126953, finished rewards 22.52, envs finished 1
2026-01-17 13:29:49,681 : worker.worker : DEBUG : Step 126954, finished rewards 22.13, envs finished 1
2026-01-17 13:29:49,809 : worker.worker : DEBUG : Step 126968, finished rewards -0.66, envs finished 1
2026-01-17 13:29:50,058 : agent.on_policy : DEBUG : Mean Losses: [6.047903943806887]
2026-01-17 13:29:50,060 : worker.worker : DEBUG : Step 126976, finished rewards 23.80, envs finished 1
2026-01-17 13:29:50,223 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:29:50,310 : agent.on_policy : DEBUG : Mean Losses: [2.3355970606207848]
2026-01-17 13:29:50,312 : worker.worker : DEBUG : Step 127008, finished rewards -32.16, envs finished 1
2026-01-17 13:29:50,486 : worker.worker : DEBUG : Step 127029, finished rewards 29.26, envs finished 1
2026-01-17 13:29:50,511 : worker.worker : DEBUG : Step 127032, finished rewards 16.43, envs finished 1
2026-01-17 13:29:50,728 : agent.on_policy : DEBUG : Mean Losses: [6.663787215948105]
2026-01-17 13:29:50,743 : worker.worker : DEBUG : Step 127042, finished rewards 18.73, envs finished 1
2026-01-17 13:29:50,886 : agent.on_policy : DEBUG : Mean Losses: [2.8985328609123826]
2026-01-17 13:29:50,899 : worker.worker : DEBUG : Step 127073, finished rewards 10.80, envs finished 1
2026-01-17 13:29:50,944 : worker.worker : DEBUG : Step 127077, finished rewards -0.57, envs finished 1
2026-01-17 13:29:51,143 : agent.on_policy : DEBUG : Mean Losses: [4.404291093349457]
2026-01-17 13:29:51,263 : worker.worker : DEBUG : Step 127120, finished rewards 25.46, envs finished 1
2026-01-17 13:29:51,335 : worker.worker : DEBUG : Step 127126, finished rewards -21.25, envs finished 1
2026-01-17 13:29:51,372 : worker.worker : DEBUG : Step 127130, finished rewards 3.73, envs finished 1
2026-01-17 13:29:51,416 : worker.worker : DEBUG : Step 127134, finished rewards -27.41, envs finished 1
2026-01-17 13:29:51,549 : agent.on_policy : DEBUG : Mean Losses: [10.419509246945381]
2026-01-17 13:29:51,660 : worker.worker : DEBUG : Step 127150, finished rewards 35.97, envs finished 1
2026-01-17 13:29:51,775 : worker.worker : DEBUG : Step 127159, finished rewards -1.07, envs finished 1
2026-01-17 13:29:51,946 : agent.on_policy : DEBUG : Mean Losses: [4.513678511604667]
2026-01-17 13:29:51,982 : worker.worker : DEBUG : Step 127174, finished rewards 0.04, envs finished 1
2026-01-17 13:29:52,200 : agent.on_policy : DEBUG : Mean Losses: [2.749496456235647]
2026-01-17 13:29:52,523 : agent.on_policy : DEBUG : Mean Losses: [4.110051665455103]
2026-01-17 13:29:52,540 : worker.worker : DEBUG : Step 127235, finished rewards 36.44, envs finished 1
2026-01-17 13:29:52,577 : worker.worker : DEBUG : Step 127242, finished rewards -0.51, envs finished 1
2026-01-17 13:29:52,598 : worker.worker : DEBUG : Step 127244, finished rewards 23.20, envs finished 1
2026-01-17 13:29:52,647 : worker.worker : DEBUG : Step 127253, finished rewards -2.02, envs finished 1
2026-01-17 13:29:52,677 : worker.worker : DEBUG : Step 127259, finished rewards -3.87, envs finished 1
2026-01-17 13:29:52,768 : agent.on_policy : DEBUG : Mean Losses: [11.80510875582695]
2026-01-17 13:29:52,868 : worker.worker : DEBUG : Step 127275, finished rewards -38.30, envs finished 1
2026-01-17 13:29:52,890 : worker.worker : DEBUG : Step 127276, finished rewards -14.41, envs finished 1
2026-01-17 13:29:53,078 : worker.worker : DEBUG : Step 127294, finished rewards 4.16, envs finished 1
2026-01-17 13:29:53,229 : agent.on_policy : DEBUG : Mean Losses: [6.026064328849316]
2026-01-17 13:29:53,300 : worker.worker : DEBUG : Step 127312, finished rewards 35.74, envs finished 1
2026-01-17 13:29:53,341 : worker.worker : DEBUG : Step 127320, finished rewards 36.18, envs finished 1
2026-01-17 13:29:53,405 : worker.worker : DEBUG : Step 127327, finished rewards 37.70, envs finished 1
2026-01-17 13:29:53,556 : agent.on_policy : DEBUG : Mean Losses: [8.78569883480668]
2026-01-17 13:29:53,590 : worker.worker : DEBUG : Step 127335, finished rewards 36.53, envs finished 1
2026-01-17 13:29:53,649 : worker.worker : DEBUG : Step 127350, finished rewards 13.19, envs finished 1
2026-01-17 13:29:53,784 : agent.on_policy : DEBUG : Mean Losses: [4.36000803206116]
2026-01-17 13:29:54,027 : agent.on_policy : DEBUG : Mean Losses: [3.392390191555023]
2026-01-17 13:29:54,038 : worker.worker : DEBUG : Step 127395, finished rewards 16.99, envs finished 1
2026-01-17 13:29:54,044 : worker.worker : DEBUG : Step 127396, finished rewards 6.35, envs finished 1
2026-01-17 13:29:54,183 : agent.on_policy : DEBUG : Mean Losses: [5.494692042469978]
2026-01-17 13:29:54,284 : worker.worker : DEBUG : Step 127438, finished rewards 6.43, envs finished 1
2026-01-17 13:29:54,479 : worker.worker : DEBUG : Step 127455, finished rewards -7.74, envs finished 1
2026-01-17 13:29:54,585 : agent.on_policy : DEBUG : Mean Losses: [7.147911250591278]
2026-01-17 13:29:54,606 : worker.worker : DEBUG : Step 127461, finished rewards -38.75, envs finished 1
2026-01-17 13:29:54,624 : worker.worker : DEBUG : Step 127464, finished rewards -0.22, envs finished 1
2026-01-17 13:29:54,734 : worker.worker : DEBUG : Step 127480, finished rewards 29.54, envs finished 1
2026-01-17 13:29:54,862 : agent.on_policy : DEBUG : Mean Losses: [8.596615418791771]
2026-01-17 13:29:54,865 : worker.worker : DEBUG : Step 127488, finished rewards 25.06, envs finished 1
2026-01-17 13:29:54,966 : worker.worker : DEBUG : Step 127504, finished rewards -15.36, envs finished 1
2026-01-17 13:29:54,985 : worker.worker : DEBUG : Step 127509, finished rewards -41.16, envs finished 1
2026-01-17 13:29:55,112 : agent.on_policy : DEBUG : Mean Losses: [5.154587375000119]
2026-01-17 13:29:55,311 : agent.on_policy : DEBUG : Mean Losses: [2.97862352989614]
2026-01-17 13:29:55,316 : worker.worker : DEBUG : Step 127553, finished rewards 25.02, envs finished 1
2026-01-17 13:29:55,377 : worker.worker : DEBUG : Step 127571, finished rewards 26.55, envs finished 1
2026-01-17 13:29:55,389 : worker.worker : DEBUG : Step 127574, finished rewards -9.87, envs finished 1
2026-01-17 13:29:55,529 : agent.on_policy : DEBUG : Mean Losses: [6.607859030365944]
2026-01-17 13:29:55,555 : worker.worker : DEBUG : Step 127590, finished rewards 4.29, envs finished 2
2026-01-17 13:29:55,599 : worker.worker : DEBUG : Step 127599, finished rewards 26.84, envs finished 1
2026-01-17 13:29:55,792 : agent.on_policy : DEBUG : Mean Losses: [5.407640021294355]
2026-01-17 13:29:55,893 : worker.worker : DEBUG : Step 127643, finished rewards 26.84, envs finished 1
2026-01-17 13:29:55,907 : worker.worker : DEBUG : Step 127647, finished rewards 36.72, envs finished 1
2026-01-17 13:29:56,030 : agent.on_policy : DEBUG : Mean Losses: [7.425573013722897]
2026-01-17 13:29:56,071 : worker.worker : DEBUG : Step 127655, finished rewards -14.57, envs finished 1
2026-01-17 13:29:56,134 : worker.worker : DEBUG : Step 127663, finished rewards 27.98, envs finished 1
2026-01-17 13:29:56,170 : worker.worker : DEBUG : Step 127669, finished rewards -26.11, envs finished 1
2026-01-17 13:29:56,198 : worker.worker : DEBUG : Step 127676, finished rewards 35.98, envs finished 1
2026-01-17 13:29:56,309 : agent.on_policy : DEBUG : Mean Losses: [10.054938063025475]
2026-01-17 13:29:56,447 : worker.worker : DEBUG : Step 127701, finished rewards 16.12, envs finished 1
2026-01-17 13:29:56,541 : agent.on_policy : DEBUG : Mean Losses: [2.2064974093809724]
2026-01-17 13:29:56,577 : worker.worker : DEBUG : Step 127721, finished rewards -4.44, envs finished 1
2026-01-17 13:29:56,693 : worker.worker : DEBUG : Step 127739, finished rewards 21.55, envs finished 1
2026-01-17 13:29:56,830 : agent.on_policy : DEBUG : Mean Losses: [6.447260178625584]
2026-01-17 13:29:56,842 : worker.worker : DEBUG : Step 127746, finished rewards 30.75, envs finished 1
2026-01-17 13:29:56,849 : worker.worker : DEBUG : Step 127747, finished rewards 24.14, envs finished 1
2026-01-17 13:29:56,922 : worker.worker : DEBUG : Step 127764, finished rewards 7.99, envs finished 1
2026-01-17 13:29:56,965 : worker.worker : DEBUG : Step 127775, finished rewards 18.71, envs finished 1
2026-01-17 13:29:57,080 : agent.on_policy : DEBUG : Mean Losses: [5.59123270213604]
2026-01-17 13:29:57,131 : worker.worker : DEBUG : Step 127782, finished rewards 8.11, envs finished 1
2026-01-17 13:29:57,284 : worker.worker : DEBUG : Step 127804, finished rewards 30.87, envs finished 1
2026-01-17 13:29:57,354 : agent.on_policy : DEBUG : Mean Losses: [4.846953427419066]
2026-01-17 13:29:57,564 : agent.on_policy : DEBUG : Mean Losses: [2.9031724482774734]
2026-01-17 13:29:57,590 : worker.worker : DEBUG : Step 127849, finished rewards 10.85, envs finished 1
2026-01-17 13:29:57,621 : worker.worker : DEBUG : Step 127856, finished rewards 24.05, envs finished 1
2026-01-17 13:29:57,666 : worker.worker : DEBUG : Step 127867, finished rewards 3.47, envs finished 1
2026-01-17 13:29:57,671 : worker.worker : DEBUG : Step 127868, finished rewards -31.78, envs finished 1
2026-01-17 13:29:57,737 : agent.on_policy : DEBUG : Mean Losses: [8.886967241764069]
2026-01-17 13:29:57,742 : worker.worker : DEBUG : Step 127872, finished rewards 3.70, envs finished 1
2026-01-17 13:29:57,767 : worker.worker : DEBUG : Step 127877, finished rewards 15.79, envs finished 1
2026-01-17 13:29:57,879 : worker.worker : DEBUG : Step 127893, finished rewards 26.67, envs finished 1
2026-01-17 13:29:58,052 : agent.on_policy : DEBUG : Mean Losses: [5.069805510342121]
2026-01-17 13:29:58,057 : worker.worker : DEBUG : Step 127905, finished rewards 0.38, envs finished 1
2026-01-17 13:29:58,181 : worker.worker : DEBUG : Step 127924, finished rewards 37.97, envs finished 1
2026-01-17 13:29:58,331 : agent.on_policy : DEBUG : Mean Losses: [3.513033950701356]
2026-01-17 13:29:58,425 : worker.worker : DEBUG : Step 127966, finished rewards 22.86, envs finished 1
2026-01-17 13:29:58,531 : agent.on_policy : DEBUG : Mean Losses: [4.239980131387711]
2026-01-17 13:29:58,584 : worker.worker : DEBUG : Step 127978, finished rewards 12.36, envs finished 1
2026-01-17 13:29:58,654 : worker.worker : DEBUG : Step 127985, finished rewards 0.47, envs finished 1
2026-01-17 13:29:58,718 : worker.worker : DEBUG : Step 127992, finished rewards 19.49, envs finished 1
2026-01-17 13:29:58,775 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:29:58,970 : agent.on_policy : DEBUG : Mean Losses: [6.616978093981743]
2026-01-17 13:29:59,001 : worker.worker : DEBUG : Step 128002, finished rewards 4.82, envs finished 1
2026-01-17 13:29:59,048 : worker.worker : DEBUG : Step 128007, finished rewards -6.48, envs finished 1
2026-01-17 13:29:59,067 : worker.worker : DEBUG : Step 128010, finished rewards 29.04, envs finished 1
2026-01-17 13:29:59,177 : worker.worker : DEBUG : Step 128024, finished rewards 4.76, envs finished 1
2026-01-17 13:29:59,305 : agent.on_policy : DEBUG : Mean Losses: [5.764926120638847]
2026-01-17 13:29:59,500 : agent.on_policy : DEBUG : Mean Losses: [1.427341933362186]
2026-01-17 13:29:59,764 : agent.on_policy : DEBUG : Mean Losses: [2.974695011973381]
2026-01-17 13:29:59,841 : worker.worker : DEBUG : Step 128101, finished rewards -5.54, envs finished 1
2026-01-17 13:29:59,918 : worker.worker : DEBUG : Step 128112, finished rewards 8.85, envs finished 1
2026-01-17 13:29:59,968 : worker.worker : DEBUG : Step 128117, finished rewards 3.92, envs finished 1
2026-01-17 13:29:59,993 : worker.worker : DEBUG : Step 128121, finished rewards 8.77, envs finished 1
2026-01-17 13:30:00,115 : agent.on_policy : DEBUG : Mean Losses: [8.516072452068329]
2026-01-17 13:30:00,123 : worker.worker : DEBUG : Step 128129, finished rewards 18.42, envs finished 1
2026-01-17 13:30:00,163 : worker.worker : DEBUG : Step 128136, finished rewards -0.95, envs finished 1
2026-01-17 13:30:00,198 : worker.worker : DEBUG : Step 128142, finished rewards -21.04, envs finished 1
2026-01-17 13:30:00,326 : agent.on_policy : DEBUG : Mean Losses: [4.9070880971848965]
2026-01-17 13:30:00,451 : worker.worker : DEBUG : Step 128171, finished rewards 42.60, envs finished 1
2026-01-17 13:30:00,578 : worker.worker : DEBUG : Step 128187, finished rewards 42.51, envs finished 1
2026-01-17 13:30:00,704 : agent.on_policy : DEBUG : Mean Losses: [5.889431070536375]
2026-01-17 13:30:00,707 : worker.worker : DEBUG : Step 128192, finished rewards -59.70, envs finished 1
2026-01-17 13:30:00,840 : worker.worker : DEBUG : Step 128211, finished rewards 26.65, envs finished 1
2026-01-17 13:30:00,994 : agent.on_policy : DEBUG : Mean Losses: [4.09558629244566]
2026-01-17 13:30:01,008 : worker.worker : DEBUG : Step 128228, finished rewards 19.14, envs finished 1
2026-01-17 13:30:01,062 : worker.worker : DEBUG : Step 128242, finished rewards 14.39, envs finished 1
2026-01-17 13:30:01,181 : agent.on_policy : DEBUG : Mean Losses: [3.9812670671381056]
2026-01-17 13:30:01,210 : worker.worker : DEBUG : Step 128259, finished rewards -3.19, envs finished 2
2026-01-17 13:30:01,216 : worker.worker : DEBUG : Step 128260, finished rewards 39.00, envs finished 1
2026-01-17 13:30:01,235 : worker.worker : DEBUG : Step 128263, finished rewards 24.04, envs finished 1
2026-01-17 13:30:01,257 : worker.worker : DEBUG : Step 128268, finished rewards 36.75, envs finished 1
2026-01-17 13:30:01,384 : agent.on_policy : DEBUG : Mean Losses: [6.643267374485731]
2026-01-17 13:30:01,453 : worker.worker : DEBUG : Step 128295, finished rewards 30.26, envs finished 1
2026-01-17 13:30:01,638 : agent.on_policy : DEBUG : Mean Losses: [2.861106812953949]
2026-01-17 13:30:01,836 : agent.on_policy : DEBUG : Mean Losses: [2.4600150734186172]
2026-01-17 13:30:01,874 : worker.worker : DEBUG : Step 128362, finished rewards 16.77, envs finished 2
2026-01-17 13:30:01,923 : worker.worker : DEBUG : Step 128373, finished rewards -16.30, envs finished 1
2026-01-17 13:30:01,933 : worker.worker : DEBUG : Step 128375, finished rewards 14.11, envs finished 1
2026-01-17 13:30:01,941 : worker.worker : DEBUG : Step 128376, finished rewards 9.64, envs finished 1
2026-01-17 13:30:02,026 : agent.on_policy : DEBUG : Mean Losses: [10.123976975679398]
2026-01-17 13:30:02,049 : worker.worker : DEBUG : Step 128390, finished rewards 2.87, envs finished 1
2026-01-17 13:30:02,139 : worker.worker : DEBUG : Step 128402, finished rewards -15.42, envs finished 1
2026-01-17 13:30:02,295 : agent.on_policy : DEBUG : Mean Losses: [3.7466802708804607]
2026-01-17 13:30:02,323 : worker.worker : DEBUG : Step 128423, finished rewards 0.93, envs finished 1
2026-01-17 13:30:02,482 : worker.worker : DEBUG : Step 128439, finished rewards 36.06, envs finished 1
2026-01-17 13:30:02,718 : agent.on_policy : DEBUG : Mean Losses: [4.355761058628559]
2026-01-17 13:30:02,796 : worker.worker : DEBUG : Step 128465, finished rewards 20.66, envs finished 2
2026-01-17 13:30:03,028 : agent.on_policy : DEBUG : Mean Losses: [5.510891031473875]
2026-01-17 13:30:03,171 : worker.worker : DEBUG : Step 128495, finished rewards 23.21, envs finished 1
2026-01-17 13:30:03,254 : worker.worker : DEBUG : Step 128503, finished rewards 8.78, envs finished 1
2026-01-17 13:30:03,436 : agent.on_policy : DEBUG : Mean Losses: [7.562710819765925]
2026-01-17 13:30:03,519 : worker.worker : DEBUG : Step 128520, finished rewards 32.49, envs finished 1
2026-01-17 13:30:03,559 : worker.worker : DEBUG : Step 128526, finished rewards -15.11, envs finished 1
2026-01-17 13:30:02,899 : worker.worker : DEBUG : Step 128536, finished rewards -20.28, envs finished 1
2026-01-17 13:30:03,092 : agent.on_policy : DEBUG : Mean Losses: [6.820435158908367]
2026-01-17 13:30:03,238 : worker.worker : DEBUG : Step 128573, finished rewards 14.22, envs finished 1
2026-01-17 13:30:03,345 : agent.on_policy : DEBUG : Mean Losses: [3.4769674204289913]
2026-01-17 13:30:03,447 : worker.worker : DEBUG : Step 128594, finished rewards 20.62, envs finished 1
2026-01-17 13:30:03,465 : worker.worker : DEBUG : Step 128597, finished rewards -3.35, envs finished 1
2026-01-17 13:30:03,487 : worker.worker : DEBUG : Step 128601, finished rewards 31.35, envs finished 1
2026-01-17 13:30:03,626 : agent.on_policy : DEBUG : Mean Losses: [9.094453305006027]
2026-01-17 13:30:03,659 : worker.worker : DEBUG : Step 128611, finished rewards -42.36, envs finished 1
2026-01-17 13:30:03,702 : worker.worker : DEBUG : Step 128617, finished rewards 24.76, envs finished 1
2026-01-17 13:30:03,741 : worker.worker : DEBUG : Step 128626, finished rewards 26.72, envs finished 1
2026-01-17 13:30:03,833 : agent.on_policy : DEBUG : Mean Losses: [6.169812880456448]
2026-01-17 13:30:03,873 : worker.worker : DEBUG : Step 128650, finished rewards -15.24, envs finished 1
2026-01-17 13:30:04,054 : agent.on_policy : DEBUG : Mean Losses: [3.810177117586136]
2026-01-17 13:30:04,063 : worker.worker : DEBUG : Step 128674, finished rewards 37.24, envs finished 1
2026-01-17 13:30:04,101 : worker.worker : DEBUG : Step 128685, finished rewards 9.40, envs finished 1
2026-01-17 13:30:04,145 : worker.worker : DEBUG : Step 128695, finished rewards 41.97, envs finished 1
2026-01-17 13:30:04,220 : agent.on_policy : DEBUG : Mean Losses: [7.843526130542159]
2026-01-17 13:30:04,225 : worker.worker : DEBUG : Step 128704, finished rewards 18.45, envs finished 1
2026-01-17 13:30:04,270 : worker.worker : DEBUG : Step 128715, finished rewards 21.31, envs finished 1
2026-01-17 13:30:04,366 : worker.worker : DEBUG : Step 128727, finished rewards -4.68, envs finished 1
2026-01-17 13:30:04,497 : agent.on_policy : DEBUG : Mean Losses: [4.417034849524498]
2026-01-17 13:30:04,552 : worker.worker : DEBUG : Step 128742, finished rewards 24.34, envs finished 1
2026-01-17 13:30:04,762 : agent.on_policy : DEBUG : Mean Losses: [3.025954019278288]
2026-01-17 13:30:04,805 : worker.worker : DEBUG : Step 128782, finished rewards 14.83, envs finished 1
2026-01-17 13:30:04,846 : worker.worker : DEBUG : Step 128793, finished rewards 9.80, envs finished 1
2026-01-17 13:30:04,938 : agent.on_policy : DEBUG : Mean Losses: [6.16550836712122]
2026-01-17 13:30:05,079 : worker.worker : DEBUG : Step 128820, finished rewards 7.76, envs finished 1
2026-01-17 13:30:05,089 : worker.worker : DEBUG : Step 128821, finished rewards 1.84, envs finished 1
2026-01-17 13:30:05,122 : worker.worker : DEBUG : Step 128823, finished rewards 10.12, envs finished 1
2026-01-17 13:30:05,225 : agent.on_policy : DEBUG : Mean Losses: [8.268128618597984]
2026-01-17 13:30:05,437 : agent.on_policy : DEBUG : Mean Losses: [2.433682484552264]
2026-01-17 13:30:05,465 : worker.worker : DEBUG : Step 128872, finished rewards 24.57, envs finished 1
2026-01-17 13:30:05,505 : worker.worker : DEBUG : Step 128883, finished rewards 26.80, envs finished 1
2026-01-17 13:30:05,550 : worker.worker : DEBUG : Step 128895, finished rewards -9.60, envs finished 1
2026-01-17 13:30:05,607 : agent.on_policy : DEBUG : Mean Losses: [6.517427906394005]
2026-01-17 13:30:05,632 : worker.worker : DEBUG : Step 128901, finished rewards -101.46, envs finished 1
2026-01-17 13:30:05,657 : worker.worker : DEBUG : Step 128907, finished rewards -41.64, envs finished 1
2026-01-17 13:30:05,681 : worker.worker : DEBUG : Step 128912, finished rewards 26.02, envs finished 1
2026-01-17 13:30:05,840 : agent.on_policy : DEBUG : Mean Losses: [5.125612698495388]
2026-01-17 13:30:05,902 : worker.worker : DEBUG : Step 128947, finished rewards -1.10, envs finished 1
2026-01-17 13:30:05,927 : worker.worker : DEBUG : Step 128953, finished rewards 4.57, envs finished 1
2026-01-17 13:30:06,059 : agent.on_policy : DEBUG : Mean Losses: [3.9340606592595577]
2026-01-17 13:30:06,081 : worker.worker : DEBUG : Step 128963, finished rewards 42.38, envs finished 1
2026-01-17 13:30:06,173 : worker.worker : DEBUG : Step 128975, finished rewards 16.86, envs finished 1
2026-01-17 13:30:06,193 : worker.worker : DEBUG : Step 128979, finished rewards 21.47, envs finished 1
2026-01-17 13:30:06,357 : agent.on_policy : DEBUG : Mean Losses: [6.038419164717197]
2026-01-17 13:30:06,373 : worker.worker : DEBUG : Step 128996, finished rewards 28.23, envs finished 1
2026-01-17 13:30:06,382 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:30:06,511 : agent.on_policy : DEBUG : Mean Losses: [2.945449534803629]
2026-01-17 13:30:06,597 : worker.worker : DEBUG : Step 129036, finished rewards 6.73, envs finished 1
2026-01-17 13:30:06,625 : worker.worker : DEBUG : Step 129042, finished rewards 23.05, envs finished 1
2026-01-17 13:30:06,642 : worker.worker : DEBUG : Step 129045, finished rewards 24.88, envs finished 1
2026-01-17 13:30:06,656 : worker.worker : DEBUG : Step 129046, finished rewards -12.69, envs finished 1
2026-01-17 13:30:06,851 : agent.on_policy : DEBUG : Mean Losses: [8.104345381259918]
2026-01-17 13:30:07,155 : agent.on_policy : DEBUG : Mean Losses: [3.0328595526516438]
2026-01-17 13:30:07,213 : worker.worker : DEBUG : Step 129097, finished rewards -5.67, envs finished 1
2026-01-17 13:30:07,266 : worker.worker : DEBUG : Step 129108, finished rewards -5.43, envs finished 1
2026-01-17 13:30:07,284 : worker.worker : DEBUG : Step 129110, finished rewards -4.92, envs finished 1
2026-01-17 13:30:07,547 : agent.on_policy : DEBUG : Mean Losses: [6.5482455641031265]
2026-01-17 13:30:07,675 : worker.worker : DEBUG : Step 129136, finished rewards 25.45, envs finished 1
2026-01-17 13:30:07,732 : worker.worker : DEBUG : Step 129140, finished rewards -10.06, envs finished 1
2026-01-17 13:30:07,882 : agent.on_policy : DEBUG : Mean Losses: [4.695244433358312]
2026-01-17 13:30:07,935 : worker.worker : DEBUG : Step 129161, finished rewards 6.02, envs finished 1
2026-01-17 13:30:07,943 : worker.worker : DEBUG : Step 129162, finished rewards -3.03, envs finished 1
2026-01-17 13:30:07,955 : worker.worker : DEBUG : Step 129164, finished rewards 3.94, envs finished 1
2026-01-17 13:30:08,132 : agent.on_policy : DEBUG : Mean Losses: [4.629378207027912]
2026-01-17 13:30:08,170 : worker.worker : DEBUG : Step 129195, finished rewards 28.51, envs finished 1
2026-01-17 13:30:08,176 : worker.worker : DEBUG : Step 129196, finished rewards 24.14, envs finished 2
2026-01-17 13:30:08,289 : agent.on_policy : DEBUG : Mean Losses: [5.676273863762617]
2026-01-17 13:30:08,295 : worker.worker : DEBUG : Step 129217, finished rewards 36.01, envs finished 1
2026-01-17 13:30:08,445 : worker.worker : DEBUG : Step 129241, finished rewards 35.97, envs finished 1
2026-01-17 13:30:08,515 : agent.on_policy : DEBUG : Mean Losses: [5.7280821949243546]
2026-01-17 13:30:08,532 : worker.worker : DEBUG : Step 129251, finished rewards 25.26, envs finished 1
2026-01-17 13:30:08,650 : worker.worker : DEBUG : Step 129272, finished rewards -6.00, envs finished 1
2026-01-17 13:30:08,719 : worker.worker : DEBUG : Step 129279, finished rewards 30.92, envs finished 2
2026-01-17 13:30:08,805 : agent.on_policy : DEBUG : Mean Losses: [9.713867045938969]
2026-01-17 13:30:08,883 : worker.worker : DEBUG : Step 129287, finished rewards 25.36, envs finished 1
2026-01-17 13:30:09,074 : agent.on_policy : DEBUG : Mean Losses: [3.010233713313937]
2026-01-17 13:30:09,081 : worker.worker : DEBUG : Step 129313, finished rewards -20.19, envs finished 1
2026-01-17 13:30:09,423 : agent.on_policy : DEBUG : Mean Losses: [2.654674544930458]
2026-01-17 13:30:09,432 : worker.worker : DEBUG : Step 129345, finished rewards 23.15, envs finished 1
2026-01-17 13:30:09,499 : worker.worker : DEBUG : Step 129356, finished rewards -4.04, envs finished 1
2026-01-17 13:30:09,573 : worker.worker : DEBUG : Step 129368, finished rewards 1.50, envs finished 1
2026-01-17 13:30:09,623 : worker.worker : DEBUG : Step 129371, finished rewards 24.34, envs finished 1
2026-01-17 13:30:09,630 : worker.worker : DEBUG : Step 129372, finished rewards 17.77, envs finished 1
2026-01-17 13:30:09,697 : agent.on_policy : DEBUG : Mean Losses: [9.472862862050533]
2026-01-17 13:30:09,704 : worker.worker : DEBUG : Step 129377, finished rewards 25.90, envs finished 1
2026-01-17 13:30:09,786 : worker.worker : DEBUG : Step 129386, finished rewards 15.18, envs finished 1
2026-01-17 13:30:09,960 : agent.on_policy : DEBUG : Mean Losses: [2.9270084840245545]
2026-01-17 13:30:10,148 : agent.on_policy : DEBUG : Mean Losses: [2.304412379860878]
2026-01-17 13:30:10,173 : worker.worker : DEBUG : Step 129444, finished rewards 19.00, envs finished 1
2026-01-17 13:30:10,201 : worker.worker : DEBUG : Step 129449, finished rewards 23.85, envs finished 1
2026-01-17 13:30:10,349 : agent.on_policy : DEBUG : Mean Losses: [6.0367158353328705]
2026-01-17 13:30:10,397 : worker.worker : DEBUG : Step 129476, finished rewards 20.88, envs finished 1
2026-01-17 13:30:10,418 : worker.worker : DEBUG : Step 129479, finished rewards 11.29, envs finished 1
2026-01-17 13:30:10,446 : worker.worker : DEBUG : Step 129482, finished rewards -25.76, envs finished 1
2026-01-17 13:30:10,463 : worker.worker : DEBUG : Step 129485, finished rewards 20.84, envs finished 1
2026-01-17 13:30:10,480 : worker.worker : DEBUG : Step 129487, finished rewards 6.19, envs finished 1
2026-01-17 13:30:10,502 : worker.worker : DEBUG : Step 129491, finished rewards 4.75, envs finished 1
2026-01-17 13:30:10,599 : agent.on_policy : DEBUG : Mean Losses: [8.583321288228035]
2026-01-17 13:30:10,715 : worker.worker : DEBUG : Step 129527, finished rewards 31.10, envs finished 1
2026-01-17 13:30:10,840 : agent.on_policy : DEBUG : Mean Losses: [3.4746501967310905]
2026-01-17 13:30:10,975 : worker.worker : DEBUG : Step 129555, finished rewards 37.40, envs finished 1
2026-01-17 13:30:11,028 : worker.worker : DEBUG : Step 129559, finished rewards 30.76, envs finished 1
2026-01-17 13:30:11,181 : agent.on_policy : DEBUG : Mean Losses: [6.540124595165253]
2026-01-17 13:30:11,260 : worker.worker : DEBUG : Step 129578, finished rewards 24.97, envs finished 1
2026-01-17 13:30:11,372 : worker.worker : DEBUG : Step 129590, finished rewards -11.15, envs finished 1
2026-01-17 13:30:11,440 : worker.worker : DEBUG : Step 129596, finished rewards 10.32, envs finished 1
2026-01-17 13:30:11,590 : agent.on_policy : DEBUG : Mean Losses: [6.212940983474255]
2026-01-17 13:30:11,668 : worker.worker : DEBUG : Step 129620, finished rewards -10.02, envs finished 1
2026-01-17 13:30:11,688 : worker.worker : DEBUG : Step 129623, finished rewards -4.83, envs finished 1
2026-01-17 13:30:11,858 : agent.on_policy : DEBUG : Mean Losses: [5.077585395425558]
2026-01-17 13:30:12,011 : worker.worker : DEBUG : Step 129658, finished rewards -4.50, envs finished 1
2026-01-17 13:30:12,037 : worker.worker : DEBUG : Step 129662, finished rewards 14.86, envs finished 1
2026-01-17 13:30:12,152 : agent.on_policy : DEBUG : Mean Losses: [3.988123919814825]
2026-01-17 13:30:12,239 : worker.worker : DEBUG : Step 129672, finished rewards 7.41, envs finished 1
2026-01-17 13:30:12,490 : agent.on_policy : DEBUG : Mean Losses: [2.8910242058336735]
2026-01-17 13:30:12,509 : worker.worker : DEBUG : Step 129701, finished rewards 8.84, envs finished 1
2026-01-17 13:30:12,602 : worker.worker : DEBUG : Step 129727, finished rewards -2.74, envs finished 1
2026-01-17 13:30:12,723 : agent.on_policy : DEBUG : Mean Losses: [4.40720244217664]
2026-01-17 13:30:12,767 : worker.worker : DEBUG : Step 129733, finished rewards 36.97, envs finished 1
2026-01-17 13:30:12,869 : worker.worker : DEBUG : Step 129743, finished rewards 5.86, envs finished 1
2026-01-17 13:30:12,921 : worker.worker : DEBUG : Step 129748, finished rewards 36.07, envs finished 1
2026-01-17 13:30:12,993 : worker.worker : DEBUG : Step 129754, finished rewards 22.65, envs finished 1
2026-01-17 13:30:13,145 : agent.on_policy : DEBUG : Mean Losses: [8.984123073518276]
2026-01-17 13:30:13,163 : worker.worker : DEBUG : Step 129762, finished rewards -27.52, envs finished 1
2026-01-17 13:30:13,225 : worker.worker : DEBUG : Step 129767, finished rewards -14.47, envs finished 1
2026-01-17 13:30:13,490 : agent.on_policy : DEBUG : Mean Losses: [2.768492756411433]
2026-01-17 13:30:13,521 : worker.worker : DEBUG : Step 129801, finished rewards 18.10, envs finished 1
2026-01-17 13:30:13,606 : worker.worker : DEBUG : Step 129818, finished rewards 24.94, envs finished 1
2026-01-17 13:30:13,614 : worker.worker : DEBUG : Step 129819, finished rewards 36.54, envs finished 1
2026-01-17 13:30:13,730 : agent.on_policy : DEBUG : Mean Losses: [7.307987213134766]
2026-01-17 13:30:13,763 : worker.worker : DEBUG : Step 129829, finished rewards 22.09, envs finished 1
2026-01-17 13:30:14,000 : agent.on_policy : DEBUG : Mean Losses: [2.790219253860414]
2026-01-17 13:30:14,060 : worker.worker : DEBUG : Step 129867, finished rewards 8.45, envs finished 1
2026-01-17 13:30:14,087 : worker.worker : DEBUG : Step 129871, finished rewards 13.36, envs finished 1
2026-01-17 13:30:14,119 : worker.worker : DEBUG : Step 129876, finished rewards -3.84, envs finished 1
2026-01-17 13:30:14,177 : worker.worker : DEBUG : Step 129881, finished rewards 10.81, envs finished 1
2026-01-17 13:30:14,341 : agent.on_policy : DEBUG : Mean Losses: [6.196078084409237]
2026-01-17 13:30:14,433 : worker.worker : DEBUG : Step 129915, finished rewards 29.02, envs finished 1
2026-01-17 13:30:14,547 : agent.on_policy : DEBUG : Mean Losses: [5.010101765394211]
2026-01-17 13:30:14,570 : worker.worker : DEBUG : Step 129924, finished rewards 0.94, envs finished 1
2026-01-17 13:30:14,761 : worker.worker : DEBUG : Step 129951, finished rewards -3.94, envs finished 1
2026-01-17 13:30:14,818 : agent.on_policy : DEBUG : Mean Losses: [4.8318201676011086]
2026-01-17 13:30:14,875 : worker.worker : DEBUG : Step 129966, finished rewards -14.96, envs finished 1
2026-01-17 13:30:15,055 : agent.on_policy : DEBUG : Mean Losses: [3.624060697853565]
2026-01-17 13:30:15,069 : worker.worker : DEBUG : Step 129988, finished rewards 10.56, envs finished 1
2026-01-17 13:30:15,077 : worker.worker : DEBUG : Step 129990, finished rewards 3.50, envs finished 1
2026-01-17 13:30:15,091 : worker.worker : DEBUG : Step 129992, finished rewards 0.13, envs finished 1
2026-01-17 13:30:15,156 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:30:15,209 : worker.worker : INFO : Step 130000, Avg Reward 9.7656, Max Reward 42.6041, Loss [5.31319389]
2026-01-17 13:30:15,286 : worker.worker : DEBUG : Step 130009, finished rewards -1.46, envs finished 1
2026-01-17 13:30:15,448 : agent.on_policy : DEBUG : Mean Losses: [5.578341793268919]
2026-01-17 13:30:15,475 : worker.worker : DEBUG : Step 130023, finished rewards 13.12, envs finished 1
2026-01-17 13:30:15,628 : agent.on_policy : DEBUG : Mean Losses: [3.6632768381386995]
2026-01-17 13:30:15,729 : worker.worker : DEBUG : Step 130066, finished rewards -9.20, envs finished 1
2026-01-17 13:30:15,742 : worker.worker : DEBUG : Step 130069, finished rewards 6.08, envs finished 1
2026-01-17 13:30:15,750 : worker.worker : DEBUG : Step 130071, finished rewards 14.17, envs finished 1
2026-01-17 13:30:15,883 : agent.on_policy : DEBUG : Mean Losses: [8.420820204541087]
2026-01-17 13:30:15,996 : worker.worker : DEBUG : Step 130101, finished rewards 13.09, envs finished 1
2026-01-17 13:30:16,023 : worker.worker : DEBUG : Step 130107, finished rewards 30.14, envs finished 1
2026-01-17 13:30:16,084 : worker.worker : DEBUG : Step 130111, finished rewards 5.63, envs finished 1
2026-01-17 13:30:16,197 : agent.on_policy : DEBUG : Mean Losses: [6.0754986414685845]
2026-01-17 13:30:16,286 : worker.worker : DEBUG : Step 130124, finished rewards 8.17, envs finished 1
2026-01-17 13:30:16,306 : worker.worker : DEBUG : Step 130128, finished rewards -13.48, envs finished 1
2026-01-17 13:30:16,472 : agent.on_policy : DEBUG : Mean Losses: [4.049025904387236]
2026-01-17 13:30:16,507 : worker.worker : DEBUG : Step 130155, finished rewards 27.53, envs finished 1
2026-01-17 13:30:16,573 : worker.worker : DEBUG : Step 130175, finished rewards 15.45, envs finished 1
2026-01-17 13:30:16,629 : agent.on_policy : DEBUG : Mean Losses: [4.1275110729038715]
2026-01-17 13:30:16,653 : worker.worker : DEBUG : Step 130180, finished rewards 42.11, envs finished 1
2026-01-17 13:30:16,751 : worker.worker : DEBUG : Step 130194, finished rewards 24.51, envs finished 1
2026-01-17 13:30:16,796 : worker.worker : DEBUG : Step 130204, finished rewards -4.89, envs finished 1
2026-01-17 13:30:16,901 : agent.on_policy : DEBUG : Mean Losses: [4.921409476548433]
2026-01-17 13:30:17,075 : worker.worker : DEBUG : Step 130239, finished rewards 30.41, envs finished 1
2026-01-17 13:30:17,177 : agent.on_policy : DEBUG : Mean Losses: [5.288136392831802]
2026-01-17 13:30:17,181 : worker.worker : DEBUG : Step 130241, finished rewards -5.74, envs finished 1
2026-01-17 13:30:17,242 : worker.worker : DEBUG : Step 130250, finished rewards 4.15, envs finished 1
2026-01-17 13:30:17,276 : worker.worker : DEBUG : Step 130253, finished rewards -2.70, envs finished 1
2026-01-17 13:30:17,342 : worker.worker : DEBUG : Step 130264, finished rewards 29.79, envs finished 1
2026-01-17 13:30:17,462 : agent.on_policy : DEBUG : Mean Losses: [6.018311216495931]
2026-01-17 13:30:17,552 : worker.worker : DEBUG : Step 130285, finished rewards 10.16, envs finished 1
2026-01-17 13:30:17,729 : agent.on_policy : DEBUG : Mean Losses: [2.8000722266733646]
2026-01-17 13:30:17,790 : worker.worker : DEBUG : Step 130322, finished rewards 29.74, envs finished 1
2026-01-17 13:30:17,933 : agent.on_policy : DEBUG : Mean Losses: [6.687884993851185]
2026-01-17 13:30:17,934 : worker.worker : DEBUG : Step 130336, finished rewards -8.40, envs finished 1
2026-01-17 13:30:17,956 : worker.worker : DEBUG : Step 130339, finished rewards -8.33, envs finished 1
2026-01-17 13:30:17,965 : worker.worker : DEBUG : Step 130340, finished rewards 26.55, envs finished 1
2026-01-17 13:30:18,200 : agent.on_policy : DEBUG : Mean Losses: [5.126945752650499]
2026-01-17 13:30:18,249 : worker.worker : DEBUG : Step 130380, finished rewards -5.28, envs finished 1
2026-01-17 13:30:18,367 : agent.on_policy : DEBUG : Mean Losses: [4.680952601134777]
2026-01-17 13:30:18,496 : worker.worker : DEBUG : Step 130422, finished rewards -28.67, envs finished 1
2026-01-17 13:30:18,521 : worker.worker : DEBUG : Step 130425, finished rewards -8.73, envs finished 1
2026-01-17 13:30:18,656 : agent.on_policy : DEBUG : Mean Losses: [6.523340597748756]
2026-01-17 13:30:18,666 : worker.worker : DEBUG : Step 130434, finished rewards 22.64, envs finished 1
2026-01-17 13:30:18,715 : worker.worker : DEBUG : Step 130438, finished rewards -21.10, envs finished 1
2026-01-17 13:30:18,912 : agent.on_policy : DEBUG : Mean Losses: [3.736396424472332]
2026-01-17 13:30:18,978 : worker.worker : DEBUG : Step 130471, finished rewards -3.15, envs finished 1
2026-01-17 13:30:19,043 : worker.worker : DEBUG : Step 130475, finished rewards -18.85, envs finished 1
2026-01-17 13:30:19,079 : worker.worker : DEBUG : Step 130480, finished rewards -5.88, envs finished 1
2026-01-17 13:30:19,261 : agent.on_policy : DEBUG : Mean Losses: [5.014385342597961]
2026-01-17 13:30:19,292 : worker.worker : DEBUG : Step 130504, finished rewards -0.23, envs finished 1
2026-01-17 13:30:19,377 : worker.worker : DEBUG : Step 130521, finished rewards 21.18, envs finished 1
2026-01-17 13:30:19,632 : agent.on_policy : DEBUG : Mean Losses: [5.461587257683277]
2026-01-17 13:30:19,704 : worker.worker : DEBUG : Step 130541, finished rewards 24.88, envs finished 1
2026-01-17 13:30:19,709 : worker.worker : DEBUG : Step 130542, finished rewards 41.49, envs finished 1
2026-01-17 13:30:19,717 : worker.worker : DEBUG : Step 130544, finished rewards 11.42, envs finished 1
2026-01-17 13:30:19,869 : agent.on_policy : DEBUG : Mean Losses: [6.269647689536214]
2026-01-17 13:30:19,889 : worker.worker : DEBUG : Step 130564, finished rewards 31.36, envs finished 1
2026-01-17 13:30:19,943 : worker.worker : DEBUG : Step 130568, finished rewards 23.97, envs finished 1
2026-01-17 13:30:19,999 : worker.worker : DEBUG : Step 130580, finished rewards -25.39, envs finished 1
2026-01-17 13:30:20,147 : agent.on_policy : DEBUG : Mean Losses: [4.765387292951345]
2026-01-17 13:30:20,148 : worker.worker : DEBUG : Step 130592, finished rewards 27.51, envs finished 1
2026-01-17 13:30:20,198 : worker.worker : DEBUG : Step 130605, finished rewards 31.35, envs finished 1
2026-01-17 13:30:20,305 : agent.on_policy : DEBUG : Mean Losses: [3.2129037491977215]
2026-01-17 13:30:20,428 : worker.worker : DEBUG : Step 130645, finished rewards 36.02, envs finished 1
2026-01-17 13:30:20,441 : worker.worker : DEBUG : Step 130647, finished rewards 14.44, envs finished 1
2026-01-17 13:30:20,481 : worker.worker : DEBUG : Step 130650, finished rewards 12.22, envs finished 1
2026-01-17 13:30:20,571 : agent.on_policy : DEBUG : Mean Losses: [9.69852165877819]
2026-01-17 13:30:20,599 : worker.worker : DEBUG : Step 130663, finished rewards 3.30, envs finished 1
2026-01-17 13:30:20,685 : worker.worker : DEBUG : Step 130673, finished rewards 11.82, envs finished 1
2026-01-17 13:30:20,887 : agent.on_policy : DEBUG : Mean Losses: [3.3690568320453167]
2026-01-17 13:30:20,951 : worker.worker : DEBUG : Step 130695, finished rewards 7.57, envs finished 1
2026-01-17 13:30:21,002 : worker.worker : DEBUG : Step 130706, finished rewards 9.53, envs finished 1
2026-01-17 13:30:21,036 : worker.worker : DEBUG : Step 130713, finished rewards 13.10, envs finished 1
2026-01-17 13:30:21,153 : agent.on_policy : DEBUG : Mean Losses: [4.46868846192956]
2026-01-17 13:30:21,250 : worker.worker : DEBUG : Step 130732, finished rewards 31.61, envs finished 1
2026-01-17 13:30:21,276 : worker.worker : DEBUG : Step 130736, finished rewards 25.10, envs finished 1
2026-01-17 13:30:21,368 : worker.worker : DEBUG : Step 130745, finished rewards 20.84, envs finished 1
2026-01-17 13:30:21,587 : agent.on_policy : DEBUG : Mean Losses: [6.5475416444242]
2026-01-17 13:30:21,600 : worker.worker : DEBUG : Step 130755, finished rewards 24.28, envs finished 1
2026-01-17 13:30:21,644 : worker.worker : DEBUG : Step 130764, finished rewards 42.03, envs finished 1
2026-01-17 13:30:21,678 : worker.worker : DEBUG : Step 130772, finished rewards 18.83, envs finished 1
2026-01-17 13:30:21,807 : agent.on_policy : DEBUG : Mean Losses: [4.941604255698621]
2026-01-17 13:30:22,006 : agent.on_policy : DEBUG : Mean Losses: [3.133062494918704]
2026-01-17 13:30:22,008 : worker.worker : DEBUG : Step 130816, finished rewards 16.59, envs finished 1
2026-01-17 13:30:22,048 : worker.worker : DEBUG : Step 130828, finished rewards 0.63, envs finished 1
2026-01-17 13:30:22,081 : worker.worker : DEBUG : Step 130836, finished rewards 19.49, envs finished 1
2026-01-17 13:30:22,088 : worker.worker : DEBUG : Step 130838, finished rewards 23.57, envs finished 1
2026-01-17 13:30:22,182 : agent.on_policy : DEBUG : Mean Losses: [7.4586707800626755]
2026-01-17 13:30:22,192 : worker.worker : DEBUG : Step 130850, finished rewards 22.88, envs finished 1
2026-01-17 13:30:22,305 : worker.worker : DEBUG : Step 130865, finished rewards 25.34, envs finished 1
2026-01-17 13:30:22,375 : worker.worker : DEBUG : Step 130873, finished rewards -6.98, envs finished 1
2026-01-17 13:30:22,577 : agent.on_policy : DEBUG : Mean Losses: [5.080586196854711]
2026-01-17 13:30:22,610 : worker.worker : DEBUG : Step 130885, finished rewards 4.48, envs finished 1
2026-01-17 13:30:22,856 : agent.on_policy : DEBUG : Mean Losses: [2.0466917902231216]
2026-01-17 13:30:22,965 : worker.worker : DEBUG : Step 130935, finished rewards 15.17, envs finished 1
2026-01-17 13:30:22,973 : worker.worker : DEBUG : Step 130936, finished rewards 10.63, envs finished 1
2026-01-17 13:30:23,151 : agent.on_policy : DEBUG : Mean Losses: [4.533646412193775]
2026-01-17 13:30:23,257 : worker.worker : DEBUG : Step 130964, finished rewards -2.04, envs finished 1
2026-01-17 13:30:23,539 : agent.on_policy : DEBUG : Mean Losses: [5.370778799057007]
2026-01-17 13:30:23,556 : worker.worker : DEBUG : Step 130977, finished rewards 13.30, envs finished 1
2026-01-17 13:30:23,567 : worker.worker : DEBUG : Step 130978, finished rewards -7.52, envs finished 1
2026-01-17 13:30:23,640 : worker.worker : DEBUG : Step 130987, finished rewards -0.35, envs finished 1
2026-01-17 13:30:23,707 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:30:23,847 : agent.on_policy : DEBUG : Mean Losses: [4.112981807440519]
2026-01-17 13:30:23,879 : worker.worker : DEBUG : Step 131011, finished rewards -1.71, envs finished 1
2026-01-17 13:30:24,082 : worker.worker : DEBUG : Step 131038, finished rewards -33.47, envs finished 1
2026-01-17 13:30:24,157 : agent.on_policy : DEBUG : Mean Losses: [3.6474869176745415]
2026-01-17 13:30:24,219 : worker.worker : DEBUG : Step 131056, finished rewards 23.18, envs finished 1
2026-01-17 13:30:24,265 : worker.worker : DEBUG : Step 131060, finished rewards -0.42, envs finished 1
2026-01-17 13:30:24,303 : worker.worker : DEBUG : Step 131065, finished rewards 3.53, envs finished 1
2026-01-17 13:30:24,388 : worker.worker : DEBUG : Step 131070, finished rewards 25.33, envs finished 1
2026-01-17 13:30:24,525 : agent.on_policy : DEBUG : Mean Losses: [8.213187716901302]
2026-01-17 13:30:24,774 : agent.on_policy : DEBUG : Mean Losses: [2.3363048266619444]
2026-01-17 13:30:24,785 : worker.worker : DEBUG : Step 131106, finished rewards 4.48, envs finished 1
2026-01-17 13:30:24,863 : worker.worker : DEBUG : Step 131124, finished rewards 28.63, envs finished 1
2026-01-17 13:30:25,034 : agent.on_policy : DEBUG : Mean Losses: [5.61921563744545]
2026-01-17 13:30:25,058 : worker.worker : DEBUG : Step 131142, finished rewards 2.61, envs finished 1
2026-01-17 13:30:25,102 : worker.worker : DEBUG : Step 131146, finished rewards 36.74, envs finished 1
2026-01-17 13:30:25,348 : agent.on_policy : DEBUG : Mean Losses: [5.305286541581154]
2026-01-17 13:30:25,378 : worker.worker : DEBUG : Step 131174, finished rewards 3.18, envs finished 1
2026-01-17 13:30:25,436 : worker.worker : DEBUG : Step 131186, finished rewards 0.19, envs finished 1
2026-01-17 13:30:25,448 : worker.worker : DEBUG : Step 131188, finished rewards -3.88, envs finished 1
2026-01-17 13:30:25,622 : agent.on_policy : DEBUG : Mean Losses: [5.871264733374119]
2026-01-17 13:30:25,623 : worker.worker : DEBUG : Step 131200, finished rewards -58.76, envs finished 1
2026-01-17 13:30:25,725 : worker.worker : DEBUG : Step 131221, finished rewards 11.24, envs finished 1
2026-01-17 13:30:25,754 : worker.worker : DEBUG : Step 131226, finished rewards 29.90, envs finished 1
2026-01-17 13:30:25,936 : agent.on_policy : DEBUG : Mean Losses: [5.9910667054355145]
2026-01-17 13:30:26,021 : worker.worker : DEBUG : Step 131247, finished rewards 8.99, envs finished 2
2026-01-17 13:30:26,117 : worker.worker : DEBUG : Step 131263, finished rewards 36.93, envs finished 1
2026-01-17 13:30:26,268 : agent.on_policy : DEBUG : Mean Losses: [6.9458693861961365]
2026-01-17 13:30:26,387 : worker.worker : DEBUG : Step 131283, finished rewards 12.22, envs finished 1
2026-01-17 13:30:26,553 : agent.on_policy : DEBUG : Mean Losses: [2.816064529120922]
2026-01-17 13:30:26,683 : worker.worker : DEBUG : Step 131324, finished rewards 19.70, envs finished 1
2026-01-17 13:30:26,689 : worker.worker : DEBUG : Step 131325, finished rewards 15.27, envs finished 1
2026-01-17 13:30:26,800 : agent.on_policy : DEBUG : Mean Losses: [6.742270432412624]
2026-01-17 13:30:26,837 : worker.worker : DEBUG : Step 131338, finished rewards 25.27, envs finished 1
2026-01-17 13:30:26,901 : worker.worker : DEBUG : Step 131347, finished rewards -25.04, envs finished 1
2026-01-17 13:30:27,044 : agent.on_policy : DEBUG : Mean Losses: [5.958551935851574]
2026-01-17 13:30:27,107 : worker.worker : DEBUG : Step 131376, finished rewards 23.50, envs finished 1
2026-01-17 13:30:27,131 : worker.worker : DEBUG : Step 131382, finished rewards -33.17, envs finished 1
2026-01-17 13:30:27,345 : agent.on_policy : DEBUG : Mean Losses: [5.248026167973876]
2026-01-17 13:30:27,380 : worker.worker : DEBUG : Step 131394, finished rewards -1.80, envs finished 1
2026-01-17 13:30:27,397 : worker.worker : DEBUG : Step 131396, finished rewards -16.49, envs finished 1
2026-01-17 13:30:27,465 : worker.worker : DEBUG : Step 131408, finished rewards 30.36, envs finished 1
2026-01-17 13:30:27,499 : worker.worker : DEBUG : Step 131417, finished rewards 24.38, envs finished 1
2026-01-17 13:30:27,652 : agent.on_policy : DEBUG : Mean Losses: [6.110896177589893]
2026-01-17 13:30:27,712 : worker.worker : DEBUG : Step 131440, finished rewards 21.08, envs finished 2
2026-01-17 13:30:27,863 : agent.on_policy : DEBUG : Mean Losses: [4.119263797998428]
2026-01-17 13:30:27,907 : worker.worker : DEBUG : Step 131467, finished rewards 25.34, envs finished 1
2026-01-17 13:30:27,988 : worker.worker : DEBUG : Step 131487, finished rewards 24.73, envs finished 1
2026-01-17 13:30:28,055 : agent.on_policy : DEBUG : Mean Losses: [5.168203264474869]
2026-01-17 13:30:28,302 : worker.worker : DEBUG : Step 131516, finished rewards 0.90, envs finished 1
2026-01-17 13:30:28,394 : agent.on_policy : DEBUG : Mean Losses: [3.8428817950189114]
2026-01-17 13:30:28,416 : worker.worker : DEBUG : Step 131525, finished rewards -12.87, envs finished 1
2026-01-17 13:30:28,505 : worker.worker : DEBUG : Step 131535, finished rewards 8.67, envs finished 1
2026-01-17 13:30:28,518 : worker.worker : DEBUG : Step 131537, finished rewards 21.23, envs finished 1
2026-01-17 13:30:28,687 : agent.on_policy : DEBUG : Mean Losses: [5.602457359433174]
2026-01-17 13:30:28,737 : worker.worker : DEBUG : Step 131566, finished rewards 20.96, envs finished 1
2026-01-17 13:30:28,756 : worker.worker : DEBUG : Step 131571, finished rewards 0.42, envs finished 1
2026-01-17 13:30:28,786 : worker.worker : DEBUG : Step 131575, finished rewards -22.67, envs finished 1
2026-01-17 13:30:28,927 : agent.on_policy : DEBUG : Mean Losses: [7.345523227006197]
2026-01-17 13:30:29,001 : worker.worker : DEBUG : Step 131606, finished rewards 3.28, envs finished 1
2026-01-17 13:30:29,141 : agent.on_policy : DEBUG : Mean Losses: [3.4975216276943684]
2026-01-17 13:30:29,160 : worker.worker : DEBUG : Step 131619, finished rewards 23.20, envs finished 1
2026-01-17 13:30:29,171 : worker.worker : DEBUG : Step 131620, finished rewards 30.62, envs finished 1
2026-01-17 13:30:29,209 : worker.worker : DEBUG : Step 131627, finished rewards 10.64, envs finished 1
2026-01-17 13:30:29,333 : agent.on_policy : DEBUG : Mean Losses: [4.722797904163599]
2026-01-17 13:30:29,421 : worker.worker : DEBUG : Step 131660, finished rewards 3.44, envs finished 1
2026-01-17 13:30:29,493 : worker.worker : DEBUG : Step 131674, finished rewards 12.04, envs finished 1
2026-01-17 13:30:29,606 : agent.on_policy : DEBUG : Mean Losses: [4.249416194856167]
2026-01-17 13:30:29,810 : worker.worker : DEBUG : Step 131696, finished rewards 4.57, envs finished 1
2026-01-17 13:30:29,870 : worker.worker : DEBUG : Step 131700, finished rewards 22.93, envs finished 1
2026-01-17 13:30:30,172 : agent.on_policy : DEBUG : Mean Losses: [5.795569211244583]
2026-01-17 13:30:30,204 : worker.worker : DEBUG : Step 131718, finished rewards -2.00, envs finished 1
2026-01-17 13:30:30,282 : worker.worker : DEBUG : Step 131740, finished rewards 3.96, envs finished 1
2026-01-17 13:30:30,344 : agent.on_policy : DEBUG : Mean Losses: [3.8415377140045166]
2026-01-17 13:30:30,383 : worker.worker : DEBUG : Step 131747, finished rewards 4.90, envs finished 1
2026-01-17 13:30:30,657 : agent.on_policy : DEBUG : Mean Losses: [4.132435351610184]
2026-01-17 13:30:30,659 : worker.worker : DEBUG : Step 131776, finished rewards 37.50, envs finished 1
2026-01-17 13:30:30,671 : worker.worker : DEBUG : Step 131779, finished rewards -20.64, envs finished 1
2026-01-17 13:30:30,761 : worker.worker : DEBUG : Step 131804, finished rewards -4.15, envs finished 1
2026-01-17 13:30:30,870 : agent.on_policy : DEBUG : Mean Losses: [4.977664359845221]
2026-01-17 13:30:30,932 : worker.worker : DEBUG : Step 131821, finished rewards -7.32, envs finished 1
2026-01-17 13:30:30,962 : worker.worker : DEBUG : Step 131825, finished rewards 14.78, envs finished 1
2026-01-17 13:30:31,140 : agent.on_policy : DEBUG : Mean Losses: [5.401823028922081]
2026-01-17 13:30:31,214 : worker.worker : DEBUG : Step 131847, finished rewards 18.90, envs finished 1
2026-01-17 13:30:31,229 : worker.worker : DEBUG : Step 131850, finished rewards 41.43, envs finished 1
2026-01-17 13:30:31,277 : worker.worker : DEBUG : Step 131860, finished rewards 29.35, envs finished 1
2026-01-17 13:30:31,462 : agent.on_policy : DEBUG : Mean Losses: [7.765037093311548]
2026-01-17 13:30:31,497 : worker.worker : DEBUG : Step 131875, finished rewards -4.51, envs finished 1
2026-01-17 13:30:31,644 : worker.worker : DEBUG : Step 131898, finished rewards 35.94, envs finished 1
2026-01-17 13:30:31,881 : agent.on_policy : DEBUG : Mean Losses: [5.109247364103794]
2026-01-17 13:30:31,991 : worker.worker : DEBUG : Step 131924, finished rewards 4.95, envs finished 1
2026-01-17 13:30:32,164 : agent.on_policy : DEBUG : Mean Losses: [4.659086264669895]
2026-01-17 13:30:32,170 : worker.worker : DEBUG : Step 131937, finished rewards 28.36, envs finished 1
2026-01-17 13:30:32,187 : worker.worker : DEBUG : Step 131941, finished rewards -74.10, envs finished 1
2026-01-17 13:30:32,208 : worker.worker : DEBUG : Step 131945, finished rewards 21.89, envs finished 1
2026-01-17 13:30:32,259 : worker.worker : DEBUG : Step 131957, finished rewards -5.92, envs finished 1
2026-01-17 13:30:32,366 : agent.on_policy : DEBUG : Mean Losses: [6.170146048069]
2026-01-17 13:30:32,471 : worker.worker : DEBUG : Step 131979, finished rewards 4.49, envs finished 1
2026-01-17 13:30:32,570 : worker.worker : DEBUG : Step 131989, finished rewards 11.05, envs finished 1
2026-01-17 13:30:32,616 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:30:32,744 : agent.on_policy : DEBUG : Mean Losses: [3.4722380470484495]
2026-01-17 13:30:32,202 : worker.worker : DEBUG : Step 132021, finished rewards 0.81, envs finished 1
2026-01-17 13:30:32,330 : agent.on_policy : DEBUG : Mean Losses: [3.5207867808640003]
2026-01-17 13:30:32,341 : worker.worker : DEBUG : Step 132034, finished rewards 22.17, envs finished 1
2026-01-17 13:30:32,464 : worker.worker : DEBUG : Step 132049, finished rewards 16.15, envs finished 1
2026-01-17 13:30:32,556 : worker.worker : DEBUG : Step 132059, finished rewards 6.03, envs finished 1
2026-01-17 13:30:32,710 : agent.on_policy : DEBUG : Mean Losses: [7.058275260031223]
2026-01-17 13:30:32,732 : worker.worker : DEBUG : Step 132069, finished rewards 9.72, envs finished 1
2026-01-17 13:30:32,811 : worker.worker : DEBUG : Step 132078, finished rewards 27.79, envs finished 1
2026-01-17 13:30:32,820 : worker.worker : DEBUG : Step 132079, finished rewards 17.16, envs finished 1
2026-01-17 13:30:32,843 : worker.worker : DEBUG : Step 132082, finished rewards -20.07, envs finished 1
2026-01-17 13:30:33,057 : agent.on_policy : DEBUG : Mean Losses: [7.151741962879896]
2026-01-17 13:30:33,219 : agent.on_policy : DEBUG : Mean Losses: [1.7995507288724184]
2026-01-17 13:30:33,286 : worker.worker : DEBUG : Step 132137, finished rewards 6.87, envs finished 1
2026-01-17 13:30:33,333 : worker.worker : DEBUG : Step 132150, finished rewards 42.48, envs finished 1
2026-01-17 13:30:33,341 : worker.worker : DEBUG : Step 132152, finished rewards 15.40, envs finished 2
2026-01-17 13:30:33,510 : agent.on_policy : DEBUG : Mean Losses: [9.501742891967297]
2026-01-17 13:30:33,522 : worker.worker : DEBUG : Step 132162, finished rewards 24.25, envs finished 1
2026-01-17 13:30:33,556 : worker.worker : DEBUG : Step 132169, finished rewards 1.95, envs finished 1
2026-01-17 13:30:33,575 : worker.worker : DEBUG : Step 132173, finished rewards 23.71, envs finished 1
2026-01-17 13:30:33,679 : agent.on_policy : DEBUG : Mean Losses: [4.2525828164070845]
2026-01-17 13:30:33,830 : worker.worker : DEBUG : Step 132221, finished rewards -6.78, envs finished 1
2026-01-17 13:30:33,890 : agent.on_policy : DEBUG : Mean Losses: [2.983500361442566]
2026-01-17 13:30:33,922 : worker.worker : DEBUG : Step 132233, finished rewards 20.77, envs finished 1
2026-01-17 13:30:33,933 : worker.worker : DEBUG : Step 132235, finished rewards 28.86, envs finished 1
2026-01-17 13:30:33,952 : worker.worker : DEBUG : Step 132238, finished rewards 28.23, envs finished 1
2026-01-17 13:30:34,034 : worker.worker : DEBUG : Step 132246, finished rewards 29.67, envs finished 1
2026-01-17 13:30:34,181 : agent.on_policy : DEBUG : Mean Losses: [9.06565461307764]
2026-01-17 13:30:34,211 : worker.worker : DEBUG : Step 132266, finished rewards 23.02, envs finished 1
2026-01-17 13:30:34,279 : worker.worker : DEBUG : Step 132274, finished rewards 4.33, envs finished 1
2026-01-17 13:30:34,522 : agent.on_policy : DEBUG : Mean Losses: [4.617036400362849]
2026-01-17 13:30:34,564 : worker.worker : DEBUG : Step 132299, finished rewards 36.17, envs finished 1
2026-01-17 13:30:34,594 : worker.worker : DEBUG : Step 132307, finished rewards -4.67, envs finished 1
2026-01-17 13:30:34,687 : agent.on_policy : DEBUG : Mean Losses: [4.089955106377602]
2026-01-17 13:30:34,788 : worker.worker : DEBUG : Step 132337, finished rewards 16.62, envs finished 1
2026-01-17 13:30:34,984 : agent.on_policy : DEBUG : Mean Losses: [4.8953671380877495]
2026-01-17 13:30:35,011 : worker.worker : DEBUG : Step 132356, finished rewards 5.08, envs finished 1
2026-01-17 13:30:35,023 : worker.worker : DEBUG : Step 132358, finished rewards 23.89, envs finished 1
2026-01-17 13:30:35,057 : worker.worker : DEBUG : Step 132365, finished rewards -3.28, envs finished 1
2026-01-17 13:30:35,091 : worker.worker : DEBUG : Step 132374, finished rewards 0.03, envs finished 1
2026-01-17 13:30:35,179 : agent.on_policy : DEBUG : Mean Losses: [6.6131425984203815]
2026-01-17 13:30:35,248 : worker.worker : DEBUG : Step 132397, finished rewards 19.30, envs finished 1
2026-01-17 13:30:35,298 : worker.worker : DEBUG : Step 132400, finished rewards 24.59, envs finished 1
2026-01-17 13:30:35,397 : worker.worker : DEBUG : Step 132410, finished rewards -8.27, envs finished 1
2026-01-17 13:30:35,494 : agent.on_policy : DEBUG : Mean Losses: [4.740385815501213]
2026-01-17 13:30:35,551 : worker.worker : DEBUG : Step 132422, finished rewards 29.45, envs finished 1
2026-01-17 13:30:35,754 : agent.on_policy : DEBUG : Mean Losses: [3.2477445024996996]
2026-01-17 13:30:35,789 : worker.worker : DEBUG : Step 132458, finished rewards 17.17, envs finished 1
2026-01-17 13:30:35,921 : agent.on_policy : DEBUG : Mean Losses: [4.073535606265068]
2026-01-17 13:30:35,940 : worker.worker : DEBUG : Step 132483, finished rewards 30.84, envs finished 1
2026-01-17 13:30:35,966 : worker.worker : DEBUG : Step 132485, finished rewards 3.19, envs finished 1
2026-01-17 13:30:35,997 : worker.worker : DEBUG : Step 132491, finished rewards -7.52, envs finished 1
2026-01-17 13:30:36,091 : worker.worker : DEBUG : Step 132511, finished rewards -7.72, envs finished 1
2026-01-17 13:30:36,204 : agent.on_policy : DEBUG : Mean Losses: [5.576733335852623]
2026-01-17 13:30:36,231 : worker.worker : DEBUG : Step 132516, finished rewards 23.29, envs finished 1
2026-01-17 13:30:36,312 : worker.worker : DEBUG : Step 132521, finished rewards 10.84, envs finished 1
2026-01-17 13:30:36,504 : agent.on_policy : DEBUG : Mean Losses: [3.4381193295121193]
2026-01-17 13:30:36,536 : worker.worker : DEBUG : Step 132553, finished rewards -11.52, envs finished 1
2026-01-17 13:30:36,541 : worker.worker : DEBUG : Step 132554, finished rewards 22.01, envs finished 1
2026-01-17 13:30:36,666 : agent.on_policy : DEBUG : Mean Losses: [3.6722196117043495]
2026-01-17 13:30:36,705 : worker.worker : DEBUG : Step 132581, finished rewards 41.34, envs finished 1
2026-01-17 13:30:36,827 : worker.worker : DEBUG : Step 132606, finished rewards 5.06, envs finished 1
2026-01-17 13:30:36,832 : worker.worker : DEBUG : Step 132607, finished rewards 24.49, envs finished 1
2026-01-17 13:30:36,934 : agent.on_policy : DEBUG : Mean Losses: [7.107415176928043]
2026-01-17 13:30:37,042 : worker.worker : DEBUG : Step 132625, finished rewards -11.21, envs finished 1
2026-01-17 13:30:37,196 : agent.on_policy : DEBUG : Mean Losses: [3.9287458024919033]
2026-01-17 13:30:37,230 : worker.worker : DEBUG : Step 132649, finished rewards -14.99, envs finished 1
2026-01-17 13:30:37,357 : agent.on_policy : DEBUG : Mean Losses: [4.181124702095985]
2026-01-17 13:30:37,370 : worker.worker : DEBUG : Step 132674, finished rewards 4.56, envs finished 1
2026-01-17 13:30:37,618 : worker.worker : DEBUG : Step 132700, finished rewards 23.01, envs finished 1
2026-01-17 13:30:37,638 : worker.worker : DEBUG : Step 132701, finished rewards 1.96, envs finished 1
2026-01-17 13:30:37,676 : worker.worker : DEBUG : Step 132703, finished rewards 21.27, envs finished 1
2026-01-17 13:30:37,778 : agent.on_policy : DEBUG : Mean Losses: [9.583695121109486]
2026-01-17 13:30:37,840 : worker.worker : DEBUG : Step 132715, finished rewards -48.31, envs finished 1
2026-01-17 13:30:38,032 : agent.on_policy : DEBUG : Mean Losses: [3.572768544778228]
2026-01-17 13:30:38,088 : worker.worker : DEBUG : Step 132750, finished rewards -57.36, envs finished 1
2026-01-17 13:30:38,118 : worker.worker : DEBUG : Step 132756, finished rewards 13.95, envs finished 1
2026-01-17 13:30:38,281 : agent.on_policy : DEBUG : Mean Losses: [4.5450462102890015]
2026-01-17 13:30:38,385 : worker.worker : DEBUG : Step 132783, finished rewards 12.00, envs finished 1
2026-01-17 13:30:38,482 : worker.worker : DEBUG : Step 132797, finished rewards -32.00, envs finished 1
2026-01-17 13:30:38,603 : agent.on_policy : DEBUG : Mean Losses: [6.222894459962845]
2026-01-17 13:30:38,630 : worker.worker : DEBUG : Step 132805, finished rewards 25.30, envs finished 1
2026-01-17 13:30:38,717 : worker.worker : DEBUG : Step 132815, finished rewards 6.45, envs finished 1
2026-01-17 13:30:38,766 : worker.worker : DEBUG : Step 132826, finished rewards 2.74, envs finished 1
2026-01-17 13:30:38,887 : agent.on_policy : DEBUG : Mean Losses: [6.68208197131753]
2026-01-17 13:30:38,996 : worker.worker : DEBUG : Step 132851, finished rewards 19.56, envs finished 1
2026-01-17 13:30:39,056 : worker.worker : DEBUG : Step 132861, finished rewards -20.50, envs finished 1
2026-01-17 13:30:39,194 : agent.on_policy : DEBUG : Mean Losses: [5.101439923048019]
2026-01-17 13:30:39,490 : worker.worker : DEBUG : Step 132893, finished rewards 10.20, envs finished 1
2026-01-17 13:30:39,548 : agent.on_policy : DEBUG : Mean Losses: [4.876406718045473]
2026-01-17 13:30:39,554 : worker.worker : DEBUG : Step 132897, finished rewards 24.46, envs finished 1
2026-01-17 13:30:39,589 : worker.worker : DEBUG : Step 132904, finished rewards 25.60, envs finished 1
2026-01-17 13:30:39,704 : worker.worker : DEBUG : Step 132923, finished rewards -2.47, envs finished 2
2026-01-17 13:30:39,824 : agent.on_policy : DEBUG : Mean Losses: [5.837428346276283]
2026-01-17 13:30:39,903 : worker.worker : DEBUG : Step 132937, finished rewards 9.74, envs finished 1
2026-01-17 13:30:40,138 : agent.on_policy : DEBUG : Mean Losses: [2.930806189775467]
2026-01-17 13:30:40,235 : worker.worker : DEBUG : Step 132990, finished rewards -13.69, envs finished 1
2026-01-17 13:30:40,333 : agent.on_policy : DEBUG : Mean Losses: [3.7826447151601315]
2026-01-17 13:30:40,340 : worker.worker : DEBUG : Step 132993, finished rewards 21.93, envs finished 1
2026-01-17 13:30:40,359 : worker.worker : DEBUG : Step 132996, finished rewards 17.63, envs finished 1
2026-01-17 13:30:40,371 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:30:40,486 : worker.worker : DEBUG : Step 133015, finished rewards -11.68, envs finished 1
2026-01-17 13:30:40,491 : worker.worker : DEBUG : Step 133016, finished rewards 10.47, envs finished 1
2026-01-17 13:30:40,637 : agent.on_policy : DEBUG : Mean Losses: [5.751209447160363]
2026-01-17 13:30:40,673 : worker.worker : DEBUG : Step 133034, finished rewards 20.72, envs finished 1
2026-01-17 13:30:40,797 : agent.on_policy : DEBUG : Mean Losses: [3.3981568217277527]
2026-01-17 13:30:40,893 : worker.worker : DEBUG : Step 133071, finished rewards -16.91, envs finished 1
2026-01-17 13:30:40,953 : worker.worker : DEBUG : Step 133079, finished rewards -16.34, envs finished 1
2026-01-17 13:30:41,019 : worker.worker : DEBUG : Step 133086, finished rewards 25.31, envs finished 1
2026-01-17 13:30:41,143 : agent.on_policy : DEBUG : Mean Losses: [6.899407800287008]
2026-01-17 13:30:41,151 : worker.worker : DEBUG : Step 133089, finished rewards 23.85, envs finished 1
2026-01-17 13:30:41,272 : worker.worker : DEBUG : Step 133110, finished rewards 23.14, envs finished 1
2026-01-17 13:30:41,283 : worker.worker : DEBUG : Step 133112, finished rewards 21.86, envs finished 1
2026-01-17 13:30:41,340 : worker.worker : DEBUG : Step 133116, finished rewards -2.53, envs finished 1
2026-01-17 13:30:41,513 : agent.on_policy : DEBUG : Mean Losses: [6.89273364841938]
2026-01-17 13:30:41,676 : worker.worker : DEBUG : Step 133142, finished rewards 11.05, envs finished 1
2026-01-17 13:30:41,841 : agent.on_policy : DEBUG : Mean Losses: [2.108514758758247]
2026-01-17 13:30:42,086 : agent.on_policy : DEBUG : Mean Losses: [2.9923075828701258]
2026-01-17 13:30:42,220 : worker.worker : DEBUG : Step 133207, finished rewards 4.24, envs finished 1
2026-01-17 13:30:42,246 : worker.worker : DEBUG : Step 133209, finished rewards 20.93, envs finished 1
2026-01-17 13:30:42,395 : agent.on_policy : DEBUG : Mean Losses: [6.442071825265884]
2026-01-17 13:30:42,457 : worker.worker : DEBUG : Step 133222, finished rewards 13.21, envs finished 1
2026-01-17 13:30:42,493 : worker.worker : DEBUG : Step 133228, finished rewards -28.40, envs finished 1
2026-01-17 13:30:42,504 : worker.worker : DEBUG : Step 133230, finished rewards -11.43, envs finished 1
2026-01-17 13:30:42,518 : worker.worker : DEBUG : Step 133232, finished rewards -22.39, envs finished 1
2026-01-17 13:30:42,574 : worker.worker : DEBUG : Step 133238, finished rewards -0.53, envs finished 1
2026-01-17 13:30:42,780 : agent.on_policy : DEBUG : Mean Losses: [8.267547607421875]
2026-01-17 13:30:43,014 : agent.on_policy : DEBUG : Mean Losses: [1.5370630137622356]
2026-01-17 13:30:43,037 : worker.worker : DEBUG : Step 133284, finished rewards -10.31, envs finished 1
2026-01-17 13:30:43,159 : worker.worker : DEBUG : Step 133310, finished rewards 18.00, envs finished 1
2026-01-17 13:30:43,297 : agent.on_policy : DEBUG : Mean Losses: [4.687828287482262]
2026-01-17 13:30:43,305 : worker.worker : DEBUG : Step 133313, finished rewards 12.55, envs finished 1
2026-01-17 13:30:43,419 : worker.worker : DEBUG : Step 133330, finished rewards 21.71, envs finished 1
2026-01-17 13:30:43,426 : worker.worker : DEBUG : Step 133331, finished rewards 23.32, envs finished 1
2026-01-17 13:30:43,455 : worker.worker : DEBUG : Step 133336, finished rewards 13.10, envs finished 1
2026-01-17 13:30:43,653 : agent.on_policy : DEBUG : Mean Losses: [7.943871825933456]
2026-01-17 13:30:43,957 : agent.on_policy : DEBUG : Mean Losses: [2.310746094211936]
2026-01-17 13:30:43,975 : worker.worker : DEBUG : Step 133380, finished rewards -4.78, envs finished 1
2026-01-17 13:30:44,025 : worker.worker : DEBUG : Step 133392, finished rewards 12.24, envs finished 1
2026-01-17 13:30:44,169 : agent.on_policy : DEBUG : Mean Losses: [4.293287217617035]
2026-01-17 13:30:44,184 : worker.worker : DEBUG : Step 133408, finished rewards -30.79, envs finished 1
2026-01-17 13:30:44,308 : worker.worker : DEBUG : Step 133426, finished rewards 8.88, envs finished 1
2026-01-17 13:30:44,419 : worker.worker : DEBUG : Step 133439, finished rewards 11.91, envs finished 1
2026-01-17 13:30:44,581 : agent.on_policy : DEBUG : Mean Losses: [4.7292140275239944]
2026-01-17 13:30:44,633 : worker.worker : DEBUG : Step 133447, finished rewards 11.59, envs finished 1
2026-01-17 13:30:44,685 : worker.worker : DEBUG : Step 133449, finished rewards 7.55, envs finished 1
2026-01-17 13:30:44,762 : worker.worker : DEBUG : Step 133453, finished rewards -9.80, envs finished 1
2026-01-17 13:30:45,151 : agent.on_policy : DEBUG : Mean Losses: [4.395607074722648]
2026-01-17 13:30:45,225 : worker.worker : DEBUG : Step 133482, finished rewards 25.05, envs finished 1
2026-01-17 13:30:45,242 : worker.worker : DEBUG : Step 133484, finished rewards 36.50, envs finished 1
2026-01-17 13:30:45,549 : agent.on_policy : DEBUG : Mean Losses: [5.139461509883404]
2026-01-17 13:30:45,626 : worker.worker : DEBUG : Step 133515, finished rewards 36.47, envs finished 1
2026-01-17 13:30:45,791 : worker.worker : DEBUG : Step 133535, finished rewards 28.24, envs finished 1
2026-01-17 13:30:45,875 : agent.on_policy : DEBUG : Mean Losses: [7.204142235219479]
2026-01-17 13:30:45,998 : worker.worker : DEBUG : Step 133547, finished rewards 20.75, envs finished 1
2026-01-17 13:30:46,008 : worker.worker : DEBUG : Step 133548, finished rewards -16.38, envs finished 1
2026-01-17 13:30:46,272 : agent.on_policy : DEBUG : Mean Losses: [4.471384534612298]
2026-01-17 13:30:46,306 : worker.worker : DEBUG : Step 133572, finished rewards -11.69, envs finished 1
2026-01-17 13:30:46,338 : worker.worker : DEBUG : Step 133576, finished rewards 24.43, envs finished 1
2026-01-17 13:30:46,346 : worker.worker : DEBUG : Step 133577, finished rewards 23.00, envs finished 1
2026-01-17 13:30:46,617 : agent.on_policy : DEBUG : Mean Losses: [4.744002442806959]
2026-01-17 13:30:46,790 : worker.worker : DEBUG : Step 133616, finished rewards 42.12, envs finished 1
2026-01-17 13:30:46,821 : worker.worker : DEBUG : Step 133620, finished rewards 14.24, envs finished 1
2026-01-17 13:30:47,021 : agent.on_policy : DEBUG : Mean Losses: [5.997880429029465]
2026-01-17 13:30:47,159 : worker.worker : DEBUG : Step 133645, finished rewards 21.61, envs finished 1
2026-01-17 13:30:47,222 : worker.worker : DEBUG : Step 133652, finished rewards 36.65, envs finished 1
2026-01-17 13:30:47,436 : agent.on_policy : DEBUG : Mean Losses: [7.3335282653570175]
2026-01-17 13:30:47,464 : worker.worker : DEBUG : Step 133666, finished rewards 22.65, envs finished 1
2026-01-17 13:30:47,509 : worker.worker : DEBUG : Step 133672, finished rewards 22.27, envs finished 1
2026-01-17 13:30:47,600 : worker.worker : DEBUG : Step 133678, finished rewards -74.23, envs finished 1
2026-01-17 13:30:47,707 : worker.worker : DEBUG : Step 133689, finished rewards -22.87, envs finished 1
2026-01-17 13:30:47,919 : agent.on_policy : DEBUG : Mean Losses: [6.384201634675264]
2026-01-17 13:30:48,034 : worker.worker : DEBUG : Step 133716, finished rewards 21.72, envs finished 1
2026-01-17 13:30:48,180 : agent.on_policy : DEBUG : Mean Losses: [3.144071839749813]
2026-01-17 13:30:48,334 : worker.worker : DEBUG : Step 133747, finished rewards 38.61, envs finished 1
2026-01-17 13:30:48,359 : worker.worker : DEBUG : Step 133748, finished rewards -0.64, envs finished 1
2026-01-17 13:30:48,867 : agent.on_policy : DEBUG : Mean Losses: [5.902675986289978]
2026-01-17 13:30:48,913 : worker.worker : DEBUG : Step 133764, finished rewards 21.46, envs finished 1
2026-01-17 13:30:49,033 : worker.worker : DEBUG : Step 133774, finished rewards -0.86, envs finished 1
2026-01-17 13:30:49,087 : worker.worker : DEBUG : Step 133775, finished rewards 29.28, envs finished 1
2026-01-17 13:30:49,427 : agent.on_policy : DEBUG : Mean Losses: [6.515397235751152]
2026-01-17 13:30:49,531 : worker.worker : DEBUG : Step 133796, finished rewards 6.54, envs finished 1
2026-01-17 13:30:50,142 : agent.on_policy : DEBUG : Mean Losses: [2.742049789056182]
2026-01-17 13:30:50,190 : worker.worker : DEBUG : Step 133829, finished rewards -36.90, envs finished 1
2026-01-17 13:30:50,460 : worker.worker : DEBUG : Step 133849, finished rewards -6.35, envs finished 1
2026-01-17 13:30:50,734 : agent.on_policy : DEBUG : Mean Losses: [3.890665626619011]
2026-01-17 13:30:50,890 : worker.worker : DEBUG : Step 133873, finished rewards 0.07, envs finished 1
2026-01-17 13:30:50,910 : worker.worker : DEBUG : Step 133875, finished rewards 0.74, envs finished 1
2026-01-17 13:30:51,127 : agent.on_policy : DEBUG : Mean Losses: [4.684757847338915]
2026-01-17 13:30:51,161 : worker.worker : DEBUG : Step 133892, finished rewards -1.06, envs finished 1
2026-01-17 13:30:51,229 : worker.worker : DEBUG : Step 133900, finished rewards -3.19, envs finished 1
2026-01-17 13:30:51,314 : worker.worker : DEBUG : Step 133907, finished rewards 33.68, envs finished 1
2026-01-17 13:30:51,531 : agent.on_policy : DEBUG : Mean Losses: [7.537823796272278]
2026-01-17 13:30:51,653 : worker.worker : DEBUG : Step 133935, finished rewards 29.15, envs finished 1
2026-01-17 13:30:51,689 : worker.worker : DEBUG : Step 133939, finished rewards -11.77, envs finished 1
2026-01-17 13:30:52,004 : agent.on_policy : DEBUG : Mean Losses: [4.89786172658205]
2026-01-17 13:30:52,015 : worker.worker : DEBUG : Step 133952, finished rewards -30.86, envs finished 1
2026-01-17 13:30:52,393 : worker.worker : DEBUG : Step 133978, finished rewards 13.40, envs finished 1
2026-01-17 13:30:52,646 : agent.on_policy : DEBUG : Mean Losses: [4.570640221238136]
2026-01-17 13:30:52,815 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:30:52,877 : worker.worker : DEBUG : Step 134002, finished rewards 19.80, envs finished 1
2026-01-17 13:30:52,964 : worker.worker : DEBUG : Step 134011, finished rewards 2.96, envs finished 1
2026-01-17 13:30:53,109 : agent.on_policy : DEBUG : Mean Losses: [5.709121026098728]
2026-01-17 13:30:53,243 : worker.worker : DEBUG : Step 134027, finished rewards 28.61, envs finished 1
2026-01-17 13:30:53,364 : worker.worker : DEBUG : Step 134034, finished rewards -1.27, envs finished 1
2026-01-17 13:30:53,537 : worker.worker : DEBUG : Step 134045, finished rewards 24.12, envs finished 1
2026-01-17 13:30:53,561 : worker.worker : DEBUG : Step 134047, finished rewards 8.91, envs finished 1
2026-01-17 13:30:53,769 : agent.on_policy : DEBUG : Mean Losses: [7.38903471082449]
2026-01-17 13:30:53,863 : worker.worker : DEBUG : Step 134061, finished rewards 12.69, envs finished 1
2026-01-17 13:30:54,125 : agent.on_policy : DEBUG : Mean Losses: [2.025293283164501]
2026-01-17 13:30:54,152 : worker.worker : DEBUG : Step 134085, finished rewards 30.92, envs finished 1
2026-01-17 13:30:54,231 : worker.worker : DEBUG : Step 134100, finished rewards 1.92, envs finished 1
2026-01-17 13:30:54,260 : worker.worker : DEBUG : Step 134104, finished rewards 36.82, envs finished 1
2026-01-17 13:30:54,308 : worker.worker : DEBUG : Step 134111, finished rewards 19.71, envs finished 1
2026-01-17 13:30:54,418 : agent.on_policy : DEBUG : Mean Losses: [7.38007805775851]
2026-01-17 13:30:54,707 : agent.on_policy : DEBUG : Mean Losses: [1.773044852539897]
2026-01-17 13:30:54,783 : worker.worker : DEBUG : Step 134160, finished rewards 4.13, envs finished 2
2026-01-17 13:30:54,827 : worker.worker : DEBUG : Step 134169, finished rewards 2.48, envs finished 1
2026-01-17 13:30:55,024 : agent.on_policy : DEBUG : Mean Losses: [5.814961887896061]
2026-01-17 13:30:55,132 : worker.worker : DEBUG : Step 134192, finished rewards 13.98, envs finished 1
2026-01-17 13:30:55,191 : worker.worker : DEBUG : Step 134201, finished rewards -10.97, envs finished 1
2026-01-17 13:30:55,375 : agent.on_policy : DEBUG : Mean Losses: [4.672772563993931]
2026-01-17 13:30:55,495 : worker.worker : DEBUG : Step 134220, finished rewards 13.18, envs finished 1
2026-01-17 13:30:55,617 : worker.worker : DEBUG : Step 134231, finished rewards -4.16, envs finished 1
2026-01-17 13:30:55,810 : agent.on_policy : DEBUG : Mean Losses: [4.703469604253769]
2026-01-17 13:30:55,908 : worker.worker : DEBUG : Step 134255, finished rewards -20.48, envs finished 1
2026-01-17 13:30:55,947 : worker.worker : DEBUG : Step 134261, finished rewards 17.85, envs finished 1
2026-01-17 13:30:56,145 : agent.on_policy : DEBUG : Mean Losses: [6.5789948254823685]
2026-01-17 13:30:56,148 : worker.worker : DEBUG : Step 134272, finished rewards 16.66, envs finished 1
2026-01-17 13:30:56,174 : worker.worker : DEBUG : Step 134276, finished rewards 36.95, envs finished 1
2026-01-17 13:30:56,408 : agent.on_policy : DEBUG : Mean Losses: [2.706035817041993]
2026-01-17 13:30:56,426 : worker.worker : DEBUG : Step 134307, finished rewards 6.14, envs finished 1
2026-01-17 13:30:56,449 : worker.worker : DEBUG : Step 134311, finished rewards -20.80, envs finished 1
2026-01-17 13:30:56,556 : worker.worker : DEBUG : Step 134335, finished rewards 16.34, envs finished 1
2026-01-17 13:30:56,665 : agent.on_policy : DEBUG : Mean Losses: [4.790628135204315]
2026-01-17 13:30:56,775 : worker.worker : DEBUG : Step 134352, finished rewards 36.46, envs finished 1
2026-01-17 13:30:56,812 : worker.worker : DEBUG : Step 134357, finished rewards 21.27, envs finished 1
2026-01-17 13:30:56,886 : worker.worker : DEBUG : Step 134364, finished rewards 11.42, envs finished 1
2026-01-17 13:30:56,977 : agent.on_policy : DEBUG : Mean Losses: [8.026233743876219]
2026-01-17 13:30:57,028 : worker.worker : DEBUG : Step 134372, finished rewards -11.54, envs finished 1
2026-01-17 13:30:57,142 : worker.worker : DEBUG : Step 134396, finished rewards 1.11, envs finished 1
2026-01-17 13:30:57,268 : agent.on_policy : DEBUG : Mean Losses: [3.385224275290966]
2026-01-17 13:30:57,366 : worker.worker : DEBUG : Step 134411, finished rewards 17.72, envs finished 1
2026-01-17 13:30:57,660 : agent.on_policy : DEBUG : Mean Losses: [3.3576862290501595]
2026-01-17 13:30:57,687 : worker.worker : DEBUG : Step 134437, finished rewards 29.99, envs finished 1
2026-01-17 13:30:57,744 : worker.worker : DEBUG : Step 134445, finished rewards -10.34, envs finished 1
2026-01-17 13:30:57,927 : worker.worker : DEBUG : Step 134460, finished rewards 20.91, envs finished 1
2026-01-17 13:30:58,084 : agent.on_policy : DEBUG : Mean Losses: [6.334508001804352]
2026-01-17 13:30:58,089 : worker.worker : DEBUG : Step 134464, finished rewards 24.37, envs finished 1
2026-01-17 13:30:58,135 : worker.worker : DEBUG : Step 134468, finished rewards -7.71, envs finished 1
2026-01-17 13:30:58,329 : worker.worker : DEBUG : Step 134493, finished rewards -7.00, envs finished 1
2026-01-17 13:30:58,448 : agent.on_policy : DEBUG : Mean Losses: [6.169696542434394]
2026-01-17 13:30:58,592 : worker.worker : DEBUG : Step 134513, finished rewards 17.59, envs finished 1
2026-01-17 13:30:58,695 : worker.worker : DEBUG : Step 134522, finished rewards -2.31, envs finished 1
2026-01-17 13:30:58,850 : agent.on_policy : DEBUG : Mean Losses: [4.721543597057462]
2026-01-17 13:30:59,021 : worker.worker : DEBUG : Step 134547, finished rewards 30.75, envs finished 1
2026-01-17 13:30:59,042 : worker.worker : DEBUG : Step 134550, finished rewards 9.41, envs finished 1
2026-01-17 13:30:59,202 : agent.on_policy : DEBUG : Mean Losses: [6.903781361877918]
2026-01-17 13:30:59,380 : worker.worker : DEBUG : Step 134587, finished rewards -4.10, envs finished 1
2026-01-17 13:30:59,404 : worker.worker : DEBUG : Step 134589, finished rewards 36.55, envs finished 1
2026-01-17 13:30:59,419 : worker.worker : DEBUG : Step 134590, finished rewards -12.55, envs finished 1
2026-01-17 13:30:59,555 : agent.on_policy : DEBUG : Mean Losses: [9.46431788802147]
2026-01-17 13:30:59,634 : worker.worker : DEBUG : Step 134600, finished rewards 14.52, envs finished 1
2026-01-17 13:30:59,676 : worker.worker : DEBUG : Step 134605, finished rewards -6.11, envs finished 1
2026-01-17 13:30:59,873 : worker.worker : DEBUG : Step 134622, finished rewards 18.22, envs finished 1
2026-01-17 13:31:00,141 : agent.on_policy : DEBUG : Mean Losses: [5.460770782083273]
2026-01-17 13:31:00,287 : worker.worker : DEBUG : Step 134655, finished rewards 42.56, envs finished 1
2026-01-17 13:31:00,402 : agent.on_policy : DEBUG : Mean Losses: [3.974671958014369]
2026-01-17 13:31:00,423 : worker.worker : DEBUG : Step 134659, finished rewards 10.21, envs finished 1
2026-01-17 13:31:00,534 : worker.worker : DEBUG : Step 134676, finished rewards 0.45, envs finished 1
2026-01-17 13:31:00,590 : worker.worker : DEBUG : Step 134682, finished rewards 24.18, envs finished 1
2026-01-17 13:31:00,769 : agent.on_policy : DEBUG : Mean Losses: [6.208884082734585]
2026-01-17 13:31:00,780 : worker.worker : DEBUG : Step 134689, finished rewards 30.41, envs finished 1
2026-01-17 13:31:00,871 : worker.worker : DEBUG : Step 134705, finished rewards 5.30, envs finished 1
2026-01-17 13:31:01,074 : agent.on_policy : DEBUG : Mean Losses: [3.923631576821208]
2026-01-17 13:31:01,094 : worker.worker : DEBUG : Step 134723, finished rewards 5.99, envs finished 1
2026-01-17 13:31:01,326 : agent.on_policy : DEBUG : Mean Losses: [2.3867675252258778]
2026-01-17 13:31:01,362 : worker.worker : DEBUG : Step 134759, finished rewards 15.45, envs finished 1
2026-01-17 13:31:01,410 : worker.worker : DEBUG : Step 134769, finished rewards -9.00, envs finished 1
2026-01-17 13:31:01,481 : worker.worker : DEBUG : Step 134781, finished rewards 24.79, envs finished 1
2026-01-17 13:31:01,568 : agent.on_policy : DEBUG : Mean Losses: [7.1149629801511765]
2026-01-17 13:31:01,572 : worker.worker : DEBUG : Step 134784, finished rewards 18.40, envs finished 1
2026-01-17 13:31:01,589 : worker.worker : DEBUG : Step 134786, finished rewards -0.93, envs finished 1
2026-01-17 13:31:01,614 : worker.worker : DEBUG : Step 134789, finished rewards 30.24, envs finished 1
2026-01-17 13:31:01,795 : worker.worker : DEBUG : Step 134814, finished rewards -8.82, envs finished 1
2026-01-17 13:31:02,028 : agent.on_policy : DEBUG : Mean Losses: [6.211264879442751]
2026-01-17 13:31:02,112 : worker.worker : DEBUG : Step 134827, finished rewards 42.68, envs finished 1
2026-01-17 13:31:01,695 : agent.on_policy : DEBUG : Mean Losses: [3.765043145045638]
2026-01-17 13:31:01,733 : worker.worker : DEBUG : Step 134854, finished rewards 42.42, envs finished 1
2026-01-17 13:31:01,773 : worker.worker : DEBUG : Step 134860, finished rewards 25.51, envs finished 1
2026-01-17 13:31:02,086 : agent.on_policy : DEBUG : Mean Losses: [6.656438201665878]
2026-01-17 13:31:02,100 : worker.worker : DEBUG : Step 134881, finished rewards 25.15, envs finished 1
2026-01-17 13:31:02,154 : worker.worker : DEBUG : Step 134886, finished rewards 18.49, envs finished 1
2026-01-17 13:31:02,482 : agent.on_policy : DEBUG : Mean Losses: [5.2487181685864925]
2026-01-17 13:31:02,774 : worker.worker : DEBUG : Step 134940, finished rewards -24.61, envs finished 1
2026-01-17 13:31:02,793 : worker.worker : DEBUG : Step 134941, finished rewards 28.43, envs finished 1
2026-01-17 13:31:02,828 : worker.worker : DEBUG : Step 134943, finished rewards 2.95, envs finished 2
2026-01-17 13:31:02,923 : agent.on_policy : DEBUG : Mean Losses: [9.241132877767086]
2026-01-17 13:31:03,108 : worker.worker : DEBUG : Step 134969, finished rewards 13.73, envs finished 1
2026-01-17 13:31:03,297 : agent.on_policy : DEBUG : Mean Losses: [3.5543855782598257]
2026-01-17 13:31:03,380 : worker.worker : DEBUG : Step 134986, finished rewards -104.13, envs finished 1
2026-01-17 13:31:03,495 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:31:03,528 : worker.worker : INFO : Step 135000, Avg Reward 9.3544, Max Reward 42.6816, Loss [5.16651148]
2026-01-17 13:31:03,673 : agent.on_policy : DEBUG : Mean Losses: [2.899804102256894]
2026-01-17 13:31:03,756 : worker.worker : DEBUG : Step 135022, finished rewards 31.77, envs finished 1
2026-01-17 13:31:03,864 : worker.worker : DEBUG : Step 135036, finished rewards -20.64, envs finished 1
2026-01-17 13:31:03,990 : agent.on_policy : DEBUG : Mean Losses: [6.378932014107704]
2026-01-17 13:31:04,084 : worker.worker : DEBUG : Step 135052, finished rewards 11.20, envs finished 1
2026-01-17 13:31:04,201 : worker.worker : DEBUG : Step 135066, finished rewards 20.98, envs finished 1
2026-01-17 13:31:04,299 : agent.on_policy : DEBUG : Mean Losses: [4.969076380133629]
2026-01-17 13:31:04,344 : worker.worker : DEBUG : Step 135075, finished rewards -9.91, envs finished 1
2026-01-17 13:31:04,361 : worker.worker : DEBUG : Step 135078, finished rewards -8.34, envs finished 1
2026-01-17 13:31:04,391 : worker.worker : DEBUG : Step 135084, finished rewards 21.25, envs finished 1
2026-01-17 13:31:04,504 : worker.worker : DEBUG : Step 135098, finished rewards -33.74, envs finished 1
2026-01-17 13:31:04,645 : agent.on_policy : DEBUG : Mean Losses: [6.904398664832115]
2026-01-17 13:31:04,676 : worker.worker : DEBUG : Step 135112, finished rewards 25.65, envs finished 1
2026-01-17 13:31:04,901 : agent.on_policy : DEBUG : Mean Losses: [2.890556687489152]
2026-01-17 13:31:04,945 : worker.worker : DEBUG : Step 135145, finished rewards 11.31, envs finished 1
2026-01-17 13:31:05,036 : worker.worker : DEBUG : Step 135163, finished rewards 29.40, envs finished 1
2026-01-17 13:31:05,151 : agent.on_policy : DEBUG : Mean Losses: [6.596244506537914]
2026-01-17 13:31:05,152 : worker.worker : DEBUG : Step 135168, finished rewards 23.59, envs finished 1
2026-01-17 13:31:05,202 : worker.worker : DEBUG : Step 135179, finished rewards 1.95, envs finished 1
2026-01-17 13:31:05,401 : agent.on_policy : DEBUG : Mean Losses: [5.003429602831602]
2026-01-17 13:31:05,416 : worker.worker : DEBUG : Step 135203, finished rewards 26.53, envs finished 1
2026-01-17 13:31:05,472 : worker.worker : DEBUG : Step 135213, finished rewards -12.90, envs finished 1
2026-01-17 13:31:05,674 : agent.on_policy : DEBUG : Mean Losses: [4.633681699633598]
2026-01-17 13:31:05,769 : worker.worker : DEBUG : Step 135258, finished rewards -29.92, envs finished 1
2026-01-17 13:31:05,775 : worker.worker : DEBUG : Step 135260, finished rewards 8.19, envs finished 1
2026-01-17 13:31:05,945 : agent.on_policy : DEBUG : Mean Losses: [5.188851401209831]
2026-01-17 13:31:06,072 : worker.worker : DEBUG : Step 135280, finished rewards 12.53, envs finished 1
2026-01-17 13:31:06,151 : worker.worker : DEBUG : Step 135288, finished rewards 11.19, envs finished 1
2026-01-17 13:31:06,181 : worker.worker : DEBUG : Step 135294, finished rewards 25.55, envs finished 1
2026-01-17 13:31:06,307 : agent.on_policy : DEBUG : Mean Losses: [7.427052082493901]
2026-01-17 13:31:06,309 : worker.worker : DEBUG : Step 135296, finished rewards 31.38, envs finished 1
2026-01-17 13:31:06,315 : worker.worker : DEBUG : Step 135297, finished rewards -4.08, envs finished 1
2026-01-17 13:31:06,459 : worker.worker : DEBUG : Step 135314, finished rewards -51.07, envs finished 1
2026-01-17 13:31:06,565 : agent.on_policy : DEBUG : Mean Losses: [2.723560556769371]
2026-01-17 13:31:06,722 : worker.worker : DEBUG : Step 135355, finished rewards 37.30, envs finished 1
2026-01-17 13:31:06,784 : agent.on_policy : DEBUG : Mean Losses: [4.982738770544529]
2026-01-17 13:31:06,898 : worker.worker : DEBUG : Step 135379, finished rewards 3.48, envs finished 1
2026-01-17 13:31:06,926 : worker.worker : DEBUG : Step 135381, finished rewards 28.34, envs finished 1
2026-01-17 13:31:07,198 : agent.on_policy : DEBUG : Mean Losses: [6.413826305419207]
2026-01-17 13:31:07,303 : worker.worker : DEBUG : Step 135400, finished rewards 10.40, envs finished 1
2026-01-17 13:31:07,455 : worker.worker : DEBUG : Step 135415, finished rewards 4.62, envs finished 1
2026-01-17 13:31:07,488 : worker.worker : DEBUG : Step 135419, finished rewards -24.51, envs finished 1
2026-01-17 13:31:07,548 : worker.worker : DEBUG : Step 135423, finished rewards -0.81, envs finished 1
2026-01-17 13:31:07,711 : agent.on_policy : DEBUG : Mean Losses: [9.093643173575401]
2026-01-17 13:31:07,753 : worker.worker : DEBUG : Step 135431, finished rewards 36.42, envs finished 1
2026-01-17 13:31:07,868 : worker.worker : DEBUG : Step 135450, finished rewards -5.28, envs finished 1
2026-01-17 13:31:08,015 : agent.on_policy : DEBUG : Mean Losses: [3.3367127906531096]
2026-01-17 13:31:08,270 : agent.on_policy : DEBUG : Mean Losses: [2.554879507049918]
2026-01-17 13:31:08,335 : worker.worker : DEBUG : Step 135506, finished rewards 25.80, envs finished 1
2026-01-17 13:31:08,356 : worker.worker : DEBUG : Step 135512, finished rewards -7.83, envs finished 1
2026-01-17 13:31:08,364 : worker.worker : DEBUG : Step 135514, finished rewards 30.83, envs finished 1
2026-01-17 13:31:08,495 : agent.on_policy : DEBUG : Mean Losses: [8.401648685336113]
2026-01-17 13:31:08,520 : worker.worker : DEBUG : Step 135526, finished rewards 36.41, envs finished 1
2026-01-17 13:31:08,587 : worker.worker : DEBUG : Step 135534, finished rewards 6.58, envs finished 1
2026-01-17 13:31:08,755 : agent.on_policy : DEBUG : Mean Losses: [6.301246328279376]
2026-01-17 13:31:08,809 : worker.worker : DEBUG : Step 135566, finished rewards -43.30, envs finished 1
2026-01-17 13:31:08,856 : worker.worker : DEBUG : Step 135580, finished rewards -11.05, envs finished 1
2026-01-17 13:31:09,011 : agent.on_policy : DEBUG : Mean Losses: [5.510473251342773]
2026-01-17 13:31:09,027 : worker.worker : DEBUG : Step 135588, finished rewards 36.65, envs finished 1
2026-01-17 13:31:09,031 : worker.worker : DEBUG : Step 135589, finished rewards -42.91, envs finished 1
2026-01-17 13:31:09,036 : worker.worker : DEBUG : Step 135590, finished rewards 30.46, envs finished 1
2026-01-17 13:31:09,321 : agent.on_policy : DEBUG : Mean Losses: [4.771011859178543]
2026-01-17 13:31:09,466 : worker.worker : DEBUG : Step 135628, finished rewards 18.24, envs finished 1
2026-01-17 13:31:09,756 : agent.on_policy : DEBUG : Mean Losses: [3.889192156493664]
2026-01-17 13:31:09,791 : worker.worker : DEBUG : Step 135659, finished rewards -0.92, envs finished 1
2026-01-17 13:31:09,796 : worker.worker : DEBUG : Step 135660, finished rewards -17.06, envs finished 1
2026-01-17 13:31:09,813 : worker.worker : DEBUG : Step 135664, finished rewards 30.01, envs finished 1
2026-01-17 13:31:09,822 : worker.worker : DEBUG : Step 135666, finished rewards 20.74, envs finished 1
2026-01-17 13:31:09,846 : worker.worker : DEBUG : Step 135671, finished rewards 32.01, envs finished 1
2026-01-17 13:31:09,869 : worker.worker : DEBUG : Step 135675, finished rewards 30.55, envs finished 1
2026-01-17 13:31:09,981 : agent.on_policy : DEBUG : Mean Losses: [11.5872118845582]
2026-01-17 13:31:10,150 : worker.worker : DEBUG : Step 135705, finished rewards 34.82, envs finished 1
2026-01-17 13:31:10,248 : agent.on_policy : DEBUG : Mean Losses: [2.8508988302201033]
2026-01-17 13:31:10,284 : worker.worker : DEBUG : Step 135722, finished rewards -5.20, envs finished 1
2026-01-17 13:31:10,395 : worker.worker : DEBUG : Step 135738, finished rewards 46.62, envs finished 1
2026-01-17 13:31:10,530 : agent.on_policy : DEBUG : Mean Losses: [6.067589074373245]
2026-01-17 13:31:10,666 : worker.worker : DEBUG : Step 135760, finished rewards 19.65, envs finished 1
2026-01-17 13:31:10,685 : worker.worker : DEBUG : Step 135763, finished rewards 14.86, envs finished 1
2026-01-17 13:31:10,863 : agent.on_policy : DEBUG : Mean Losses: [6.189054638147354]
2026-01-17 13:31:10,927 : worker.worker : DEBUG : Step 135789, finished rewards 3.24, envs finished 1
2026-01-17 13:31:10,941 : worker.worker : DEBUG : Step 135790, finished rewards 1.85, envs finished 1
2026-01-17 13:31:11,201 : agent.on_policy : DEBUG : Mean Losses: [4.94857282936573]
2026-01-17 13:31:11,248 : worker.worker : DEBUG : Step 135823, finished rewards 28.94, envs finished 1
2026-01-17 13:31:11,401 : agent.on_policy : DEBUG : Mean Losses: [4.739451974630356]
2026-01-17 13:31:11,454 : worker.worker : DEBUG : Step 135843, finished rewards -9.00, envs finished 1
2026-01-17 13:31:11,507 : worker.worker : DEBUG : Step 135849, finished rewards -3.21, envs finished 1
2026-01-17 13:31:11,597 : worker.worker : DEBUG : Step 135859, finished rewards -18.83, envs finished 1
2026-01-17 13:31:11,654 : worker.worker : DEBUG : Step 135865, finished rewards 14.06, envs finished 1
2026-01-17 13:31:11,817 : agent.on_policy : DEBUG : Mean Losses: [6.863592624664307]
2026-01-17 13:31:11,828 : worker.worker : DEBUG : Step 135874, finished rewards 10.94, envs finished 1
2026-01-17 13:31:11,863 : worker.worker : DEBUG : Step 135882, finished rewards 26.09, envs finished 1
2026-01-17 13:31:11,874 : worker.worker : DEBUG : Step 135883, finished rewards 23.57, envs finished 1
2026-01-17 13:31:12,228 : agent.on_policy : DEBUG : Mean Losses: [4.234776395373046]
2026-01-17 13:31:12,313 : worker.worker : DEBUG : Step 135916, finished rewards 22.65, envs finished 1
2026-01-17 13:31:12,579 : agent.on_policy : DEBUG : Mean Losses: [2.7761999145150185]
2026-01-17 13:31:12,849 : agent.on_policy : DEBUG : Mean Losses: [4.266981720924377]
2026-01-17 13:31:12,863 : worker.worker : DEBUG : Step 135971, finished rewards 13.42, envs finished 1
2026-01-17 13:31:12,880 : worker.worker : DEBUG : Step 135974, finished rewards -0.43, envs finished 1
2026-01-17 13:31:12,888 : worker.worker : DEBUG : Step 135975, finished rewards 10.89, envs finished 1
2026-01-17 13:31:12,985 : worker.worker : DEBUG : Step 135992, finished rewards 36.55, envs finished 1
2026-01-17 13:31:13,034 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:31:13,181 : agent.on_policy : DEBUG : Mean Losses: [8.670124376192689]
2026-01-17 13:31:13,193 : worker.worker : DEBUG : Step 136001, finished rewards 8.50, envs finished 1
2026-01-17 13:31:13,301 : worker.worker : DEBUG : Step 136008, finished rewards -7.22, envs finished 1
2026-01-17 13:31:13,495 : worker.worker : DEBUG : Step 136024, finished rewards -13.88, envs finished 1
2026-01-17 13:31:13,691 : agent.on_policy : DEBUG : Mean Losses: [4.032053116708994]
2026-01-17 13:31:13,950 : agent.on_policy : DEBUG : Mean Losses: [1.8786445502191782]
2026-01-17 13:31:14,031 : worker.worker : DEBUG : Step 136089, finished rewards -72.18, envs finished 1
2026-01-17 13:31:14,037 : worker.worker : DEBUG : Step 136090, finished rewards 9.17, envs finished 1
2026-01-17 13:31:14,043 : worker.worker : DEBUG : Step 136091, finished rewards 8.19, envs finished 1
2026-01-17 13:31:14,184 : agent.on_policy : DEBUG : Mean Losses: [7.826154991984367]
2026-01-17 13:31:14,256 : worker.worker : DEBUG : Step 136108, finished rewards 9.06, envs finished 1
2026-01-17 13:31:14,325 : worker.worker : DEBUG : Step 136113, finished rewards 11.24, envs finished 1
2026-01-17 13:31:14,407 : worker.worker : DEBUG : Step 136118, finished rewards -15.91, envs finished 1
2026-01-17 13:31:14,691 : agent.on_policy : DEBUG : Mean Losses: [6.558760978281498]
2026-01-17 13:31:15,041 : agent.on_policy : DEBUG : Mean Losses: [2.6258824188262224]
2026-01-17 13:31:15,096 : worker.worker : DEBUG : Step 136169, finished rewards -24.33, envs finished 1
2026-01-17 13:31:15,124 : worker.worker : DEBUG : Step 136173, finished rewards 31.65, envs finished 1
2026-01-17 13:31:15,186 : worker.worker : DEBUG : Step 136180, finished rewards -17.33, envs finished 1
2026-01-17 13:31:15,702 : agent.on_policy : DEBUG : Mean Losses: [6.663165599107742]
2026-01-17 13:31:15,807 : worker.worker : DEBUG : Step 136204, finished rewards 29.72, envs finished 1
2026-01-17 13:31:15,819 : worker.worker : DEBUG : Step 136205, finished rewards 10.32, envs finished 1
2026-01-17 13:31:15,963 : worker.worker : DEBUG : Step 136216, finished rewards 4.34, envs finished 1
2026-01-17 13:31:16,160 : agent.on_policy : DEBUG : Mean Losses: [6.0926575399935246]
2026-01-17 13:31:16,263 : worker.worker : DEBUG : Step 136238, finished rewards -1.01, envs finished 1
2026-01-17 13:31:16,308 : worker.worker : DEBUG : Step 136246, finished rewards 35.80, envs finished 1
2026-01-17 13:31:16,566 : agent.on_policy : DEBUG : Mean Losses: [4.176654661074281]
2026-01-17 13:31:16,614 : worker.worker : DEBUG : Step 136264, finished rewards 30.68, envs finished 1
2026-01-17 13:31:16,663 : worker.worker : DEBUG : Step 136274, finished rewards 41.55, envs finished 1
2026-01-17 13:31:16,716 : worker.worker : DEBUG : Step 136284, finished rewards -26.73, envs finished 1
2026-01-17 13:31:16,902 : agent.on_policy : DEBUG : Mean Losses: [8.096528723835945]
2026-01-17 13:31:16,929 : worker.worker : DEBUG : Step 136293, finished rewards 28.38, envs finished 1
2026-01-17 13:31:16,947 : worker.worker : DEBUG : Step 136296, finished rewards 2.06, envs finished 1
2026-01-17 13:31:16,975 : worker.worker : DEBUG : Step 136301, finished rewards 28.81, envs finished 1
2026-01-17 13:31:17,220 : agent.on_policy : DEBUG : Mean Losses: [4.639878382440656]
2026-01-17 13:31:17,235 : worker.worker : DEBUG : Step 136323, finished rewards 30.58, envs finished 1
2026-01-17 13:31:17,538 : agent.on_policy : DEBUG : Mean Losses: [2.210461676120758]
2026-01-17 13:31:17,577 : worker.worker : DEBUG : Step 136357, finished rewards 22.30, envs finished 1
2026-01-17 13:31:17,692 : worker.worker : DEBUG : Step 136370, finished rewards 29.20, envs finished 1
2026-01-17 13:31:17,916 : agent.on_policy : DEBUG : Mean Losses: [6.355934634804726]
2026-01-17 13:31:17,940 : worker.worker : DEBUG : Step 136388, finished rewards 24.96, envs finished 1
2026-01-17 13:31:17,955 : worker.worker : DEBUG : Step 136390, finished rewards 7.20, envs finished 1
2026-01-17 13:31:17,968 : worker.worker : DEBUG : Step 136391, finished rewards -15.70, envs finished 1
2026-01-17 13:31:18,095 : worker.worker : DEBUG : Step 136412, finished rewards 4.40, envs finished 1
2026-01-17 13:31:18,128 : worker.worker : DEBUG : Step 136414, finished rewards 26.68, envs finished 1
2026-01-17 13:31:18,171 : worker.worker : DEBUG : Step 136415, finished rewards 9.56, envs finished 1
2026-01-17 13:31:18,316 : agent.on_policy : DEBUG : Mean Losses: [8.277093328535557]
2026-01-17 13:31:18,629 : agent.on_policy : DEBUG : Mean Losses: [1.4023814462125301]
2026-01-17 13:31:18,720 : worker.worker : DEBUG : Step 136469, finished rewards 11.45, envs finished 1
2026-01-17 13:31:19,012 : agent.on_policy : DEBUG : Mean Losses: [4.324204262346029]
2026-01-17 13:31:19,073 : worker.worker : DEBUG : Step 136489, finished rewards 21.55, envs finished 1
2026-01-17 13:31:19,130 : worker.worker : DEBUG : Step 136499, finished rewards -2.72, envs finished 1
2026-01-17 13:31:19,353 : agent.on_policy : DEBUG : Mean Losses: [5.394790854305029]
2026-01-17 13:31:19,552 : worker.worker : DEBUG : Step 136528, finished rewards 10.11, envs finished 1
2026-01-17 13:31:19,641 : worker.worker : DEBUG : Step 136531, finished rewards -12.37, envs finished 1
2026-01-17 13:31:20,049 : agent.on_policy : DEBUG : Mean Losses: [4.790617860853672]
2026-01-17 13:31:20,058 : worker.worker : DEBUG : Step 136545, finished rewards -25.28, envs finished 1
2026-01-17 13:31:20,110 : worker.worker : DEBUG : Step 136554, finished rewards -4.70, envs finished 1
2026-01-17 13:31:20,144 : worker.worker : DEBUG : Step 136560, finished rewards -10.60, envs finished 1
2026-01-17 13:31:20,264 : worker.worker : DEBUG : Step 136573, finished rewards 15.66, envs finished 1
2026-01-17 13:31:20,447 : agent.on_policy : DEBUG : Mean Losses: [4.825596820563078]
2026-01-17 13:31:20,702 : worker.worker : DEBUG : Step 136607, finished rewards 36.46, envs finished 1
2026-01-17 13:31:20,795 : agent.on_policy : DEBUG : Mean Losses: [4.703232496976852]
2026-01-17 13:31:21,105 : agent.on_policy : DEBUG : Mean Losses: [2.9466501772403717]
2026-01-17 13:31:21,190 : worker.worker : DEBUG : Step 136657, finished rewards 30.18, envs finished 1
2026-01-17 13:31:21,266 : worker.worker : DEBUG : Step 136663, finished rewards 6.29, envs finished 1
2026-01-17 13:31:21,583 : agent.on_policy : DEBUG : Mean Losses: [7.656710460782051]
2026-01-17 13:31:21,587 : worker.worker : DEBUG : Step 136672, finished rewards -15.58, envs finished 2
2026-01-17 13:31:21,764 : worker.worker : DEBUG : Step 136692, finished rewards 30.28, envs finished 1
2026-01-17 13:31:21,852 : worker.worker : DEBUG : Step 136700, finished rewards -34.19, envs finished 1
2026-01-17 13:31:22,104 : agent.on_policy : DEBUG : Mean Losses: [5.656627690419555]
2026-01-17 13:31:22,197 : worker.worker : DEBUG : Step 136714, finished rewards -16.32, envs finished 1
2026-01-17 13:31:22,408 : agent.on_policy : DEBUG : Mean Losses: [2.63132431730628]
2026-01-17 13:31:22,597 : worker.worker : DEBUG : Step 136757, finished rewards 29.49, envs finished 1
2026-01-17 13:31:22,814 : agent.on_policy : DEBUG : Mean Losses: [5.464850593358278]
2026-01-17 13:31:22,928 : worker.worker : DEBUG : Step 136782, finished rewards 6.39, envs finished 1
2026-01-17 13:31:22,938 : worker.worker : DEBUG : Step 136784, finished rewards 29.64, envs finished 1
2026-01-17 13:31:23,019 : worker.worker : DEBUG : Step 136792, finished rewards 3.98, envs finished 1
2026-01-17 13:31:23,141 : agent.on_policy : DEBUG : Mean Losses: [8.418503642082214]
2026-01-17 13:31:23,243 : worker.worker : DEBUG : Step 136815, finished rewards 9.91, envs finished 1
2026-01-17 13:31:23,461 : agent.on_policy : DEBUG : Mean Losses: [3.5736058950424194]
2026-01-17 13:31:23,471 : worker.worker : DEBUG : Step 136833, finished rewards -16.20, envs finished 1
2026-01-17 13:31:23,554 : worker.worker : DEBUG : Step 136848, finished rewards -3.32, envs finished 1
2026-01-17 13:31:23,624 : worker.worker : DEBUG : Step 136859, finished rewards 17.90, envs finished 1
2026-01-17 13:31:23,844 : agent.on_policy : DEBUG : Mean Losses: [5.608765657991171]
2026-01-17 13:31:23,850 : worker.worker : DEBUG : Step 136864, finished rewards -61.95, envs finished 1
2026-01-17 13:31:23,874 : worker.worker : DEBUG : Step 136868, finished rewards 28.73, envs finished 1
2026-01-17 13:31:23,946 : worker.worker : DEBUG : Step 136884, finished rewards 19.02, envs finished 1
2026-01-17 13:31:24,113 : agent.on_policy : DEBUG : Mean Losses: [4.140598615631461]
2026-01-17 13:31:24,120 : worker.worker : DEBUG : Step 136897, finished rewards 31.28, envs finished 1
2026-01-17 13:31:24,222 : worker.worker : DEBUG : Step 136925, finished rewards -5.51, envs finished 1
2026-01-17 13:31:24,339 : agent.on_policy : DEBUG : Mean Losses: [3.627819962799549]
2026-01-17 13:31:24,443 : worker.worker : DEBUG : Step 136943, finished rewards 23.59, envs finished 1
2026-01-17 13:31:24,623 : agent.on_policy : DEBUG : Mean Losses: [4.389294944703579]
2026-01-17 13:31:24,625 : worker.worker : DEBUG : Step 136960, finished rewards 9.28, envs finished 2
2026-01-17 13:31:24,666 : worker.worker : DEBUG : Step 136970, finished rewards 13.23, envs finished 1
2026-01-17 13:31:24,726 : worker.worker : DEBUG : Step 136984, finished rewards 12.40, envs finished 1
2026-01-17 13:31:24,848 : agent.on_policy : DEBUG : Mean Losses: [5.090781822800636]
2026-01-17 13:31:24,888 : worker.worker : DEBUG : Step 136997, finished rewards 19.91, envs finished 1
2026-01-17 13:31:24,894 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:31:24,912 : worker.worker : DEBUG : Step 137000, finished rewards 9.12, envs finished 1
2026-01-17 13:31:25,139 : worker.worker : DEBUG : Step 137020, finished rewards 34.83, envs finished 1
2026-01-17 13:31:25,291 : agent.on_policy : DEBUG : Mean Losses: [5.377160683274269]
2026-01-17 13:31:25,461 : worker.worker : DEBUG : Step 137053, finished rewards 24.41, envs finished 1
2026-01-17 13:31:25,466 : worker.worker : DEBUG : Step 137054, finished rewards 2.35, envs finished 1
2026-01-17 13:31:25,518 : agent.on_policy : DEBUG : Mean Losses: [6.484075538814068]
2026-01-17 13:31:25,677 : worker.worker : DEBUG : Step 137084, finished rewards 8.92, envs finished 1
2026-01-17 13:31:25,756 : agent.on_policy : DEBUG : Mean Losses: [4.126471005380154]
2026-01-17 13:31:25,775 : worker.worker : DEBUG : Step 137092, finished rewards 25.63, envs finished 1
2026-01-17 13:31:25,784 : worker.worker : DEBUG : Step 137094, finished rewards 21.89, envs finished 1
2026-01-17 13:31:26,003 : agent.on_policy : DEBUG : Mean Losses: [5.249201076105237]
2026-01-17 13:31:26,088 : worker.worker : DEBUG : Step 137139, finished rewards -18.31, envs finished 1
2026-01-17 13:31:26,093 : worker.worker : DEBUG : Step 137140, finished rewards -21.93, envs finished 1
2026-01-17 13:31:26,129 : worker.worker : DEBUG : Step 137147, finished rewards 23.65, envs finished 1
2026-01-17 13:31:26,262 : agent.on_policy : DEBUG : Mean Losses: [8.947349205613136]
2026-01-17 13:31:26,269 : worker.worker : DEBUG : Step 137153, finished rewards -3.32, envs finished 1
2026-01-17 13:31:26,370 : worker.worker : DEBUG : Step 137166, finished rewards 11.19, envs finished 1
2026-01-17 13:31:26,614 : agent.on_policy : DEBUG : Mean Losses: [3.818560466170311]
2026-01-17 13:31:26,685 : worker.worker : DEBUG : Step 137200, finished rewards 6.91, envs finished 1
2026-01-17 13:31:26,715 : worker.worker : DEBUG : Step 137205, finished rewards 12.42, envs finished 1
2026-01-17 13:31:26,883 : agent.on_policy : DEBUG : Mean Losses: [5.517687477171421]
2026-01-17 13:31:26,965 : worker.worker : DEBUG : Step 137227, finished rewards -7.77, envs finished 1
2026-01-17 13:31:27,200 : agent.on_policy : DEBUG : Mean Losses: [4.630840480327606]
2026-01-17 13:31:27,231 : worker.worker : DEBUG : Step 137252, finished rewards 10.43, envs finished 1
2026-01-17 13:31:27,292 : worker.worker : DEBUG : Step 137255, finished rewards 7.67, envs finished 1
2026-01-17 13:31:27,336 : worker.worker : DEBUG : Step 137258, finished rewards 25.49, envs finished 1
2026-01-17 13:31:27,596 : agent.on_policy : DEBUG : Mean Losses: [5.980120992287993]
2026-01-17 13:31:27,769 : worker.worker : DEBUG : Step 137295, finished rewards -5.30, envs finished 1
2026-01-17 13:31:27,836 : worker.worker : DEBUG : Step 137304, finished rewards 19.08, envs finished 1
2026-01-17 13:31:28,083 : agent.on_policy : DEBUG : Mean Losses: [5.173000475391746]
2026-01-17 13:31:28,280 : worker.worker : DEBUG : Step 137325, finished rewards -33.76, envs finished 1
2026-01-17 13:31:28,796 : agent.on_policy : DEBUG : Mean Losses: [4.730882465839386]
2026-01-17 13:31:28,800 : worker.worker : DEBUG : Step 137344, finished rewards 28.03, envs finished 1
2026-01-17 13:31:28,813 : worker.worker : DEBUG : Step 137346, finished rewards -14.09, envs finished 1
2026-01-17 13:31:28,902 : worker.worker : DEBUG : Step 137360, finished rewards 17.97, envs finished 1
2026-01-17 13:31:29,095 : agent.on_policy : DEBUG : Mean Losses: [5.086793199181557]
2026-01-17 13:31:29,177 : worker.worker : DEBUG : Step 137385, finished rewards -14.94, envs finished 1
2026-01-17 13:31:29,211 : worker.worker : DEBUG : Step 137390, finished rewards -9.14, envs finished 1
2026-01-17 13:31:29,220 : worker.worker : DEBUG : Step 137391, finished rewards 22.08, envs finished 1
2026-01-17 13:31:29,427 : agent.on_policy : DEBUG : Mean Losses: [5.659510180354118]
2026-01-17 13:31:29,484 : worker.worker : DEBUG : Step 137422, finished rewards 21.41, envs finished 1
2026-01-17 13:31:29,545 : worker.worker : DEBUG : Step 137434, finished rewards -1.43, envs finished 1
2026-01-17 13:31:29,737 : agent.on_policy : DEBUG : Mean Losses: [5.357825938612223]
2026-01-17 13:31:29,837 : worker.worker : DEBUG : Step 137451, finished rewards 14.54, envs finished 1
2026-01-17 13:31:29,935 : worker.worker : DEBUG : Step 137460, finished rewards 14.38, envs finished 1
2026-01-17 13:31:30,076 : worker.worker : DEBUG : Step 137469, finished rewards 16.93, envs finished 1
2026-01-17 13:31:30,184 : agent.on_policy : DEBUG : Mean Losses: [4.928263768553734]
2026-01-17 13:31:30,195 : worker.worker : DEBUG : Step 137473, finished rewards 32.05, envs finished 1
2026-01-17 13:31:30,214 : worker.worker : DEBUG : Step 137475, finished rewards 30.70, envs finished 1
2026-01-17 13:31:30,469 : agent.on_policy : DEBUG : Mean Losses: [2.6611752044409513]
2026-01-17 13:31:30,694 : agent.on_policy : DEBUG : Mean Losses: [3.885887738317251]
2026-01-17 13:31:30,726 : worker.worker : DEBUG : Step 137541, finished rewards 15.68, envs finished 1
2026-01-17 13:31:30,769 : worker.worker : DEBUG : Step 137548, finished rewards 21.41, envs finished 1
2026-01-17 13:31:30,816 : worker.worker : DEBUG : Step 137556, finished rewards 29.72, envs finished 1
2026-01-17 13:31:30,918 : agent.on_policy : DEBUG : Mean Losses: [7.740053474903107]
2026-01-17 13:31:30,931 : worker.worker : DEBUG : Step 137571, finished rewards -18.87, envs finished 1
2026-01-17 13:31:31,026 : worker.worker : DEBUG : Step 137583, finished rewards 8.22, envs finished 2
2026-01-17 13:31:31,065 : worker.worker : DEBUG : Step 137591, finished rewards 11.91, envs finished 1
2026-01-17 13:31:31,215 : agent.on_policy : DEBUG : Mean Losses: [7.613877568393946]
2026-01-17 13:31:30,626 : worker.worker : DEBUG : Step 137623, finished rewards -57.63, envs finished 1
2026-01-17 13:31:30,710 : agent.on_policy : DEBUG : Mean Losses: [2.940469816327095]
2026-01-17 13:31:30,766 : worker.worker : DEBUG : Step 137645, finished rewards 24.39, envs finished 1
2026-01-17 13:31:30,816 : worker.worker : DEBUG : Step 137649, finished rewards 18.03, envs finished 1
2026-01-17 13:31:30,884 : worker.worker : DEBUG : Step 137661, finished rewards 14.90, envs finished 1
2026-01-17 13:31:31,041 : agent.on_policy : DEBUG : Mean Losses: [5.290883146226406]
2026-01-17 13:31:31,077 : worker.worker : DEBUG : Step 137667, finished rewards 29.59, envs finished 1
2026-01-17 13:31:31,320 : worker.worker : DEBUG : Step 137684, finished rewards 16.12, envs finished 1
2026-01-17 13:31:31,419 : worker.worker : DEBUG : Step 137691, finished rewards 16.69, envs finished 2
2026-01-17 13:31:31,596 : agent.on_policy : DEBUG : Mean Losses: [4.765204792842269]
2026-01-17 13:31:31,938 : agent.on_policy : DEBUG : Mean Losses: [2.298612058162689]
2026-01-17 13:31:31,974 : worker.worker : DEBUG : Step 137732, finished rewards 20.15, envs finished 2
2026-01-17 13:31:32,025 : worker.worker : DEBUG : Step 137737, finished rewards 35.37, envs finished 1
2026-01-17 13:31:32,313 : agent.on_policy : DEBUG : Mean Losses: [5.704065948724747]
2026-01-17 13:31:32,498 : worker.worker : DEBUG : Step 137785, finished rewards 23.21, envs finished 1
2026-01-17 13:31:32,531 : worker.worker : DEBUG : Step 137786, finished rewards 6.69, envs finished 1
2026-01-17 13:31:32,551 : worker.worker : DEBUG : Step 137787, finished rewards 15.77, envs finished 1
2026-01-17 13:31:32,710 : agent.on_policy : DEBUG : Mean Losses: [5.7468279004096985]
2026-01-17 13:31:32,945 : worker.worker : DEBUG : Step 137817, finished rewards 28.65, envs finished 1
2026-01-17 13:31:32,953 : worker.worker : DEBUG : Step 137818, finished rewards 29.14, envs finished 1
2026-01-17 13:31:32,983 : worker.worker : DEBUG : Step 137821, finished rewards -2.72, envs finished 1
2026-01-17 13:31:33,078 : agent.on_policy : DEBUG : Mean Losses: [8.053718715906143]
2026-01-17 13:31:33,087 : worker.worker : DEBUG : Step 137825, finished rewards 9.29, envs finished 1
2026-01-17 13:31:33,125 : worker.worker : DEBUG : Step 137830, finished rewards 24.01, envs finished 1
2026-01-17 13:31:33,414 : agent.on_policy : DEBUG : Mean Losses: [2.4371384903788567]
2026-01-17 13:31:33,468 : worker.worker : DEBUG : Step 137870, finished rewards 30.50, envs finished 1
2026-01-17 13:31:33,473 : worker.worker : DEBUG : Step 137871, finished rewards 29.23, envs finished 1
2026-01-17 13:31:33,516 : worker.worker : DEBUG : Step 137879, finished rewards 23.03, envs finished 1
2026-01-17 13:31:33,714 : agent.on_policy : DEBUG : Mean Losses: [6.816021278500557]
2026-01-17 13:31:33,846 : worker.worker : DEBUG : Step 137901, finished rewards 29.20, envs finished 1
2026-01-17 13:31:33,990 : worker.worker : DEBUG : Step 137912, finished rewards 22.78, envs finished 1
2026-01-17 13:31:34,272 : agent.on_policy : DEBUG : Mean Losses: [5.603821277618408]
2026-01-17 13:31:34,492 : worker.worker : DEBUG : Step 137938, finished rewards 5.10, envs finished 1
2026-01-17 13:31:34,713 : agent.on_policy : DEBUG : Mean Losses: [4.3110275864601135]
2026-01-17 13:31:34,808 : worker.worker : DEBUG : Step 137964, finished rewards 22.84, envs finished 1
2026-01-17 13:31:34,965 : worker.worker : DEBUG : Step 137983, finished rewards 9.13, envs finished 1
2026-01-17 13:31:35,090 : agent.on_policy : DEBUG : Mean Losses: [5.700442269444466]
2026-01-17 13:31:35,108 : worker.worker : DEBUG : Step 137986, finished rewards 12.11, envs finished 1
2026-01-17 13:31:35,162 : worker.worker : DEBUG : Step 137990, finished rewards -30.41, envs finished 1
2026-01-17 13:31:35,209 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:31:35,327 : worker.worker : DEBUG : Step 138014, finished rewards 8.52, envs finished 1
2026-01-17 13:31:35,473 : agent.on_policy : DEBUG : Mean Losses: [6.638540614396334]
2026-01-17 13:31:35,736 : agent.on_policy : DEBUG : Mean Losses: [2.509643577039242]
2026-01-17 13:31:35,751 : worker.worker : DEBUG : Step 138051, finished rewards 42.33, envs finished 1
2026-01-17 13:31:35,771 : worker.worker : DEBUG : Step 138055, finished rewards -78.31, envs finished 1
2026-01-17 13:31:35,788 : worker.worker : DEBUG : Step 138058, finished rewards -16.10, envs finished 1
2026-01-17 13:31:35,817 : worker.worker : DEBUG : Step 138062, finished rewards 38.25, envs finished 1
2026-01-17 13:31:35,892 : worker.worker : DEBUG : Step 138076, finished rewards 12.67, envs finished 1
2026-01-17 13:31:36,001 : agent.on_policy : DEBUG : Mean Losses: [7.01876924932003]
2026-01-17 13:31:36,021 : worker.worker : DEBUG : Step 138081, finished rewards 24.89, envs finished 1
2026-01-17 13:31:36,060 : worker.worker : DEBUG : Step 138087, finished rewards -15.77, envs finished 1
2026-01-17 13:31:36,313 : agent.on_policy : DEBUG : Mean Losses: [3.1290309466421604]
2026-01-17 13:31:36,359 : worker.worker : DEBUG : Step 138121, finished rewards 42.59, envs finished 1
2026-01-17 13:31:36,546 : agent.on_policy : DEBUG : Mean Losses: [4.598957069218159]
2026-01-17 13:31:36,554 : worker.worker : DEBUG : Step 138144, finished rewards 29.49, envs finished 1
2026-01-17 13:31:36,691 : worker.worker : DEBUG : Step 138168, finished rewards 14.25, envs finished 1
2026-01-17 13:31:36,753 : worker.worker : DEBUG : Step 138173, finished rewards 7.05, envs finished 1
2026-01-17 13:31:36,824 : agent.on_policy : DEBUG : Mean Losses: [5.19746196269989]
2026-01-17 13:31:36,964 : worker.worker : DEBUG : Step 138192, finished rewards -30.45, envs finished 1
2026-01-17 13:31:36,975 : worker.worker : DEBUG : Step 138193, finished rewards 7.67, envs finished 1
2026-01-17 13:31:37,030 : worker.worker : DEBUG : Step 138197, finished rewards 12.95, envs finished 1
2026-01-17 13:31:37,041 : worker.worker : DEBUG : Step 138198, finished rewards 10.34, envs finished 1
2026-01-17 13:31:37,054 : worker.worker : DEBUG : Step 138200, finished rewards 33.80, envs finished 1
2026-01-17 13:31:37,195 : agent.on_policy : DEBUG : Mean Losses: [6.873244751244783]
2026-01-17 13:31:37,347 : worker.worker : DEBUG : Step 138231, finished rewards 28.29, envs finished 1
2026-01-17 13:31:37,422 : agent.on_policy : DEBUG : Mean Losses: [1.9597282279282808]
2026-01-17 13:31:37,502 : worker.worker : DEBUG : Step 138256, finished rewards 46.50, envs finished 1
2026-01-17 13:31:37,728 : agent.on_policy : DEBUG : Mean Losses: [4.641541499644518]
2026-01-17 13:31:37,759 : worker.worker : DEBUG : Step 138278, finished rewards 29.06, envs finished 1
2026-01-17 13:31:37,875 : worker.worker : DEBUG : Step 138302, finished rewards -0.55, envs finished 1
2026-01-17 13:31:37,884 : worker.worker : DEBUG : Step 138303, finished rewards -6.21, envs finished 1
2026-01-17 13:31:38,005 : agent.on_policy : DEBUG : Mean Losses: [7.608806557953358]
2026-01-17 13:31:38,053 : worker.worker : DEBUG : Step 138313, finished rewards 8.66, envs finished 2
2026-01-17 13:31:38,402 : agent.on_policy : DEBUG : Mean Losses: [4.737558148801327]
2026-01-17 13:31:38,415 : worker.worker : DEBUG : Step 138339, finished rewards 11.36, envs finished 1
2026-01-17 13:31:38,455 : worker.worker : DEBUG : Step 138349, finished rewards 24.61, envs finished 1
2026-01-17 13:31:38,565 : agent.on_policy : DEBUG : Mean Losses: [4.489008970558643]
2026-01-17 13:31:38,579 : worker.worker : DEBUG : Step 138371, finished rewards -28.11, envs finished 1
2026-01-17 13:31:38,710 : worker.worker : DEBUG : Step 138390, finished rewards 10.89, envs finished 1
2026-01-17 13:31:38,779 : worker.worker : DEBUG : Step 138396, finished rewards 23.81, envs finished 1
2026-01-17 13:31:38,806 : worker.worker : DEBUG : Step 138399, finished rewards 20.59, envs finished 1
2026-01-17 13:31:38,919 : agent.on_policy : DEBUG : Mean Losses: [6.621459614485502]
2026-01-17 13:31:38,929 : worker.worker : DEBUG : Step 138402, finished rewards 26.80, envs finished 1
2026-01-17 13:31:39,137 : agent.on_policy : DEBUG : Mean Losses: [2.9255887642502785]
2026-01-17 13:31:39,160 : worker.worker : DEBUG : Step 138437, finished rewards 7.47, envs finished 1
2026-01-17 13:31:39,184 : worker.worker : DEBUG : Step 138442, finished rewards 23.56, envs finished 1
2026-01-17 13:31:39,297 : worker.worker : DEBUG : Step 138463, finished rewards 25.62, envs finished 1
2026-01-17 13:31:39,543 : agent.on_policy : DEBUG : Mean Losses: [5.124186649918556]
2026-01-17 13:31:39,557 : worker.worker : DEBUG : Step 138465, finished rewards 7.75, envs finished 1
2026-01-17 13:31:39,658 : worker.worker : DEBUG : Step 138488, finished rewards 26.77, envs finished 1
2026-01-17 13:31:39,672 : worker.worker : DEBUG : Step 138491, finished rewards 27.20, envs finished 1
2026-01-17 13:31:39,788 : agent.on_policy : DEBUG : Mean Losses: [6.639095026999712]
2026-01-17 13:31:39,795 : worker.worker : DEBUG : Step 138497, finished rewards 15.92, envs finished 2
2026-01-17 13:31:39,818 : worker.worker : DEBUG : Step 138500, finished rewards 46.82, envs finished 1
2026-01-17 13:31:39,887 : worker.worker : DEBUG : Step 138505, finished rewards 46.63, envs finished 1
2026-01-17 13:31:40,121 : agent.on_policy : DEBUG : Mean Losses: [4.396116269752383]
2026-01-17 13:31:40,181 : worker.worker : DEBUG : Step 138543, finished rewards 33.95, envs finished 1
2026-01-17 13:31:40,383 : agent.on_policy : DEBUG : Mean Losses: [3.2707900404930115]
2026-01-17 13:31:40,455 : worker.worker : DEBUG : Step 138577, finished rewards 35.23, envs finished 1
2026-01-17 13:31:40,496 : worker.worker : DEBUG : Step 138588, finished rewards 8.28, envs finished 1
2026-01-17 13:31:40,502 : worker.worker : DEBUG : Step 138589, finished rewards 25.77, envs finished 1
2026-01-17 13:31:40,633 : agent.on_policy : DEBUG : Mean Losses: [6.685784727334976]
2026-01-17 13:31:40,744 : worker.worker : DEBUG : Step 138604, finished rewards 9.01, envs finished 1
2026-01-17 13:31:40,930 : worker.worker : DEBUG : Step 138620, finished rewards 8.30, envs finished 1
2026-01-17 13:31:41,098 : agent.on_policy : DEBUG : Mean Losses: [5.088210877031088]
2026-01-17 13:31:41,200 : worker.worker : DEBUG : Step 138633, finished rewards -10.78, envs finished 1
2026-01-17 13:31:41,401 : worker.worker : DEBUG : Step 138654, finished rewards 36.10, envs finished 1
2026-01-17 13:31:41,532 : agent.on_policy : DEBUG : Mean Losses: [5.4180027693510056]
2026-01-17 13:31:41,633 : worker.worker : DEBUG : Step 138668, finished rewards -0.27, envs finished 1
2026-01-17 13:31:41,683 : worker.worker : DEBUG : Step 138674, finished rewards -16.76, envs finished 1
2026-01-17 13:31:41,729 : worker.worker : DEBUG : Step 138675, finished rewards 30.79, envs finished 1
2026-01-17 13:31:41,935 : agent.on_policy : DEBUG : Mean Losses: [5.401932463049889]
2026-01-17 13:31:41,976 : worker.worker : DEBUG : Step 138692, finished rewards 17.39, envs finished 1
2026-01-17 13:31:42,315 : agent.on_policy : DEBUG : Mean Losses: [2.215884707868099]
2026-01-17 13:31:42,335 : worker.worker : DEBUG : Step 138723, finished rewards 25.34, envs finished 1
2026-01-17 13:31:42,346 : worker.worker : DEBUG : Step 138724, finished rewards 4.68, envs finished 1
2026-01-17 13:31:42,584 : agent.on_policy : DEBUG : Mean Losses: [3.687254138290882]
2026-01-17 13:31:42,631 : worker.worker : DEBUG : Step 138762, finished rewards -13.83, envs finished 1
2026-01-17 13:31:42,684 : worker.worker : DEBUG : Step 138773, finished rewards 19.26, envs finished 1
2026-01-17 13:31:42,690 : worker.worker : DEBUG : Step 138774, finished rewards 2.36, envs finished 1
2026-01-17 13:31:42,702 : worker.worker : DEBUG : Step 138775, finished rewards 17.58, envs finished 1
2026-01-17 13:31:42,735 : worker.worker : DEBUG : Step 138781, finished rewards 9.27, envs finished 1
2026-01-17 13:31:42,890 : agent.on_policy : DEBUG : Mean Losses: [9.169010203331709]
2026-01-17 13:31:43,162 : agent.on_policy : DEBUG : Mean Losses: [1.4986736625432968]
2026-01-17 13:31:43,263 : worker.worker : DEBUG : Step 138831, finished rewards -9.19, envs finished 1
2026-01-17 13:31:43,418 : worker.worker : DEBUG : Step 138846, finished rewards 5.42, envs finished 1
2026-01-17 13:31:43,542 : agent.on_policy : DEBUG : Mean Losses: [4.764117680490017]
2026-01-17 13:31:43,561 : worker.worker : DEBUG : Step 138851, finished rewards 35.75, envs finished 1
2026-01-17 13:31:43,570 : worker.worker : DEBUG : Step 138852, finished rewards 35.65, envs finished 1
2026-01-17 13:31:43,657 : worker.worker : DEBUG : Step 138859, finished rewards -9.72, envs finished 1
2026-01-17 13:31:43,690 : worker.worker : DEBUG : Step 138864, finished rewards 25.85, envs finished 1
2026-01-17 13:31:43,859 : agent.on_policy : DEBUG : Mean Losses: [6.317000871524215]
2026-01-17 13:31:43,921 : worker.worker : DEBUG : Step 138895, finished rewards -4.65, envs finished 1
2026-01-17 13:31:44,141 : agent.on_policy : DEBUG : Mean Losses: [2.121990779414773]
2026-01-17 13:31:44,245 : worker.worker : DEBUG : Step 138935, finished rewards -21.39, envs finished 1
2026-01-17 13:31:44,258 : worker.worker : DEBUG : Step 138936, finished rewards 35.37, envs finished 1
2026-01-17 13:31:44,428 : agent.on_policy : DEBUG : Mean Losses: [6.61033871024847]
2026-01-17 13:31:44,437 : worker.worker : DEBUG : Step 138945, finished rewards 9.61, envs finished 1
2026-01-17 13:31:44,690 : worker.worker : DEBUG : Step 138971, finished rewards -0.08, envs finished 1
2026-01-17 13:31:44,773 : agent.on_policy : DEBUG : Mean Losses: [5.251230774447322]
2026-01-17 13:31:44,813 : worker.worker : DEBUG : Step 138985, finished rewards -8.31, envs finished 1
2026-01-17 13:31:44,845 : worker.worker : DEBUG : Step 138989, finished rewards 22.62, envs finished 1
2026-01-17 13:31:44,927 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:31:45,209 : agent.on_policy : DEBUG : Mean Losses: [4.568981733173132]
2026-01-17 13:31:45,238 : worker.worker : DEBUG : Step 139010, finished rewards -10.91, envs finished 1
2026-01-17 13:31:45,329 : worker.worker : DEBUG : Step 139020, finished rewards 30.72, envs finished 1
2026-01-17 13:31:45,460 : worker.worker : DEBUG : Step 139033, finished rewards -32.55, envs finished 1
2026-01-17 13:31:45,499 : worker.worker : DEBUG : Step 139038, finished rewards 18.63, envs finished 1
2026-01-17 13:31:45,673 : agent.on_policy : DEBUG : Mean Losses: [6.180233012884855]
2026-01-17 13:31:45,792 : worker.worker : DEBUG : Step 139053, finished rewards 31.60, envs finished 1
2026-01-17 13:31:45,915 : worker.worker : DEBUG : Step 139066, finished rewards 3.77, envs finished 1
2026-01-17 13:31:46,056 : agent.on_policy : DEBUG : Mean Losses: [3.7999814599752426]
2026-01-17 13:31:46,274 : worker.worker : DEBUG : Step 139097, finished rewards 9.97, envs finished 1
2026-01-17 13:31:46,387 : agent.on_policy : DEBUG : Mean Losses: [3.730668481439352]
2026-01-17 13:31:46,415 : worker.worker : DEBUG : Step 139110, finished rewards 25.96, envs finished 1
2026-01-17 13:31:46,535 : worker.worker : DEBUG : Step 139126, finished rewards -8.32, envs finished 1
2026-01-17 13:31:46,693 : agent.on_policy : DEBUG : Mean Losses: [5.222195953130722]
2026-01-17 13:31:46,738 : worker.worker : DEBUG : Step 139141, finished rewards -4.43, envs finished 1
2026-01-17 13:31:46,775 : worker.worker : DEBUG : Step 139145, finished rewards 10.30, envs finished 1
2026-01-17 13:31:46,820 : worker.worker : DEBUG : Step 139150, finished rewards 15.13, envs finished 1
2026-01-17 13:31:46,910 : worker.worker : DEBUG : Step 139164, finished rewards 19.54, envs finished 1
2026-01-17 13:31:47,064 : agent.on_policy : DEBUG : Mean Losses: [6.214027959853411]
2026-01-17 13:31:47,209 : worker.worker : DEBUG : Step 139185, finished rewards 39.05, envs finished 1
2026-01-17 13:31:47,430 : agent.on_policy : DEBUG : Mean Losses: [3.8914877828210592]
2026-01-17 13:31:47,521 : worker.worker : DEBUG : Step 139217, finished rewards 35.35, envs finished 1
2026-01-17 13:31:47,540 : worker.worker : DEBUG : Step 139220, finished rewards 39.01, envs finished 1
2026-01-17 13:31:47,551 : worker.worker : DEBUG : Step 139221, finished rewards 5.15, envs finished 1
2026-01-17 13:31:47,573 : worker.worker : DEBUG : Step 139224, finished rewards 20.03, envs finished 1
2026-01-17 13:31:47,657 : worker.worker : DEBUG : Step 139231, finished rewards -5.41, envs finished 1
2026-01-17 13:31:47,778 : agent.on_policy : DEBUG : Mean Losses: [9.221664495766163]
2026-01-17 13:31:48,021 : worker.worker : DEBUG : Step 139255, finished rewards 26.02, envs finished 1
2026-01-17 13:31:48,237 : agent.on_policy : DEBUG : Mean Losses: [3.4328200556337833]
2026-01-17 13:31:48,304 : worker.worker : DEBUG : Step 139280, finished rewards 46.46, envs finished 1
2026-01-17 13:31:48,523 : agent.on_policy : DEBUG : Mean Losses: [5.7825900465250015]
2026-01-17 13:31:48,604 : worker.worker : DEBUG : Step 139314, finished rewards 0.55, envs finished 1
2026-01-17 13:31:48,617 : worker.worker : DEBUG : Step 139316, finished rewards 25.82, envs finished 1
2026-01-17 13:31:48,645 : worker.worker : DEBUG : Step 139319, finished rewards 27.58, envs finished 1
2026-01-17 13:31:48,661 : worker.worker : DEBUG : Step 139321, finished rewards -36.00, envs finished 1
2026-01-17 13:31:48,864 : agent.on_policy : DEBUG : Mean Losses: [9.098385326564312]
2026-01-17 13:31:48,877 : worker.worker : DEBUG : Step 139330, finished rewards 9.89, envs finished 1
2026-01-17 13:31:49,114 : agent.on_policy : DEBUG : Mean Losses: [2.526640983298421]
2026-01-17 13:31:49,274 : worker.worker : DEBUG : Step 139373, finished rewards 23.64, envs finished 1
2026-01-17 13:31:49,291 : worker.worker : DEBUG : Step 139375, finished rewards -20.22, envs finished 1
2026-01-17 13:31:49,559 : agent.on_policy : DEBUG : Mean Losses: [4.108840003609657]
2026-01-17 13:31:49,621 : worker.worker : DEBUG : Step 139400, finished rewards -13.76, envs finished 1
2026-01-17 13:31:49,636 : worker.worker : DEBUG : Step 139401, finished rewards 29.51, envs finished 1
2026-01-17 13:31:49,852 : worker.worker : DEBUG : Step 139412, finished rewards 25.03, envs finished 1
2026-01-17 13:31:50,035 : agent.on_policy : DEBUG : Mean Losses: [5.097579933702946]
2026-01-17 13:31:50,059 : worker.worker : DEBUG : Step 139429, finished rewards 13.82, envs finished 1
2026-01-17 13:31:50,122 : worker.worker : DEBUG : Step 139443, finished rewards 4.78, envs finished 1
2026-01-17 13:31:50,185 : worker.worker : DEBUG : Step 139451, finished rewards 2.80, envs finished 1
2026-01-17 13:31:50,455 : agent.on_policy : DEBUG : Mean Losses: [3.412225667387247]
2026-01-17 13:31:50,570 : worker.worker : DEBUG : Step 139466, finished rewards 26.81, envs finished 1
2026-01-17 13:31:50,794 : agent.on_policy : DEBUG : Mean Losses: [3.0152133144438267]
2026-01-17 13:31:50,857 : worker.worker : DEBUG : Step 139502, finished rewards -1.66, envs finished 1
2026-01-17 13:31:50,883 : worker.worker : DEBUG : Step 139506, finished rewards 12.00, envs finished 1
2026-01-17 13:31:51,063 : agent.on_policy : DEBUG : Mean Losses: [4.214513473212719]
2026-01-17 13:31:51,096 : worker.worker : DEBUG : Step 139526, finished rewards -1.11, envs finished 1
2026-01-17 13:31:51,159 : worker.worker : DEBUG : Step 139530, finished rewards 7.68, envs finished 1
2026-01-17 13:31:51,202 : worker.worker : DEBUG : Step 139537, finished rewards 29.18, envs finished 1
2026-01-17 13:31:51,331 : worker.worker : DEBUG : Step 139550, finished rewards 4.47, envs finished 1
2026-01-17 13:31:51,344 : worker.worker : DEBUG : Step 139551, finished rewards 28.90, envs finished 1
2026-01-17 13:31:51,508 : agent.on_policy : DEBUG : Mean Losses: [7.5386751517653465]
2026-01-17 13:31:51,568 : worker.worker : DEBUG : Step 139559, finished rewards 6.32, envs finished 1
2026-01-17 13:31:51,839 : agent.on_policy : DEBUG : Mean Losses: [1.534381345845759]
2026-01-17 13:31:51,953 : worker.worker : DEBUG : Step 139609, finished rewards 15.43, envs finished 1
2026-01-17 13:31:52,137 : agent.on_policy : DEBUG : Mean Losses: [4.102611195296049]
2026-01-17 13:31:52,215 : worker.worker : DEBUG : Step 139634, finished rewards 1.72, envs finished 1
2026-01-17 13:31:52,255 : worker.worker : DEBUG : Step 139642, finished rewards 18.05, envs finished 2
2026-01-17 13:31:52,293 : worker.worker : DEBUG : Step 139647, finished rewards 12.28, envs finished 1
2026-01-17 13:31:52,440 : agent.on_policy : DEBUG : Mean Losses: [8.083465322852135]
2026-01-17 13:31:52,561 : worker.worker : DEBUG : Step 139660, finished rewards 16.94, envs finished 1
2026-01-17 13:31:52,632 : worker.worker : DEBUG : Step 139664, finished rewards -9.91, envs finished 1
2026-01-17 13:31:52,707 : worker.worker : DEBUG : Step 139671, finished rewards 3.37, envs finished 1
2026-01-17 13:31:52,978 : agent.on_policy : DEBUG : Mean Losses: [6.431015215814114]
2026-01-17 13:31:53,154 : worker.worker : DEBUG : Step 139700, finished rewards 26.60, envs finished 1
2026-01-17 13:31:53,290 : agent.on_policy : DEBUG : Mean Losses: [2.7867604605853558]
2026-01-17 13:31:53,366 : worker.worker : DEBUG : Step 139719, finished rewards 36.48, envs finished 1
2026-01-17 13:31:53,445 : worker.worker : DEBUG : Step 139730, finished rewards 26.90, envs finished 1
2026-01-17 13:31:53,526 : worker.worker : DEBUG : Step 139735, finished rewards 41.63, envs finished 1
2026-01-17 13:31:53,843 : agent.on_policy : DEBUG : Mean Losses: [8.182009652256966]
2026-01-17 13:31:54,066 : worker.worker : DEBUG : Step 139768, finished rewards 21.28, envs finished 1
2026-01-17 13:31:54,111 : worker.worker : DEBUG : Step 139771, finished rewards -3.74, envs finished 1
2026-01-17 13:31:54,239 : agent.on_policy : DEBUG : Mean Losses: [5.738519176840782]
2026-01-17 13:31:54,328 : worker.worker : DEBUG : Step 139783, finished rewards 16.04, envs finished 1
2026-01-17 13:31:54,344 : worker.worker : DEBUG : Step 139785, finished rewards 29.70, envs finished 1
2026-01-17 13:31:54,457 : worker.worker : DEBUG : Step 139793, finished rewards 46.71, envs finished 1
2026-01-17 13:31:54,573 : worker.worker : DEBUG : Step 139804, finished rewards 29.53, envs finished 1
2026-01-17 13:31:54,819 : agent.on_policy : DEBUG : Mean Losses: [7.894144102931023]
2026-01-17 13:31:54,914 : worker.worker : DEBUG : Step 139818, finished rewards -32.96, envs finished 1
2026-01-17 13:31:55,154 : agent.on_policy : DEBUG : Mean Losses: [2.01744600944221]
2026-01-17 13:31:55,174 : worker.worker : DEBUG : Step 139843, finished rewards 14.20, envs finished 1
2026-01-17 13:31:55,230 : worker.worker : DEBUG : Step 139853, finished rewards 29.29, envs finished 1
2026-01-17 13:31:55,433 : agent.on_policy : DEBUG : Mean Losses: [5.132369618862867]
2026-01-17 13:31:55,489 : worker.worker : DEBUG : Step 139884, finished rewards 28.25, envs finished 1
2026-01-17 13:31:55,505 : worker.worker : DEBUG : Step 139886, finished rewards 31.90, envs finished 1
2026-01-17 13:31:55,535 : worker.worker : DEBUG : Step 139891, finished rewards 4.02, envs finished 1
2026-01-17 13:31:55,573 : worker.worker : DEBUG : Step 139896, finished rewards 11.22, envs finished 1
2026-01-17 13:31:55,787 : agent.on_policy : DEBUG : Mean Losses: [8.299675280228257]
2026-01-17 13:31:55,837 : worker.worker : DEBUG : Step 139914, finished rewards -1.34, envs finished 1
2026-01-17 13:31:55,898 : worker.worker : DEBUG : Step 139927, finished rewards 12.28, envs finished 1
2026-01-17 13:31:56,008 : worker.worker : DEBUG : Step 139935, finished rewards 24.47, envs finished 1
2026-01-17 13:31:56,144 : agent.on_policy : DEBUG : Mean Losses: [4.925566755235195]
2026-01-17 13:31:56,387 : worker.worker : DEBUG : Step 139967, finished rewards 36.49, envs finished 1
2026-01-17 13:31:56,510 : agent.on_policy : DEBUG : Mean Losses: [4.456455931067467]
2026-01-17 13:31:56,628 : worker.worker : DEBUG : Step 139984, finished rewards -3.14, envs finished 1
2026-01-17 13:31:56,729 : worker.worker : DEBUG : Step 139993, finished rewards 12.30, envs finished 1
2026-01-17 13:31:56,761 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:31:56,898 : agent.on_policy : DEBUG : Mean Losses: [6.0348754320293665]
2026-01-17 13:31:56,912 : worker.worker : INFO : Step 140000, Avg Reward 11.1135, Max Reward 46.8243, Loss [5.1596662]
2026-01-17 13:31:57,066 : worker.worker : DEBUG : Step 140019, finished rewards 0.63, envs finished 1
2026-01-17 13:31:57,129 : worker.worker : DEBUG : Step 140030, finished rewards 21.61, envs finished 1
2026-01-17 13:31:57,210 : agent.on_policy : DEBUG : Mean Losses: [4.836310889571905]
2026-01-17 13:31:57,227 : worker.worker : DEBUG : Step 140033, finished rewards 13.90, envs finished 1
2026-01-17 13:31:57,241 : worker.worker : DEBUG : Step 140034, finished rewards -8.28, envs finished 1
2026-01-17 13:31:57,664 : agent.on_policy : DEBUG : Mean Losses: [2.9896252006292343]
2026-01-17 13:31:57,686 : worker.worker : DEBUG : Step 140067, finished rewards -14.83, envs finished 1
2026-01-17 13:31:57,754 : worker.worker : DEBUG : Step 140078, finished rewards 13.60, envs finished 1
2026-01-17 13:31:57,793 : worker.worker : DEBUG : Step 140085, finished rewards 25.09, envs finished 1
2026-01-17 13:31:58,010 : agent.on_policy : DEBUG : Mean Losses: [4.77675249055028]
2026-01-17 13:31:58,042 : worker.worker : DEBUG : Step 140102, finished rewards 3.49, envs finished 1
2026-01-17 13:31:58,193 : worker.worker : DEBUG : Step 140126, finished rewards 23.13, envs finished 1
2026-01-17 13:31:58,323 : agent.on_policy : DEBUG : Mean Losses: [4.10203318297863]
2026-01-17 13:31:58,368 : worker.worker : DEBUG : Step 140132, finished rewards 16.83, envs finished 1
2026-01-17 13:31:58,455 : worker.worker : DEBUG : Step 140143, finished rewards 3.84, envs finished 1
2026-01-17 13:31:58,524 : worker.worker : DEBUG : Step 140151, finished rewards 5.29, envs finished 1
2026-01-17 13:31:58,854 : agent.on_policy : DEBUG : Mean Losses: [4.948129005730152]
2026-01-17 13:31:58,907 : worker.worker : DEBUG : Step 140168, finished rewards 30.31, envs finished 1
2026-01-17 13:31:59,130 : agent.on_policy : DEBUG : Mean Losses: [4.112627558410168]
2026-01-17 13:31:59,221 : worker.worker : DEBUG : Step 140214, finished rewards -9.08, envs finished 1
2026-01-17 13:31:59,275 : worker.worker : DEBUG : Step 140222, finished rewards 5.61, envs finished 1
2026-01-17 13:31:59,400 : agent.on_policy : DEBUG : Mean Losses: [4.528762917965651]
2026-01-17 13:31:59,497 : worker.worker : DEBUG : Step 140235, finished rewards 31.50, envs finished 1
2026-01-17 13:31:59,506 : worker.worker : DEBUG : Step 140237, finished rewards 17.09, envs finished 1
2026-01-17 13:31:59,532 : worker.worker : DEBUG : Step 140241, finished rewards -20.76, envs finished 1
2026-01-17 13:31:59,742 : agent.on_policy : DEBUG : Mean Losses: [5.666934907436371]
2026-01-17 13:31:59,743 : worker.worker : DEBUG : Step 140256, finished rewards -2.72, envs finished 1
2026-01-17 13:31:59,915 : worker.worker : DEBUG : Step 140274, finished rewards 16.53, envs finished 1
2026-01-17 13:32:00,288 : agent.on_policy : DEBUG : Mean Losses: [2.6113074868917465]
2026-01-17 13:32:00,407 : worker.worker : DEBUG : Step 140303, finished rewards -19.89, envs finished 1
2026-01-17 13:32:00,521 : worker.worker : DEBUG : Step 140318, finished rewards 32.11, envs finished 1
2026-01-17 13:31:59,874 : agent.on_policy : DEBUG : Mean Losses: [5.387465551495552]
2026-01-17 13:31:59,936 : worker.worker : DEBUG : Step 140336, finished rewards 11.66, envs finished 1
2026-01-17 13:31:59,976 : worker.worker : DEBUG : Step 140345, finished rewards -3.87, envs finished 1
2026-01-17 13:31:59,998 : worker.worker : DEBUG : Step 140350, finished rewards 9.91, envs finished 1
2026-01-17 13:32:00,111 : agent.on_policy : DEBUG : Mean Losses: [5.717812649905682]
2026-01-17 13:32:00,207 : worker.worker : DEBUG : Step 140368, finished rewards -2.20, envs finished 1
2026-01-17 13:32:00,218 : worker.worker : DEBUG : Step 140370, finished rewards 20.85, envs finished 1
2026-01-17 13:32:00,411 : agent.on_policy : DEBUG : Mean Losses: [3.7512539625167847]
2026-01-17 13:32:00,511 : worker.worker : DEBUG : Step 140396, finished rewards 25.76, envs finished 1
2026-01-17 13:32:00,516 : worker.worker : DEBUG : Step 140397, finished rewards 1.73, envs finished 1
2026-01-17 13:32:00,623 : worker.worker : DEBUG : Step 140412, finished rewards 35.29, envs finished 1
2026-01-17 13:32:00,632 : worker.worker : DEBUG : Step 140413, finished rewards 46.56, envs finished 1
2026-01-17 13:32:00,786 : agent.on_policy : DEBUG : Mean Losses: [9.158341996371746]
2026-01-17 13:32:00,814 : worker.worker : DEBUG : Step 140421, finished rewards 14.67, envs finished 1
2026-01-17 13:32:00,819 : worker.worker : DEBUG : Step 140422, finished rewards 35.44, envs finished 1
2026-01-17 13:32:01,061 : agent.on_policy : DEBUG : Mean Losses: [2.62048424128443]
2026-01-17 13:32:01,109 : worker.worker : DEBUG : Step 140459, finished rewards 26.39, envs finished 1
2026-01-17 13:32:01,157 : worker.worker : DEBUG : Step 140469, finished rewards 20.78, envs finished 1
2026-01-17 13:32:01,298 : agent.on_policy : DEBUG : Mean Losses: [4.360546916723251]
2026-01-17 13:32:01,341 : worker.worker : DEBUG : Step 140483, finished rewards 28.35, envs finished 1
2026-01-17 13:32:01,392 : worker.worker : DEBUG : Step 140490, finished rewards 41.43, envs finished 1
2026-01-17 13:32:01,478 : worker.worker : DEBUG : Step 140504, finished rewards 25.66, envs finished 1
2026-01-17 13:32:01,561 : worker.worker : DEBUG : Step 140510, finished rewards 13.02, envs finished 1
2026-01-17 13:32:01,701 : agent.on_policy : DEBUG : Mean Losses: [8.161187782883644]
2026-01-17 13:32:01,857 : worker.worker : DEBUG : Step 140535, finished rewards 37.66, envs finished 1
2026-01-17 13:32:01,909 : worker.worker : DEBUG : Step 140542, finished rewards -3.94, envs finished 1
2026-01-17 13:32:02,100 : agent.on_policy : DEBUG : Mean Losses: [5.895205453038216]
2026-01-17 13:32:02,284 : worker.worker : DEBUG : Step 140561, finished rewards -6.10, envs finished 1
2026-01-17 13:32:02,362 : worker.worker : DEBUG : Step 140569, finished rewards 28.86, envs finished 1
2026-01-17 13:32:02,591 : agent.on_policy : DEBUG : Mean Losses: [5.461469808593392]
2026-01-17 13:32:02,615 : worker.worker : DEBUG : Step 140580, finished rewards 36.59, envs finished 1
2026-01-17 13:32:02,676 : worker.worker : DEBUG : Step 140593, finished rewards 18.96, envs finished 2
2026-01-17 13:32:02,741 : worker.worker : DEBUG : Step 140602, finished rewards 9.94, envs finished 1
2026-01-17 13:32:02,958 : agent.on_policy : DEBUG : Mean Losses: [6.186061880551279]
2026-01-17 13:32:03,085 : worker.worker : DEBUG : Step 140619, finished rewards 37.28, envs finished 1
2026-01-17 13:32:03,354 : agent.on_policy : DEBUG : Mean Losses: [2.624103032052517]
2026-01-17 13:32:03,469 : worker.worker : DEBUG : Step 140655, finished rewards 4.04, envs finished 1
2026-01-17 13:32:03,661 : agent.on_policy : DEBUG : Mean Losses: [4.163529548794031]
2026-01-17 13:32:03,793 : worker.worker : DEBUG : Step 140690, finished rewards 9.86, envs finished 1
2026-01-17 13:32:03,842 : worker.worker : DEBUG : Step 140695, finished rewards 17.49, envs finished 1
2026-01-17 13:32:03,986 : agent.on_policy : DEBUG : Mean Losses: [6.119525298476219]
2026-01-17 13:32:04,103 : worker.worker : DEBUG : Step 140717, finished rewards -23.07, envs finished 1
2026-01-17 13:32:04,109 : worker.worker : DEBUG : Step 140718, finished rewards -18.50, envs finished 1
2026-01-17 13:32:04,135 : worker.worker : DEBUG : Step 140722, finished rewards 2.83, envs finished 1
2026-01-17 13:32:04,247 : worker.worker : DEBUG : Step 140735, finished rewards -6.33, envs finished 1
2026-01-17 13:32:04,361 : agent.on_policy : DEBUG : Mean Losses: [8.518807135522366]
2026-01-17 13:32:04,500 : worker.worker : DEBUG : Step 140759, finished rewards 16.43, envs finished 1
2026-01-17 13:32:04,644 : agent.on_policy : DEBUG : Mean Losses: [3.639600705355406]
2026-01-17 13:32:04,673 : worker.worker : DEBUG : Step 140772, finished rewards -16.10, envs finished 1
2026-01-17 13:32:04,945 : agent.on_policy : DEBUG : Mean Losses: [3.836262736469507]
2026-01-17 13:32:04,959 : worker.worker : DEBUG : Step 140802, finished rewards 15.09, envs finished 1
2026-01-17 13:32:04,980 : worker.worker : DEBUG : Step 140805, finished rewards 27.19, envs finished 1
2026-01-17 13:32:05,072 : worker.worker : DEBUG : Step 140823, finished rewards 18.09, envs finished 1
2026-01-17 13:32:05,085 : worker.worker : DEBUG : Step 140825, finished rewards -8.20, envs finished 1
2026-01-17 13:32:05,231 : agent.on_policy : DEBUG : Mean Losses: [5.5529680997133255]
2026-01-17 13:32:05,355 : worker.worker : DEBUG : Step 140849, finished rewards -3.14, envs finished 1
2026-01-17 13:32:05,530 : agent.on_policy : DEBUG : Mean Losses: [3.1501838341355324]
2026-01-17 13:32:05,640 : worker.worker : DEBUG : Step 140890, finished rewards -7.01, envs finished 1
2026-01-17 13:32:05,795 : agent.on_policy : DEBUG : Mean Losses: [3.565378524363041]
2026-01-17 13:32:05,826 : worker.worker : DEBUG : Step 140906, finished rewards -4.62, envs finished 1
2026-01-17 13:32:05,839 : worker.worker : DEBUG : Step 140908, finished rewards 14.00, envs finished 1
2026-01-17 13:32:06,096 : agent.on_policy : DEBUG : Mean Losses: [5.597638875246048]
2026-01-17 13:32:06,180 : worker.worker : DEBUG : Step 140934, finished rewards 10.44, envs finished 1
2026-01-17 13:32:06,271 : worker.worker : DEBUG : Step 140945, finished rewards 0.17, envs finished 1
2026-01-17 13:32:06,286 : worker.worker : DEBUG : Step 140946, finished rewards -4.65, envs finished 1
2026-01-17 13:32:06,399 : worker.worker : DEBUG : Step 140957, finished rewards -61.94, envs finished 1
2026-01-17 13:32:06,561 : agent.on_policy : DEBUG : Mean Losses: [6.345722705125809]
2026-01-17 13:32:06,628 : worker.worker : DEBUG : Step 140970, finished rewards 4.79, envs finished 1
2026-01-17 13:32:06,729 : worker.worker : DEBUG : Step 140986, finished rewards 33.48, envs finished 1
2026-01-17 13:32:06,875 : agent.on_policy : DEBUG : Mean Losses: [5.376457720994949]
2026-01-17 13:32:06,908 : worker.worker : DEBUG : Step 140997, finished rewards 26.43, envs finished 1
2026-01-17 13:32:06,927 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:32:07,069 : worker.worker : DEBUG : Step 141012, finished rewards 1.93, envs finished 1
2026-01-17 13:32:07,330 : agent.on_policy : DEBUG : Mean Losses: [3.459709981456399]
2026-01-17 13:32:07,395 : worker.worker : DEBUG : Step 141036, finished rewards 18.52, envs finished 1
2026-01-17 13:32:07,442 : worker.worker : DEBUG : Step 141049, finished rewards 13.62, envs finished 1
2026-01-17 13:32:07,449 : worker.worker : DEBUG : Step 141051, finished rewards 14.82, envs finished 1
2026-01-17 13:32:07,592 : agent.on_policy : DEBUG : Mean Losses: [6.284415245056152]
2026-01-17 13:32:07,614 : worker.worker : DEBUG : Step 141062, finished rewards 25.48, envs finished 1
2026-01-17 13:32:07,656 : worker.worker : DEBUG : Step 141073, finished rewards 27.72, envs finished 1
2026-01-17 13:32:07,754 : agent.on_policy : DEBUG : Mean Losses: [3.56896448507905]
2026-01-17 13:32:07,755 : worker.worker : DEBUG : Step 141088, finished rewards 10.31, envs finished 1
2026-01-17 13:32:07,763 : worker.worker : DEBUG : Step 141090, finished rewards 24.98, envs finished 1
2026-01-17 13:32:07,841 : worker.worker : DEBUG : Step 141098, finished rewards 29.34, envs finished 1
2026-01-17 13:32:08,229 : agent.on_policy : DEBUG : Mean Losses: [3.640551089309156]
2026-01-17 13:32:08,257 : worker.worker : DEBUG : Step 141122, finished rewards 28.68, envs finished 1
2026-01-17 13:32:08,304 : worker.worker : DEBUG : Step 141127, finished rewards 38.15, envs finished 1
2026-01-17 13:32:08,686 : agent.on_policy : DEBUG : Mean Losses: [3.035108271986246]
2026-01-17 13:32:08,715 : worker.worker : DEBUG : Step 141156, finished rewards 22.82, envs finished 1
2026-01-17 13:32:08,734 : worker.worker : DEBUG : Step 141159, finished rewards 28.70, envs finished 1
2026-01-17 13:32:08,747 : worker.worker : DEBUG : Step 141161, finished rewards 10.67, envs finished 1
2026-01-17 13:32:08,891 : worker.worker : DEBUG : Step 141174, finished rewards 28.69, envs finished 1
2026-01-17 13:32:08,999 : worker.worker : DEBUG : Step 141183, finished rewards 29.15, envs finished 1
2026-01-17 13:32:09,141 : agent.on_policy : DEBUG : Mean Losses: [8.038467898964882]
2026-01-17 13:32:09,147 : worker.worker : DEBUG : Step 141184, finished rewards 22.10, envs finished 1
2026-01-17 13:32:09,587 : worker.worker : DEBUG : Step 141214, finished rewards 24.17, envs finished 1
2026-01-17 13:32:10,025 : agent.on_policy : DEBUG : Mean Losses: [2.8725160658359528]
2026-01-17 13:32:10,112 : worker.worker : DEBUG : Step 141230, finished rewards 41.51, envs finished 1
2026-01-17 13:32:10,445 : agent.on_policy : DEBUG : Mean Losses: [4.203631829470396]
2026-01-17 13:32:10,449 : worker.worker : DEBUG : Step 141248, finished rewards 2.39, envs finished 1
2026-01-17 13:32:10,490 : worker.worker : DEBUG : Step 141250, finished rewards 23.04, envs finished 1
2026-01-17 13:32:10,758 : worker.worker : DEBUG : Step 141275, finished rewards 19.61, envs finished 1
2026-01-17 13:32:10,976 : agent.on_policy : DEBUG : Mean Losses: [4.6380483359098434]
2026-01-17 13:32:11,002 : worker.worker : DEBUG : Step 141284, finished rewards 20.00, envs finished 1
2026-01-17 13:32:11,187 : worker.worker : DEBUG : Step 141304, finished rewards -8.04, envs finished 1
2026-01-17 13:32:11,564 : agent.on_policy : DEBUG : Mean Losses: [5.610362157225609]
2026-01-17 13:32:11,921 : worker.worker : DEBUG : Step 141337, finished rewards 30.33, envs finished 1
2026-01-17 13:32:12,417 : agent.on_policy : DEBUG : Mean Losses: [4.493797406554222]
2026-01-17 13:32:12,423 : worker.worker : DEBUG : Step 141344, finished rewards 10.50, envs finished 1
2026-01-17 13:32:12,516 : worker.worker : DEBUG : Step 141355, finished rewards 41.72, envs finished 1
2026-01-17 13:32:12,552 : worker.worker : DEBUG : Step 141358, finished rewards -13.31, envs finished 1
2026-01-17 13:32:12,621 : worker.worker : DEBUG : Step 141363, finished rewards -36.90, envs finished 1
2026-01-17 13:32:12,744 : worker.worker : DEBUG : Step 141371, finished rewards 3.79, envs finished 1
2026-01-17 13:32:13,529 : agent.on_policy : DEBUG : Mean Losses: [7.464499235153198]
2026-01-17 13:32:13,882 : worker.worker : DEBUG : Step 141397, finished rewards 2.30, envs finished 1
2026-01-17 13:32:14,230 : agent.on_policy : DEBUG : Mean Losses: [3.234631635248661]
2026-01-17 13:32:14,263 : worker.worker : DEBUG : Step 141413, finished rewards 10.57, envs finished 1
2026-01-17 13:32:14,319 : worker.worker : DEBUG : Step 141421, finished rewards 35.71, envs finished 1
2026-01-17 13:32:14,345 : worker.worker : DEBUG : Step 141425, finished rewards 41.38, envs finished 1
2026-01-17 13:32:14,612 : agent.on_policy : DEBUG : Mean Losses: [6.636135324835777]
2026-01-17 13:32:14,695 : worker.worker : DEBUG : Step 141445, finished rewards 12.79, envs finished 1
2026-01-17 13:32:14,789 : worker.worker : DEBUG : Step 141451, finished rewards 26.73, envs finished 1
2026-01-17 13:32:15,486 : agent.on_policy : DEBUG : Mean Losses: [4.093689262866974]
2026-01-17 13:32:15,704 : worker.worker : DEBUG : Step 141494, finished rewards -8.82, envs finished 1
2026-01-17 13:32:15,767 : worker.worker : DEBUG : Step 141498, finished rewards -3.10, envs finished 1
2026-01-17 13:32:15,956 : agent.on_policy : DEBUG : Mean Losses: [4.541353918612003]
2026-01-17 13:32:16,187 : worker.worker : DEBUG : Step 141524, finished rewards 6.56, envs finished 2
2026-01-17 13:32:16,301 : worker.worker : DEBUG : Step 141532, finished rewards 28.45, envs finished 1
2026-01-17 13:32:16,566 : agent.on_policy : DEBUG : Mean Losses: [6.89137414470315]
2026-01-17 13:32:16,682 : worker.worker : DEBUG : Step 141544, finished rewards 1.38, envs finished 1
2026-01-17 13:32:17,049 : agent.on_policy : DEBUG : Mean Losses: [3.6378494650125504]
2026-01-17 13:32:17,125 : worker.worker : DEBUG : Step 141580, finished rewards 28.06, envs finished 1
2026-01-17 13:32:17,234 : worker.worker : DEBUG : Step 141593, finished rewards 42.31, envs finished 1
2026-01-17 13:32:17,544 : agent.on_policy : DEBUG : Mean Losses: [6.564963407814503]
2026-01-17 13:32:17,602 : worker.worker : DEBUG : Step 141608, finished rewards 10.27, envs finished 1
2026-01-17 13:32:17,796 : worker.worker : DEBUG : Step 141626, finished rewards -34.56, envs finished 1
2026-01-17 13:32:17,815 : worker.worker : DEBUG : Step 141627, finished rewards 21.71, envs finished 1
2026-01-17 13:32:18,050 : agent.on_policy : DEBUG : Mean Losses: [5.7213082909584045]
2026-01-17 13:32:18,127 : worker.worker : DEBUG : Step 141638, finished rewards -54.94, envs finished 1
2026-01-17 13:32:18,387 : worker.worker : DEBUG : Step 141661, finished rewards 5.91, envs finished 1
2026-01-17 13:32:18,578 : agent.on_policy : DEBUG : Mean Losses: [5.023428820073605]
2026-01-17 13:32:18,626 : worker.worker : DEBUG : Step 141665, finished rewards 28.00, envs finished 1
2026-01-17 13:32:18,989 : agent.on_policy : DEBUG : Mean Losses: [2.167989421170205]
2026-01-17 13:32:19,055 : worker.worker : DEBUG : Step 141708, finished rewards 20.32, envs finished 1
2026-01-17 13:32:19,076 : worker.worker : DEBUG : Step 141711, finished rewards 6.30, envs finished 1
2026-01-17 13:32:19,142 : worker.worker : DEBUG : Step 141719, finished rewards 24.67, envs finished 1
2026-01-17 13:32:19,157 : worker.worker : DEBUG : Step 141720, finished rewards -39.33, envs finished 1
2026-01-17 13:32:19,217 : worker.worker : DEBUG : Step 141723, finished rewards 30.98, envs finished 1
2026-01-17 13:32:19,448 : agent.on_policy : DEBUG : Mean Losses: [7.923245042562485]
2026-01-17 13:32:19,843 : worker.worker : DEBUG : Step 141755, finished rewards 23.06, envs finished 1
2026-01-17 13:32:19,898 : worker.worker : DEBUG : Step 141758, finished rewards -3.18, envs finished 1
2026-01-17 13:32:19,922 : worker.worker : DEBUG : Step 141759, finished rewards 23.68, envs finished 1
2026-01-17 13:32:20,171 : agent.on_policy : DEBUG : Mean Losses: [6.696585275232792]
2026-01-17 13:32:20,314 : worker.worker : DEBUG : Step 141785, finished rewards 35.63, envs finished 1
2026-01-17 13:32:20,544 : agent.on_policy : DEBUG : Mean Losses: [3.2087532486766577]
2026-01-17 13:32:20,697 : worker.worker : DEBUG : Step 141816, finished rewards 23.09, envs finished 1
2026-01-17 13:32:20,975 : agent.on_policy : DEBUG : Mean Losses: [4.222717568278313]
2026-01-17 13:32:21,077 : worker.worker : DEBUG : Step 141837, finished rewards 11.81, envs finished 1
2026-01-17 13:32:21,297 : worker.worker : DEBUG : Step 141855, finished rewards 21.75, envs finished 1
2026-01-17 13:32:21,513 : agent.on_policy : DEBUG : Mean Losses: [5.737721607089043]
2026-01-17 13:32:21,569 : worker.worker : DEBUG : Step 141860, finished rewards -4.17, envs finished 1
2026-01-17 13:32:21,641 : worker.worker : DEBUG : Step 141866, finished rewards -25.58, envs finished 1
2026-01-17 13:32:21,756 : worker.worker : DEBUG : Step 141871, finished rewards 6.72, envs finished 1
2026-01-17 13:32:21,880 : worker.worker : DEBUG : Step 141881, finished rewards 22.78, envs finished 1
2026-01-17 13:32:22,099 : agent.on_policy : DEBUG : Mean Losses: [6.728833399713039]
2026-01-17 13:32:22,293 : worker.worker : DEBUG : Step 141911, finished rewards -15.56, envs finished 1
2026-01-17 13:32:22,513 : agent.on_policy : DEBUG : Mean Losses: [4.468375075608492]
2026-01-17 13:32:22,539 : worker.worker : DEBUG : Step 141922, finished rewards 29.82, envs finished 1
2026-01-17 13:32:22,596 : worker.worker : DEBUG : Step 141924, finished rewards 12.70, envs finished 1
2026-01-17 13:32:23,168 : agent.on_policy : DEBUG : Mean Losses: [3.384396854788065]
2026-01-17 13:32:23,189 : worker.worker : DEBUG : Step 141953, finished rewards 24.66, envs finished 1
2026-01-17 13:32:23,317 : worker.worker : DEBUG : Step 141963, finished rewards 17.68, envs finished 2
2026-01-17 13:32:23,368 : worker.worker : DEBUG : Step 141968, finished rewards 28.82, envs finished 1
2026-01-17 13:32:23,644 : agent.on_policy : DEBUG : Mean Losses: [6.09317609667778]
2026-01-17 13:32:23,688 : worker.worker : DEBUG : Step 141988, finished rewards 8.11, envs finished 1
2026-01-17 13:32:23,775 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:32:24,066 : agent.on_policy : DEBUG : Mean Losses: [2.7174066603183746]
2026-01-17 13:32:24,213 : worker.worker : DEBUG : Step 142034, finished rewards 8.31, envs finished 1
2026-01-17 13:32:24,284 : worker.worker : DEBUG : Step 142039, finished rewards 36.80, envs finished 1
2026-01-17 13:32:24,318 : worker.worker : DEBUG : Step 142045, finished rewards 35.42, envs finished 1
2026-01-17 13:32:24,504 : agent.on_policy : DEBUG : Mean Losses: [9.15969430655241]
2026-01-17 13:32:24,506 : worker.worker : DEBUG : Step 142048, finished rewards 28.62, envs finished 1
2026-01-17 13:32:24,561 : worker.worker : DEBUG : Step 142052, finished rewards -1.43, envs finished 1
2026-01-17 13:32:24,664 : worker.worker : DEBUG : Step 142060, finished rewards 17.77, envs finished 1
2026-01-17 13:32:24,772 : worker.worker : DEBUG : Step 142075, finished rewards 28.37, envs finished 1
2026-01-17 13:32:24,939 : agent.on_policy : DEBUG : Mean Losses: [5.432168675586581]
2026-01-17 13:32:25,260 : agent.on_policy : DEBUG : Mean Losses: [1.8211760940030217]
2026-01-17 13:32:25,294 : worker.worker : DEBUG : Step 142117, finished rewards 34.98, envs finished 1
2026-01-17 13:32:25,310 : worker.worker : DEBUG : Step 142120, finished rewards 29.56, envs finished 1
2026-01-17 13:32:25,562 : agent.on_policy : DEBUG : Mean Losses: [5.178422823548317]
2026-01-17 13:32:25,833 : worker.worker : DEBUG : Step 142171, finished rewards 5.97, envs finished 1
2026-01-17 13:32:25,853 : worker.worker : DEBUG : Step 142172, finished rewards 21.24, envs finished 1
2026-01-17 13:32:26,295 : agent.on_policy : DEBUG : Mean Losses: [6.542678859084845]
2026-01-17 13:32:26,417 : worker.worker : DEBUG : Step 142189, finished rewards 0.10, envs finished 1
2026-01-17 13:32:26,451 : worker.worker : DEBUG : Step 142194, finished rewards -6.17, envs finished 1
2026-01-17 13:32:26,579 : worker.worker : DEBUG : Step 142207, finished rewards -15.20, envs finished 1
2026-01-17 13:32:26,807 : agent.on_policy : DEBUG : Mean Losses: [6.907760392874479]
2026-01-17 13:32:26,825 : worker.worker : DEBUG : Step 142210, finished rewards 25.84, envs finished 1
2026-01-17 13:32:26,885 : worker.worker : DEBUG : Step 142217, finished rewards 20.62, envs finished 1
2026-01-17 13:32:27,205 : agent.on_policy : DEBUG : Mean Losses: [2.5312544479966164]
2026-01-17 13:32:27,251 : worker.worker : DEBUG : Step 142248, finished rewards -40.25, envs finished 1
2026-01-17 13:32:27,525 : agent.on_policy : DEBUG : Mean Losses: [3.6410127133131027]
2026-01-17 13:32:27,532 : worker.worker : DEBUG : Step 142273, finished rewards 46.47, envs finished 1
2026-01-17 13:32:27,545 : worker.worker : DEBUG : Step 142274, finished rewards 29.70, envs finished 1
2026-01-17 13:32:27,591 : worker.worker : DEBUG : Step 142280, finished rewards 13.23, envs finished 1
2026-01-17 13:32:27,656 : worker.worker : DEBUG : Step 142289, finished rewards 4.88, envs finished 1
2026-01-17 13:32:27,872 : agent.on_policy : DEBUG : Mean Losses: [5.845790535211563]
2026-01-17 13:32:27,903 : worker.worker : DEBUG : Step 142306, finished rewards 22.09, envs finished 1
2026-01-17 13:32:28,005 : worker.worker : DEBUG : Step 142315, finished rewards 6.04, envs finished 1
2026-01-17 13:32:28,270 : agent.on_policy : DEBUG : Mean Losses: [4.662169367074966]
2026-01-17 13:32:28,283 : worker.worker : DEBUG : Step 142338, finished rewards 25.74, envs finished 2
2026-01-17 13:32:28,366 : worker.worker : DEBUG : Step 142354, finished rewards 14.10, envs finished 1
2026-01-17 13:32:28,550 : agent.on_policy : DEBUG : Mean Losses: [3.636189851909876]
2026-01-17 13:32:28,767 : worker.worker : DEBUG : Step 142383, finished rewards 10.50, envs finished 1
2026-01-17 13:32:28,907 : worker.worker : DEBUG : Step 142394, finished rewards 25.40, envs finished 2
2026-01-17 13:32:28,946 : worker.worker : DEBUG : Step 142399, finished rewards 24.76, envs finished 1
2026-01-17 13:32:29,137 : agent.on_policy : DEBUG : Mean Losses: [7.220166467130184]
2026-01-17 13:32:29,310 : worker.worker : DEBUG : Step 142413, finished rewards -6.84, envs finished 1
2026-01-17 13:32:29,406 : worker.worker : DEBUG : Step 142423, finished rewards 29.64, envs finished 1
2026-01-17 13:32:29,639 : agent.on_policy : DEBUG : Mean Losses: [3.64971717633307]
2026-01-17 13:32:29,745 : worker.worker : DEBUG : Step 142451, finished rewards 19.56, envs finished 1
2026-01-17 13:32:29,596 : agent.on_policy : DEBUG : Mean Losses: [2.5802787225693464]
2026-01-17 13:32:29,658 : worker.worker : DEBUG : Step 142468, finished rewards 7.62, envs finished 1
2026-01-17 13:32:29,820 : worker.worker : DEBUG : Step 142476, finished rewards 23.86, envs finished 1
2026-01-17 13:32:29,858 : worker.worker : DEBUG : Step 142479, finished rewards 28.96, envs finished 1
2026-01-17 13:32:30,015 : worker.worker : DEBUG : Step 142488, finished rewards 25.18, envs finished 1
2026-01-17 13:32:30,325 : agent.on_policy : DEBUG : Mean Losses: [6.166962191462517]
2026-01-17 13:32:30,373 : worker.worker : DEBUG : Step 142503, finished rewards 15.68, envs finished 1
2026-01-17 13:32:30,516 : worker.worker : DEBUG : Step 142518, finished rewards 15.35, envs finished 1
2026-01-17 13:32:30,866 : agent.on_policy : DEBUG : Mean Losses: [3.0668930374085903]
2026-01-17 13:32:30,947 : worker.worker : DEBUG : Step 142539, finished rewards 10.78, envs finished 1
2026-01-17 13:32:31,329 : agent.on_policy : DEBUG : Mean Losses: [3.7763741761446]
2026-01-17 13:32:31,340 : worker.worker : DEBUG : Step 142561, finished rewards 28.93, envs finished 1
2026-01-17 13:32:31,361 : worker.worker : DEBUG : Step 142564, finished rewards 8.52, envs finished 1
2026-01-17 13:32:31,504 : worker.worker : DEBUG : Step 142582, finished rewards 16.29, envs finished 1
2026-01-17 13:32:31,848 : agent.on_policy : DEBUG : Mean Losses: [4.136283028870821]
2026-01-17 13:32:32,224 : worker.worker : DEBUG : Step 142614, finished rewards -3.26, envs finished 1
2026-01-17 13:32:32,311 : worker.worker : DEBUG : Step 142619, finished rewards 6.65, envs finished 1
2026-01-17 13:32:32,624 : agent.on_policy : DEBUG : Mean Losses: [6.4209321066737175]
2026-01-17 13:32:32,676 : worker.worker : DEBUG : Step 142628, finished rewards -12.16, envs finished 1
2026-01-17 13:32:32,765 : worker.worker : DEBUG : Step 142636, finished rewards 5.45, envs finished 1
2026-01-17 13:32:32,931 : worker.worker : DEBUG : Step 142647, finished rewards 28.60, envs finished 1
2026-01-17 13:32:33,846 : agent.on_policy : DEBUG : Mean Losses: [6.677281055599451]
2026-01-17 13:32:33,859 : worker.worker : DEBUG : Step 142656, finished rewards 25.59, envs finished 1
2026-01-17 13:32:34,070 : worker.worker : DEBUG : Step 142669, finished rewards 27.54, envs finished 1
2026-01-17 13:32:34,091 : worker.worker : DEBUG : Step 142670, finished rewards -1.16, envs finished 1
2026-01-17 13:32:34,673 : agent.on_policy : DEBUG : Mean Losses: [4.087050257250667]
2026-01-17 13:32:34,881 : worker.worker : DEBUG : Step 142703, finished rewards 38.30, envs finished 1
2026-01-17 13:32:35,275 : agent.on_policy : DEBUG : Mean Losses: [3.8633468598127365]
2026-01-17 13:32:35,394 : worker.worker : DEBUG : Step 142730, finished rewards 7.61, envs finished 1
2026-01-17 13:32:35,485 : worker.worker : DEBUG : Step 142737, finished rewards 7.22, envs finished 1
2026-01-17 13:32:35,786 : agent.on_policy : DEBUG : Mean Losses: [5.992255501449108]
2026-01-17 13:32:35,820 : worker.worker : DEBUG : Step 142758, finished rewards 11.32, envs finished 2
2026-01-17 13:32:36,285 : agent.on_policy : DEBUG : Mean Losses: [5.2175503596663475]
2026-01-17 13:32:36,307 : worker.worker : DEBUG : Step 142787, finished rewards -3.90, envs finished 1
2026-01-17 13:32:36,382 : worker.worker : DEBUG : Step 142796, finished rewards 23.48, envs finished 1
2026-01-17 13:32:36,439 : worker.worker : DEBUG : Step 142803, finished rewards -3.51, envs finished 1
2026-01-17 13:32:36,684 : agent.on_policy : DEBUG : Mean Losses: [5.659418314695358]
2026-01-17 13:32:36,751 : worker.worker : DEBUG : Step 142826, finished rewards 26.08, envs finished 1
2026-01-17 13:32:36,779 : worker.worker : DEBUG : Step 142830, finished rewards -15.51, envs finished 1
2026-01-17 13:32:36,788 : worker.worker : DEBUG : Step 142831, finished rewards 20.26, envs finished 1
2026-01-17 13:32:37,017 : agent.on_policy : DEBUG : Mean Losses: [6.146715074777603]
2026-01-17 13:32:37,065 : worker.worker : DEBUG : Step 142857, finished rewards 42.80, envs finished 1
2026-01-17 13:32:37,192 : worker.worker : DEBUG : Step 142878, finished rewards 3.02, envs finished 1
2026-01-17 13:32:37,427 : agent.on_policy : DEBUG : Mean Losses: [4.198464099317789]
2026-01-17 13:32:37,461 : worker.worker : DEBUG : Step 142882, finished rewards 0.20, envs finished 1
2026-01-17 13:32:37,617 : worker.worker : DEBUG : Step 142905, finished rewards 13.64, envs finished 1
2026-01-17 13:32:37,774 : agent.on_policy : DEBUG : Mean Losses: [3.489399453625083]
2026-01-17 13:32:37,936 : worker.worker : DEBUG : Step 142929, finished rewards 0.03, envs finished 1
2026-01-17 13:32:37,954 : worker.worker : DEBUG : Step 142930, finished rewards 20.24, envs finished 1
2026-01-17 13:32:38,252 : agent.on_policy : DEBUG : Mean Losses: [6.057449102401733]
2026-01-17 13:32:38,309 : worker.worker : DEBUG : Step 142952, finished rewards 5.00, envs finished 1
2026-01-17 13:32:38,371 : worker.worker : DEBUG : Step 142959, finished rewards -5.71, envs finished 1
2026-01-17 13:32:38,486 : worker.worker : DEBUG : Step 142968, finished rewards 14.28, envs finished 1
2026-01-17 13:32:38,713 : agent.on_policy : DEBUG : Mean Losses: [4.71634853631258]
2026-01-17 13:32:38,931 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:32:39,028 : worker.worker : DEBUG : Step 143005, finished rewards 37.85, envs finished 1
2026-01-17 13:32:39,200 : agent.on_policy : DEBUG : Mean Losses: [5.812198027968407]
2026-01-17 13:32:39,276 : worker.worker : DEBUG : Step 143016, finished rewards 7.55, envs finished 1
2026-01-17 13:32:39,477 : worker.worker : DEBUG : Step 143028, finished rewards -9.75, envs finished 1
2026-01-17 13:32:39,509 : worker.worker : DEBUG : Step 143029, finished rewards 17.87, envs finished 1
2026-01-17 13:32:39,957 : agent.on_policy : DEBUG : Mean Losses: [7.086525987833738]
2026-01-17 13:32:40,078 : worker.worker : DEBUG : Step 143051, finished rewards 31.00, envs finished 1
2026-01-17 13:32:40,111 : worker.worker : DEBUG : Step 143055, finished rewards -9.22, envs finished 1
2026-01-17 13:32:40,128 : worker.worker : DEBUG : Step 143056, finished rewards 15.28, envs finished 1
2026-01-17 13:32:40,404 : agent.on_policy : DEBUG : Mean Losses: [4.294680589810014]
2026-01-17 13:32:40,713 : agent.on_policy : DEBUG : Mean Losses: [2.1679410338401794]
2026-01-17 13:32:40,780 : worker.worker : DEBUG : Step 143114, finished rewards 28.87, envs finished 1
2026-01-17 13:32:40,809 : worker.worker : DEBUG : Step 143118, finished rewards 16.53, envs finished 1
2026-01-17 13:32:40,826 : worker.worker : DEBUG : Step 143120, finished rewards 7.48, envs finished 1
2026-01-17 13:32:40,968 : worker.worker : DEBUG : Step 143132, finished rewards 15.22, envs finished 1
2026-01-17 13:32:41,216 : agent.on_policy : DEBUG : Mean Losses: [8.657226800918579]
2026-01-17 13:32:41,342 : worker.worker : DEBUG : Step 143146, finished rewards 21.71, envs finished 1
2026-01-17 13:32:41,544 : worker.worker : DEBUG : Step 143165, finished rewards 11.42, envs finished 1
2026-01-17 13:32:41,737 : agent.on_policy : DEBUG : Mean Losses: [4.501140732318163]
2026-01-17 13:32:41,759 : worker.worker : DEBUG : Step 143170, finished rewards -29.24, envs finished 1
2026-01-17 13:32:41,841 : worker.worker : DEBUG : Step 143182, finished rewards 0.14, envs finished 1
2026-01-17 13:32:42,080 : agent.on_policy : DEBUG : Mean Losses: [2.825367420911789]
2026-01-17 13:32:42,095 : worker.worker : DEBUG : Step 143202, finished rewards 32.10, envs finished 1
2026-01-17 13:32:42,269 : worker.worker : DEBUG : Step 143220, finished rewards 13.28, envs finished 1
2026-01-17 13:32:42,631 : agent.on_policy : DEBUG : Mean Losses: [4.828198283910751]
2026-01-17 13:32:42,639 : worker.worker : DEBUG : Step 143232, finished rewards 13.20, envs finished 1
2026-01-17 13:32:42,710 : worker.worker : DEBUG : Step 143238, finished rewards 25.59, envs finished 1
2026-01-17 13:32:42,796 : worker.worker : DEBUG : Step 143243, finished rewards 15.38, envs finished 1
2026-01-17 13:32:42,945 : worker.worker : DEBUG : Step 143250, finished rewards 29.22, envs finished 1
2026-01-17 13:32:43,177 : agent.on_policy : DEBUG : Mean Losses: [5.405245143920183]
2026-01-17 13:32:43,213 : worker.worker : DEBUG : Step 143269, finished rewards 19.32, envs finished 1
2026-01-17 13:32:43,226 : worker.worker : DEBUG : Step 143270, finished rewards 29.67, envs finished 1
2026-01-17 13:32:43,437 : worker.worker : DEBUG : Step 143295, finished rewards 23.69, envs finished 1
2026-01-17 13:32:43,621 : agent.on_policy : DEBUG : Mean Losses: [3.6606302969157696]
2026-01-17 13:32:43,965 : agent.on_policy : DEBUG : Mean Losses: [3.2703052586875856]
2026-01-17 13:32:44,032 : worker.worker : DEBUG : Step 143342, finished rewards 21.52, envs finished 1
2026-01-17 13:32:44,075 : worker.worker : DEBUG : Step 143348, finished rewards 9.33, envs finished 1
2026-01-17 13:32:44,092 : worker.worker : DEBUG : Step 143351, finished rewards 4.80, envs finished 1
2026-01-17 13:32:44,103 : worker.worker : DEBUG : Step 143352, finished rewards 17.57, envs finished 1
2026-01-17 13:32:44,146 : worker.worker : DEBUG : Step 143355, finished rewards 28.90, envs finished 1
2026-01-17 13:32:44,253 : agent.on_policy : DEBUG : Mean Losses: [8.357830941677094]
2026-01-17 13:32:44,270 : worker.worker : DEBUG : Step 143363, finished rewards 23.98, envs finished 1
2026-01-17 13:32:44,386 : worker.worker : DEBUG : Step 143374, finished rewards -21.65, envs finished 1
2026-01-17 13:32:44,631 : agent.on_policy : DEBUG : Mean Losses: [2.692240886390209]
2026-01-17 13:32:44,787 : worker.worker : DEBUG : Step 143407, finished rewards 8.59, envs finished 1
2026-01-17 13:32:45,031 : agent.on_policy : DEBUG : Mean Losses: [3.0627400800585747]
2026-01-17 13:32:45,036 : worker.worker : DEBUG : Step 143424, finished rewards 41.92, envs finished 1
2026-01-17 13:32:45,357 : agent.on_policy : DEBUG : Mean Losses: [3.5754953995347023]
2026-01-17 13:32:45,400 : worker.worker : DEBUG : Step 143466, finished rewards 14.79, envs finished 1
2026-01-17 13:32:45,471 : worker.worker : DEBUG : Step 143481, finished rewards 12.59, envs finished 1
2026-01-17 13:32:45,572 : agent.on_policy : DEBUG : Mean Losses: [6.8475412130355835]
2026-01-17 13:32:45,575 : worker.worker : DEBUG : Step 143488, finished rewards -11.23, envs finished 1
2026-01-17 13:32:45,615 : worker.worker : DEBUG : Step 143490, finished rewards 30.51, envs finished 1
2026-01-17 13:32:45,643 : worker.worker : DEBUG : Step 143492, finished rewards -8.14, envs finished 2
2026-01-17 13:32:45,899 : agent.on_policy : DEBUG : Mean Losses: [4.748838387429714]
2026-01-17 13:32:45,933 : worker.worker : DEBUG : Step 143526, finished rewards 14.42, envs finished 1
2026-01-17 13:32:46,060 : worker.worker : DEBUG : Step 143544, finished rewards -26.30, envs finished 1
2026-01-17 13:32:46,224 : agent.on_policy : DEBUG : Mean Losses: [4.090666074305773]
2026-01-17 13:32:46,593 : agent.on_policy : DEBUG : Mean Losses: [4.394904643297195]
2026-01-17 13:32:46,603 : worker.worker : DEBUG : Step 143584, finished rewards 22.61, envs finished 1
2026-01-17 13:32:46,679 : worker.worker : DEBUG : Step 143591, finished rewards 18.28, envs finished 1
2026-01-17 13:32:46,848 : worker.worker : DEBUG : Step 143611, finished rewards 4.54, envs finished 1
2026-01-17 13:32:46,983 : agent.on_policy : DEBUG : Mean Losses: [6.473560675978661]
2026-01-17 13:32:47,023 : worker.worker : DEBUG : Step 143622, finished rewards 21.68, envs finished 1
2026-01-17 13:32:47,052 : worker.worker : DEBUG : Step 143627, finished rewards -24.41, envs finished 1
2026-01-17 13:32:47,094 : worker.worker : DEBUG : Step 143635, finished rewards -2.97, envs finished 1
2026-01-17 13:32:47,133 : worker.worker : DEBUG : Step 143637, finished rewards 24.52, envs finished 1
2026-01-17 13:32:47,271 : agent.on_policy : DEBUG : Mean Losses: [7.546887144446373]
2026-01-17 13:32:47,580 : agent.on_policy : DEBUG : Mean Losses: [2.1989839375019073]
2026-01-17 13:32:47,588 : worker.worker : DEBUG : Step 143681, finished rewards 20.73, envs finished 1
2026-01-17 13:32:47,594 : worker.worker : DEBUG : Step 143682, finished rewards 26.23, envs finished 1
2026-01-17 13:32:47,646 : worker.worker : DEBUG : Step 143692, finished rewards -64.89, envs finished 1
2026-01-17 13:32:47,843 : agent.on_policy : DEBUG : Mean Losses: [4.671924516558647]
2026-01-17 13:32:47,889 : worker.worker : DEBUG : Step 143719, finished rewards 24.94, envs finished 1
2026-01-17 13:32:47,927 : worker.worker : DEBUG : Step 143725, finished rewards 16.54, envs finished 1
2026-01-17 13:32:47,940 : worker.worker : DEBUG : Step 143727, finished rewards 5.13, envs finished 1
2026-01-17 13:32:48,006 : worker.worker : DEBUG : Step 143741, finished rewards 18.61, envs finished 1
2026-01-17 13:32:48,111 : agent.on_policy : DEBUG : Mean Losses: [6.448544453829527]
2026-01-17 13:32:48,160 : worker.worker : DEBUG : Step 143752, finished rewards 6.41, envs finished 1
2026-01-17 13:32:48,603 : agent.on_policy : DEBUG : Mean Losses: [3.0512163415551186]
2026-01-17 13:32:48,685 : worker.worker : DEBUG : Step 143794, finished rewards 16.82, envs finished 1
2026-01-17 13:32:48,722 : worker.worker : DEBUG : Step 143801, finished rewards 38.12, envs finished 1
2026-01-17 13:32:48,933 : agent.on_policy : DEBUG : Mean Losses: [7.134413316845894]
2026-01-17 13:32:48,974 : worker.worker : DEBUG : Step 143812, finished rewards -1.47, envs finished 1
2026-01-17 13:32:49,108 : worker.worker : DEBUG : Step 143819, finished rewards 19.35, envs finished 1
2026-01-17 13:32:49,140 : worker.worker : DEBUG : Step 143821, finished rewards -10.38, envs finished 1
2026-01-17 13:32:49,193 : worker.worker : DEBUG : Step 143827, finished rewards 29.46, envs finished 1
2026-01-17 13:32:49,473 : agent.on_policy : DEBUG : Mean Losses: [5.706131622195244]
2026-01-17 13:32:49,637 : worker.worker : DEBUG : Step 143858, finished rewards 13.15, envs finished 1
2026-01-17 13:32:49,755 : worker.worker : DEBUG : Step 143864, finished rewards -4.75, envs finished 1
2026-01-17 13:32:50,043 : agent.on_policy : DEBUG : Mean Losses: [4.532552517950535]
2026-01-17 13:32:50,066 : worker.worker : DEBUG : Step 143875, finished rewards 46.67, envs finished 1
2026-01-17 13:32:50,135 : worker.worker : DEBUG : Step 143889, finished rewards 42.48, envs finished 1
2026-01-17 13:32:50,145 : worker.worker : DEBUG : Step 143890, finished rewards 41.57, envs finished 1
2026-01-17 13:32:50,375 : agent.on_policy : DEBUG : Mean Losses: [8.382901856675744]
2026-01-17 13:32:50,378 : worker.worker : DEBUG : Step 143904, finished rewards 13.94, envs finished 1
2026-01-17 13:32:50,660 : worker.worker : DEBUG : Step 143929, finished rewards -3.23, envs finished 1
2026-01-17 13:32:50,929 : agent.on_policy : DEBUG : Mean Losses: [2.9519178960472345]
2026-01-17 13:32:51,124 : worker.worker : DEBUG : Step 143953, finished rewards 27.24, envs finished 1
2026-01-17 13:32:51,249 : worker.worker : DEBUG : Step 143965, finished rewards 25.98, envs finished 1
2026-01-17 13:32:51,369 : agent.on_policy : DEBUG : Mean Losses: [6.726989913731813]
2026-01-17 13:32:51,378 : worker.worker : DEBUG : Step 143968, finished rewards -1.01, envs finished 2
2026-01-17 13:32:51,643 : worker.worker : DEBUG : Step 143989, finished rewards 16.51, envs finished 1
2026-01-17 13:32:51,713 : worker.worker : DEBUG : Step 143997, finished rewards 25.07, envs finished 1
2026-01-17 13:32:51,723 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:32:51,890 : agent.on_policy : DEBUG : Mean Losses: [5.609576703980565]
2026-01-17 13:32:52,136 : worker.worker : DEBUG : Step 144021, finished rewards 25.52, envs finished 1
2026-01-17 13:32:52,309 : agent.on_policy : DEBUG : Mean Losses: [5.182170243933797]
2026-01-17 13:32:52,354 : worker.worker : DEBUG : Step 144039, finished rewards 41.71, envs finished 2
2026-01-17 13:32:52,444 : worker.worker : DEBUG : Step 144057, finished rewards 2.77, envs finished 2
2026-01-17 13:32:52,466 : worker.worker : DEBUG : Step 144061, finished rewards 11.05, envs finished 1
2026-01-17 13:32:52,684 : agent.on_policy : DEBUG : Mean Losses: [8.599111437797546]
2026-01-17 13:32:52,860 : worker.worker : DEBUG : Step 144083, finished rewards 23.75, envs finished 1
2026-01-17 13:32:52,908 : worker.worker : DEBUG : Step 144088, finished rewards 25.72, envs finished 1
2026-01-17 13:32:53,074 : agent.on_policy : DEBUG : Mean Losses: [3.7917316034436226]
2026-01-17 13:32:53,493 : agent.on_policy : DEBUG : Mean Losses: [2.3852831535041332]
2026-01-17 13:32:53,641 : worker.worker : DEBUG : Step 144142, finished rewards 16.41, envs finished 1
2026-01-17 13:32:53,660 : worker.worker : DEBUG : Step 144143, finished rewards 31.35, envs finished 1
2026-01-17 13:32:53,809 : worker.worker : DEBUG : Step 144155, finished rewards 19.36, envs finished 1
2026-01-17 13:32:54,052 : agent.on_policy : DEBUG : Mean Losses: [6.879797786474228]
2026-01-17 13:32:54,146 : worker.worker : DEBUG : Step 144169, finished rewards -6.64, envs finished 1
2026-01-17 13:32:54,295 : worker.worker : DEBUG : Step 144183, finished rewards -25.37, envs finished 1
2026-01-17 13:32:54,536 : agent.on_policy : DEBUG : Mean Losses: [3.9382209852337837]
2026-01-17 13:32:54,561 : worker.worker : DEBUG : Step 144194, finished rewards -6.60, envs finished 1
2026-01-17 13:32:54,838 : worker.worker : DEBUG : Step 144222, finished rewards -5.12, envs finished 1
2026-01-17 13:32:55,002 : agent.on_policy : DEBUG : Mean Losses: [4.764704614877701]
2026-01-17 13:32:55,109 : worker.worker : DEBUG : Step 144234, finished rewards 24.76, envs finished 1
2026-01-17 13:32:55,182 : worker.worker : DEBUG : Step 144244, finished rewards 26.42, envs finished 1
2026-01-17 13:32:55,388 : agent.on_policy : DEBUG : Mean Losses: [7.463378041982651]
2026-01-17 13:32:55,482 : worker.worker : DEBUG : Step 144270, finished rewards 30.74, envs finished 1
2026-01-17 13:32:55,580 : worker.worker : DEBUG : Step 144277, finished rewards -10.86, envs finished 2
2026-01-17 13:32:55,799 : agent.on_policy : DEBUG : Mean Losses: [6.7101093381643295]
2026-01-17 13:32:55,876 : worker.worker : DEBUG : Step 144295, finished rewards 17.84, envs finished 1
2026-01-17 13:32:55,897 : worker.worker : DEBUG : Step 144296, finished rewards -18.88, envs finished 1
2026-01-17 13:32:56,241 : agent.on_policy : DEBUG : Mean Losses: [4.238787144422531]
2026-01-17 13:32:56,278 : worker.worker : DEBUG : Step 144326, finished rewards 30.79, envs finished 1
2026-01-17 13:32:56,367 : worker.worker : DEBUG : Step 144341, finished rewards 4.88, envs finished 1
2026-01-17 13:32:56,519 : agent.on_policy : DEBUG : Mean Losses: [4.360370449721813]
2026-01-17 13:32:56,536 : worker.worker : DEBUG : Step 144355, finished rewards 33.62, envs finished 1
2026-01-17 13:32:56,584 : worker.worker : DEBUG : Step 144358, finished rewards 2.16, envs finished 1
2026-01-17 13:32:56,617 : worker.worker : DEBUG : Step 144362, finished rewards 43.09, envs finished 1
2026-01-17 13:32:56,649 : worker.worker : DEBUG : Step 144367, finished rewards 20.35, envs finished 1
2026-01-17 13:32:56,782 : agent.on_policy : DEBUG : Mean Losses: [6.5187171176075935]
2026-01-17 13:32:56,873 : worker.worker : DEBUG : Step 144393, finished rewards 6.22, envs finished 1
2026-01-17 13:32:57,177 : agent.on_policy : DEBUG : Mean Losses: [3.437737539410591]
2026-01-17 13:32:57,205 : worker.worker : DEBUG : Step 144418, finished rewards 46.41, envs finished 1
2026-01-17 13:32:57,235 : worker.worker : DEBUG : Step 144420, finished rewards 1.25, envs finished 1
2026-01-17 13:32:57,324 : worker.worker : DEBUG : Step 144432, finished rewards 24.77, envs finished 1
2026-01-17 13:32:57,600 : agent.on_policy : DEBUG : Mean Losses: [5.212494373321533]
2026-01-17 13:32:57,749 : worker.worker : DEBUG : Step 144472, finished rewards -13.99, envs finished 1
2026-01-17 13:32:58,011 : agent.on_policy : DEBUG : Mean Losses: [6.067197434604168]
2026-01-17 13:32:58,022 : worker.worker : DEBUG : Step 144481, finished rewards 5.89, envs finished 1
2026-01-17 13:32:58,056 : worker.worker : DEBUG : Step 144486, finished rewards 23.47, envs finished 1
2026-01-17 13:32:58,090 : worker.worker : DEBUG : Step 144491, finished rewards 0.09, envs finished 1
2026-01-17 13:32:58,137 : worker.worker : DEBUG : Step 144498, finished rewards 36.50, envs finished 1
2026-01-17 13:32:58,218 : worker.worker : DEBUG : Step 144509, finished rewards 26.33, envs finished 1
2026-01-17 13:32:58,333 : agent.on_policy : DEBUG : Mean Losses: [6.989528633654118]
2026-01-17 13:32:58,443 : worker.worker : DEBUG : Step 144523, finished rewards 24.31, envs finished 1
2026-01-17 13:32:58,805 : agent.on_policy : DEBUG : Mean Losses: [3.043317422270775]
2026-01-17 13:32:58,892 : worker.worker : DEBUG : Step 144562, finished rewards 26.60, envs finished 1
2026-01-17 13:32:58,448 : agent.on_policy : DEBUG : Mean Losses: [4.177782192826271]
2026-01-17 13:32:58,458 : worker.worker : DEBUG : Step 144577, finished rewards -61.05, envs finished 1
2026-01-17 13:32:58,515 : worker.worker : DEBUG : Step 144585, finished rewards 15.02, envs finished 1
2026-01-17 13:32:58,644 : worker.worker : DEBUG : Step 144606, finished rewards 6.85, envs finished 1
2026-01-17 13:32:58,792 : agent.on_policy : DEBUG : Mean Losses: [6.301000900566578]
2026-01-17 13:32:58,861 : worker.worker : DEBUG : Step 144612, finished rewards 10.38, envs finished 1
2026-01-17 13:32:58,890 : worker.worker : DEBUG : Step 144615, finished rewards -1.33, envs finished 1
2026-01-17 13:32:59,235 : worker.worker : DEBUG : Step 144639, finished rewards 20.58, envs finished 2
2026-01-17 13:32:59,766 : agent.on_policy : DEBUG : Mean Losses: [5.373731191270053]
2026-01-17 13:32:59,969 : worker.worker : DEBUG : Step 144667, finished rewards 32.28, envs finished 1
2026-01-17 13:33:00,206 : agent.on_policy : DEBUG : Mean Losses: [4.011128567159176]
2026-01-17 13:33:00,274 : worker.worker : DEBUG : Step 144683, finished rewards -32.15, envs finished 1
2026-01-17 13:33:00,406 : worker.worker : DEBUG : Step 144698, finished rewards 24.75, envs finished 1
2026-01-17 13:33:00,450 : worker.worker : DEBUG : Step 144703, finished rewards 26.23, envs finished 1
2026-01-17 13:33:00,532 : agent.on_policy : DEBUG : Mean Losses: [6.044807255268097]
2026-01-17 13:33:00,625 : worker.worker : DEBUG : Step 144717, finished rewards 19.82, envs finished 1
2026-01-17 13:33:00,678 : worker.worker : DEBUG : Step 144719, finished rewards -10.20, envs finished 1
2026-01-17 13:33:00,707 : worker.worker : DEBUG : Step 144723, finished rewards 29.90, envs finished 1
2026-01-17 13:33:00,892 : agent.on_policy : DEBUG : Mean Losses: [5.299076564610004]
2026-01-17 13:33:00,989 : worker.worker : DEBUG : Step 144754, finished rewards 5.93, envs finished 1
2026-01-17 13:33:01,060 : worker.worker : DEBUG : Step 144762, finished rewards 46.11, envs finished 1
2026-01-17 13:33:01,381 : agent.on_policy : DEBUG : Mean Losses: [5.234966300427914]
2026-01-17 13:33:01,390 : worker.worker : DEBUG : Step 144768, finished rewards 20.25, envs finished 1
2026-01-17 13:33:01,739 : agent.on_policy : DEBUG : Mean Losses: [3.378323908895254]
2026-01-17 13:33:01,742 : worker.worker : DEBUG : Step 144800, finished rewards 20.67, envs finished 1
2026-01-17 13:33:01,761 : worker.worker : DEBUG : Step 144803, finished rewards 29.20, envs finished 1
2026-01-17 13:33:01,873 : worker.worker : DEBUG : Step 144824, finished rewards 14.71, envs finished 1
2026-01-17 13:33:02,081 : agent.on_policy : DEBUG : Mean Losses: [5.740370713174343]
2026-01-17 13:33:02,327 : worker.worker : DEBUG : Step 144851, finished rewards -17.28, envs finished 1
2026-01-17 13:33:02,513 : worker.worker : DEBUG : Step 144863, finished rewards 20.16, envs finished 1
2026-01-17 13:33:02,690 : agent.on_policy : DEBUG : Mean Losses: [5.632974687963724]
2026-01-17 13:33:03,055 : worker.worker : DEBUG : Step 144885, finished rewards -13.14, envs finished 1
2026-01-17 13:33:03,365 : agent.on_policy : DEBUG : Mean Losses: [4.9353154599666595]
2026-01-17 13:33:03,387 : worker.worker : DEBUG : Step 144899, finished rewards 21.21, envs finished 1
2026-01-17 13:33:03,410 : worker.worker : DEBUG : Step 144902, finished rewards 1.73, envs finished 1
2026-01-17 13:33:03,483 : worker.worker : DEBUG : Step 144914, finished rewards 9.13, envs finished 1
2026-01-17 13:33:03,517 : worker.worker : DEBUG : Step 144919, finished rewards 22.22, envs finished 1
2026-01-17 13:33:03,699 : agent.on_policy : DEBUG : Mean Losses: [5.484270511195064]
2026-01-17 13:33:03,951 : agent.on_policy : DEBUG : Mean Losses: [2.4040956888347864]
2026-01-17 13:33:03,955 : worker.worker : DEBUG : Step 144960, finished rewards 13.47, envs finished 1
2026-01-17 13:33:03,985 : worker.worker : DEBUG : Step 144966, finished rewards -39.72, envs finished 1
2026-01-17 13:33:04,000 : worker.worker : DEBUG : Step 144968, finished rewards 32.11, envs finished 1
2026-01-17 13:33:04,070 : worker.worker : DEBUG : Step 144980, finished rewards 35.48, envs finished 1
2026-01-17 13:33:04,111 : worker.worker : DEBUG : Step 144988, finished rewards 9.99, envs finished 1
2026-01-17 13:33:04,235 : agent.on_policy : DEBUG : Mean Losses: [7.7612771689891815]
2026-01-17 13:33:04,273 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:33:04,312 : worker.worker : INFO : Step 145000, Avg Reward 13.0133, Max Reward 46.6749, Loss [5.01490256]
2026-01-17 13:33:04,374 : worker.worker : DEBUG : Step 145012, finished rewards 12.62, envs finished 1
2026-01-17 13:33:04,524 : agent.on_policy : DEBUG : Mean Losses: [4.829004312865436]
2026-01-17 13:33:04,562 : worker.worker : DEBUG : Step 145032, finished rewards 9.52, envs finished 1
2026-01-17 13:33:04,641 : worker.worker : DEBUG : Step 145051, finished rewards 24.54, envs finished 1
2026-01-17 13:33:04,780 : agent.on_policy : DEBUG : Mean Losses: [5.545040212571621]
2026-01-17 13:33:04,802 : worker.worker : DEBUG : Step 145060, finished rewards 25.85, envs finished 1
2026-01-17 13:33:04,962 : worker.worker : DEBUG : Step 145080, finished rewards 24.67, envs finished 1
2026-01-17 13:33:04,986 : worker.worker : DEBUG : Step 145085, finished rewards -26.06, envs finished 1
2026-01-17 13:33:04,991 : worker.worker : DEBUG : Step 145086, finished rewards 14.28, envs finished 1
2026-01-17 13:33:05,050 : agent.on_policy : DEBUG : Mean Losses: [8.094338648021221]
2026-01-17 13:33:05,096 : worker.worker : DEBUG : Step 145097, finished rewards 29.30, envs finished 1
2026-01-17 13:33:05,136 : worker.worker : DEBUG : Step 145104, finished rewards -9.33, envs finished 1
2026-01-17 13:33:05,207 : worker.worker : DEBUG : Step 145111, finished rewards 34.50, envs finished 1
2026-01-17 13:33:05,315 : agent.on_policy : DEBUG : Mean Losses: [5.457847620360553]
2026-01-17 13:33:05,393 : worker.worker : DEBUG : Step 145128, finished rewards 37.38, envs finished 1
2026-01-17 13:33:05,607 : agent.on_policy : DEBUG : Mean Losses: [1.9594759941101074]
2026-01-17 13:33:05,673 : worker.worker : DEBUG : Step 145170, finished rewards 27.08, envs finished 1
2026-01-17 13:33:05,683 : worker.worker : DEBUG : Step 145172, finished rewards 10.61, envs finished 1
2026-01-17 13:33:05,884 : agent.on_policy : DEBUG : Mean Losses: [5.243565171957016]
2026-01-17 13:33:05,986 : worker.worker : DEBUG : Step 145198, finished rewards 20.05, envs finished 1
2026-01-17 13:33:05,991 : worker.worker : DEBUG : Step 145199, finished rewards 26.59, envs finished 1
2026-01-17 13:33:06,110 : worker.worker : DEBUG : Step 145215, finished rewards -3.04, envs finished 1
2026-01-17 13:33:06,241 : agent.on_policy : DEBUG : Mean Losses: [7.019166894257069]
2026-01-17 13:33:06,267 : worker.worker : DEBUG : Step 145221, finished rewards -7.47, envs finished 1
2026-01-17 13:33:06,324 : worker.worker : DEBUG : Step 145229, finished rewards 21.68, envs finished 1
2026-01-17 13:33:06,357 : worker.worker : DEBUG : Step 145233, finished rewards -6.48, envs finished 1
2026-01-17 13:33:06,536 : agent.on_policy : DEBUG : Mean Losses: [4.777474962174892]
2026-01-17 13:33:06,591 : worker.worker : DEBUG : Step 145255, finished rewards 28.83, envs finished 1
2026-01-17 13:33:06,851 : agent.on_policy : DEBUG : Mean Losses: [3.908183863386512]
2026-01-17 13:33:06,867 : worker.worker : DEBUG : Step 145285, finished rewards 45.74, envs finished 1
2026-01-17 13:33:06,955 : worker.worker : DEBUG : Step 145306, finished rewards 12.97, envs finished 1
2026-01-17 13:33:06,985 : worker.worker : DEBUG : Step 145310, finished rewards 16.48, envs finished 1
2026-01-17 13:33:07,000 : worker.worker : DEBUG : Step 145311, finished rewards 20.96, envs finished 1
2026-01-17 13:33:07,226 : agent.on_policy : DEBUG : Mean Losses: [7.971717849373817]
2026-01-17 13:33:07,271 : worker.worker : DEBUG : Step 145318, finished rewards -17.31, envs finished 1
2026-01-17 13:33:07,280 : worker.worker : DEBUG : Step 145320, finished rewards 27.49, envs finished 1
2026-01-17 13:33:07,373 : worker.worker : DEBUG : Step 145339, finished rewards 29.42, envs finished 1
2026-01-17 13:33:07,377 : worker.worker : DEBUG : Step 145340, finished rewards 16.17, envs finished 1
2026-01-17 13:33:07,532 : agent.on_policy : DEBUG : Mean Losses: [5.985460525378585]
2026-01-17 13:33:07,858 : agent.on_policy : DEBUG : Mean Losses: [1.2463863603770733]
2026-01-17 13:33:07,871 : worker.worker : DEBUG : Step 145379, finished rewards 24.12, envs finished 1
2026-01-17 13:33:07,923 : worker.worker : DEBUG : Step 145391, finished rewards 28.70, envs finished 1
2026-01-17 13:33:07,954 : worker.worker : DEBUG : Step 145398, finished rewards 27.64, envs finished 1
2026-01-17 13:33:08,155 : agent.on_policy : DEBUG : Mean Losses: [6.691991671919823]
2026-01-17 13:33:08,215 : worker.worker : DEBUG : Step 145415, finished rewards 16.01, envs finished 1
2026-01-17 13:33:08,267 : worker.worker : DEBUG : Step 145418, finished rewards 21.11, envs finished 1
2026-01-17 13:33:08,299 : worker.worker : DEBUG : Step 145420, finished rewards 17.63, envs finished 1
2026-01-17 13:33:08,418 : worker.worker : DEBUG : Step 145432, finished rewards 24.77, envs finished 1
2026-01-17 13:33:08,581 : agent.on_policy : DEBUG : Mean Losses: [6.488776382058859]
2026-01-17 13:33:08,800 : agent.on_policy : DEBUG : Mean Losses: [3.5258394200354815]
2026-01-17 13:33:08,814 : worker.worker : DEBUG : Step 145475, finished rewards -4.09, envs finished 1
2026-01-17 13:33:08,857 : worker.worker : DEBUG : Step 145484, finished rewards 23.20, envs finished 1
2026-01-17 13:33:08,886 : worker.worker : DEBUG : Step 145491, finished rewards 9.60, envs finished 1
2026-01-17 13:33:08,994 : agent.on_policy : DEBUG : Mean Losses: [5.34091180562973]
2026-01-17 13:33:09,002 : worker.worker : DEBUG : Step 145506, finished rewards 29.12, envs finished 1
2026-01-17 13:33:09,009 : worker.worker : DEBUG : Step 145508, finished rewards 23.49, envs finished 1
2026-01-17 13:33:09,226 : agent.on_policy : DEBUG : Mean Losses: [4.866757173091173]
2026-01-17 13:33:09,265 : worker.worker : DEBUG : Step 145546, finished rewards 9.34, envs finished 1
2026-01-17 13:33:09,277 : worker.worker : DEBUG : Step 145549, finished rewards -18.88, envs finished 1
2026-01-17 13:33:09,326 : worker.worker : DEBUG : Step 145561, finished rewards -8.24, envs finished 1
2026-01-17 13:33:09,354 : worker.worker : DEBUG : Step 145567, finished rewards 38.31, envs finished 1
2026-01-17 13:33:09,515 : agent.on_policy : DEBUG : Mean Losses: [6.7403321117162704]
2026-01-17 13:33:09,747 : worker.worker : DEBUG : Step 145589, finished rewards 8.56, envs finished 1
2026-01-17 13:33:09,844 : agent.on_policy : DEBUG : Mean Losses: [3.0167638305574656]
2026-01-17 13:33:09,957 : worker.worker : DEBUG : Step 145617, finished rewards -2.37, envs finished 1
2026-01-17 13:33:09,962 : worker.worker : DEBUG : Step 145618, finished rewards 11.44, envs finished 1
2026-01-17 13:33:10,005 : worker.worker : DEBUG : Step 145624, finished rewards 5.21, envs finished 1
2026-01-17 13:33:10,229 : agent.on_policy : DEBUG : Mean Losses: [4.605909734964371]
2026-01-17 13:33:10,301 : worker.worker : DEBUG : Step 145639, finished rewards 22.95, envs finished 1
2026-01-17 13:33:10,591 : agent.on_policy : DEBUG : Mean Losses: [3.5634919200092554]
2026-01-17 13:33:10,614 : worker.worker : DEBUG : Step 145670, finished rewards 16.00, envs finished 1
2026-01-17 13:33:10,670 : worker.worker : DEBUG : Step 145684, finished rewards -10.88, envs finished 1
2026-01-17 13:33:10,813 : agent.on_policy : DEBUG : Mean Losses: [6.44588041305542]
2026-01-17 13:33:10,869 : worker.worker : DEBUG : Step 145708, finished rewards 29.99, envs finished 1
2026-01-17 13:33:10,938 : worker.worker : DEBUG : Step 145726, finished rewards -2.02, envs finished 1
2026-01-17 13:33:11,062 : agent.on_policy : DEBUG : Mean Losses: [6.300153955817223]
2026-01-17 13:33:11,093 : worker.worker : DEBUG : Step 145732, finished rewards 10.20, envs finished 1
2026-01-17 13:33:11,185 : worker.worker : DEBUG : Step 145743, finished rewards -35.64, envs finished 1
2026-01-17 13:33:11,371 : agent.on_policy : DEBUG : Mean Losses: [4.947886850684881]
2026-01-17 13:33:11,451 : worker.worker : DEBUG : Step 145771, finished rewards 46.43, envs finished 1
2026-01-17 13:33:11,463 : worker.worker : DEBUG : Step 145773, finished rewards 16.94, envs finished 1
2026-01-17 13:33:11,483 : worker.worker : DEBUG : Step 145776, finished rewards -24.60, envs finished 1
2026-01-17 13:33:11,692 : agent.on_policy : DEBUG : Mean Losses: [7.816775389015675]
2026-01-17 13:33:11,705 : worker.worker : DEBUG : Step 145796, finished rewards -13.07, envs finished 1
2026-01-17 13:33:11,755 : worker.worker : DEBUG : Step 145811, finished rewards 30.26, envs finished 1
2026-01-17 13:33:11,783 : worker.worker : DEBUG : Step 145820, finished rewards 35.06, envs finished 1
2026-01-17 13:33:11,856 : agent.on_policy : DEBUG : Mean Losses: [6.373968988656998]
2026-01-17 13:33:11,875 : worker.worker : DEBUG : Step 145828, finished rewards 21.89, envs finished 1
2026-01-17 13:33:11,924 : worker.worker : DEBUG : Step 145837, finished rewards -14.38, envs finished 1
2026-01-17 13:33:11,989 : worker.worker : DEBUG : Step 145842, finished rewards 42.35, envs finished 1
2026-01-17 13:33:12,185 : agent.on_policy : DEBUG : Mean Losses: [7.232158616185188]
2026-01-17 13:33:12,215 : worker.worker : DEBUG : Step 145862, finished rewards 28.92, envs finished 1
2026-01-17 13:33:12,287 : worker.worker : DEBUG : Step 145878, finished rewards 31.10, envs finished 1
2026-01-17 13:33:12,468 : agent.on_policy : DEBUG : Mean Losses: [5.159430451691151]
2026-01-17 13:33:12,546 : worker.worker : DEBUG : Step 145901, finished rewards -1.15, envs finished 1
2026-01-17 13:33:12,658 : worker.worker : DEBUG : Step 145918, finished rewards 25.74, envs finished 1
2026-01-17 13:33:12,746 : agent.on_policy : DEBUG : Mean Losses: [6.239791475236416]
2026-01-17 13:33:12,762 : worker.worker : DEBUG : Step 145924, finished rewards 15.78, envs finished 1
2026-01-17 13:33:12,899 : worker.worker : DEBUG : Step 145937, finished rewards 0.05, envs finished 1
2026-01-17 13:33:13,003 : worker.worker : DEBUG : Step 145947, finished rewards 28.34, envs finished 1
2026-01-17 13:33:13,020 : worker.worker : DEBUG : Step 145949, finished rewards 16.96, envs finished 1
2026-01-17 13:33:13,205 : agent.on_policy : DEBUG : Mean Losses: [5.913605563342571]
2026-01-17 13:33:13,233 : worker.worker : DEBUG : Step 145955, finished rewards 4.83, envs finished 1
2026-01-17 13:33:13,590 : agent.on_policy : DEBUG : Mean Losses: [2.8303888142108917]
2026-01-17 13:33:13,653 : worker.worker : DEBUG : Step 145995, finished rewards 37.71, envs finished 1
2026-01-17 13:33:13,670 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:33:13,877 : agent.on_policy : DEBUG : Mean Losses: [3.9499412551522255]
2026-01-17 13:33:13,941 : worker.worker : DEBUG : Step 146023, finished rewards 20.25, envs finished 1
2026-01-17 13:33:14,032 : worker.worker : DEBUG : Step 146035, finished rewards -24.60, envs finished 1
2026-01-17 13:33:14,094 : worker.worker : DEBUG : Step 146038, finished rewards 30.40, envs finished 1
2026-01-17 13:33:14,306 : agent.on_policy : DEBUG : Mean Losses: [8.75311616808176]
2026-01-17 13:33:14,312 : worker.worker : DEBUG : Step 146049, finished rewards 19.68, envs finished 1
2026-01-17 13:33:14,376 : worker.worker : DEBUG : Step 146062, finished rewards -25.17, envs finished 1
2026-01-17 13:33:14,548 : agent.on_policy : DEBUG : Mean Losses: [4.5860400423407555]
2026-01-17 13:33:14,553 : worker.worker : DEBUG : Step 146081, finished rewards -0.03, envs finished 1
2026-01-17 13:33:14,568 : worker.worker : DEBUG : Step 146085, finished rewards 25.71, envs finished 1
2026-01-17 13:33:14,749 : agent.on_policy : DEBUG : Mean Losses: [3.4772296771407127]
2026-01-17 13:33:14,798 : worker.worker : DEBUG : Step 146120, finished rewards 32.85, envs finished 1
2026-01-17 13:33:14,841 : worker.worker : DEBUG : Step 146130, finished rewards 22.19, envs finished 1
2026-01-17 13:33:14,850 : worker.worker : DEBUG : Step 146132, finished rewards 41.57, envs finished 1
2026-01-17 13:33:14,875 : worker.worker : DEBUG : Step 146135, finished rewards 28.58, envs finished 1
2026-01-17 13:33:14,918 : worker.worker : DEBUG : Step 146143, finished rewards 6.22, envs finished 1
2026-01-17 13:33:14,987 : agent.on_policy : DEBUG : Mean Losses: [10.948978766798973]
2026-01-17 13:33:15,207 : agent.on_policy : DEBUG : Mean Losses: [2.3307085298001766]
2026-01-17 13:33:15,209 : worker.worker : DEBUG : Step 146176, finished rewards 25.82, envs finished 1
2026-01-17 13:33:15,297 : worker.worker : DEBUG : Step 146197, finished rewards 7.77, envs finished 1
2026-01-17 13:33:15,354 : worker.worker : DEBUG : Step 146204, finished rewards 43.63, envs finished 1
2026-01-17 13:33:15,484 : agent.on_policy : DEBUG : Mean Losses: [6.353524807840586]
2026-01-17 13:33:15,527 : worker.worker : DEBUG : Step 146220, finished rewards 28.16, envs finished 2
2026-01-17 13:33:15,762 : agent.on_policy : DEBUG : Mean Losses: [5.271401941776276]
2026-01-17 13:33:15,785 : worker.worker : DEBUG : Step 146245, finished rewards -141.10, envs finished 1
2026-01-17 13:33:15,847 : worker.worker : DEBUG : Step 146256, finished rewards 9.69, envs finished 1
2026-01-17 13:33:15,853 : worker.worker : DEBUG : Step 146257, finished rewards 1.21, envs finished 1
2026-01-17 13:33:15,891 : worker.worker : DEBUG : Step 146264, finished rewards 28.00, envs finished 1
2026-01-17 13:33:16,047 : agent.on_policy : DEBUG : Mean Losses: [5.122751595452428]
2026-01-17 13:33:16,184 : worker.worker : DEBUG : Step 146295, finished rewards 22.26, envs finished 1
2026-01-17 13:33:16,272 : agent.on_policy : DEBUG : Mean Losses: [2.648426679894328]
2026-01-17 13:33:16,275 : worker.worker : DEBUG : Step 146304, finished rewards 31.09, envs finished 1
2026-01-17 13:33:16,285 : worker.worker : DEBUG : Step 146306, finished rewards 23.56, envs finished 2
2026-01-17 13:33:16,338 : worker.worker : DEBUG : Step 146315, finished rewards 41.32, envs finished 1
2026-01-17 13:33:16,571 : agent.on_policy : DEBUG : Mean Losses: [4.874177072197199]
2026-01-17 13:33:16,603 : worker.worker : DEBUG : Step 146343, finished rewards 29.52, envs finished 1
2026-01-17 13:33:16,672 : worker.worker : DEBUG : Step 146362, finished rewards 14.95, envs finished 1
2026-01-17 13:33:16,793 : agent.on_policy : DEBUG : Mean Losses: [3.826825637370348]
2026-01-17 13:33:16,797 : worker.worker : DEBUG : Step 146368, finished rewards 14.40, envs finished 1
2026-01-17 13:33:16,903 : worker.worker : DEBUG : Step 146390, finished rewards 29.53, envs finished 1
2026-01-17 13:33:16,908 : worker.worker : DEBUG : Step 146391, finished rewards 22.23, envs finished 1
2026-01-17 13:33:16,914 : worker.worker : DEBUG : Step 146392, finished rewards 28.21, envs finished 1
2026-01-17 13:33:17,070 : agent.on_policy : DEBUG : Mean Losses: [6.742264220491052]
2026-01-17 13:33:17,280 : agent.on_policy : DEBUG : Mean Losses: [3.689641992561519]
2026-01-17 13:33:17,321 : worker.worker : DEBUG : Step 146441, finished rewards -4.91, envs finished 1
2026-01-17 13:33:17,354 : worker.worker : DEBUG : Step 146448, finished rewards 28.61, envs finished 1
2026-01-17 13:33:17,383 : worker.worker : DEBUG : Step 146454, finished rewards -0.64, envs finished 1
2026-01-17 13:33:17,389 : worker.worker : DEBUG : Step 146455, finished rewards 12.15, envs finished 1
2026-01-17 13:33:17,506 : agent.on_policy : DEBUG : Mean Losses: [6.72346256673336]
2026-01-17 13:33:17,626 : worker.worker : DEBUG : Step 146481, finished rewards 9.68, envs finished 1
2026-01-17 13:33:17,633 : worker.worker : DEBUG : Step 146482, finished rewards 25.80, envs finished 1
2026-01-17 13:33:17,744 : worker.worker : DEBUG : Step 146495, finished rewards 13.17, envs finished 1
2026-01-17 13:33:17,897 : agent.on_policy : DEBUG : Mean Losses: [6.600571610033512]
2026-01-17 13:33:17,902 : worker.worker : DEBUG : Step 146496, finished rewards 14.59, envs finished 1
2026-01-17 13:33:18,049 : worker.worker : DEBUG : Step 146516, finished rewards 42.53, envs finished 1
2026-01-17 13:33:18,112 : worker.worker : DEBUG : Step 146524, finished rewards 41.36, envs finished 1
2026-01-17 13:33:18,426 : agent.on_policy : DEBUG : Mean Losses: [6.471743706613779]
2026-01-17 13:33:18,546 : worker.worker : DEBUG : Step 146545, finished rewards 46.80, envs finished 1
2026-01-17 13:33:18,709 : agent.on_policy : DEBUG : Mean Losses: [4.8486253544688225]
2026-01-17 13:33:18,740 : worker.worker : DEBUG : Step 146565, finished rewards -0.38, envs finished 1
2026-01-17 13:33:18,774 : worker.worker : DEBUG : Step 146567, finished rewards 8.29, envs finished 1
2026-01-17 13:33:18,911 : worker.worker : DEBUG : Step 146580, finished rewards 20.71, envs finished 1
2026-01-17 13:33:18,986 : worker.worker : DEBUG : Step 146587, finished rewards 24.77, envs finished 1
2026-01-17 13:33:19,153 : agent.on_policy : DEBUG : Mean Losses: [6.551805784925818]
2026-01-17 13:33:19,166 : worker.worker : DEBUG : Step 146595, finished rewards 34.19, envs finished 1
2026-01-17 13:33:19,206 : worker.worker : DEBUG : Step 146601, finished rewards 35.67, envs finished 1
2026-01-17 13:33:19,354 : agent.on_policy : DEBUG : Mean Losses: [3.535100158303976]
2026-01-17 13:33:19,398 : worker.worker : DEBUG : Step 146627, finished rewards -3.54, envs finished 1
2026-01-17 13:33:19,464 : worker.worker : DEBUG : Step 146637, finished rewards 24.59, envs finished 1
2026-01-17 13:33:19,686 : agent.on_policy : DEBUG : Mean Losses: [3.0682110711932182]
2026-01-17 13:33:19,706 : worker.worker : DEBUG : Step 146659, finished rewards 22.01, envs finished 1
2026-01-17 13:33:20,031 : agent.on_policy : DEBUG : Mean Losses: [3.199217975139618]
2026-01-17 13:33:20,032 : worker.worker : DEBUG : Step 146688, finished rewards 2.89, envs finished 1
2026-01-17 13:33:20,037 : worker.worker : DEBUG : Step 146689, finished rewards 17.06, envs finished 1
2026-01-17 13:33:20,066 : worker.worker : DEBUG : Step 146695, finished rewards 20.07, envs finished 1
2026-01-17 13:33:20,088 : worker.worker : DEBUG : Step 146700, finished rewards 18.18, envs finished 1
2026-01-17 13:33:20,221 : agent.on_policy : DEBUG : Mean Losses: [4.6424447521567345]
2026-01-17 13:33:20,314 : worker.worker : DEBUG : Step 146732, finished rewards 22.10, envs finished 1
2026-01-17 13:33:20,348 : worker.worker : DEBUG : Step 146738, finished rewards -17.04, envs finished 1
2026-01-17 13:33:20,543 : agent.on_policy : DEBUG : Mean Losses: [4.948630392551422]
2026-01-17 13:33:20,583 : worker.worker : DEBUG : Step 146760, finished rewards 40.73, envs finished 1
2026-01-17 13:33:20,651 : worker.worker : DEBUG : Step 146775, finished rewards 0.18, envs finished 1
2026-01-17 13:33:20,685 : worker.worker : DEBUG : Step 146783, finished rewards 22.53, envs finished 1
2026-01-17 13:33:20,819 : agent.on_policy : DEBUG : Mean Losses: [6.071897737681866]
2026-01-17 13:33:20,847 : worker.worker : DEBUG : Step 146789, finished rewards 22.39, envs finished 1
2026-01-17 13:33:21,001 : worker.worker : DEBUG : Step 146815, finished rewards -2.36, envs finished 1
2026-01-17 13:33:21,054 : agent.on_policy : DEBUG : Mean Losses: [5.235977930948138]
2026-01-17 13:33:21,087 : worker.worker : DEBUG : Step 146824, finished rewards 28.64, envs finished 1
2026-01-17 13:33:21,300 : agent.on_policy : DEBUG : Mean Losses: [4.6483582854270935]
2026-01-17 13:33:21,303 : worker.worker : DEBUG : Step 146848, finished rewards -14.23, envs finished 1
2026-01-17 13:33:21,398 : worker.worker : DEBUG : Step 146867, finished rewards 27.83, envs finished 1
2026-01-17 13:33:21,405 : worker.worker : DEBUG : Step 146868, finished rewards -3.74, envs finished 1
2026-01-17 13:33:21,524 : worker.worker : DEBUG : Step 146879, finished rewards 22.92, envs finished 1
2026-01-17 13:33:21,597 : agent.on_policy : DEBUG : Mean Losses: [5.96039916574955]
2026-01-17 13:33:21,752 : worker.worker : DEBUG : Step 146898, finished rewards 9.78, envs finished 1
2026-01-17 13:33:21,813 : worker.worker : DEBUG : Step 146903, finished rewards -9.14, envs finished 1
2026-01-17 13:33:21,832 : worker.worker : DEBUG : Step 146904, finished rewards 27.08, envs finished 1
2026-01-17 13:33:22,003 : agent.on_policy : DEBUG : Mean Losses: [5.9871125146746635]
2026-01-17 13:33:22,179 : worker.worker : DEBUG : Step 146938, finished rewards 9.77, envs finished 1
2026-01-17 13:33:22,305 : agent.on_policy : DEBUG : Mean Losses: [3.262155780568719]
2026-01-17 13:33:22,419 : worker.worker : DEBUG : Step 146956, finished rewards 13.35, envs finished 1
2026-01-17 13:33:22,541 : worker.worker : DEBUG : Step 146967, finished rewards 20.57, envs finished 1
2026-01-17 13:33:22,599 : worker.worker : DEBUG : Step 146974, finished rewards 41.72, envs finished 1
2026-01-17 13:33:22,764 : agent.on_policy : DEBUG : Mean Losses: [7.127233417704701]
2026-01-17 13:33:22,868 : worker.worker : DEBUG : Step 146990, finished rewards 10.33, envs finished 1
2026-01-17 13:33:22,910 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:33:23,088 : agent.on_policy : DEBUG : Mean Losses: [4.694879360496998]
2026-01-17 13:33:23,147 : worker.worker : DEBUG : Step 147013, finished rewards -13.22, envs finished 1
2026-01-17 13:33:23,229 : worker.worker : DEBUG : Step 147025, finished rewards 28.32, envs finished 1
2026-01-17 13:33:23,393 : worker.worker : DEBUG : Step 147034, finished rewards 34.49, envs finished 1
2026-01-17 13:33:23,576 : agent.on_policy : DEBUG : Mean Losses: [8.159810188226402]
2026-01-17 13:33:23,600 : worker.worker : DEBUG : Step 147044, finished rewards -11.02, envs finished 1
2026-01-17 13:33:23,611 : worker.worker : DEBUG : Step 147045, finished rewards -12.04, envs finished 1
2026-01-17 13:33:23,771 : worker.worker : DEBUG : Step 147061, finished rewards 23.93, envs finished 1
2026-01-17 13:33:23,810 : worker.worker : DEBUG : Step 147062, finished rewards 41.50, envs finished 1
2026-01-17 13:33:23,836 : worker.worker : DEBUG : Step 147064, finished rewards 26.52, envs finished 1
2026-01-17 13:33:24,040 : agent.on_policy : DEBUG : Mean Losses: [7.064580298960209]
2026-01-17 13:33:24,329 : agent.on_policy : DEBUG : Mean Losses: [1.8459099419414997]
2026-01-17 13:33:24,396 : worker.worker : DEBUG : Step 147117, finished rewards 25.58, envs finished 1
2026-01-17 13:33:24,437 : worker.worker : DEBUG : Step 147125, finished rewards 8.78, envs finished 1
2026-01-17 13:33:24,463 : worker.worker : DEBUG : Step 147130, finished rewards 29.68, envs finished 1
2026-01-17 13:33:24,632 : agent.on_policy : DEBUG : Mean Losses: [7.702201277017593]
2026-01-17 13:33:24,726 : worker.worker : DEBUG : Step 147160, finished rewards 2.15, envs finished 1
2026-01-17 13:33:24,884 : agent.on_policy : DEBUG : Mean Losses: [4.048478409647942]
2026-01-17 13:33:24,915 : worker.worker : DEBUG : Step 147176, finished rewards -7.81, envs finished 1
2026-01-17 13:33:24,968 : worker.worker : DEBUG : Step 147181, finished rewards 2.53, envs finished 1
2026-01-17 13:33:25,046 : worker.worker : DEBUG : Step 147193, finished rewards -2.80, envs finished 1
2026-01-17 13:33:25,212 : agent.on_policy : DEBUG : Mean Losses: [6.225699622184038]
2026-01-17 13:33:25,251 : worker.worker : DEBUG : Step 147211, finished rewards -13.88, envs finished 1
2026-01-17 13:33:25,369 : agent.on_policy : DEBUG : Mean Losses: [4.470590330660343]
2026-01-17 13:33:25,533 : worker.worker : DEBUG : Step 147253, finished rewards 24.88, envs finished 1
2026-01-17 13:33:25,574 : worker.worker : DEBUG : Step 147262, finished rewards -10.05, envs finished 1
2026-01-17 13:33:25,640 : agent.on_policy : DEBUG : Mean Losses: [7.099052704870701]
2026-01-17 13:33:25,643 : worker.worker : DEBUG : Step 147264, finished rewards 41.96, envs finished 1
2026-01-17 13:33:25,674 : worker.worker : DEBUG : Step 147271, finished rewards 25.63, envs finished 1
2026-01-17 13:33:25,679 : worker.worker : DEBUG : Step 147272, finished rewards -12.36, envs finished 1
2026-01-17 13:33:25,696 : worker.worker : DEBUG : Step 147275, finished rewards -17.87, envs finished 1
2026-01-17 13:33:25,886 : agent.on_policy : DEBUG : Mean Losses: [5.030457980930805]
2026-01-17 13:33:25,906 : worker.worker : DEBUG : Step 147301, finished rewards 25.74, envs finished 1
2026-01-17 13:33:25,963 : worker.worker : DEBUG : Step 147314, finished rewards -5.53, envs finished 1
2026-01-17 13:33:26,148 : agent.on_policy : DEBUG : Mean Losses: [2.824161097407341]
2026-01-17 13:33:26,559 : agent.on_policy : DEBUG : Mean Losses: [3.15042644739151]
2026-01-17 13:33:26,633 : worker.worker : DEBUG : Step 147376, finished rewards 18.61, envs finished 1
2026-01-17 13:33:26,644 : worker.worker : DEBUG : Step 147378, finished rewards 10.48, envs finished 1
2026-01-17 13:33:26,662 : worker.worker : DEBUG : Step 147380, finished rewards 4.66, envs finished 1
2026-01-17 13:33:26,678 : worker.worker : DEBUG : Step 147382, finished rewards 1.76, envs finished 1
2026-01-17 13:33:26,690 : worker.worker : DEBUG : Step 147384, finished rewards 19.83, envs finished 2
2026-01-17 13:33:26,826 : agent.on_policy : DEBUG : Mean Losses: [11.075382634997368]
2026-01-17 13:33:26,906 : worker.worker : DEBUG : Step 147404, finished rewards 25.78, envs finished 1
2026-01-17 13:33:27,029 : worker.worker : DEBUG : Step 147419, finished rewards -18.54, envs finished 1
2026-01-17 13:33:27,228 : agent.on_policy : DEBUG : Mean Losses: [3.5220180843025446]
2026-01-17 13:33:27,402 : worker.worker : DEBUG : Step 147451, finished rewards 41.90, envs finished 1
2026-01-17 13:33:27,527 : agent.on_policy : DEBUG : Mean Losses: [3.654924936592579]
2026-01-17 13:33:27,717 : worker.worker : DEBUG : Step 147486, finished rewards 11.70, envs finished 1
2026-01-17 13:33:27,774 : agent.on_policy : DEBUG : Mean Losses: [4.685543984174728]
2026-01-17 13:33:27,779 : worker.worker : DEBUG : Step 147489, finished rewards 12.20, envs finished 1
2026-01-17 13:33:27,798 : worker.worker : DEBUG : Step 147493, finished rewards 10.31, envs finished 1
2026-01-17 13:33:27,842 : worker.worker : DEBUG : Step 147502, finished rewards 3.57, envs finished 1
2026-01-17 13:33:27,919 : worker.worker : DEBUG : Step 147509, finished rewards 28.91, envs finished 1
2026-01-17 13:33:28,096 : agent.on_policy : DEBUG : Mean Losses: [5.783350475132465]
2026-01-17 13:33:28,108 : worker.worker : DEBUG : Step 147523, finished rewards -12.08, envs finished 1
2026-01-17 13:33:28,142 : worker.worker : DEBUG : Step 147530, finished rewards -1.12, envs finished 1
2026-01-17 13:33:28,196 : worker.worker : DEBUG : Step 147543, finished rewards 25.84, envs finished 1
2026-01-17 13:33:27,622 : agent.on_policy : DEBUG : Mean Losses: [4.748857252299786]
2026-01-17 13:33:27,698 : worker.worker : DEBUG : Step 147565, finished rewards 34.86, envs finished 1
2026-01-17 13:33:27,730 : worker.worker : DEBUG : Step 147571, finished rewards 42.34, envs finished 1
2026-01-17 13:33:27,763 : worker.worker : DEBUG : Step 147577, finished rewards 27.33, envs finished 1
2026-01-17 13:33:27,986 : agent.on_policy : DEBUG : Mean Losses: [7.078243676573038]
2026-01-17 13:33:28,004 : worker.worker : DEBUG : Step 147586, finished rewards 46.47, envs finished 1
2026-01-17 13:33:28,112 : worker.worker : DEBUG : Step 147606, finished rewards 46.48, envs finished 1
2026-01-17 13:33:28,251 : agent.on_policy : DEBUG : Mean Losses: [5.963131234049797]
2026-01-17 13:33:28,260 : worker.worker : DEBUG : Step 147617, finished rewards 11.00, envs finished 1
2026-01-17 13:33:28,374 : worker.worker : DEBUG : Step 147635, finished rewards -7.94, envs finished 1
2026-01-17 13:33:28,610 : agent.on_policy : DEBUG : Mean Losses: [3.6138895135372877]
2026-01-17 13:33:28,616 : worker.worker : DEBUG : Step 147648, finished rewards 6.21, envs finished 1
2026-01-17 13:33:28,963 : agent.on_policy : DEBUG : Mean Losses: [1.7303809523582458]
2026-01-17 13:33:29,061 : worker.worker : DEBUG : Step 147700, finished rewards 1.03, envs finished 1
2026-01-17 13:33:29,075 : worker.worker : DEBUG : Step 147702, finished rewards 4.02, envs finished 1
2026-01-17 13:33:29,094 : worker.worker : DEBUG : Step 147705, finished rewards 42.60, envs finished 1
2026-01-17 13:33:29,425 : agent.on_policy : DEBUG : Mean Losses: [8.564492166042328]
2026-01-17 13:33:29,451 : worker.worker : DEBUG : Step 147714, finished rewards -0.07, envs finished 1
2026-01-17 13:33:29,520 : worker.worker : DEBUG : Step 147729, finished rewards -19.41, envs finished 1
2026-01-17 13:33:29,694 : agent.on_policy : DEBUG : Mean Losses: [4.200103372335434]
2026-01-17 13:33:29,696 : worker.worker : DEBUG : Step 147744, finished rewards -1.98, envs finished 1
2026-01-17 13:33:29,758 : worker.worker : DEBUG : Step 147759, finished rewards 8.54, envs finished 1
2026-01-17 13:33:29,788 : worker.worker : DEBUG : Step 147765, finished rewards -7.36, envs finished 1
2026-01-17 13:33:30,057 : agent.on_policy : DEBUG : Mean Losses: [4.721228431910276]
2026-01-17 13:33:30,061 : worker.worker : DEBUG : Step 147776, finished rewards 41.30, envs finished 1
2026-01-17 13:33:30,201 : worker.worker : DEBUG : Step 147794, finished rewards 25.37, envs finished 1
2026-01-17 13:33:30,275 : worker.worker : DEBUG : Step 147804, finished rewards 15.71, envs finished 1
2026-01-17 13:33:30,435 : agent.on_policy : DEBUG : Mean Losses: [4.115794882178307]
2026-01-17 13:33:30,438 : worker.worker : DEBUG : Step 147808, finished rewards 23.06, envs finished 1
2026-01-17 13:33:30,590 : worker.worker : DEBUG : Step 147829, finished rewards 41.55, envs finished 1
2026-01-17 13:33:30,739 : agent.on_policy : DEBUG : Mean Losses: [3.8433367908000946]
2026-01-17 13:33:30,798 : worker.worker : DEBUG : Step 147844, finished rewards 20.59, envs finished 1
2026-01-17 13:33:30,826 : worker.worker : DEBUG : Step 147849, finished rewards 6.09, envs finished 1
2026-01-17 13:33:31,133 : agent.on_policy : DEBUG : Mean Losses: [3.5738083869218826]
2026-01-17 13:33:31,136 : worker.worker : DEBUG : Step 147872, finished rewards 17.37, envs finished 1
2026-01-17 13:33:31,200 : worker.worker : DEBUG : Step 147882, finished rewards 18.72, envs finished 1
2026-01-17 13:33:31,442 : agent.on_policy : DEBUG : Mean Losses: [3.7347946744412184]
2026-01-17 13:33:31,457 : worker.worker : DEBUG : Step 147907, finished rewards 17.90, envs finished 1
2026-01-17 13:33:31,518 : worker.worker : DEBUG : Step 147921, finished rewards 24.56, envs finished 1
2026-01-17 13:33:31,542 : worker.worker : DEBUG : Step 147926, finished rewards 14.71, envs finished 1
2026-01-17 13:33:31,577 : worker.worker : DEBUG : Step 147933, finished rewards 31.48, envs finished 1
2026-01-17 13:33:31,713 : agent.on_policy : DEBUG : Mean Losses: [8.045114532113075]
2026-01-17 13:33:31,756 : worker.worker : DEBUG : Step 147944, finished rewards 5.94, envs finished 2
2026-01-17 13:33:31,916 : worker.worker : DEBUG : Step 147960, finished rewards 27.85, envs finished 1
2026-01-17 13:33:32,085 : agent.on_policy : DEBUG : Mean Losses: [5.122802600264549]
2026-01-17 13:33:32,307 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:33:32,402 : agent.on_policy : DEBUG : Mean Losses: [2.455224208533764]
2026-01-17 13:33:32,425 : worker.worker : DEBUG : Step 148002, finished rewards 41.67, envs finished 1
2026-01-17 13:33:32,532 : worker.worker : DEBUG : Step 148017, finished rewards -5.49, envs finished 1
2026-01-17 13:33:32,588 : worker.worker : DEBUG : Step 148024, finished rewards 7.38, envs finished 1
2026-01-17 13:33:32,793 : agent.on_policy : DEBUG : Mean Losses: [5.724879890680313]
2026-01-17 13:33:32,939 : worker.worker : DEBUG : Step 148041, finished rewards 32.86, envs finished 1
2026-01-17 13:33:33,106 : worker.worker : DEBUG : Step 148052, finished rewards -1.19, envs finished 1
2026-01-17 13:33:33,183 : worker.worker : DEBUG : Step 148056, finished rewards 11.98, envs finished 1
2026-01-17 13:33:33,396 : agent.on_policy : DEBUG : Mean Losses: [5.737907074391842]
2026-01-17 13:33:33,517 : worker.worker : DEBUG : Step 148077, finished rewards -23.99, envs finished 1
2026-01-17 13:33:33,545 : worker.worker : DEBUG : Step 148081, finished rewards -6.35, envs finished 1
2026-01-17 13:33:33,723 : agent.on_policy : DEBUG : Mean Losses: [3.3658056426793337]
2026-01-17 13:33:33,725 : worker.worker : DEBUG : Step 148096, finished rewards 24.14, envs finished 1
2026-01-17 13:33:33,797 : worker.worker : DEBUG : Step 148115, finished rewards 24.91, envs finished 1
2026-01-17 13:33:33,957 : agent.on_policy : DEBUG : Mean Losses: [4.653889540582895]
2026-01-17 13:33:34,004 : worker.worker : DEBUG : Step 148141, finished rewards 24.79, envs finished 2
2026-01-17 13:33:34,070 : worker.worker : DEBUG : Step 148158, finished rewards 16.68, envs finished 1
2026-01-17 13:33:34,134 : agent.on_policy : DEBUG : Mean Losses: [5.459550812840462]
2026-01-17 13:33:34,138 : worker.worker : DEBUG : Step 148160, finished rewards 35.53, envs finished 1
2026-01-17 13:33:34,257 : worker.worker : DEBUG : Step 148175, finished rewards 22.38, envs finished 1
2026-01-17 13:33:34,284 : worker.worker : DEBUG : Step 148179, finished rewards 32.00, envs finished 1
2026-01-17 13:33:34,662 : agent.on_policy : DEBUG : Mean Losses: [5.763011198490858]
2026-01-17 13:33:34,791 : worker.worker : DEBUG : Step 148217, finished rewards 17.61, envs finished 1
2026-01-17 13:33:34,949 : agent.on_policy : DEBUG : Mean Losses: [2.657132837921381]
2026-01-17 13:33:35,000 : worker.worker : DEBUG : Step 148235, finished rewards 22.77, envs finished 1
2026-01-17 13:33:35,045 : worker.worker : DEBUG : Step 148243, finished rewards 18.66, envs finished 1
2026-01-17 13:33:35,128 : worker.worker : DEBUG : Step 148254, finished rewards -81.42, envs finished 1
2026-01-17 13:33:35,266 : agent.on_policy : DEBUG : Mean Losses: [4.851311564445496]
2026-01-17 13:33:35,418 : worker.worker : DEBUG : Step 148277, finished rewards 8.46, envs finished 1
2026-01-17 13:33:35,491 : worker.worker : DEBUG : Step 148281, finished rewards 17.47, envs finished 1
2026-01-17 13:33:35,714 : agent.on_policy : DEBUG : Mean Losses: [4.0864549949765205]
2026-01-17 13:33:35,973 : worker.worker : DEBUG : Step 148312, finished rewards -6.88, envs finished 1
2026-01-17 13:33:36,082 : agent.on_policy : DEBUG : Mean Losses: [4.526413090527058]
2026-01-17 13:33:36,299 : worker.worker : DEBUG : Step 148349, finished rewards 21.39, envs finished 1
2026-01-17 13:33:36,390 : agent.on_policy : DEBUG : Mean Losses: [5.563531905412674]
2026-01-17 13:33:36,398 : worker.worker : DEBUG : Step 148353, finished rewards -30.35, envs finished 1
2026-01-17 13:33:36,409 : worker.worker : DEBUG : Step 148355, finished rewards 5.78, envs finished 1
2026-01-17 13:33:36,418 : worker.worker : DEBUG : Step 148356, finished rewards 34.57, envs finished 1
2026-01-17 13:33:36,442 : worker.worker : DEBUG : Step 148358, finished rewards -14.19, envs finished 1
2026-01-17 13:33:36,545 : worker.worker : DEBUG : Step 148369, finished rewards 27.87, envs finished 1
2026-01-17 13:33:36,809 : agent.on_policy : DEBUG : Mean Losses: [6.163388612680137]
2026-01-17 13:33:36,828 : worker.worker : DEBUG : Step 148387, finished rewards -15.50, envs finished 1
2026-01-17 13:33:36,966 : worker.worker : DEBUG : Step 148411, finished rewards 19.25, envs finished 1
2026-01-17 13:33:37,142 : agent.on_policy : DEBUG : Mean Losses: [2.950695304200053]
2026-01-17 13:33:37,255 : worker.worker : DEBUG : Step 148426, finished rewards 35.16, envs finished 1
2026-01-17 13:33:37,534 : agent.on_policy : DEBUG : Mean Losses: [4.6914184698835015]
2026-01-17 13:33:37,593 : worker.worker : DEBUG : Step 148459, finished rewards 15.41, envs finished 1
2026-01-17 13:33:37,862 : agent.on_policy : DEBUG : Mean Losses: [5.070963054895401]
2026-01-17 13:33:37,906 : worker.worker : DEBUG : Step 148487, finished rewards -7.17, envs finished 1
2026-01-17 13:33:37,923 : worker.worker : DEBUG : Step 148489, finished rewards -1.00, envs finished 2
2026-01-17 13:33:38,009 : worker.worker : DEBUG : Step 148501, finished rewards 8.50, envs finished 1
2026-01-17 13:33:38,230 : agent.on_policy : DEBUG : Mean Losses: [7.216970071196556]
2026-01-17 13:33:38,317 : worker.worker : DEBUG : Step 148517, finished rewards 16.10, envs finished 1
2026-01-17 13:33:38,360 : worker.worker : DEBUG : Step 148522, finished rewards -23.75, envs finished 1
2026-01-17 13:33:38,620 : agent.on_policy : DEBUG : Mean Losses: [3.508822910487652]
2026-01-17 13:33:38,656 : worker.worker : DEBUG : Step 148550, finished rewards 25.93, envs finished 1
2026-01-17 13:33:38,670 : worker.worker : DEBUG : Step 148552, finished rewards 46.85, envs finished 1
2026-01-17 13:33:38,688 : worker.worker : DEBUG : Step 148554, finished rewards -0.69, envs finished 1
2026-01-17 13:33:38,889 : agent.on_policy : DEBUG : Mean Losses: [5.817088179290295]
2026-01-17 13:33:39,109 : agent.on_policy : DEBUG : Mean Losses: [3.1794289648532867]
2026-01-17 13:33:39,112 : worker.worker : DEBUG : Step 148608, finished rewards 9.05, envs finished 1
2026-01-17 13:33:39,131 : worker.worker : DEBUG : Step 148611, finished rewards 9.98, envs finished 1
2026-01-17 13:33:39,170 : worker.worker : DEBUG : Step 148619, finished rewards 19.55, envs finished 1
2026-01-17 13:33:39,239 : worker.worker : DEBUG : Step 148633, finished rewards 33.49, envs finished 1
2026-01-17 13:33:39,259 : worker.worker : DEBUG : Step 148636, finished rewards 11.56, envs finished 1
2026-01-17 13:33:39,275 : worker.worker : DEBUG : Step 148638, finished rewards 31.42, envs finished 1
2026-01-17 13:33:39,417 : agent.on_policy : DEBUG : Mean Losses: [10.066814988851547]
2026-01-17 13:33:39,510 : worker.worker : DEBUG : Step 148650, finished rewards -9.40, envs finished 1
2026-01-17 13:33:39,587 : worker.worker : DEBUG : Step 148654, finished rewards 18.16, envs finished 1
2026-01-17 13:33:39,964 : agent.on_policy : DEBUG : Mean Losses: [3.1790151689201593]
2026-01-17 13:33:40,037 : worker.worker : DEBUG : Step 148686, finished rewards 37.88, envs finished 1
2026-01-17 13:33:40,096 : worker.worker : DEBUG : Step 148702, finished rewards 32.14, envs finished 1
2026-01-17 13:33:40,217 : agent.on_policy : DEBUG : Mean Losses: [4.883201846852899]
2026-01-17 13:33:40,292 : worker.worker : DEBUG : Step 148711, finished rewards 17.47, envs finished 1
2026-01-17 13:33:40,356 : worker.worker : DEBUG : Step 148718, finished rewards 29.56, envs finished 1
2026-01-17 13:33:40,422 : worker.worker : DEBUG : Step 148726, finished rewards 29.10, envs finished 1
2026-01-17 13:33:40,440 : worker.worker : DEBUG : Step 148728, finished rewards 24.01, envs finished 1
2026-01-17 13:33:40,618 : agent.on_policy : DEBUG : Mean Losses: [7.4999292232096195]
2026-01-17 13:33:40,634 : worker.worker : DEBUG : Step 148736, finished rewards 28.96, envs finished 1
2026-01-17 13:33:40,849 : worker.worker : DEBUG : Step 148760, finished rewards 15.46, envs finished 1
2026-01-17 13:33:41,021 : agent.on_policy : DEBUG : Mean Losses: [2.7092060819268227]
2026-01-17 13:33:41,071 : worker.worker : DEBUG : Step 148776, finished rewards 26.66, envs finished 1
2026-01-17 13:33:41,190 : worker.worker : DEBUG : Step 148788, finished rewards 42.59, envs finished 1
2026-01-17 13:33:41,431 : agent.on_policy : DEBUG : Mean Losses: [5.029870418831706]
2026-01-17 13:33:41,552 : worker.worker : DEBUG : Step 148816, finished rewards 8.81, envs finished 1
2026-01-17 13:33:41,668 : worker.worker : DEBUG : Step 148828, finished rewards 25.42, envs finished 1
2026-01-17 13:33:41,685 : worker.worker : DEBUG : Step 148830, finished rewards 5.42, envs finished 1
2026-01-17 13:33:41,812 : agent.on_policy : DEBUG : Mean Losses: [5.360817231237888]
2026-01-17 13:33:41,957 : worker.worker : DEBUG : Step 148854, finished rewards 5.23, envs finished 1
2026-01-17 13:33:41,965 : worker.worker : DEBUG : Step 148855, finished rewards 34.28, envs finished 1
2026-01-17 13:33:42,065 : agent.on_policy : DEBUG : Mean Losses: [5.479353072121739]
2026-01-17 13:33:42,109 : worker.worker : DEBUG : Step 148874, finished rewards 31.51, envs finished 1
2026-01-17 13:33:42,229 : worker.worker : DEBUG : Step 148894, finished rewards -29.85, envs finished 1
2026-01-17 13:33:42,608 : agent.on_policy : DEBUG : Mean Losses: [3.8341796351596713]
2026-01-17 13:33:42,620 : worker.worker : DEBUG : Step 148896, finished rewards -8.09, envs finished 1
2026-01-17 13:33:42,788 : worker.worker : DEBUG : Step 148918, finished rewards 18.22, envs finished 1
2026-01-17 13:33:43,083 : agent.on_policy : DEBUG : Mean Losses: [2.8418263252824545]
2026-01-17 13:33:43,166 : worker.worker : DEBUG : Step 148937, finished rewards 13.67, envs finished 1
2026-01-17 13:33:43,215 : worker.worker : DEBUG : Step 148942, finished rewards 27.67, envs finished 1
2026-01-17 13:33:43,241 : worker.worker : DEBUG : Step 148944, finished rewards 27.25, envs finished 1
2026-01-17 13:33:43,354 : worker.worker : DEBUG : Step 148952, finished rewards 1.68, envs finished 1
2026-01-17 13:33:43,588 : agent.on_policy : DEBUG : Mean Losses: [7.896915584802628]
2026-01-17 13:33:43,618 : worker.worker : DEBUG : Step 148964, finished rewards 42.39, envs finished 1
2026-01-17 13:33:43,710 : worker.worker : DEBUG : Step 148975, finished rewards 17.72, envs finished 1
2026-01-17 13:33:43,756 : worker.worker : DEBUG : Step 148980, finished rewards 31.14, envs finished 1
2026-01-17 13:33:44,035 : agent.on_policy : DEBUG : Mean Losses: [5.660178314894438]
2026-01-17 13:33:44,110 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:33:44,300 : worker.worker : DEBUG : Step 149021, finished rewards 15.42, envs finished 1
2026-01-17 13:33:44,475 : agent.on_policy : DEBUG : Mean Losses: [3.2301699370145798]
2026-01-17 13:33:44,745 : worker.worker : DEBUG : Step 149050, finished rewards 29.25, envs finished 1
2026-01-17 13:33:44,913 : agent.on_policy : DEBUG : Mean Losses: [5.887354388833046]
2026-01-17 13:33:44,963 : worker.worker : DEBUG : Step 149062, finished rewards 3.67, envs finished 1
2026-01-17 13:33:45,014 : worker.worker : DEBUG : Step 149068, finished rewards -3.76, envs finished 1
2026-01-17 13:33:45,069 : worker.worker : DEBUG : Step 149075, finished rewards 17.46, envs finished 1
2026-01-17 13:33:45,130 : worker.worker : DEBUG : Step 149081, finished rewards -7.30, envs finished 1
2026-01-17 13:33:45,465 : agent.on_policy : DEBUG : Mean Losses: [7.4670384004712105]
2026-01-17 13:33:45,756 : agent.on_policy : DEBUG : Mean Losses: [3.2449969947338104]
2026-01-17 13:33:45,781 : worker.worker : DEBUG : Step 149125, finished rewards 4.65, envs finished 2
2026-01-17 13:33:45,822 : worker.worker : DEBUG : Step 149133, finished rewards 31.90, envs finished 1
2026-01-17 13:33:46,045 : agent.on_policy : DEBUG : Mean Losses: [5.399038657546043]
2026-01-17 13:33:46,094 : worker.worker : DEBUG : Step 149159, finished rewards 19.98, envs finished 1
2026-01-17 13:33:46,108 : worker.worker : DEBUG : Step 149161, finished rewards 23.48, envs finished 1
2026-01-17 13:33:46,192 : worker.worker : DEBUG : Step 149174, finished rewards 25.29, envs finished 1
2026-01-17 13:33:46,413 : agent.on_policy : DEBUG : Mean Losses: [5.726226095110178]
2026-01-17 13:33:46,438 : worker.worker : DEBUG : Step 149186, finished rewards 10.58, envs finished 1
2026-01-17 13:33:46,782 : agent.on_policy : DEBUG : Mean Losses: [3.681329905986786]
2026-01-17 13:33:46,853 : worker.worker : DEBUG : Step 149223, finished rewards 20.11, envs finished 1
2026-01-17 13:33:46,932 : worker.worker : DEBUG : Step 149237, finished rewards 17.38, envs finished 1
2026-01-17 13:33:47,017 : worker.worker : DEBUG : Step 149242, finished rewards 6.41, envs finished 1
2026-01-17 13:33:47,029 : worker.worker : DEBUG : Step 149243, finished rewards -59.24, envs finished 1
2026-01-17 13:33:47,197 : agent.on_policy : DEBUG : Mean Losses: [7.0146147310733795]
2026-01-17 13:33:47,325 : worker.worker : DEBUG : Step 149259, finished rewards 29.48, envs finished 1
2026-01-17 13:33:47,419 : worker.worker : DEBUG : Step 149273, finished rewards 27.98, envs finished 1
2026-01-17 13:33:47,502 : worker.worker : DEBUG : Step 149277, finished rewards 7.30, envs finished 1
2026-01-17 13:33:47,699 : agent.on_policy : DEBUG : Mean Losses: [5.884616379626095]
2026-01-17 13:33:47,873 : worker.worker : DEBUG : Step 149293, finished rewards 1.04, envs finished 1
2026-01-17 13:33:48,179 : agent.on_policy : DEBUG : Mean Losses: [2.3838060572743416]
2026-01-17 13:33:48,246 : worker.worker : DEBUG : Step 149325, finished rewards 32.89, envs finished 1
2026-01-17 13:33:48,315 : worker.worker : DEBUG : Step 149333, finished rewards 6.77, envs finished 1
2026-01-17 13:33:48,389 : worker.worker : DEBUG : Step 149335, finished rewards 21.44, envs finished 1
2026-01-17 13:33:48,428 : worker.worker : DEBUG : Step 149336, finished rewards 23.88, envs finished 1
2026-01-17 13:33:48,505 : worker.worker : DEBUG : Step 149343, finished rewards 41.60, envs finished 1
2026-01-17 13:33:48,807 : agent.on_policy : DEBUG : Mean Losses: [9.37784381210804]
2026-01-17 13:33:48,898 : worker.worker : DEBUG : Step 149358, finished rewards 22.67, envs finished 1
2026-01-17 13:33:49,084 : agent.on_policy : DEBUG : Mean Losses: [1.9604544416069984]
2026-01-17 13:33:49,200 : worker.worker : DEBUG : Step 149392, finished rewards 7.59, envs finished 1
2026-01-17 13:33:49,298 : worker.worker : DEBUG : Step 149401, finished rewards 11.65, envs finished 1
2026-01-17 13:33:49,440 : agent.on_policy : DEBUG : Mean Losses: [3.90682090818882]
2026-01-17 13:33:49,536 : worker.worker : DEBUG : Step 149424, finished rewards 18.99, envs finished 1
2026-01-17 13:33:49,554 : worker.worker : DEBUG : Step 149427, finished rewards 24.90, envs finished 1
2026-01-17 13:33:49,631 : worker.worker : DEBUG : Step 149431, finished rewards 21.17, envs finished 1
2026-01-17 13:33:49,654 : worker.worker : DEBUG : Step 149434, finished rewards 22.52, envs finished 1
2026-01-17 13:33:49,981 : agent.on_policy : DEBUG : Mean Losses: [6.537253178656101]
2026-01-17 13:33:50,356 : agent.on_policy : DEBUG : Mean Losses: [1.5883454233407974]
2026-01-17 13:33:50,367 : worker.worker : DEBUG : Step 149474, finished rewards 5.90, envs finished 1
2026-01-17 13:33:50,386 : worker.worker : DEBUG : Step 149477, finished rewards -4.54, envs finished 1
2026-01-17 13:33:50,505 : worker.worker : DEBUG : Step 149499, finished rewards 21.28, envs finished 1
2026-01-17 13:33:50,616 : agent.on_policy : DEBUG : Mean Losses: [4.738190170377493]
2026-01-17 13:33:50,761 : worker.worker : DEBUG : Step 149517, finished rewards 24.07, envs finished 1
2026-01-17 13:33:50,784 : worker.worker : DEBUG : Step 149519, finished rewards 15.38, envs finished 2
2026-01-17 13:33:50,846 : worker.worker : DEBUG : Step 149528, finished rewards 21.09, envs finished 1
2026-01-17 13:33:51,000 : agent.on_policy : DEBUG : Mean Losses: [5.6471174489706755]
2026-01-17 13:33:51,007 : worker.worker : DEBUG : Step 149537, finished rewards 15.69, envs finished 1
2026-01-17 13:33:51,213 : agent.on_policy : DEBUG : Mean Losses: [2.1751395538449287]
2026-01-17 13:33:51,228 : worker.worker : DEBUG : Step 149570, finished rewards 20.89, envs finished 1
2026-01-17 13:33:51,274 : worker.worker : DEBUG : Step 149580, finished rewards 14.76, envs finished 1
2026-01-17 13:33:51,421 : agent.on_policy : DEBUG : Mean Losses: [4.494158200919628]
2026-01-17 13:33:51,504 : worker.worker : DEBUG : Step 149608, finished rewards 11.71, envs finished 1
2026-01-17 13:33:51,602 : worker.worker : DEBUG : Step 149620, finished rewards 19.73, envs finished 1
2026-01-17 13:33:51,672 : worker.worker : DEBUG : Step 149627, finished rewards 15.09, envs finished 1
2026-01-17 13:33:51,810 : agent.on_policy : DEBUG : Mean Losses: [6.544200882315636]
2026-01-17 13:33:51,821 : worker.worker : DEBUG : Step 149633, finished rewards 46.38, envs finished 1
2026-01-17 13:33:51,904 : worker.worker : DEBUG : Step 149638, finished rewards 17.35, envs finished 1
2026-01-17 13:33:51,987 : worker.worker : DEBUG : Step 149649, finished rewards 4.96, envs finished 1
2026-01-17 13:33:52,090 : worker.worker : DEBUG : Step 149661, finished rewards -10.18, envs finished 1
2026-01-17 13:33:52,245 : agent.on_policy : DEBUG : Mean Losses: [3.9414828717708588]
2026-01-17 13:33:52,479 : agent.on_policy : DEBUG : Mean Losses: [1.7740508131682873]
2026-01-17 13:33:52,581 : worker.worker : DEBUG : Step 149718, finished rewards 26.47, envs finished 1
2026-01-17 13:33:52,590 : worker.worker : DEBUG : Step 149719, finished rewards 42.46, envs finished 1
2026-01-17 13:33:52,617 : worker.worker : DEBUG : Step 149724, finished rewards 5.51, envs finished 1
2026-01-17 13:33:52,802 : agent.on_policy : DEBUG : Mean Losses: [8.57868579775095]
2026-01-17 13:33:52,839 : worker.worker : DEBUG : Step 149732, finished rewards 24.75, envs finished 1
2026-01-17 13:33:52,912 : worker.worker : DEBUG : Step 149737, finished rewards 36.19, envs finished 1
2026-01-17 13:33:52,995 : worker.worker : DEBUG : Step 149746, finished rewards 1.76, envs finished 1
2026-01-17 13:33:53,092 : worker.worker : DEBUG : Step 149758, finished rewards 0.19, envs finished 1
2026-01-17 13:33:53,210 : agent.on_policy : DEBUG : Mean Losses: [6.004240687005222]
2026-01-17 13:33:53,223 : worker.worker : DEBUG : Step 149762, finished rewards -27.51, envs finished 1
2026-01-17 13:33:53,485 : agent.on_policy : DEBUG : Mean Losses: [1.1838553994894028]
2026-01-17 13:33:53,616 : worker.worker : DEBUG : Step 149818, finished rewards 20.07, envs finished 1
2026-01-17 13:33:53,828 : agent.on_policy : DEBUG : Mean Losses: [4.142184592783451]
2026-01-17 13:33:53,836 : worker.worker : DEBUG : Step 149825, finished rewards 34.16, envs finished 1
2026-01-17 13:33:53,885 : worker.worker : DEBUG : Step 149833, finished rewards 19.71, envs finished 1
2026-01-17 13:33:53,908 : worker.worker : DEBUG : Step 149837, finished rewards 7.98, envs finished 2
2026-01-17 13:33:53,990 : worker.worker : DEBUG : Step 149855, finished rewards 19.62, envs finished 1
2026-01-17 13:33:54,077 : agent.on_policy : DEBUG : Mean Losses: [6.5235200971364975]
2026-01-17 13:33:54,107 : worker.worker : DEBUG : Step 149856, finished rewards 24.44, envs finished 1
2026-01-17 13:33:54,213 : worker.worker : DEBUG : Step 149867, finished rewards -2.12, envs finished 1
2026-01-17 13:33:54,421 : agent.on_policy : DEBUG : Mean Losses: [2.6282142531126738]
2026-01-17 13:33:54,502 : worker.worker : DEBUG : Step 149895, finished rewards 42.59, envs finished 1
2026-01-17 13:33:54,812 : agent.on_policy : DEBUG : Mean Losses: [3.1959201246500015]
2026-01-17 13:33:54,907 : worker.worker : DEBUG : Step 149928, finished rewards 25.43, envs finished 1
2026-01-17 13:33:54,933 : worker.worker : DEBUG : Step 149930, finished rewards 46.60, envs finished 1
2026-01-17 13:33:55,012 : worker.worker : DEBUG : Step 149943, finished rewards -1.89, envs finished 1
2026-01-17 13:33:55,234 : agent.on_policy : DEBUG : Mean Losses: [7.660361021757126]
2026-01-17 13:33:55,276 : worker.worker : DEBUG : Step 149954, finished rewards 18.81, envs finished 1
2026-01-17 13:33:55,333 : worker.worker : DEBUG : Step 149957, finished rewards 19.74, envs finished 1
2026-01-17 13:33:55,364 : worker.worker : DEBUG : Step 149963, finished rewards 9.40, envs finished 1
2026-01-17 13:33:55,395 : worker.worker : DEBUG : Step 149968, finished rewards -10.95, envs finished 1
2026-01-17 13:33:55,581 : agent.on_policy : DEBUG : Mean Losses: [4.2012159284204245]
2026-01-17 13:33:55,634 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:33:55,648 : worker.worker : INFO : Step 150000, Avg Reward 14.8354, Max Reward 46.8527, Loss [5.07883041]
2026-01-17 13:33:55,652 : network.model : INFO : Saved model to logs/Acrobot-Sarsa/model.pt
2026-01-17 13:33:56,836 : evaluate.evaluate : INFO : Evaluation results: mean = -122.00, std = 0.00, min = -122.00, max = -122.00, count = 1
2026-01-17 13:33:58,774 : worker.worker : DEBUG : Step 150008, finished rewards 11.19, envs finished 1
2026-01-17 13:33:58,900 : agent.on_policy : DEBUG : Mean Losses: [2.13846680149436]
2026-01-17 13:33:59,069 : worker.worker : DEBUG : Step 150037, finished rewards 14.13, envs finished 1
2026-01-17 13:33:59,334 : agent.on_policy : DEBUG : Mean Losses: [5.077312804758549]
2026-01-17 13:33:59,468 : worker.worker : DEBUG : Step 150057, finished rewards 9.92, envs finished 2
2026-01-17 13:33:59,565 : worker.worker : DEBUG : Step 150063, finished rewards 22.75, envs finished 1
2026-01-17 13:33:59,839 : agent.on_policy : DEBUG : Mean Losses: [5.640137851238251]
2026-01-17 13:33:59,902 : worker.worker : DEBUG : Step 150090, finished rewards -3.02, envs finished 1
2026-01-17 13:33:59,945 : worker.worker : DEBUG : Step 150098, finished rewards -26.24, envs finished 1
2026-01-17 13:33:59,998 : worker.worker : DEBUG : Step 150103, finished rewards -18.29, envs finished 1
2026-01-17 13:34:00,083 : worker.worker : DEBUG : Step 150110, finished rewards 18.13, envs finished 1
2026-01-17 13:34:00,164 : agent.on_policy : DEBUG : Mean Losses: [5.578084345906973]
2026-01-17 13:34:00,417 : agent.on_policy : DEBUG : Mean Losses: [2.414906330406666]
2026-01-17 13:34:00,509 : worker.worker : DEBUG : Step 150172, finished rewards 7.83, envs finished 1
2026-01-17 13:34:00,515 : worker.worker : DEBUG : Step 150174, finished rewards -8.38, envs finished 1
2026-01-17 13:34:00,602 : agent.on_policy : DEBUG : Mean Losses: [6.452447183430195]
2026-01-17 13:34:00,604 : worker.worker : DEBUG : Step 150176, finished rewards 13.05, envs finished 1
2026-01-17 13:34:00,633 : worker.worker : DEBUG : Step 150179, finished rewards 26.87, envs finished 1
2026-01-17 13:34:00,662 : worker.worker : DEBUG : Step 150184, finished rewards 31.12, envs finished 1
2026-01-17 13:34:00,670 : worker.worker : DEBUG : Step 150185, finished rewards -1.23, envs finished 1
2026-01-17 13:34:00,950 : agent.on_policy : DEBUG : Mean Losses: [4.343246405944228]
2026-01-17 13:34:00,982 : worker.worker : DEBUG : Step 150216, finished rewards 13.93, envs finished 1
2026-01-17 13:34:00,994 : worker.worker : DEBUG : Step 150219, finished rewards 15.85, envs finished 1
2026-01-17 13:34:01,154 : agent.on_policy : DEBUG : Mean Losses: [2.757096566259861]
2026-01-17 13:34:01,265 : worker.worker : DEBUG : Step 150263, finished rewards 30.20, envs finished 1
2026-01-17 13:34:01,285 : worker.worker : DEBUG : Step 150267, finished rewards 27.25, envs finished 1
2026-01-17 13:34:01,430 : agent.on_policy : DEBUG : Mean Losses: [6.496142655611038]
2026-01-17 13:34:01,479 : worker.worker : DEBUG : Step 150285, finished rewards 17.76, envs finished 1
2026-01-17 13:34:01,483 : worker.worker : DEBUG : Step 150286, finished rewards 19.08, envs finished 1
2026-01-17 13:34:01,512 : worker.worker : DEBUG : Step 150292, finished rewards 5.18, envs finished 1
2026-01-17 13:34:01,621 : agent.on_policy : DEBUG : Mean Losses: [5.815836243331432]
2026-01-17 13:34:01,625 : worker.worker : DEBUG : Step 150305, finished rewards 27.08, envs finished 1
2026-01-17 13:34:01,736 : worker.worker : DEBUG : Step 150321, finished rewards 19.00, envs finished 1
2026-01-17 13:34:02,064 : agent.on_policy : DEBUG : Mean Losses: [2.574951246380806]
2026-01-17 13:34:02,318 : worker.worker : DEBUG : Step 150361, finished rewards 22.21, envs finished 1
2026-01-17 13:34:02,327 : worker.worker : DEBUG : Step 150362, finished rewards 19.89, envs finished 1
2026-01-17 13:34:02,349 : worker.worker : DEBUG : Step 150365, finished rewards 33.58, envs finished 1
2026-01-17 13:34:02,538 : agent.on_policy : DEBUG : Mean Losses: [7.307792127132416]
2026-01-17 13:34:02,553 : worker.worker : DEBUG : Step 150371, finished rewards 30.03, envs finished 1
2026-01-17 13:34:02,674 : worker.worker : DEBUG : Step 150385, finished rewards 23.40, envs finished 1
2026-01-17 13:34:02,882 : agent.on_policy : DEBUG : Mean Losses: [5.376306753605604]
2026-01-17 13:34:02,883 : worker.worker : DEBUG : Step 150400, finished rewards 21.74, envs finished 1
2026-01-17 13:34:02,916 : worker.worker : DEBUG : Step 150407, finished rewards 28.97, envs finished 1
2026-01-17 13:34:03,191 : agent.on_policy : DEBUG : Mean Losses: [2.613178074359894]
2026-01-17 13:34:03,203 : worker.worker : DEBUG : Step 150434, finished rewards -6.79, envs finished 1
2026-01-17 13:34:03,289 : worker.worker : DEBUG : Step 150452, finished rewards 24.64, envs finished 1
2026-01-17 13:34:03,320 : worker.worker : DEBUG : Step 150457, finished rewards 25.22, envs finished 1
2026-01-17 13:34:03,341 : worker.worker : DEBUG : Step 150460, finished rewards 27.57, envs finished 1
2026-01-17 13:34:03,483 : agent.on_policy : DEBUG : Mean Losses: [6.725195810198784]
2026-01-17 13:34:03,608 : worker.worker : DEBUG : Step 150485, finished rewards 3.16, envs finished 1
2026-01-17 13:34:03,660 : worker.worker : DEBUG : Step 150492, finished rewards 29.03, envs finished 1
2026-01-17 13:34:03,695 : worker.worker : DEBUG : Step 150495, finished rewards 22.36, envs finished 1
2026-01-17 13:34:03,807 : agent.on_policy : DEBUG : Mean Losses: [4.583359025418758]
2026-01-17 13:34:03,865 : worker.worker : DEBUG : Step 150508, finished rewards 3.61, envs finished 1
2026-01-17 13:34:04,086 : agent.on_policy : DEBUG : Mean Losses: [3.2858972437679768]
2026-01-17 13:34:04,098 : worker.worker : DEBUG : Step 150531, finished rewards 41.52, envs finished 1
2026-01-17 13:34:04,181 : worker.worker : DEBUG : Step 150550, finished rewards 22.52, envs finished 1
2026-01-17 13:34:04,199 : worker.worker : DEBUG : Step 150554, finished rewards 21.42, envs finished 1
2026-01-17 13:34:04,308 : agent.on_policy : DEBUG : Mean Losses: [5.3647439405322075]
2026-01-17 13:34:04,319 : worker.worker : DEBUG : Step 150562, finished rewards 37.45, envs finished 1
2026-01-17 13:34:04,346 : worker.worker : DEBUG : Step 150566, finished rewards 1.58, envs finished 1
2026-01-17 13:34:04,629 : agent.on_policy : DEBUG : Mean Losses: [2.859747676178813]
2026-01-17 13:34:04,733 : worker.worker : DEBUG : Step 150611, finished rewards 13.89, envs finished 1
2026-01-17 13:34:04,791 : worker.worker : DEBUG : Step 150623, finished rewards 4.22, envs finished 1
2026-01-17 13:34:04,872 : agent.on_policy : DEBUG : Mean Losses: [3.8733794391155243]
2026-01-17 13:34:04,891 : worker.worker : DEBUG : Step 150627, finished rewards 36.30, envs finished 1
2026-01-17 13:34:04,918 : worker.worker : DEBUG : Step 150632, finished rewards 16.02, envs finished 1
2026-01-17 13:34:04,962 : worker.worker : DEBUG : Step 150640, finished rewards 2.91, envs finished 1
2026-01-17 13:34:04,975 : worker.worker : DEBUG : Step 150642, finished rewards 37.83, envs finished 1
2026-01-17 13:34:05,174 : agent.on_policy : DEBUG : Mean Losses: [6.011352098081261]
2026-01-17 13:34:05,229 : worker.worker : DEBUG : Step 150670, finished rewards 13.08, envs finished 1
2026-01-17 13:34:05,284 : worker.worker : DEBUG : Step 150685, finished rewards -5.88, envs finished 1
2026-01-17 13:34:05,393 : agent.on_policy : DEBUG : Mean Losses: [3.2607395239174366]
2026-01-17 13:34:05,482 : worker.worker : DEBUG : Step 150700, finished rewards 27.54, envs finished 1
2026-01-17 13:34:05,592 : worker.worker : DEBUG : Step 150715, finished rewards 26.12, envs finished 1
2026-01-17 13:34:05,734 : agent.on_policy : DEBUG : Mean Losses: [4.7584654074162245]
2026-01-17 13:34:05,838 : worker.worker : DEBUG : Step 150731, finished rewards 24.24, envs finished 1
2026-01-17 13:34:05,844 : worker.worker : DEBUG : Step 150732, finished rewards 20.20, envs finished 1
2026-01-17 13:34:05,868 : worker.worker : DEBUG : Step 150735, finished rewards 10.75, envs finished 1
2026-01-17 13:34:05,933 : worker.worker : DEBUG : Step 150742, finished rewards 18.45, envs finished 1
2026-01-17 13:34:06,084 : agent.on_policy : DEBUG : Mean Losses: [5.241443587467074]
2026-01-17 13:34:06,269 : worker.worker : DEBUG : Step 150771, finished rewards 28.87, envs finished 1
2026-01-17 13:34:06,447 : agent.on_policy : DEBUG : Mean Losses: [4.273334585130215]
2026-01-17 13:34:06,455 : worker.worker : DEBUG : Step 150785, finished rewards 42.64, envs finished 1
2026-01-17 13:34:06,541 : worker.worker : DEBUG : Step 150795, finished rewards 1.13, envs finished 1
2026-01-17 13:34:06,600 : worker.worker : DEBUG : Step 150802, finished rewards 42.59, envs finished 1
2026-01-17 13:34:06,902 : agent.on_policy : DEBUG : Mean Losses: [5.024553209543228]
2026-01-17 13:34:07,024 : worker.worker : DEBUG : Step 150841, finished rewards -11.59, envs finished 1
2026-01-17 13:34:07,259 : agent.on_policy : DEBUG : Mean Losses: [4.121297974139452]
2026-01-17 13:34:07,294 : worker.worker : DEBUG : Step 150852, finished rewards 3.12, envs finished 1
2026-01-17 13:34:07,341 : worker.worker : DEBUG : Step 150857, finished rewards 8.00, envs finished 1
2026-01-17 13:34:07,356 : worker.worker : DEBUG : Step 150858, finished rewards 1.73, envs finished 1
2026-01-17 13:34:07,626 : agent.on_policy : DEBUG : Mean Losses: [5.6038093864917755]
2026-01-17 13:34:07,678 : worker.worker : DEBUG : Step 150893, finished rewards 1.80, envs finished 1
2026-01-17 13:34:07,736 : worker.worker : DEBUG : Step 150904, finished rewards 12.97, envs finished 1
2026-01-17 13:34:07,926 : agent.on_policy : DEBUG : Mean Losses: [4.686720825731754]
2026-01-17 13:34:08,023 : worker.worker : DEBUG : Step 150925, finished rewards 0.33, envs finished 1
2026-01-17 13:34:08,252 : agent.on_policy : DEBUG : Mean Losses: [3.908473640680313]
2026-01-17 13:34:08,271 : worker.worker : DEBUG : Step 150948, finished rewards 20.41, envs finished 1
2026-01-17 13:34:08,277 : worker.worker : DEBUG : Step 150949, finished rewards 25.24, envs finished 1
2026-01-17 13:34:08,289 : worker.worker : DEBUG : Step 150951, finished rewards 23.72, envs finished 1
2026-01-17 13:34:08,323 : worker.worker : DEBUG : Step 150958, finished rewards 5.84, envs finished 1
2026-01-17 13:34:08,441 : agent.on_policy : DEBUG : Mean Losses: [5.012245606631041]
2026-01-17 13:34:08,583 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:34:08,652 : worker.worker : DEBUG : Step 151003, finished rewards 34.21, envs finished 1
2026-01-17 13:34:08,665 : worker.worker : DEBUG : Step 151004, finished rewards 11.21, envs finished 1
2026-01-17 13:34:08,688 : worker.worker : DEBUG : Step 151007, finished rewards 17.09, envs finished 1
2026-01-17 13:34:08,809 : agent.on_policy : DEBUG : Mean Losses: [5.932540103793144]
2026-01-17 13:34:08,893 : worker.worker : DEBUG : Step 151025, finished rewards -61.00, envs finished 1
2026-01-17 13:34:09,069 : agent.on_policy : DEBUG : Mean Losses: [4.974595649167895]
2026-01-17 13:34:09,144 : worker.worker : DEBUG : Step 151046, finished rewards 20.77, envs finished 1
2026-01-17 13:34:09,396 : worker.worker : DEBUG : Step 151071, finished rewards 2.42, envs finished 1
2026-01-17 13:34:09,621 : agent.on_policy : DEBUG : Mean Losses: [4.45064477622509]
2026-01-17 13:34:09,850 : worker.worker : DEBUG : Step 151086, finished rewards -8.01, envs finished 1
2026-01-17 13:34:09,949 : worker.worker : DEBUG : Step 151095, finished rewards -9.61, envs finished 1
2026-01-17 13:34:10,034 : worker.worker : DEBUG : Step 151102, finished rewards 23.11, envs finished 1
2026-01-17 13:34:10,171 : agent.on_policy : DEBUG : Mean Losses: [7.106356583535671]
2026-01-17 13:34:10,239 : worker.worker : DEBUG : Step 151107, finished rewards 18.02, envs finished 1
2026-01-17 13:34:10,499 : worker.worker : DEBUG : Step 151126, finished rewards 18.57, envs finished 1
2026-01-17 13:34:10,553 : worker.worker : DEBUG : Step 151132, finished rewards -1.70, envs finished 1
2026-01-17 13:34:10,699 : agent.on_policy : DEBUG : Mean Losses: [3.7363446578383446]
2026-01-17 13:34:11,075 : worker.worker : DEBUG : Step 151164, finished rewards 7.53, envs finished 1
2026-01-17 13:34:11,238 : agent.on_policy : DEBUG : Mean Losses: [2.478948064148426]
2026-01-17 13:34:11,576 : worker.worker : DEBUG : Step 151186, finished rewards 19.13, envs finished 1
2026-01-17 13:34:11,659 : worker.worker : DEBUG : Step 151194, finished rewards 16.52, envs finished 2
2026-01-17 13:34:11,682 : worker.worker : DEBUG : Step 151196, finished rewards 23.00, envs finished 1
2026-01-17 13:34:11,885 : agent.on_policy : DEBUG : Mean Losses: [6.230834625661373]
2026-01-17 13:34:12,336 : agent.on_policy : DEBUG : Mean Losses: [2.250586450099945]
2026-01-17 13:34:12,346 : worker.worker : DEBUG : Step 151233, finished rewards 13.97, envs finished 1
2026-01-17 13:34:12,440 : worker.worker : DEBUG : Step 151242, finished rewards 3.24, envs finished 1
2026-01-17 13:34:12,865 : agent.on_policy : DEBUG : Mean Losses: [3.9327203929424286]
2026-01-17 13:34:12,868 : worker.worker : DEBUG : Step 151264, finished rewards 19.62, envs finished 1
2026-01-17 13:34:12,932 : worker.worker : DEBUG : Step 151270, finished rewards 29.62, envs finished 1
2026-01-17 13:34:12,979 : worker.worker : DEBUG : Step 151272, finished rewards -8.39, envs finished 1
2026-01-17 13:34:13,048 : worker.worker : DEBUG : Step 151282, finished rewards 28.56, envs finished 1
2026-01-17 13:34:13,363 : agent.on_policy : DEBUG : Mean Losses: [5.4125946424901485]
2026-01-17 13:34:13,844 : agent.on_policy : DEBUG : Mean Losses: [3.592521011829376]
2026-01-17 13:34:13,857 : worker.worker : DEBUG : Step 151330, finished rewards 21.38, envs finished 1
2026-01-17 13:34:13,865 : worker.worker : DEBUG : Step 151331, finished rewards -8.77, envs finished 1
2026-01-17 13:34:13,912 : worker.worker : DEBUG : Step 151336, finished rewards -6.64, envs finished 1
2026-01-17 13:34:14,018 : worker.worker : DEBUG : Step 151353, finished rewards 42.13, envs finished 1
2026-01-17 13:34:14,229 : agent.on_policy : DEBUG : Mean Losses: [6.97525055333972]
2026-01-17 13:34:14,603 : agent.on_policy : DEBUG : Mean Losses: [2.824156701564789]
2026-01-17 13:34:14,606 : worker.worker : DEBUG : Step 151392, finished rewards -13.59, envs finished 1
2026-01-17 13:34:14,652 : worker.worker : DEBUG : Step 151398, finished rewards 2.78, envs finished 1
2026-01-17 13:34:14,721 : worker.worker : DEBUG : Step 151409, finished rewards -11.84, envs finished 1
2026-01-17 13:34:14,743 : worker.worker : DEBUG : Step 151412, finished rewards -10.62, envs finished 1
2026-01-17 13:34:14,970 : agent.on_policy : DEBUG : Mean Losses: [5.329802118241787]
2026-01-17 13:34:15,000 : worker.worker : DEBUG : Step 151429, finished rewards 36.77, envs finished 1
2026-01-17 13:34:15,017 : worker.worker : DEBUG : Step 151431, finished rewards 18.69, envs finished 2
2026-01-17 13:34:15,059 : worker.worker : DEBUG : Step 151437, finished rewards 19.00, envs finished 1
2026-01-17 13:34:15,275 : agent.on_policy : DEBUG : Mean Losses: [4.553915299475193]
2026-01-17 13:34:15,436 : worker.worker : DEBUG : Step 151473, finished rewards 38.02, envs finished 1
2026-01-17 13:34:15,481 : worker.worker : DEBUG : Step 151476, finished rewards 46.15, envs finished 1
2026-01-17 13:34:15,508 : worker.worker : DEBUG : Step 151478, finished rewards 29.20, envs finished 1
2026-01-17 13:34:15,789 : agent.on_policy : DEBUG : Mean Losses: [6.66203872859478]
2026-01-17 13:34:15,855 : worker.worker : DEBUG : Step 151501, finished rewards 42.45, envs finished 1
2026-01-17 13:34:15,888 : worker.worker : DEBUG : Step 151507, finished rewards 42.72, envs finished 1
2026-01-17 13:34:16,136 : agent.on_policy : DEBUG : Mean Losses: [5.522909544408321]
2026-01-17 13:34:16,147 : worker.worker : DEBUG : Step 151521, finished rewards 24.72, envs finished 1
2026-01-17 13:34:16,261 : worker.worker : DEBUG : Step 151537, finished rewards -5.39, envs finished 1
2026-01-17 13:34:16,535 : agent.on_policy : DEBUG : Mean Losses: [4.636030964553356]
2026-01-17 13:34:16,607 : worker.worker : DEBUG : Step 151565, finished rewards -9.01, envs finished 1
2026-01-17 13:34:16,656 : worker.worker : DEBUG : Step 151575, finished rewards 18.51, envs finished 1
2026-01-17 13:34:16,864 : agent.on_policy : DEBUG : Mean Losses: [5.452849559485912]
2026-01-17 13:34:16,867 : worker.worker : DEBUG : Step 151584, finished rewards 15.58, envs finished 1
2026-01-17 13:34:16,941 : worker.worker : DEBUG : Step 151594, finished rewards 23.98, envs finished 1
2026-01-17 13:34:17,022 : worker.worker : DEBUG : Step 151605, finished rewards -5.58, envs finished 1
2026-01-17 13:34:17,221 : agent.on_policy : DEBUG : Mean Losses: [3.6087053157389164]
2026-01-17 13:34:17,285 : worker.worker : DEBUG : Step 151621, finished rewards 17.99, envs finished 1
2026-01-17 13:34:17,370 : worker.worker : DEBUG : Step 151632, finished rewards 8.33, envs finished 1
2026-01-17 13:34:17,767 : agent.on_policy : DEBUG : Mean Losses: [2.5951021648943424]
2026-01-17 13:34:17,780 : worker.worker : DEBUG : Step 151650, finished rewards 8.14, envs finished 1
2026-01-17 13:34:18,095 : agent.on_policy : DEBUG : Mean Losses: [3.1975312158465385]
2026-01-17 13:34:18,187 : worker.worker : DEBUG : Step 151696, finished rewards 17.17, envs finished 1
2026-01-17 13:34:18,232 : worker.worker : DEBUG : Step 151702, finished rewards 7.51, envs finished 1
2026-01-17 13:34:18,448 : agent.on_policy : DEBUG : Mean Losses: [6.9773228764534]
2026-01-17 13:34:18,480 : worker.worker : DEBUG : Step 151718, finished rewards -24.41, envs finished 1
2026-01-17 13:34:18,498 : worker.worker : DEBUG : Step 151721, finished rewards -7.36, envs finished 1
2026-01-17 13:34:18,599 : worker.worker : DEBUG : Step 151742, finished rewards 13.01, envs finished 1
2026-01-17 13:34:18,731 : agent.on_policy : DEBUG : Mean Losses: [6.34192182123661]
2026-01-17 13:34:18,756 : worker.worker : DEBUG : Step 151747, finished rewards 8.76, envs finished 1
2026-01-17 13:34:18,878 : worker.worker : DEBUG : Step 151762, finished rewards -26.58, envs finished 1
2026-01-17 13:34:19,071 : agent.on_policy : DEBUG : Mean Losses: [3.5851054303348064]
2026-01-17 13:34:19,159 : worker.worker : DEBUG : Step 151795, finished rewards 20.62, envs finished 1
2026-01-17 13:34:19,192 : worker.worker : DEBUG : Step 151802, finished rewards 18.37, envs finished 1
2026-01-17 13:34:19,325 : agent.on_policy : DEBUG : Mean Losses: [5.1978421956300735]
2026-01-17 13:34:19,375 : worker.worker : DEBUG : Step 151813, finished rewards 40.89, envs finished 1
2026-01-17 13:34:19,426 : worker.worker : DEBUG : Step 151819, finished rewards 19.59, envs finished 1
2026-01-17 13:34:19,469 : worker.worker : DEBUG : Step 151829, finished rewards 32.97, envs finished 1
2026-01-17 13:34:19,494 : worker.worker : DEBUG : Step 151834, finished rewards 9.73, envs finished 1
2026-01-17 13:34:19,651 : agent.on_policy : DEBUG : Mean Losses: [6.5850841253995895]
2026-01-17 13:34:19,667 : worker.worker : DEBUG : Step 151844, finished rewards -43.99, envs finished 1
2026-01-17 13:34:19,673 : worker.worker : DEBUG : Step 151845, finished rewards 31.80, envs finished 1
2026-01-17 13:34:20,099 : agent.on_policy : DEBUG : Mean Losses: [2.76987736672163]
2026-01-17 13:34:20,147 : worker.worker : DEBUG : Step 151884, finished rewards 41.01, envs finished 1
2026-01-17 13:34:20,159 : worker.worker : DEBUG : Step 151887, finished rewards 26.22, envs finished 1
2026-01-17 13:34:20,171 : worker.worker : DEBUG : Step 151889, finished rewards 28.97, envs finished 1
2026-01-17 13:34:20,313 : agent.on_policy : DEBUG : Mean Losses: [6.540264070034027]
2026-01-17 13:34:20,455 : worker.worker : DEBUG : Step 151922, finished rewards 13.77, envs finished 1
2026-01-17 13:34:20,563 : worker.worker : DEBUG : Step 151931, finished rewards 28.21, envs finished 1
2026-01-17 13:34:20,743 : agent.on_policy : DEBUG : Mean Losses: [5.283046763390303]
2026-01-17 13:34:20,855 : worker.worker : DEBUG : Step 151954, finished rewards 11.60, envs finished 1
2026-01-17 13:34:20,974 : worker.worker : DEBUG : Step 151966, finished rewards -6.83, envs finished 1
2026-01-17 13:34:21,097 : agent.on_policy : DEBUG : Mean Losses: [4.109379276633263]
2026-01-17 13:34:21,202 : worker.worker : DEBUG : Step 151982, finished rewards 25.03, envs finished 1
2026-01-17 13:34:21,236 : worker.worker : DEBUG : Step 151988, finished rewards -1.56, envs finished 1
2026-01-17 13:34:21,328 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:34:21,475 : agent.on_policy : DEBUG : Mean Losses: [4.973976328969002]
2026-01-17 13:34:21,658 : worker.worker : DEBUG : Step 152021, finished rewards -4.40, envs finished 1
2026-01-17 13:34:21,730 : worker.worker : DEBUG : Step 152031, finished rewards 10.67, envs finished 1
2026-01-17 13:34:21,859 : agent.on_policy : DEBUG : Mean Losses: [4.823244296014309]
2026-01-17 13:34:21,908 : worker.worker : DEBUG : Step 152035, finished rewards 41.81, envs finished 1
2026-01-17 13:34:22,145 : worker.worker : DEBUG : Step 152056, finished rewards 17.79, envs finished 1
2026-01-17 13:34:22,235 : agent.on_policy : DEBUG : Mean Losses: [4.067195104435086]
2026-01-17 13:34:22,244 : worker.worker : DEBUG : Step 152066, finished rewards -6.69, envs finished 1
2026-01-17 13:34:22,265 : worker.worker : DEBUG : Step 152071, finished rewards 27.51, envs finished 1
2026-01-17 13:34:22,360 : worker.worker : DEBUG : Step 152083, finished rewards 1.72, envs finished 1
2026-01-17 13:34:22,536 : agent.on_policy : DEBUG : Mean Losses: [4.0138207003474236]
2026-01-17 13:34:22,624 : worker.worker : DEBUG : Step 152112, finished rewards 5.60, envs finished 1
2026-01-17 13:34:22,683 : worker.worker : DEBUG : Step 152121, finished rewards 28.74, envs finished 1
2026-01-17 13:34:22,848 : agent.on_policy : DEBUG : Mean Losses: [4.4496512077748775]
2026-01-17 13:34:22,881 : worker.worker : DEBUG : Step 152130, finished rewards 15.94, envs finished 2
2026-01-17 13:34:22,916 : worker.worker : DEBUG : Step 152134, finished rewards 38.75, envs finished 2
2026-01-17 13:34:23,008 : worker.worker : DEBUG : Step 152154, finished rewards 41.81, envs finished 1
2026-01-17 13:34:23,135 : agent.on_policy : DEBUG : Mean Losses: [6.23883453477174]
2026-01-17 13:34:23,162 : worker.worker : DEBUG : Step 152164, finished rewards 23.89, envs finished 1
2026-01-17 13:34:23,445 : agent.on_policy : DEBUG : Mean Losses: [1.789479237049818]
2026-01-17 13:34:23,721 : agent.on_policy : DEBUG : Mean Losses: [2.6964684072881937]
2026-01-17 13:34:23,748 : worker.worker : DEBUG : Step 152228, finished rewards 14.57, envs finished 1
2026-01-17 13:34:23,772 : worker.worker : DEBUG : Step 152232, finished rewards 17.79, envs finished 1
2026-01-17 13:34:23,803 : worker.worker : DEBUG : Step 152237, finished rewards 12.51, envs finished 1
2026-01-17 13:34:23,837 : worker.worker : DEBUG : Step 152243, finished rewards 13.66, envs finished 1
2026-01-17 13:34:23,852 : worker.worker : DEBUG : Step 152246, finished rewards 24.26, envs finished 1
2026-01-17 13:34:23,889 : worker.worker : DEBUG : Step 152254, finished rewards -10.50, envs finished 1
2026-01-17 13:34:23,949 : agent.on_policy : DEBUG : Mean Losses: [9.28121131658554]
2026-01-17 13:34:24,108 : worker.worker : DEBUG : Step 152276, finished rewards -7.12, envs finished 1
2026-01-17 13:34:24,138 : worker.worker : DEBUG : Step 152282, finished rewards 2.35, envs finished 1
2026-01-17 13:34:24,218 : agent.on_policy : DEBUG : Mean Losses: [3.5929197277873755]
2026-01-17 13:34:24,254 : worker.worker : DEBUG : Step 152298, finished rewards 42.47, envs finished 1
2026-01-17 13:34:24,442 : agent.on_policy : DEBUG : Mean Losses: [3.1225184947252274]
2026-01-17 13:34:24,528 : worker.worker : DEBUG : Step 152346, finished rewards 41.35, envs finished 1
2026-01-17 13:34:24,537 : worker.worker : DEBUG : Step 152348, finished rewards 25.94, envs finished 1
2026-01-17 13:34:24,554 : worker.worker : DEBUG : Step 152351, finished rewards 15.10, envs finished 1
2026-01-17 13:34:24,685 : agent.on_policy : DEBUG : Mean Losses: [6.426181174814701]
2026-01-17 13:34:24,783 : worker.worker : DEBUG : Step 152360, finished rewards -0.13, envs finished 1
2026-01-17 13:34:24,820 : worker.worker : DEBUG : Step 152364, finished rewards 5.38, envs finished 1
2026-01-17 13:34:25,136 : agent.on_policy : DEBUG : Mean Losses: [3.103166571818292]
2026-01-17 13:34:25,139 : worker.worker : DEBUG : Step 152384, finished rewards 18.30, envs finished 1
2026-01-17 13:34:25,182 : worker.worker : DEBUG : Step 152392, finished rewards -7.03, envs finished 1
2026-01-17 13:34:25,329 : agent.on_policy : DEBUG : Mean Losses: [3.250002108514309]
2026-01-17 13:34:25,397 : worker.worker : DEBUG : Step 152421, finished rewards 42.27, envs finished 1
2026-01-17 13:34:25,494 : worker.worker : DEBUG : Step 152439, finished rewards 22.69, envs finished 1
2026-01-17 13:34:25,619 : agent.on_policy : DEBUG : Mean Losses: [5.6843956261873245]
2026-01-17 13:34:25,621 : worker.worker : DEBUG : Step 152448, finished rewards 17.81, envs finished 1
2026-01-17 13:34:25,785 : worker.worker : DEBUG : Step 152474, finished rewards 19.67, envs finished 1
2026-01-17 13:34:25,860 : agent.on_policy : DEBUG : Mean Losses: [5.365633971989155]
2026-01-17 13:34:25,874 : worker.worker : DEBUG : Step 152484, finished rewards 25.80, envs finished 1
2026-01-17 13:34:25,919 : worker.worker : DEBUG : Step 152493, finished rewards 1.67, envs finished 1
2026-01-17 13:34:26,149 : agent.on_policy : DEBUG : Mean Losses: [3.9845619201660156]
2026-01-17 13:34:26,155 : worker.worker : DEBUG : Step 152513, finished rewards 24.89, envs finished 1
2026-01-17 13:34:26,174 : worker.worker : DEBUG : Step 152518, finished rewards 6.20, envs finished 1
2026-01-17 13:34:26,317 : agent.on_policy : DEBUG : Mean Losses: [3.116446115076542]
2026-01-17 13:34:26,357 : worker.worker : DEBUG : Step 152546, finished rewards 11.51, envs finished 1
2026-01-17 13:34:26,396 : worker.worker : DEBUG : Step 152548, finished rewards -36.82, envs finished 1
2026-01-17 13:34:26,427 : worker.worker : DEBUG : Step 152553, finished rewards 14.23, envs finished 1
2026-01-17 13:34:26,471 : worker.worker : DEBUG : Step 152561, finished rewards 35.14, envs finished 1
2026-01-17 13:34:26,600 : agent.on_policy : DEBUG : Mean Losses: [5.233941772021353]
2026-01-17 13:34:26,685 : worker.worker : DEBUG : Step 152582, finished rewards 10.73, envs finished 1
2026-01-17 13:34:26,062 : worker.worker : DEBUG : Step 152601, finished rewards 27.94, envs finished 1
2026-01-17 13:34:26,163 : agent.on_policy : DEBUG : Mean Losses: [5.358772121369839]
2026-01-17 13:34:26,165 : worker.worker : DEBUG : Step 152608, finished rewards 12.89, envs finished 1
2026-01-17 13:34:26,424 : worker.worker : DEBUG : Step 152638, finished rewards 23.78, envs finished 1
2026-01-17 13:34:26,522 : agent.on_policy : DEBUG : Mean Losses: [4.846140466630459]
2026-01-17 13:34:26,674 : worker.worker : DEBUG : Step 152663, finished rewards 19.67, envs finished 1
2026-01-17 13:34:26,697 : worker.worker : DEBUG : Step 152667, finished rewards 4.29, envs finished 1
2026-01-17 13:34:26,742 : worker.worker : DEBUG : Step 152668, finished rewards -22.16, envs finished 1
2026-01-17 13:34:26,769 : worker.worker : DEBUG : Step 152669, finished rewards 16.36, envs finished 1
2026-01-17 13:34:26,871 : agent.on_policy : DEBUG : Mean Losses: [7.034121762495488]
2026-01-17 13:34:27,012 : worker.worker : DEBUG : Step 152691, finished rewards 9.32, envs finished 1
2026-01-17 13:34:27,108 : worker.worker : DEBUG : Step 152699, finished rewards 26.07, envs finished 1
2026-01-17 13:34:27,260 : agent.on_policy : DEBUG : Mean Losses: [4.65906123444438]
2026-01-17 13:34:27,281 : worker.worker : DEBUG : Step 152708, finished rewards 40.28, envs finished 1
2026-01-17 13:34:27,360 : worker.worker : DEBUG : Step 152716, finished rewards 9.24, envs finished 1
2026-01-17 13:34:27,701 : agent.on_policy : DEBUG : Mean Losses: [3.9820442385971546]
2026-01-17 13:34:27,755 : worker.worker : DEBUG : Step 152742, finished rewards 38.67, envs finished 1
2026-01-17 13:34:27,807 : worker.worker : DEBUG : Step 152749, finished rewards 31.32, envs finished 1
2026-01-17 13:34:27,923 : worker.worker : DEBUG : Step 152760, finished rewards 41.10, envs finished 1
2026-01-17 13:34:27,961 : worker.worker : DEBUG : Step 152767, finished rewards 19.43, envs finished 1
2026-01-17 13:34:28,087 : agent.on_policy : DEBUG : Mean Losses: [6.378640778362751]
2026-01-17 13:34:28,203 : worker.worker : DEBUG : Step 152783, finished rewards 38.69, envs finished 1
2026-01-17 13:34:28,216 : worker.worker : DEBUG : Step 152785, finished rewards 5.03, envs finished 1
2026-01-17 13:34:28,385 : agent.on_policy : DEBUG : Mean Losses: [4.217901781201363]
2026-01-17 13:34:28,395 : worker.worker : DEBUG : Step 152802, finished rewards 29.33, envs finished 1
2026-01-17 13:34:28,483 : worker.worker : DEBUG : Step 152826, finished rewards 2.19, envs finished 1
2026-01-17 13:34:28,587 : agent.on_policy : DEBUG : Mean Losses: [4.2552173137664795]
2026-01-17 13:34:28,704 : worker.worker : DEBUG : Step 152854, finished rewards 41.56, envs finished 1
2026-01-17 13:34:28,854 : agent.on_policy : DEBUG : Mean Losses: [5.049686595797539]
2026-01-17 13:34:28,878 : worker.worker : DEBUG : Step 152865, finished rewards 11.87, envs finished 2
2026-01-17 13:34:28,903 : worker.worker : DEBUG : Step 152866, finished rewards 0.69, envs finished 1
2026-01-17 13:34:29,050 : worker.worker : DEBUG : Step 152880, finished rewards 9.03, envs finished 1
2026-01-17 13:34:29,389 : agent.on_policy : DEBUG : Mean Losses: [4.6428910456597805]
2026-01-17 13:34:29,396 : worker.worker : DEBUG : Step 152896, finished rewards 42.53, envs finished 1
2026-01-17 13:34:29,505 : worker.worker : DEBUG : Step 152906, finished rewards 3.30, envs finished 1
2026-01-17 13:34:29,639 : worker.worker : DEBUG : Step 152919, finished rewards 6.33, envs finished 1
2026-01-17 13:34:29,787 : agent.on_policy : DEBUG : Mean Losses: [2.9972929060459137]
2026-01-17 13:34:29,846 : worker.worker : DEBUG : Step 152944, finished rewards 26.33, envs finished 1
2026-01-17 13:34:29,913 : worker.worker : DEBUG : Step 152959, finished rewards 21.96, envs finished 1
2026-01-17 13:34:30,065 : agent.on_policy : DEBUG : Mean Losses: [4.408935502171516]
2026-01-17 13:34:30,184 : worker.worker : DEBUG : Step 152976, finished rewards 12.64, envs finished 1
2026-01-17 13:34:30,204 : worker.worker : DEBUG : Step 152979, finished rewards 20.96, envs finished 1
2026-01-17 13:34:30,371 : agent.on_policy : DEBUG : Mean Losses: [4.430444370023906]
2026-01-17 13:34:30,394 : worker.worker : DEBUG : Step 152998, finished rewards -6.72, envs finished 1
2026-01-17 13:34:30,395 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:34:30,495 : worker.worker : DEBUG : Step 153021, finished rewards 18.00, envs finished 1
2026-01-17 13:34:30,615 : agent.on_policy : DEBUG : Mean Losses: [4.376163739711046]
2026-01-17 13:34:30,658 : worker.worker : DEBUG : Step 153034, finished rewards -5.17, envs finished 1
2026-01-17 13:34:30,691 : worker.worker : DEBUG : Step 153036, finished rewards 37.27, envs finished 1
2026-01-17 13:34:30,889 : agent.on_policy : DEBUG : Mean Losses: [4.584789305925369]
2026-01-17 13:34:30,900 : worker.worker : DEBUG : Step 153057, finished rewards -30.56, envs finished 1
2026-01-17 13:34:30,932 : worker.worker : DEBUG : Step 153063, finished rewards 30.34, envs finished 1
2026-01-17 13:34:30,962 : worker.worker : DEBUG : Step 153068, finished rewards 42.64, envs finished 1
2026-01-17 13:34:30,993 : worker.worker : DEBUG : Step 153073, finished rewards -3.13, envs finished 1
2026-01-17 13:34:31,138 : agent.on_policy : DEBUG : Mean Losses: [5.469005614519119]
2026-01-17 13:34:31,205 : worker.worker : DEBUG : Step 153091, finished rewards 42.85, envs finished 1
2026-01-17 13:34:31,384 : worker.worker : DEBUG : Step 153111, finished rewards -1.21, envs finished 1
2026-01-17 13:34:31,485 : agent.on_policy : DEBUG : Mean Losses: [2.898814845830202]
2026-01-17 13:34:31,553 : worker.worker : DEBUG : Step 153133, finished rewards 19.01, envs finished 1
2026-01-17 13:34:31,619 : worker.worker : DEBUG : Step 153136, finished rewards 35.86, envs finished 1
2026-01-17 13:34:31,857 : agent.on_policy : DEBUG : Mean Losses: [5.107002034783363]
2026-01-17 13:34:31,962 : worker.worker : DEBUG : Step 153165, finished rewards 17.10, envs finished 1
2026-01-17 13:34:32,087 : worker.worker : DEBUG : Step 153174, finished rewards 14.29, envs finished 1
2026-01-17 13:34:32,290 : agent.on_policy : DEBUG : Mean Losses: [5.249027252197266]
2026-01-17 13:34:32,340 : worker.worker : DEBUG : Step 153188, finished rewards 23.89, envs finished 1
2026-01-17 13:34:32,428 : worker.worker : DEBUG : Step 153200, finished rewards -17.43, envs finished 1
2026-01-17 13:34:32,442 : worker.worker : DEBUG : Step 153202, finished rewards 24.75, envs finished 1
2026-01-17 13:34:32,475 : worker.worker : DEBUG : Step 153206, finished rewards -2.41, envs finished 1
2026-01-17 13:34:32,770 : agent.on_policy : DEBUG : Mean Losses: [5.946134902536869]
2026-01-17 13:34:32,843 : worker.worker : DEBUG : Step 153227, finished rewards 25.19, envs finished 1
2026-01-17 13:34:33,122 : agent.on_policy : DEBUG : Mean Losses: [2.6485565565526485]
2026-01-17 13:34:33,589 : agent.on_policy : DEBUG : Mean Losses: [3.527983456850052]
2026-01-17 13:34:33,662 : worker.worker : DEBUG : Step 153293, finished rewards -20.23, envs finished 1
2026-01-17 13:34:33,678 : worker.worker : DEBUG : Step 153296, finished rewards 22.47, envs finished 1
2026-01-17 13:34:33,723 : worker.worker : DEBUG : Step 153303, finished rewards -11.10, envs finished 1
2026-01-17 13:34:33,734 : worker.worker : DEBUG : Step 153304, finished rewards 11.72, envs finished 2
2026-01-17 13:34:33,756 : worker.worker : DEBUG : Step 153305, finished rewards 19.55, envs finished 1
2026-01-17 13:34:33,775 : worker.worker : DEBUG : Step 153306, finished rewards 26.25, envs finished 1
2026-01-17 13:34:33,896 : agent.on_policy : DEBUG : Mean Losses: [8.481050878763199]
2026-01-17 13:34:33,949 : worker.worker : DEBUG : Step 153319, finished rewards 23.73, envs finished 1
2026-01-17 13:34:34,213 : agent.on_policy : DEBUG : Mean Losses: [1.516231656074524]
2026-01-17 13:34:34,442 : agent.on_policy : DEBUG : Mean Losses: [2.289177030324936]
2026-01-17 13:34:34,459 : worker.worker : DEBUG : Step 153378, finished rewards 34.42, envs finished 1
2026-01-17 13:34:34,536 : worker.worker : DEBUG : Step 153394, finished rewards 26.99, envs finished 1
2026-01-17 13:34:34,558 : worker.worker : DEBUG : Step 153398, finished rewards 15.43, envs finished 1
2026-01-17 13:34:34,714 : agent.on_policy : DEBUG : Mean Losses: [7.392862021923065]
2026-01-17 13:34:34,721 : worker.worker : DEBUG : Step 153409, finished rewards 13.01, envs finished 1
2026-01-17 13:34:34,834 : worker.worker : DEBUG : Step 153421, finished rewards 7.81, envs finished 1
2026-01-17 13:34:34,905 : worker.worker : DEBUG : Step 153431, finished rewards 9.63, envs finished 1
2026-01-17 13:34:35,067 : agent.on_policy : DEBUG : Mean Losses: [4.860602185130119]
2026-01-17 13:34:35,093 : worker.worker : DEBUG : Step 153443, finished rewards -12.20, envs finished 1
2026-01-17 13:34:35,120 : worker.worker : DEBUG : Step 153448, finished rewards 41.40, envs finished 1
2026-01-17 13:34:35,144 : worker.worker : DEBUG : Step 153451, finished rewards -1.83, envs finished 1
2026-01-17 13:34:35,280 : agent.on_policy : DEBUG : Mean Losses: [3.55928798019886]
2026-01-17 13:34:35,408 : worker.worker : DEBUG : Step 153491, finished rewards 40.69, envs finished 1
2026-01-17 13:34:35,605 : agent.on_policy : DEBUG : Mean Losses: [4.000140614807606]
2026-01-17 13:34:35,618 : worker.worker : DEBUG : Step 153507, finished rewards 19.98, envs finished 1
2026-01-17 13:34:35,654 : worker.worker : DEBUG : Step 153515, finished rewards 3.89, envs finished 1
2026-01-17 13:34:35,695 : worker.worker : DEBUG : Step 153523, finished rewards 36.62, envs finished 1
2026-01-17 13:34:35,834 : agent.on_policy : DEBUG : Mean Losses: [5.287767864763737]
2026-01-17 13:34:35,900 : worker.worker : DEBUG : Step 153540, finished rewards -14.02, envs finished 1
2026-01-17 13:34:35,954 : worker.worker : DEBUG : Step 153549, finished rewards 4.71, envs finished 1
2026-01-17 13:34:36,011 : worker.worker : DEBUG : Step 153559, finished rewards 12.57, envs finished 2
2026-01-17 13:34:36,027 : worker.worker : DEBUG : Step 153562, finished rewards 41.84, envs finished 1
2026-01-17 13:34:36,222 : agent.on_policy : DEBUG : Mean Losses: [6.630876047536731]
2026-01-17 13:34:36,271 : worker.worker : DEBUG : Step 153577, finished rewards 42.25, envs finished 1
2026-01-17 13:34:36,504 : agent.on_policy : DEBUG : Mean Losses: [2.5125040896236897]
2026-01-17 13:34:36,768 : agent.on_policy : DEBUG : Mean Losses: [5.0100561529397964]
2026-01-17 13:34:36,778 : worker.worker : DEBUG : Step 153633, finished rewards 25.77, envs finished 1
2026-01-17 13:34:36,787 : worker.worker : DEBUG : Step 153634, finished rewards 29.38, envs finished 1
2026-01-17 13:34:36,849 : worker.worker : DEBUG : Step 153649, finished rewards 26.67, envs finished 1
2026-01-17 13:34:36,906 : worker.worker : DEBUG : Step 153663, finished rewards -15.88, envs finished 1
2026-01-17 13:34:37,024 : agent.on_policy : DEBUG : Mean Losses: [6.966526091098785]
2026-01-17 13:34:37,060 : worker.worker : DEBUG : Step 153669, finished rewards -11.76, envs finished 1
2026-01-17 13:34:37,127 : worker.worker : DEBUG : Step 153675, finished rewards 6.98, envs finished 1
2026-01-17 13:34:37,471 : agent.on_policy : DEBUG : Mean Losses: [3.835585180670023]
2026-01-17 13:34:37,585 : worker.worker : DEBUG : Step 153726, finished rewards -13.44, envs finished 1
2026-01-17 13:34:37,708 : agent.on_policy : DEBUG : Mean Losses: [5.003543086349964]
2026-01-17 13:34:37,766 : worker.worker : DEBUG : Step 153740, finished rewards 25.10, envs finished 1
2026-01-17 13:34:37,883 : worker.worker : DEBUG : Step 153749, finished rewards 10.78, envs finished 2
2026-01-17 13:34:38,068 : agent.on_policy : DEBUG : Mean Losses: [7.384148091077805]
2026-01-17 13:34:38,075 : worker.worker : DEBUG : Step 153761, finished rewards 28.33, envs finished 1
2026-01-17 13:34:38,105 : worker.worker : DEBUG : Step 153766, finished rewards -51.37, envs finished 1
2026-01-17 13:34:38,209 : worker.worker : DEBUG : Step 153791, finished rewards -1.09, envs finished 1
2026-01-17 13:34:38,323 : agent.on_policy : DEBUG : Mean Losses: [4.068676921539009]
2026-01-17 13:34:38,466 : worker.worker : DEBUG : Step 153813, finished rewards 27.54, envs finished 1
2026-01-17 13:34:38,505 : worker.worker : DEBUG : Step 153820, finished rewards 40.97, envs finished 1
2026-01-17 13:34:38,631 : agent.on_policy : DEBUG : Mean Losses: [4.981819601729512]
2026-01-17 13:34:38,711 : worker.worker : DEBUG : Step 153831, finished rewards 32.60, envs finished 1
2026-01-17 13:34:38,909 : worker.worker : DEBUG : Step 153852, finished rewards 24.99, envs finished 1
2026-01-17 13:34:39,218 : agent.on_policy : DEBUG : Mean Losses: [4.689592387527227]
2026-01-17 13:34:39,699 : agent.on_policy : DEBUG : Mean Losses: [2.277675326913595]
2026-01-17 13:34:39,713 : worker.worker : DEBUG : Step 153889, finished rewards -14.66, envs finished 1
2026-01-17 13:34:39,746 : worker.worker : DEBUG : Step 153892, finished rewards 19.16, envs finished 1
2026-01-17 13:34:40,020 : worker.worker : DEBUG : Step 153911, finished rewards 33.83, envs finished 1
2026-01-17 13:34:40,156 : agent.on_policy : DEBUG : Mean Losses: [6.573266804218292]
2026-01-17 13:34:40,166 : worker.worker : DEBUG : Step 153920, finished rewards -8.10, envs finished 1
2026-01-17 13:34:40,260 : worker.worker : DEBUG : Step 153927, finished rewards 14.72, envs finished 1
2026-01-17 13:34:40,409 : worker.worker : DEBUG : Step 153940, finished rewards 27.50, envs finished 1
2026-01-17 13:34:40,661 : agent.on_policy : DEBUG : Mean Losses: [4.841442197561264]
2026-01-17 13:34:40,736 : worker.worker : DEBUG : Step 153962, finished rewards 42.49, envs finished 1
2026-01-17 13:34:40,872 : worker.worker : DEBUG : Step 153973, finished rewards -18.94, envs finished 1
2026-01-17 13:34:41,074 : agent.on_policy : DEBUG : Mean Losses: [4.46658032387495]
2026-01-17 13:34:41,143 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:34:41,156 : worker.worker : DEBUG : Step 154000, finished rewards 26.27, envs finished 1
2026-01-17 13:34:41,174 : worker.worker : DEBUG : Step 154002, finished rewards 32.94, envs finished 1
2026-01-17 13:34:41,201 : worker.worker : DEBUG : Step 154004, finished rewards 46.18, envs finished 1
2026-01-17 13:34:41,334 : worker.worker : DEBUG : Step 154014, finished rewards -1.31, envs finished 1
2026-01-17 13:34:41,521 : agent.on_policy : DEBUG : Mean Losses: [8.048847705125809]
2026-01-17 13:34:41,553 : worker.worker : DEBUG : Step 154020, finished rewards 25.19, envs finished 1
2026-01-17 13:34:41,773 : worker.worker : DEBUG : Step 154044, finished rewards 42.23, envs finished 1
2026-01-17 13:34:41,900 : agent.on_policy : DEBUG : Mean Losses: [3.7755790278315544]
2026-01-17 13:34:42,135 : worker.worker : DEBUG : Step 154075, finished rewards 5.41, envs finished 1
2026-01-17 13:34:42,249 : agent.on_policy : DEBUG : Mean Losses: [3.442418225109577]
2026-01-17 13:34:42,266 : worker.worker : DEBUG : Step 154083, finished rewards 46.36, envs finished 1
2026-01-17 13:34:42,401 : worker.worker : DEBUG : Step 154096, finished rewards 25.51, envs finished 2
2026-01-17 13:34:42,452 : worker.worker : DEBUG : Step 154100, finished rewards 28.89, envs finished 1
2026-01-17 13:34:42,684 : agent.on_policy : DEBUG : Mean Losses: [6.292280450463295]
2026-01-17 13:34:42,964 : agent.on_policy : DEBUG : Mean Losses: [1.910424344241619]
2026-01-17 13:34:43,044 : worker.worker : DEBUG : Step 154160, finished rewards 20.36, envs finished 1
2026-01-17 13:34:43,071 : worker.worker : DEBUG : Step 154164, finished rewards -20.01, envs finished 1
2026-01-17 13:34:43,141 : worker.worker : DEBUG : Step 154172, finished rewards -10.72, envs finished 1
2026-01-17 13:34:43,356 : agent.on_policy : DEBUG : Mean Losses: [6.888286262750626]
2026-01-17 13:34:43,466 : worker.worker : DEBUG : Step 154183, finished rewards 28.57, envs finished 1
2026-01-17 13:34:43,489 : worker.worker : DEBUG : Step 154185, finished rewards 15.01, envs finished 1
2026-01-17 13:34:43,514 : worker.worker : DEBUG : Step 154188, finished rewards 12.47, envs finished 1
2026-01-17 13:34:43,552 : worker.worker : DEBUG : Step 154193, finished rewards 23.24, envs finished 1
2026-01-17 13:34:43,810 : agent.on_policy : DEBUG : Mean Losses: [6.660712823271751]
2026-01-17 13:34:43,949 : worker.worker : DEBUG : Step 154238, finished rewards -13.23, envs finished 1
2026-01-17 13:34:44,079 : agent.on_policy : DEBUG : Mean Losses: [1.9430146887898445]
2026-01-17 13:34:44,311 : agent.on_policy : DEBUG : Mean Losses: [3.250779204070568]
2026-01-17 13:34:44,324 : worker.worker : DEBUG : Step 154275, finished rewards 10.68, envs finished 1
2026-01-17 13:34:44,343 : worker.worker : DEBUG : Step 154278, finished rewards 22.79, envs finished 1
2026-01-17 13:34:44,362 : worker.worker : DEBUG : Step 154281, finished rewards 22.32, envs finished 2
2026-01-17 13:34:44,404 : worker.worker : DEBUG : Step 154287, finished rewards 21.87, envs finished 1
2026-01-17 13:34:44,481 : worker.worker : DEBUG : Step 154303, finished rewards 4.04, envs finished 1
2026-01-17 13:34:44,547 : agent.on_policy : DEBUG : Mean Losses: [7.924793351441622]
2026-01-17 13:34:44,615 : worker.worker : DEBUG : Step 154308, finished rewards 41.18, envs finished 1
2026-01-17 13:34:44,717 : worker.worker : DEBUG : Step 154321, finished rewards -23.01, envs finished 1
2026-01-17 13:34:44,963 : agent.on_policy : DEBUG : Mean Losses: [2.7380682341754436]
2026-01-17 13:34:45,081 : worker.worker : DEBUG : Step 154351, finished rewards 46.27, envs finished 1
2026-01-17 13:34:45,258 : agent.on_policy : DEBUG : Mean Losses: [4.461817245930433]
2026-01-17 13:34:45,318 : worker.worker : DEBUG : Step 154374, finished rewards 23.03, envs finished 1
2026-01-17 13:34:45,365 : worker.worker : DEBUG : Step 154377, finished rewards 16.47, envs finished 1
2026-01-17 13:34:45,451 : worker.worker : DEBUG : Step 154383, finished rewards 17.17, envs finished 1
2026-01-17 13:34:45,701 : agent.on_policy : DEBUG : Mean Losses: [5.939095050096512]
2026-01-17 13:34:45,718 : worker.worker : DEBUG : Step 154403, finished rewards 13.94, envs finished 2
2026-01-17 13:34:45,748 : worker.worker : DEBUG : Step 154408, finished rewards 22.14, envs finished 1
2026-01-17 13:34:45,849 : worker.worker : DEBUG : Step 154429, finished rewards 8.09, envs finished 1
2026-01-17 13:34:46,013 : agent.on_policy : DEBUG : Mean Losses: [5.158841922879219]
2026-01-17 13:34:46,051 : worker.worker : DEBUG : Step 154434, finished rewards 31.83, envs finished 1
2026-01-17 13:34:46,298 : worker.worker : DEBUG : Step 154458, finished rewards 30.80, envs finished 1
2026-01-17 13:34:46,397 : agent.on_policy : DEBUG : Mean Losses: [4.0083850510418415]
2026-01-17 13:34:46,400 : worker.worker : DEBUG : Step 154464, finished rewards 34.27, envs finished 1
2026-01-17 13:34:46,454 : worker.worker : DEBUG : Step 154471, finished rewards 46.64, envs finished 1
2026-01-17 13:34:46,500 : worker.worker : DEBUG : Step 154473, finished rewards 21.08, envs finished 1
2026-01-17 13:34:46,590 : worker.worker : DEBUG : Step 154485, finished rewards 32.30, envs finished 1
2026-01-17 13:34:46,678 : worker.worker : DEBUG : Step 154491, finished rewards 27.95, envs finished 1
2026-01-17 13:34:46,843 : agent.on_policy : DEBUG : Mean Losses: [6.495369873940945]
2026-01-17 13:34:47,059 : worker.worker : DEBUG : Step 154525, finished rewards 22.47, envs finished 1
2026-01-17 13:34:47,125 : agent.on_policy : DEBUG : Mean Losses: [3.1079098992049694]
2026-01-17 13:34:47,148 : worker.worker : DEBUG : Step 154532, finished rewards 17.84, envs finished 1
2026-01-17 13:34:47,204 : worker.worker : DEBUG : Step 154542, finished rewards 34.16, envs finished 1
2026-01-17 13:34:47,514 : agent.on_policy : DEBUG : Mean Losses: [5.40901306271553]
2026-01-17 13:34:47,581 : worker.worker : DEBUG : Step 154564, finished rewards 22.57, envs finished 1
2026-01-17 13:34:47,694 : worker.worker : DEBUG : Step 154579, finished rewards 24.69, envs finished 1
2026-01-17 13:34:47,794 : worker.worker : DEBUG : Step 154587, finished rewards -2.65, envs finished 1
2026-01-17 13:34:47,956 : agent.on_policy : DEBUG : Mean Losses: [7.219322755932808]
2026-01-17 13:34:47,982 : worker.worker : DEBUG : Step 154598, finished rewards 6.82, envs finished 1
2026-01-17 13:34:48,049 : worker.worker : DEBUG : Step 154602, finished rewards 42.56, envs finished 1
2026-01-17 13:34:48,194 : worker.worker : DEBUG : Step 154617, finished rewards 24.68, envs finished 1
2026-01-17 13:34:48,476 : agent.on_policy : DEBUG : Mean Losses: [4.8779371455311775]
2026-01-17 13:34:48,553 : worker.worker : DEBUG : Step 154630, finished rewards 27.24, envs finished 1
2026-01-17 13:34:48,684 : worker.worker : DEBUG : Step 154648, finished rewards -15.15, envs finished 1
2026-01-17 13:34:48,939 : agent.on_policy : DEBUG : Mean Losses: [3.736907083541155]
2026-01-17 13:34:49,019 : worker.worker : DEBUG : Step 154672, finished rewards 30.93, envs finished 1
2026-01-17 13:34:49,083 : worker.worker : DEBUG : Step 154683, finished rewards 17.26, envs finished 1
2026-01-17 13:34:49,151 : worker.worker : DEBUG : Step 154687, finished rewards 27.07, envs finished 1
2026-01-17 13:34:49,250 : agent.on_policy : DEBUG : Mean Losses: [6.455400262027979]
2026-01-17 13:34:49,346 : worker.worker : DEBUG : Step 154696, finished rewards 33.18, envs finished 1
2026-01-17 13:34:49,516 : worker.worker : DEBUG : Step 154715, finished rewards 30.81, envs finished 1
2026-01-17 13:34:49,529 : worker.worker : DEBUG : Step 154716, finished rewards 8.42, envs finished 1
2026-01-17 13:34:49,630 : agent.on_policy : DEBUG : Mean Losses: [5.277979549020529]
2026-01-17 13:34:49,836 : worker.worker : DEBUG : Step 154740, finished rewards 25.99, envs finished 1
2026-01-17 13:34:50,217 : agent.on_policy : DEBUG : Mean Losses: [2.8150206431746483]
2026-01-17 13:34:50,329 : worker.worker : DEBUG : Step 154775, finished rewards 58.96, envs finished 1
2026-01-17 13:34:50,357 : worker.worker : DEBUG : Step 154779, finished rewards 32.33, envs finished 1
2026-01-17 13:34:50,413 : worker.worker : DEBUG : Step 154782, finished rewards 21.61, envs finished 1
2026-01-17 13:34:50,553 : agent.on_policy : DEBUG : Mean Losses: [7.192168176174164]
2026-01-17 13:34:50,622 : worker.worker : DEBUG : Step 154788, finished rewards 15.81, envs finished 1
2026-01-17 13:34:50,799 : worker.worker : DEBUG : Step 154810, finished rewards -11.41, envs finished 1
2026-01-17 13:34:50,943 : agent.on_policy : DEBUG : Mean Losses: [3.971914744004607]
2026-01-17 13:34:50,963 : worker.worker : DEBUG : Step 154816, finished rewards 19.85, envs finished 1
2026-01-17 13:34:51,092 : worker.worker : DEBUG : Step 154825, finished rewards 28.72, envs finished 1
2026-01-17 13:34:51,326 : agent.on_policy : DEBUG : Mean Losses: [5.404251754283905]
2026-01-17 13:34:51,434 : worker.worker : DEBUG : Step 154871, finished rewards 22.03, envs finished 1
2026-01-17 13:34:51,477 : worker.worker : DEBUG : Step 154876, finished rewards -14.66, envs finished 1
2026-01-17 13:34:51,662 : agent.on_policy : DEBUG : Mean Losses: [5.295331746339798]
2026-01-17 13:34:51,773 : worker.worker : DEBUG : Step 154886, finished rewards 25.85, envs finished 2
2026-01-17 13:34:52,034 : worker.worker : DEBUG : Step 154899, finished rewards 6.61, envs finished 1
2026-01-17 13:34:52,123 : worker.worker : DEBUG : Step 154909, finished rewards 4.07, envs finished 1
2026-01-17 13:34:52,303 : agent.on_policy : DEBUG : Mean Losses: [6.005240626633167]
2026-01-17 13:34:52,369 : worker.worker : DEBUG : Step 154922, finished rewards 13.55, envs finished 1
2026-01-17 13:34:52,428 : worker.worker : DEBUG : Step 154931, finished rewards 13.35, envs finished 1
2026-01-17 13:34:53,138 : agent.on_policy : DEBUG : Mean Losses: [3.3391325771808624]
2026-01-17 13:34:53,359 : worker.worker : DEBUG : Step 154969, finished rewards 22.39, envs finished 1
2026-01-17 13:34:53,413 : worker.worker : DEBUG : Step 154974, finished rewards 29.44, envs finished 1
2026-01-17 13:34:53,488 : agent.on_policy : DEBUG : Mean Losses: [5.545077741146088]
2026-01-17 13:34:53,522 : worker.worker : DEBUG : Step 154978, finished rewards 43.22, envs finished 1
2026-01-17 13:34:53,557 : worker.worker : DEBUG : Step 154979, finished rewards 15.20, envs finished 1
2026-01-17 13:34:53,704 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:34:53,757 : worker.worker : INFO : Step 155000, Avg Reward 15.9817, Max Reward 58.9575, Loss [4.74699037]
2026-01-17 13:34:53,775 : worker.worker : DEBUG : Step 155001, finished rewards 42.43, envs finished 1
2026-01-17 13:34:53,995 : agent.on_policy : DEBUG : Mean Losses: [5.7269008085131645]
2026-01-17 13:34:54,015 : worker.worker : DEBUG : Step 155012, finished rewards 19.52, envs finished 1
2026-01-17 13:34:54,073 : worker.worker : DEBUG : Step 155023, finished rewards 19.03, envs finished 1
2026-01-17 13:34:54,295 : agent.on_policy : DEBUG : Mean Losses: [3.6513746231794357]
2026-01-17 13:34:54,342 : worker.worker : DEBUG : Step 155050, finished rewards 42.23, envs finished 1
2026-01-17 13:34:54,387 : worker.worker : DEBUG : Step 155060, finished rewards 27.07, envs finished 1
2026-01-17 13:34:54,525 : agent.on_policy : DEBUG : Mean Losses: [3.4737685844302177]
2026-01-17 13:34:54,629 : worker.worker : DEBUG : Step 155086, finished rewards 8.54, envs finished 1
2026-01-17 13:34:54,644 : worker.worker : DEBUG : Step 155088, finished rewards 11.59, envs finished 1
2026-01-17 13:34:54,842 : agent.on_policy : DEBUG : Mean Losses: [3.590031072497368]
2026-01-17 13:34:54,893 : worker.worker : DEBUG : Step 155115, finished rewards 29.44, envs finished 1
2026-01-17 13:34:54,918 : worker.worker : DEBUG : Step 155119, finished rewards 22.01, envs finished 1
2026-01-17 13:34:54,961 : worker.worker : DEBUG : Step 155126, finished rewards 7.55, envs finished 1
2026-01-17 13:34:55,129 : agent.on_policy : DEBUG : Mean Losses: [6.310602992773056]
2026-01-17 13:34:55,158 : worker.worker : DEBUG : Step 155140, finished rewards 33.63, envs finished 1
2026-01-17 13:34:55,245 : worker.worker : DEBUG : Step 155150, finished rewards -14.92, envs finished 1
2026-01-17 13:34:55,490 : agent.on_policy : DEBUG : Mean Losses: [3.001580785959959]
2026-01-17 13:34:55,607 : worker.worker : DEBUG : Step 155196, finished rewards 8.74, envs finished 1
2026-01-17 13:34:55,805 : agent.on_policy : DEBUG : Mean Losses: [3.851623073220253]
2026-01-17 13:34:55,819 : worker.worker : DEBUG : Step 155202, finished rewards 28.70, envs finished 1
2026-01-17 13:34:55,615 : worker.worker : DEBUG : Step 155212, finished rewards 39.51, envs finished 1
2026-01-17 13:34:55,214 : worker.worker : DEBUG : Step 155214, finished rewards 0.93, envs finished 1
2026-01-17 13:34:55,239 : worker.worker : DEBUG : Step 155216, finished rewards 19.67, envs finished 1
2026-01-17 13:34:55,270 : worker.worker : DEBUG : Step 155221, finished rewards 21.06, envs finished 1
2026-01-17 13:34:55,277 : worker.worker : DEBUG : Step 155222, finished rewards 39.69, envs finished 1
2026-01-17 13:34:55,894 : agent.on_policy : DEBUG : Mean Losses: [8.91414774209261]
2026-01-17 13:34:56,036 : worker.worker : DEBUG : Step 155255, finished rewards 10.02, envs finished 1
2026-01-17 13:34:56,201 : agent.on_policy : DEBUG : Mean Losses: [2.5905586034059525]
2026-01-17 13:34:56,503 : agent.on_policy : DEBUG : Mean Losses: [3.41797536611557]
2026-01-17 13:34:56,533 : worker.worker : DEBUG : Step 155305, finished rewards 15.40, envs finished 1
2026-01-17 13:34:56,540 : worker.worker : DEBUG : Step 155307, finished rewards 28.50, envs finished 1
2026-01-17 13:34:56,565 : worker.worker : DEBUG : Step 155312, finished rewards 19.26, envs finished 1
2026-01-17 13:34:56,580 : worker.worker : DEBUG : Step 155315, finished rewards 22.57, envs finished 1
2026-01-17 13:34:56,673 : agent.on_policy : DEBUG : Mean Losses: [8.276589572429657]
2026-01-17 13:34:56,706 : worker.worker : DEBUG : Step 155336, finished rewards 33.66, envs finished 1
2026-01-17 13:34:56,798 : worker.worker : DEBUG : Step 155346, finished rewards -7.38, envs finished 1
2026-01-17 13:34:56,813 : worker.worker : DEBUG : Step 155349, finished rewards -5.30, envs finished 1
2026-01-17 13:34:57,010 : agent.on_policy : DEBUG : Mean Losses: [4.743179306387901]
2026-01-17 13:34:57,040 : worker.worker : DEBUG : Step 155368, finished rewards -19.27, envs finished 1
2026-01-17 13:34:57,177 : agent.on_policy : DEBUG : Mean Losses: [2.242488369345665]
2026-01-17 13:34:57,226 : worker.worker : DEBUG : Step 155397, finished rewards 32.83, envs finished 1
2026-01-17 13:34:57,261 : worker.worker : DEBUG : Step 155401, finished rewards 22.16, envs finished 1
2026-01-17 13:34:57,339 : worker.worker : DEBUG : Step 155417, finished rewards 12.50, envs finished 1
2026-01-17 13:34:57,348 : worker.worker : DEBUG : Step 155419, finished rewards 41.57, envs finished 1
2026-01-17 13:34:57,499 : agent.on_policy : DEBUG : Mean Losses: [7.360535502433777]
2026-01-17 13:34:57,640 : worker.worker : DEBUG : Step 155441, finished rewards 8.91, envs finished 1
2026-01-17 13:34:57,657 : worker.worker : DEBUG : Step 155444, finished rewards 17.83, envs finished 1
2026-01-17 13:34:57,838 : agent.on_policy : DEBUG : Mean Losses: [3.5218502655625343]
2026-01-17 13:34:57,855 : worker.worker : DEBUG : Step 155460, finished rewards 5.66, envs finished 1
2026-01-17 13:34:57,918 : worker.worker : DEBUG : Step 155473, finished rewards 14.31, envs finished 1
2026-01-17 13:34:57,925 : worker.worker : DEBUG : Step 155474, finished rewards 37.45, envs finished 1
2026-01-17 13:34:58,149 : agent.on_policy : DEBUG : Mean Losses: [4.749786362051964]
2026-01-17 13:34:58,257 : worker.worker : DEBUG : Step 155519, finished rewards 1.75, envs finished 1
2026-01-17 13:34:58,371 : agent.on_policy : DEBUG : Mean Losses: [3.5550041273236275]
2026-01-17 13:34:58,388 : worker.worker : DEBUG : Step 155523, finished rewards 17.19, envs finished 1
2026-01-17 13:34:58,536 : worker.worker : DEBUG : Step 155535, finished rewards 9.14, envs finished 1
2026-01-17 13:34:58,575 : worker.worker : DEBUG : Step 155539, finished rewards 20.61, envs finished 1
2026-01-17 13:34:58,852 : agent.on_policy : DEBUG : Mean Losses: [5.666934318840504]
2026-01-17 13:34:58,912 : worker.worker : DEBUG : Step 155560, finished rewards 12.62, envs finished 1
2026-01-17 13:34:58,953 : worker.worker : DEBUG : Step 155569, finished rewards 13.67, envs finished 1
2026-01-17 13:34:58,978 : worker.worker : DEBUG : Step 155575, finished rewards 20.92, envs finished 1
2026-01-17 13:34:59,146 : agent.on_policy : DEBUG : Mean Losses: [5.385090947151184]
2026-01-17 13:34:59,164 : worker.worker : DEBUG : Step 155590, finished rewards 9.65, envs finished 1
2026-01-17 13:34:59,199 : worker.worker : DEBUG : Step 155599, finished rewards 35.21, envs finished 1
2026-01-17 13:34:59,217 : worker.worker : DEBUG : Step 155604, finished rewards 42.15, envs finished 1
2026-01-17 13:34:59,516 : agent.on_policy : DEBUG : Mean Losses: [7.102166876196861]
2026-01-17 13:34:59,580 : worker.worker : DEBUG : Step 155625, finished rewards 13.67, envs finished 1
2026-01-17 13:34:59,635 : worker.worker : DEBUG : Step 155639, finished rewards 41.79, envs finished 1
2026-01-17 13:34:59,792 : agent.on_policy : DEBUG : Mean Losses: [5.316360034048557]
2026-01-17 13:34:59,890 : worker.worker : DEBUG : Step 155675, finished rewards 36.25, envs finished 1
2026-01-17 13:35:00,034 : agent.on_policy : DEBUG : Mean Losses: [5.414177991449833]
2026-01-17 13:35:00,084 : worker.worker : DEBUG : Step 155688, finished rewards 2.85, envs finished 1
2026-01-17 13:35:00,122 : worker.worker : DEBUG : Step 155692, finished rewards 18.74, envs finished 1
2026-01-17 13:35:00,214 : worker.worker : DEBUG : Step 155703, finished rewards 19.74, envs finished 1
2026-01-17 13:35:00,441 : agent.on_policy : DEBUG : Mean Losses: [6.609555870294571]
2026-01-17 13:35:00,447 : worker.worker : DEBUG : Step 155713, finished rewards 27.46, envs finished 1
2026-01-17 13:35:00,573 : worker.worker : DEBUG : Step 155727, finished rewards -12.32, envs finished 1
2026-01-17 13:35:00,659 : worker.worker : DEBUG : Step 155733, finished rewards 23.35, envs finished 1
2026-01-17 13:35:00,829 : agent.on_policy : DEBUG : Mean Losses: [4.3747141771018505]
2026-01-17 13:35:00,985 : worker.worker : DEBUG : Step 155762, finished rewards -40.97, envs finished 1
2026-01-17 13:35:01,093 : worker.worker : DEBUG : Step 155774, finished rewards 23.17, envs finished 1
2026-01-17 13:35:01,239 : agent.on_policy : DEBUG : Mean Losses: [5.783059231936932]
2026-01-17 13:35:01,477 : worker.worker : DEBUG : Step 155807, finished rewards 22.59, envs finished 1
2026-01-17 13:35:01,568 : agent.on_policy : DEBUG : Mean Losses: [4.282890219241381]
2026-01-17 13:35:01,586 : worker.worker : DEBUG : Step 155813, finished rewards -1.11, envs finished 1
2026-01-17 13:35:01,620 : worker.worker : DEBUG : Step 155819, finished rewards 27.99, envs finished 1
2026-01-17 13:35:01,699 : worker.worker : DEBUG : Step 155827, finished rewards 22.91, envs finished 1
2026-01-17 13:35:01,715 : worker.worker : DEBUG : Step 155830, finished rewards 13.90, envs finished 1
2026-01-17 13:35:01,751 : worker.worker : DEBUG : Step 155837, finished rewards -5.59, envs finished 1
2026-01-17 13:35:01,866 : agent.on_policy : DEBUG : Mean Losses: [7.500137850642204]
2026-01-17 13:35:01,883 : worker.worker : DEBUG : Step 155843, finished rewards 32.59, envs finished 1
2026-01-17 13:35:02,149 : agent.on_policy : DEBUG : Mean Losses: [1.7363084871321917]
2026-01-17 13:35:02,278 : worker.worker : DEBUG : Step 155897, finished rewards 6.36, envs finished 1
2026-01-17 13:35:02,497 : agent.on_policy : DEBUG : Mean Losses: [3.4915110915899277]
2026-01-17 13:35:02,595 : worker.worker : DEBUG : Step 155914, finished rewards 12.48, envs finished 1
2026-01-17 13:35:02,785 : worker.worker : DEBUG : Step 155930, finished rewards 17.42, envs finished 1
2026-01-17 13:35:02,833 : worker.worker : DEBUG : Step 155935, finished rewards 5.18, envs finished 1
2026-01-17 13:35:03,011 : agent.on_policy : DEBUG : Mean Losses: [4.819977555423975]
2026-01-17 13:35:03,098 : worker.worker : DEBUG : Step 155945, finished rewards 11.98, envs finished 1
2026-01-17 13:35:03,199 : worker.worker : DEBUG : Step 155957, finished rewards 13.61, envs finished 1
2026-01-17 13:35:03,246 : worker.worker : DEBUG : Step 155961, finished rewards 45.93, envs finished 1
2026-01-17 13:35:03,302 : worker.worker : DEBUG : Step 155967, finished rewards 31.95, envs finished 1
2026-01-17 13:35:03,471 : agent.on_policy : DEBUG : Mean Losses: [7.7799973748624325]
2026-01-17 13:35:03,789 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:35:03,845 : agent.on_policy : DEBUG : Mean Losses: [1.8938075117766857]
2026-01-17 13:35:03,891 : worker.worker : DEBUG : Step 156011, finished rewards -40.57, envs finished 1
2026-01-17 13:35:04,025 : worker.worker : DEBUG : Step 156028, finished rewards 31.88, envs finished 1
2026-01-17 13:35:04,188 : agent.on_policy : DEBUG : Mean Losses: [6.136003330349922]
2026-01-17 13:35:04,190 : worker.worker : DEBUG : Step 156032, finished rewards 19.15, envs finished 1
2026-01-17 13:35:04,214 : worker.worker : DEBUG : Step 156036, finished rewards 2.55, envs finished 1
2026-01-17 13:35:04,385 : worker.worker : DEBUG : Step 156057, finished rewards 1.62, envs finished 1
2026-01-17 13:35:04,545 : agent.on_policy : DEBUG : Mean Losses: [4.174093998968601]
2026-01-17 13:35:04,587 : worker.worker : DEBUG : Step 156071, finished rewards 12.46, envs finished 1
2026-01-17 13:35:04,612 : worker.worker : DEBUG : Step 156072, finished rewards 12.15, envs finished 1
2026-01-17 13:35:04,665 : worker.worker : DEBUG : Step 156076, finished rewards 12.08, envs finished 1
2026-01-17 13:35:04,894 : agent.on_policy : DEBUG : Mean Losses: [4.783871173858643]
2026-01-17 13:35:04,923 : worker.worker : DEBUG : Step 156101, finished rewards 41.82, envs finished 1
2026-01-17 13:35:04,929 : worker.worker : DEBUG : Step 156102, finished rewards 38.84, envs finished 1
2026-01-17 13:35:05,083 : agent.on_policy : DEBUG : Mean Losses: [3.7166223227977753]
2026-01-17 13:35:05,292 : worker.worker : DEBUG : Step 156149, finished rewards 25.50, envs finished 1
2026-01-17 13:35:05,346 : worker.worker : DEBUG : Step 156157, finished rewards 29.04, envs finished 1
2026-01-17 13:35:05,409 : agent.on_policy : DEBUG : Mean Losses: [8.432332888245583]
2026-01-17 13:35:05,410 : worker.worker : DEBUG : Step 156160, finished rewards 33.39, envs finished 1
2026-01-17 13:35:05,449 : worker.worker : DEBUG : Step 156165, finished rewards 46.20, envs finished 1
2026-01-17 13:35:05,518 : worker.worker : DEBUG : Step 156170, finished rewards -21.81, envs finished 1
2026-01-17 13:35:05,531 : worker.worker : DEBUG : Step 156173, finished rewards -7.02, envs finished 1
2026-01-17 13:35:05,571 : worker.worker : DEBUG : Step 156180, finished rewards 15.18, envs finished 1
2026-01-17 13:35:05,756 : agent.on_policy : DEBUG : Mean Losses: [5.392322331666946]
2026-01-17 13:35:05,837 : worker.worker : DEBUG : Step 156201, finished rewards 23.22, envs finished 1
2026-01-17 13:35:06,087 : agent.on_policy : DEBUG : Mean Losses: [2.166156053543091]
2026-01-17 13:35:06,177 : worker.worker : DEBUG : Step 156249, finished rewards 26.48, envs finished 1
2026-01-17 13:35:06,320 : agent.on_policy : DEBUG : Mean Losses: [5.002178408205509]
2026-01-17 13:35:06,453 : worker.worker : DEBUG : Step 156277, finished rewards 38.84, envs finished 1
2026-01-17 13:35:06,459 : worker.worker : DEBUG : Step 156278, finished rewards -4.69, envs finished 1
2026-01-17 13:35:06,470 : worker.worker : DEBUG : Step 156280, finished rewards 12.78, envs finished 1
2026-01-17 13:35:06,480 : worker.worker : DEBUG : Step 156281, finished rewards 15.25, envs finished 1
2026-01-17 13:35:06,519 : worker.worker : DEBUG : Step 156284, finished rewards 8.33, envs finished 1
2026-01-17 13:35:06,634 : agent.on_policy : DEBUG : Mean Losses: [9.357768781483173]
2026-01-17 13:35:06,785 : worker.worker : DEBUG : Step 156309, finished rewards -6.53, envs finished 1
2026-01-17 13:35:06,824 : worker.worker : DEBUG : Step 156317, finished rewards -14.68, envs finished 1
2026-01-17 13:35:06,834 : worker.worker : DEBUG : Step 156319, finished rewards 42.78, envs finished 1
2026-01-17 13:35:06,892 : agent.on_policy : DEBUG : Mean Losses: [4.766489600762725]
2026-01-17 13:35:07,173 : agent.on_policy : DEBUG : Mean Losses: [0.9041226087138057]
2026-01-17 13:35:07,224 : worker.worker : DEBUG : Step 156359, finished rewards 32.95, envs finished 1
2026-01-17 13:35:07,277 : worker.worker : DEBUG : Step 156366, finished rewards 27.54, envs finished 1
2026-01-17 13:35:07,391 : worker.worker : DEBUG : Step 156379, finished rewards 18.69, envs finished 1
2026-01-17 13:35:07,555 : agent.on_policy : DEBUG : Mean Losses: [6.116159208118916]
2026-01-17 13:35:07,566 : worker.worker : DEBUG : Step 156386, finished rewards 19.19, envs finished 1
2026-01-17 13:35:07,834 : worker.worker : DEBUG : Step 156407, finished rewards 4.28, envs finished 1
2026-01-17 13:35:07,853 : worker.worker : DEBUG : Step 156410, finished rewards 24.03, envs finished 1
2026-01-17 13:35:07,872 : worker.worker : DEBUG : Step 156411, finished rewards 17.18, envs finished 1
2026-01-17 13:35:08,039 : agent.on_policy : DEBUG : Mean Losses: [6.825610898435116]
2026-01-17 13:35:08,093 : worker.worker : DEBUG : Step 156425, finished rewards 14.26, envs finished 1
2026-01-17 13:35:08,451 : agent.on_policy : DEBUG : Mean Losses: [1.7937424201518297]
2026-01-17 13:35:08,494 : worker.worker : DEBUG : Step 156459, finished rewards 23.63, envs finished 1
2026-01-17 13:35:08,569 : worker.worker : DEBUG : Step 156479, finished rewards 24.91, envs finished 1
2026-01-17 13:35:08,632 : agent.on_policy : DEBUG : Mean Losses: [4.30840328335762]
2026-01-17 13:35:08,663 : worker.worker : DEBUG : Step 156482, finished rewards 3.39, envs finished 1
2026-01-17 13:35:08,706 : worker.worker : DEBUG : Step 156485, finished rewards 12.80, envs finished 1
2026-01-17 13:35:08,784 : worker.worker : DEBUG : Step 156497, finished rewards 28.12, envs finished 1
2026-01-17 13:35:08,825 : worker.worker : DEBUG : Step 156507, finished rewards 32.83, envs finished 1
2026-01-17 13:35:08,954 : agent.on_policy : DEBUG : Mean Losses: [6.377490540966392]
2026-01-17 13:35:08,956 : worker.worker : DEBUG : Step 156512, finished rewards 17.92, envs finished 1
2026-01-17 13:35:09,100 : worker.worker : DEBUG : Step 156533, finished rewards 0.72, envs finished 1
2026-01-17 13:35:09,181 : agent.on_policy : DEBUG : Mean Losses: [3.148560108616948]
2026-01-17 13:35:09,215 : worker.worker : DEBUG : Step 156552, finished rewards 42.93, envs finished 1
2026-01-17 13:35:09,250 : worker.worker : DEBUG : Step 156560, finished rewards 20.37, envs finished 1
2026-01-17 13:35:09,476 : agent.on_policy : DEBUG : Mean Losses: [3.680224761366844]
2026-01-17 13:35:09,518 : worker.worker : DEBUG : Step 156583, finished rewards 28.19, envs finished 1
2026-01-17 13:35:09,583 : worker.worker : DEBUG : Step 156594, finished rewards 9.19, envs finished 1
2026-01-17 13:35:09,871 : agent.on_policy : DEBUG : Mean Losses: [4.5763770043849945]
2026-01-17 13:35:09,877 : worker.worker : DEBUG : Step 156609, finished rewards -2.58, envs finished 1
2026-01-17 13:35:09,887 : worker.worker : DEBUG : Step 156611, finished rewards 15.98, envs finished 1
2026-01-17 13:35:09,902 : worker.worker : DEBUG : Step 156614, finished rewards 17.91, envs finished 1
2026-01-17 13:35:10,102 : agent.on_policy : DEBUG : Mean Losses: [4.355912847444415]
2026-01-17 13:35:10,161 : worker.worker : DEBUG : Step 156653, finished rewards 41.92, envs finished 1
2026-01-17 13:35:10,204 : worker.worker : DEBUG : Step 156663, finished rewards -1.90, envs finished 1
2026-01-17 13:35:10,368 : agent.on_policy : DEBUG : Mean Losses: [4.553190015256405]
2026-01-17 13:35:10,388 : worker.worker : DEBUG : Step 156678, finished rewards 5.30, envs finished 1
2026-01-17 13:35:10,399 : worker.worker : DEBUG : Step 156680, finished rewards 29.09, envs finished 1
2026-01-17 13:35:10,481 : worker.worker : DEBUG : Step 156690, finished rewards 39.04, envs finished 1
2026-01-17 13:35:10,524 : worker.worker : DEBUG : Step 156698, finished rewards 28.54, envs finished 1
2026-01-17 13:35:10,694 : agent.on_policy : DEBUG : Mean Losses: [7.917759224772453]
2026-01-17 13:35:10,905 : worker.worker : DEBUG : Step 156733, finished rewards -41.25, envs finished 1
2026-01-17 13:35:10,984 : agent.on_policy : DEBUG : Mean Losses: [3.6966259572654963]
2026-01-17 13:35:11,005 : worker.worker : DEBUG : Step 156741, finished rewards 27.58, envs finished 1
2026-01-17 13:35:11,114 : worker.worker : DEBUG : Step 156758, finished rewards -8.35, envs finished 1
2026-01-17 13:35:11,305 : agent.on_policy : DEBUG : Mean Losses: [4.224537279456854]
2026-01-17 13:35:11,315 : worker.worker : DEBUG : Step 156770, finished rewards 12.32, envs finished 1
2026-01-17 13:35:11,414 : worker.worker : DEBUG : Step 156780, finished rewards 32.18, envs finished 1
2026-01-17 13:35:11,467 : worker.worker : DEBUG : Step 156785, finished rewards 12.34, envs finished 1
2026-01-17 13:35:11,507 : worker.worker : DEBUG : Step 156788, finished rewards 19.77, envs finished 1
2026-01-17 13:35:11,769 : agent.on_policy : DEBUG : Mean Losses: [6.29318137280643]
2026-01-17 13:35:11,873 : worker.worker : DEBUG : Step 156825, finished rewards 25.39, envs finished 1
2026-01-17 13:35:11,880 : worker.worker : DEBUG : Step 156827, finished rewards 27.98, envs finished 1
2026-01-17 13:35:11,895 : worker.worker : DEBUG : Step 156829, finished rewards 42.43, envs finished 1
2026-01-17 13:35:12,021 : agent.on_policy : DEBUG : Mean Losses: [5.6927491296082735]
2026-01-17 13:35:12,314 : worker.worker : DEBUG : Step 156862, finished rewards 20.59, envs finished 1
2026-01-17 13:35:12,478 : agent.on_policy : DEBUG : Mean Losses: [2.2399293072521687]
2026-01-17 13:35:12,585 : worker.worker : DEBUG : Step 156883, finished rewards 17.28, envs finished 1
2026-01-17 13:35:12,627 : worker.worker : DEBUG : Step 156889, finished rewards 15.55, envs finished 1
2026-01-17 13:35:12,827 : agent.on_policy : DEBUG : Mean Losses: [4.8365064188838005]
2026-01-17 13:35:12,878 : worker.worker : DEBUG : Step 156904, finished rewards -5.91, envs finished 1
2026-01-17 13:35:13,083 : worker.worker : DEBUG : Step 156924, finished rewards 17.99, envs finished 1
2026-01-17 13:35:13,260 : agent.on_policy : DEBUG : Mean Losses: [7.133974467404187]
2026-01-17 13:35:13,351 : worker.worker : DEBUG : Step 156939, finished rewards -16.47, envs finished 1
2026-01-17 13:35:13,527 : worker.worker : DEBUG : Step 156953, finished rewards -6.54, envs finished 1
2026-01-17 13:35:13,759 : agent.on_policy : DEBUG : Mean Losses: [5.1132423505187035]
2026-01-17 13:35:13,772 : worker.worker : DEBUG : Step 156962, finished rewards 19.79, envs finished 1
2026-01-17 13:35:13,792 : worker.worker : DEBUG : Step 156965, finished rewards 36.51, envs finished 1
2026-01-17 13:35:13,835 : worker.worker : DEBUG : Step 156972, finished rewards -7.16, envs finished 1
2026-01-17 13:35:13,893 : worker.worker : DEBUG : Step 156977, finished rewards 24.41, envs finished 1
2026-01-17 13:35:14,070 : agent.on_policy : DEBUG : Mean Losses: [4.35757165029645]
2026-01-17 13:35:14,098 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:35:14,116 : worker.worker : DEBUG : Step 157003, finished rewards 34.49, envs finished 1
2026-01-17 13:35:14,237 : agent.on_policy : DEBUG : Mean Losses: [4.339302979409695]
2026-01-17 13:35:14,250 : worker.worker : DEBUG : Step 157026, finished rewards 0.30, envs finished 1
2026-01-17 13:35:14,340 : worker.worker : DEBUG : Step 157035, finished rewards 41.76, envs finished 1
2026-01-17 13:35:14,474 : worker.worker : DEBUG : Step 157053, finished rewards 33.00, envs finished 1
2026-01-17 13:35:14,573 : agent.on_policy : DEBUG : Mean Losses: [6.112889118492603]
2026-01-17 13:35:14,634 : worker.worker : DEBUG : Step 157064, finished rewards 17.09, envs finished 1
2026-01-17 13:35:14,647 : worker.worker : DEBUG : Step 157065, finished rewards -0.70, envs finished 1
2026-01-17 13:35:14,788 : worker.worker : DEBUG : Step 157078, finished rewards 3.56, envs finished 1
2026-01-17 13:35:14,813 : worker.worker : DEBUG : Step 157079, finished rewards 14.85, envs finished 1
2026-01-17 13:35:14,962 : agent.on_policy : DEBUG : Mean Losses: [4.726858973503113]
2026-01-17 13:35:15,049 : worker.worker : DEBUG : Step 157094, finished rewards 25.21, envs finished 1
2026-01-17 13:35:15,227 : worker.worker : DEBUG : Step 157118, finished rewards 30.73, envs finished 1
2026-01-17 13:35:15,350 : agent.on_policy : DEBUG : Mean Losses: [3.4721251539885998]
2026-01-17 13:35:15,479 : worker.worker : DEBUG : Step 157133, finished rewards 16.77, envs finished 1
2026-01-17 13:35:15,617 : worker.worker : DEBUG : Step 157151, finished rewards 28.18, envs finished 1
2026-01-17 13:35:15,676 : agent.on_policy : DEBUG : Mean Losses: [3.8605970861390233]
2026-01-17 13:35:15,702 : worker.worker : DEBUG : Step 157157, finished rewards 15.75, envs finished 1
2026-01-17 13:35:15,742 : worker.worker : DEBUG : Step 157166, finished rewards 18.03, envs finished 1
2026-01-17 13:35:15,862 : worker.worker : DEBUG : Step 157178, finished rewards 19.69, envs finished 1
2026-01-17 13:35:16,015 : agent.on_policy : DEBUG : Mean Losses: [5.103404299356043]
2026-01-17 13:35:16,180 : worker.worker : DEBUG : Step 157199, finished rewards 1.42, envs finished 1
2026-01-17 13:35:16,334 : worker.worker : DEBUG : Step 157214, finished rewards 21.56, envs finished 1
2026-01-17 13:35:16,341 : worker.worker : DEBUG : Step 157215, finished rewards 34.06, envs finished 1
2026-01-17 13:35:16,553 : agent.on_policy : DEBUG : Mean Losses: [5.497922755777836]
2026-01-17 13:35:16,636 : worker.worker : DEBUG : Step 157228, finished rewards -5.26, envs finished 1
2026-01-17 13:35:16,850 : agent.on_policy : DEBUG : Mean Losses: [3.634327046573162]
2026-01-17 13:35:16,934 : worker.worker : DEBUG : Step 157261, finished rewards 9.73, envs finished 1
2026-01-17 13:35:16,978 : worker.worker : DEBUG : Step 157268, finished rewards 11.45, envs finished 1
2026-01-17 13:35:17,054 : worker.worker : DEBUG : Step 157274, finished rewards 24.27, envs finished 1
2026-01-17 13:35:17,093 : worker.worker : DEBUG : Step 157279, finished rewards 9.70, envs finished 1
2026-01-17 13:35:17,214 : agent.on_policy : DEBUG : Mean Losses: [6.064605392515659]
2026-01-17 13:35:17,297 : worker.worker : DEBUG : Step 157297, finished rewards 29.43, envs finished 1
2026-01-17 13:35:17,313 : worker.worker : DEBUG : Step 157300, finished rewards 17.29, envs finished 1
2026-01-17 13:35:17,524 : agent.on_policy : DEBUG : Mean Losses: [3.944420079700649]
2026-01-17 13:35:17,675 : worker.worker : DEBUG : Step 157329, finished rewards 19.53, envs finished 1
2026-01-17 13:35:17,691 : worker.worker : DEBUG : Step 157332, finished rewards 42.13, envs finished 1
2026-01-17 13:35:17,930 : agent.on_policy : DEBUG : Mean Losses: [4.880708416923881]
2026-01-17 13:35:17,958 : worker.worker : DEBUG : Step 157349, finished rewards 42.61, envs finished 1
2026-01-17 13:35:17,978 : worker.worker : DEBUG : Step 157353, finished rewards 29.36, envs finished 1
2026-01-17 13:35:18,031 : worker.worker : DEBUG : Step 157366, finished rewards 26.09, envs finished 1
2026-01-17 13:35:18,055 : worker.worker : DEBUG : Step 157371, finished rewards 41.82, envs finished 1
2026-01-17 13:35:18,166 : agent.on_policy : DEBUG : Mean Losses: [5.898445213213563]
2026-01-17 13:35:18,205 : worker.worker : DEBUG : Step 157382, finished rewards 29.85, envs finished 1
2026-01-17 13:35:18,477 : agent.on_policy : DEBUG : Mean Losses: [2.563752582296729]
2026-01-17 13:35:18,485 : worker.worker : DEBUG : Step 157409, finished rewards 35.66, envs finished 1
2026-01-17 13:35:18,566 : worker.worker : DEBUG : Step 157421, finished rewards 41.00, envs finished 1
2026-01-17 13:35:18,580 : worker.worker : DEBUG : Step 157423, finished rewards 41.18, envs finished 1
2026-01-17 13:35:18,765 : agent.on_policy : DEBUG : Mean Losses: [5.47110989689827]
2026-01-17 13:35:18,913 : worker.worker : DEBUG : Step 157464, finished rewards 18.82, envs finished 1
2026-01-17 13:35:18,922 : worker.worker : DEBUG : Step 157466, finished rewards -5.47, envs finished 1
2026-01-17 13:35:18,935 : worker.worker : DEBUG : Step 157468, finished rewards 19.90, envs finished 1
2026-01-17 13:35:18,948 : worker.worker : DEBUG : Step 157470, finished rewards -5.03, envs finished 1
2026-01-17 13:35:19,024 : agent.on_policy : DEBUG : Mean Losses: [6.946967966854572]
2026-01-17 13:35:19,064 : worker.worker : DEBUG : Step 157480, finished rewards 42.25, envs finished 1
2026-01-17 13:35:19,268 : agent.on_policy : DEBUG : Mean Losses: [2.2568439804017544]
2026-01-17 13:35:19,288 : worker.worker : DEBUG : Step 157509, finished rewards 0.76, envs finished 1
2026-01-17 13:35:19,364 : worker.worker : DEBUG : Step 157530, finished rewards 46.18, envs finished 1
2026-01-17 13:35:19,380 : worker.worker : DEBUG : Step 157533, finished rewards 8.55, envs finished 1
2026-01-17 13:35:19,393 : worker.worker : DEBUG : Step 157535, finished rewards 10.55, envs finished 1
2026-01-17 13:35:19,514 : agent.on_policy : DEBUG : Mean Losses: [5.6144164726138115]
2026-01-17 13:35:19,758 : agent.on_policy : DEBUG : Mean Losses: [2.921460587531328]
2026-01-17 13:35:19,860 : worker.worker : DEBUG : Step 157587, finished rewards 36.63, envs finished 1
2026-01-17 13:35:19,877 : worker.worker : DEBUG : Step 157588, finished rewards 14.28, envs finished 1
2026-01-17 13:35:19,943 : worker.worker : DEBUG : Step 157592, finished rewards 0.72, envs finished 1
2026-01-17 13:35:19,979 : worker.worker : DEBUG : Step 157594, finished rewards -3.67, envs finished 1
2026-01-17 13:35:20,234 : agent.on_policy : DEBUG : Mean Losses: [6.868078634142876]
2026-01-17 13:35:20,314 : worker.worker : DEBUG : Step 157610, finished rewards -14.76, envs finished 1
2026-01-17 13:35:20,647 : agent.on_policy : DEBUG : Mean Losses: [3.4617522060871124]
2026-01-17 13:35:20,696 : worker.worker : DEBUG : Step 157639, finished rewards 15.32, envs finished 1
2026-01-17 13:35:20,738 : worker.worker : DEBUG : Step 157645, finished rewards 12.12, envs finished 1
2026-01-17 13:35:20,795 : worker.worker : DEBUG : Step 157657, finished rewards 0.38, envs finished 1
2026-01-17 13:35:20,925 : agent.on_policy : DEBUG : Mean Losses: [6.439196199178696]
2026-01-17 13:35:21,036 : worker.worker : DEBUG : Step 157676, finished rewards 32.51, envs finished 1
2026-01-17 13:35:21,068 : worker.worker : DEBUG : Step 157681, finished rewards 41.88, envs finished 1
2026-01-17 13:35:21,296 : agent.on_policy : DEBUG : Mean Losses: [6.5289022624492645]
2026-01-17 13:35:21,346 : worker.worker : DEBUG : Step 157709, finished rewards 8.04, envs finished 1
2026-01-17 13:35:21,604 : agent.on_policy : DEBUG : Mean Losses: [4.915614727884531]
2026-01-17 13:35:21,695 : worker.worker : DEBUG : Step 157737, finished rewards 24.12, envs finished 1
2026-01-17 13:35:21,740 : worker.worker : DEBUG : Step 157743, finished rewards 16.64, envs finished 1
2026-01-17 13:35:21,757 : worker.worker : DEBUG : Step 157744, finished rewards 27.88, envs finished 1
2026-01-17 13:35:21,866 : worker.worker : DEBUG : Step 157753, finished rewards 39.86, envs finished 1
2026-01-17 13:35:22,101 : agent.on_policy : DEBUG : Mean Losses: [8.719919539988041]
2026-01-17 13:35:22,149 : worker.worker : DEBUG : Step 157770, finished rewards 23.67, envs finished 1
2026-01-17 13:35:22,238 : worker.worker : DEBUG : Step 157791, finished rewards 32.50, envs finished 1
2026-01-17 13:35:22,291 : agent.on_policy : DEBUG : Mean Losses: [4.82398602925241]
2026-01-17 13:35:22,309 : worker.worker : DEBUG : Step 157793, finished rewards -42.41, envs finished 1
2026-01-17 13:35:22,498 : worker.worker : DEBUG : Step 157813, finished rewards 38.83, envs finished 1
2026-01-17 13:35:22,595 : agent.on_policy : DEBUG : Mean Losses: [3.480248063802719]
2026-01-17 13:35:22,613 : worker.worker : DEBUG : Step 157828, finished rewards -66.58, envs finished 1
2026-01-17 13:35:22,727 : worker.worker : DEBUG : Step 157840, finished rewards 21.23, envs finished 1
2026-01-17 13:35:22,768 : worker.worker : DEBUG : Step 157846, finished rewards 18.18, envs finished 1
2026-01-17 13:35:22,942 : agent.on_policy : DEBUG : Mean Losses: [5.895313926041126]
2026-01-17 13:35:22,970 : worker.worker : DEBUG : Step 157863, finished rewards 33.69, envs finished 2
2026-01-17 13:35:22,985 : worker.worker : DEBUG : Step 157866, finished rewards 15.34, envs finished 1
2026-01-17 13:35:23,066 : worker.worker : DEBUG : Step 157884, finished rewards 23.97, envs finished 1
2026-01-17 13:35:23,131 : agent.on_policy : DEBUG : Mean Losses: [4.258493784815073]
2026-01-17 13:35:23,378 : worker.worker : DEBUG : Step 157918, finished rewards 34.74, envs finished 1
2026-01-17 13:35:23,450 : agent.on_policy : DEBUG : Mean Losses: [4.341404430568218]
2026-01-17 13:35:23,503 : worker.worker : DEBUG : Step 157931, finished rewards 17.77, envs finished 1
2026-01-17 13:35:23,522 : worker.worker : DEBUG : Step 157933, finished rewards 27.92, envs finished 1
2026-01-17 13:35:23,538 : worker.worker : DEBUG : Step 157934, finished rewards 41.99, envs finished 1
2026-01-17 13:35:23,686 : worker.worker : DEBUG : Step 157950, finished rewards 28.18, envs finished 1
2026-01-17 13:35:23,875 : agent.on_policy : DEBUG : Mean Losses: [5.915057078003883]
2026-01-17 13:35:23,936 : worker.worker : DEBUG : Step 157958, finished rewards 25.33, envs finished 1
2026-01-17 13:35:23,964 : worker.worker : DEBUG : Step 157962, finished rewards 5.19, envs finished 1
2026-01-17 13:35:24,077 : worker.worker : DEBUG : Step 157976, finished rewards 25.78, envs finished 1
2026-01-17 13:35:24,196 : agent.on_policy : DEBUG : Mean Losses: [3.6973725222051144]
2026-01-17 13:35:24,300 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:35:24,465 : agent.on_policy : DEBUG : Mean Losses: [2.598029389977455]
2026-01-17 13:35:24,536 : worker.worker : DEBUG : Step 158035, finished rewards 3.88, envs finished 1
2026-01-17 13:35:24,706 : agent.on_policy : DEBUG : Mean Losses: [5.190711587667465]
2026-01-17 13:35:24,719 : worker.worker : DEBUG : Step 158050, finished rewards 24.03, envs finished 1
2026-01-17 13:35:24,763 : worker.worker : DEBUG : Step 158061, finished rewards -0.59, envs finished 1
2026-01-17 13:35:24,771 : worker.worker : DEBUG : Step 158063, finished rewards 10.09, envs finished 1
2026-01-17 13:35:24,784 : worker.worker : DEBUG : Step 158065, finished rewards -6.52, envs finished 1
2026-01-17 13:35:24,822 : worker.worker : DEBUG : Step 158073, finished rewards -8.89, envs finished 1
2026-01-17 13:35:24,890 : agent.on_policy : DEBUG : Mean Losses: [6.022499138489366]
2026-01-17 13:35:24,943 : worker.worker : DEBUG : Step 158091, finished rewards 0.49, envs finished 1
2026-01-17 13:35:25,043 : worker.worker : DEBUG : Step 158105, finished rewards 40.75, envs finished 1
2026-01-17 13:35:24,433 : agent.on_policy : DEBUG : Mean Losses: [5.623605154454708]
2026-01-17 13:35:24,466 : worker.worker : DEBUG : Step 158113, finished rewards -3.93, envs finished 1
2026-01-17 13:35:24,697 : worker.worker : DEBUG : Step 158134, finished rewards 41.93, envs finished 1
2026-01-17 13:35:24,863 : agent.on_policy : DEBUG : Mean Losses: [4.23929875344038]
2026-01-17 13:35:24,945 : worker.worker : DEBUG : Step 158158, finished rewards 10.54, envs finished 1
2026-01-17 13:35:25,004 : worker.worker : DEBUG : Step 158167, finished rewards 17.11, envs finished 1
2026-01-17 13:35:25,026 : worker.worker : DEBUG : Step 158169, finished rewards 20.23, envs finished 1
2026-01-17 13:35:25,235 : agent.on_policy : DEBUG : Mean Losses: [5.522637143731117]
2026-01-17 13:35:25,249 : worker.worker : DEBUG : Step 158177, finished rewards 5.26, envs finished 1
2026-01-17 13:35:25,473 : worker.worker : DEBUG : Step 158199, finished rewards 27.96, envs finished 1
2026-01-17 13:35:25,497 : worker.worker : DEBUG : Step 158200, finished rewards 11.26, envs finished 1
2026-01-17 13:35:25,608 : agent.on_policy : DEBUG : Mean Losses: [5.219963195733726]
2026-01-17 13:35:25,616 : worker.worker : DEBUG : Step 158209, finished rewards 15.04, envs finished 1
2026-01-17 13:35:25,802 : worker.worker : DEBUG : Step 158237, finished rewards 34.54, envs finished 1
2026-01-17 13:35:25,945 : agent.on_policy : DEBUG : Mean Losses: [3.643783437088132]
2026-01-17 13:35:25,998 : worker.worker : DEBUG : Step 158253, finished rewards 28.99, envs finished 1
2026-01-17 13:35:26,034 : worker.worker : DEBUG : Step 158261, finished rewards 28.23, envs finished 2
2026-01-17 13:35:26,195 : agent.on_policy : DEBUG : Mean Losses: [5.308615036308765]
2026-01-17 13:35:26,292 : worker.worker : DEBUG : Step 158286, finished rewards 28.56, envs finished 1
2026-01-17 13:35:26,526 : agent.on_policy : DEBUG : Mean Losses: [4.280516963452101]
2026-01-17 13:35:26,632 : worker.worker : DEBUG : Step 158334, finished rewards 39.85, envs finished 1
2026-01-17 13:35:26,745 : agent.on_policy : DEBUG : Mean Losses: [7.371152013540268]
2026-01-17 13:35:26,840 : worker.worker : DEBUG : Step 158346, finished rewards -6.43, envs finished 3
2026-01-17 13:35:26,875 : worker.worker : DEBUG : Step 158352, finished rewards 6.30, envs finished 1
2026-01-17 13:35:26,930 : worker.worker : DEBUG : Step 158356, finished rewards -22.13, envs finished 1
2026-01-17 13:35:27,146 : agent.on_policy : DEBUG : Mean Losses: [7.097099304199219]
2026-01-17 13:35:27,199 : worker.worker : DEBUG : Step 158382, finished rewards 3.00, envs finished 1
2026-01-17 13:35:27,219 : worker.worker : DEBUG : Step 158387, finished rewards 15.90, envs finished 1
2026-01-17 13:35:27,389 : agent.on_policy : DEBUG : Mean Losses: [3.4177504386752844]
2026-01-17 13:35:27,447 : worker.worker : DEBUG : Step 158416, finished rewards 33.01, envs finished 1
2026-01-17 13:35:27,498 : worker.worker : DEBUG : Step 158429, finished rewards 31.85, envs finished 1
2026-01-17 13:35:27,611 : agent.on_policy : DEBUG : Mean Losses: [4.657683193683624]
2026-01-17 13:35:27,706 : worker.worker : DEBUG : Step 158441, finished rewards 22.09, envs finished 1
2026-01-17 13:35:27,732 : worker.worker : DEBUG : Step 158443, finished rewards 21.03, envs finished 1
2026-01-17 13:35:27,814 : worker.worker : DEBUG : Step 158448, finished rewards 25.26, envs finished 1
2026-01-17 13:35:27,880 : worker.worker : DEBUG : Step 158451, finished rewards 46.13, envs finished 1
2026-01-17 13:35:28,184 : agent.on_policy : DEBUG : Mean Losses: [7.5633619874715805]
2026-01-17 13:35:28,187 : worker.worker : DEBUG : Step 158464, finished rewards 19.70, envs finished 1
2026-01-17 13:35:28,266 : worker.worker : DEBUG : Step 158484, finished rewards 19.52, envs finished 1
2026-01-17 13:35:28,448 : agent.on_policy : DEBUG : Mean Losses: [2.1408147383481264]
2026-01-17 13:35:28,615 : worker.worker : DEBUG : Step 158523, finished rewards 10.45, envs finished 1
2026-01-17 13:35:28,834 : agent.on_policy : DEBUG : Mean Losses: [3.779829751700163]
2026-01-17 13:35:28,885 : worker.worker : DEBUG : Step 158535, finished rewards 13.55, envs finished 1
2026-01-17 13:35:28,988 : worker.worker : DEBUG : Step 158548, finished rewards 45.96, envs finished 1
2026-01-17 13:35:29,158 : agent.on_policy : DEBUG : Mean Losses: [5.995719950646162]
2026-01-17 13:35:29,161 : worker.worker : DEBUG : Step 158560, finished rewards 15.65, envs finished 1
2026-01-17 13:35:29,190 : worker.worker : DEBUG : Step 158567, finished rewards 3.19, envs finished 1
2026-01-17 13:35:29,208 : worker.worker : DEBUG : Step 158571, finished rewards -2.81, envs finished 1
2026-01-17 13:35:29,233 : worker.worker : DEBUG : Step 158576, finished rewards 8.88, envs finished 1
2026-01-17 13:35:29,287 : worker.worker : DEBUG : Step 158582, finished rewards -8.10, envs finished 1
2026-01-17 13:35:29,324 : worker.worker : DEBUG : Step 158586, finished rewards 46.60, envs finished 1
2026-01-17 13:35:29,649 : agent.on_policy : DEBUG : Mean Losses: [7.399249896407127]
2026-01-17 13:35:30,024 : agent.on_policy : DEBUG : Mean Losses: [1.0734677240252495]
2026-01-17 13:35:30,302 : agent.on_policy : DEBUG : Mean Losses: [4.073288522660732]
2026-01-17 13:35:30,315 : worker.worker : DEBUG : Step 158658, finished rewards 1.18, envs finished 1
2026-01-17 13:35:30,323 : worker.worker : DEBUG : Step 158659, finished rewards 27.82, envs finished 1
2026-01-17 13:35:30,423 : worker.worker : DEBUG : Step 158675, finished rewards 11.68, envs finished 1
2026-01-17 13:35:30,450 : worker.worker : DEBUG : Step 158678, finished rewards 24.04, envs finished 1
2026-01-17 13:35:30,518 : worker.worker : DEBUG : Step 158682, finished rewards 11.73, envs finished 1
2026-01-17 13:35:30,553 : worker.worker : DEBUG : Step 158685, finished rewards 14.13, envs finished 1
2026-01-17 13:35:30,567 : worker.worker : DEBUG : Step 158687, finished rewards 16.33, envs finished 1
2026-01-17 13:35:30,701 : agent.on_policy : DEBUG : Mean Losses: [7.509800910949707]
2026-01-17 13:35:30,731 : worker.worker : DEBUG : Step 158695, finished rewards -14.39, envs finished 1
2026-01-17 13:35:30,982 : agent.on_policy : DEBUG : Mean Losses: [1.1169376783072948]
2026-01-17 13:35:31,017 : worker.worker : DEBUG : Step 158728, finished rewards 41.50, envs finished 1
2026-01-17 13:35:31,102 : worker.worker : DEBUG : Step 158746, finished rewards 27.29, envs finished 1
2026-01-17 13:35:31,264 : agent.on_policy : DEBUG : Mean Losses: [5.360366649925709]
2026-01-17 13:35:31,283 : worker.worker : DEBUG : Step 158756, finished rewards 41.47, envs finished 1
2026-01-17 13:35:31,434 : worker.worker : DEBUG : Step 158774, finished rewards 28.52, envs finished 1
2026-01-17 13:35:31,448 : worker.worker : DEBUG : Step 158776, finished rewards 24.44, envs finished 1
2026-01-17 13:35:31,554 : agent.on_policy : DEBUG : Mean Losses: [5.701023902744055]
2026-01-17 13:35:31,683 : worker.worker : DEBUG : Step 158801, finished rewards 5.71, envs finished 1
2026-01-17 13:35:31,866 : agent.on_policy : DEBUG : Mean Losses: [4.206003677099943]
2026-01-17 13:35:31,960 : worker.worker : DEBUG : Step 158829, finished rewards 17.88, envs finished 1
2026-01-17 13:35:32,081 : worker.worker : DEBUG : Step 158844, finished rewards -9.34, envs finished 1
2026-01-17 13:35:32,305 : agent.on_policy : DEBUG : Mean Losses: [5.261114776134491]
2026-01-17 13:35:32,321 : worker.worker : DEBUG : Step 158848, finished rewards 29.17, envs finished 2
2026-01-17 13:35:32,540 : worker.worker : DEBUG : Step 158871, finished rewards 21.29, envs finished 1
2026-01-17 13:35:32,645 : agent.on_policy : DEBUG : Mean Losses: [3.958651978522539]
2026-01-17 13:35:32,662 : worker.worker : DEBUG : Step 158884, finished rewards -52.55, envs finished 1
2026-01-17 13:35:32,793 : worker.worker : DEBUG : Step 158899, finished rewards 28.53, envs finished 1
2026-01-17 13:35:33,000 : agent.on_policy : DEBUG : Mean Losses: [2.85826687887311]
2026-01-17 13:35:33,087 : worker.worker : DEBUG : Step 158933, finished rewards 15.09, envs finished 1
2026-01-17 13:35:33,295 : agent.on_policy : DEBUG : Mean Losses: [3.898000545799732]
2026-01-17 13:35:33,305 : worker.worker : DEBUG : Step 158946, finished rewards 17.55, envs finished 1
2026-01-17 13:35:33,325 : worker.worker : DEBUG : Step 158949, finished rewards 19.37, envs finished 1
2026-01-17 13:35:33,504 : worker.worker : DEBUG : Step 158969, finished rewards 29.08, envs finished 1
2026-01-17 13:35:33,554 : worker.worker : DEBUG : Step 158971, finished rewards 31.71, envs finished 2
2026-01-17 13:35:33,668 : agent.on_policy : DEBUG : Mean Losses: [5.2234188839793205]
2026-01-17 13:35:33,837 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:35:33,939 : agent.on_policy : DEBUG : Mean Losses: [2.885961264371872]
2026-01-17 13:35:34,072 : worker.worker : DEBUG : Step 159023, finished rewards 37.70, envs finished 1
2026-01-17 13:35:34,118 : worker.worker : DEBUG : Step 159031, finished rewards 32.40, envs finished 1
2026-01-17 13:35:34,135 : worker.worker : DEBUG : Step 159034, finished rewards -9.29, envs finished 1
2026-01-17 13:35:34,286 : agent.on_policy : DEBUG : Mean Losses: [8.984621033072472]
2026-01-17 13:35:34,348 : worker.worker : DEBUG : Step 159045, finished rewards 39.25, envs finished 1
2026-01-17 13:35:34,394 : worker.worker : DEBUG : Step 159055, finished rewards -16.27, envs finished 2
2026-01-17 13:35:34,427 : worker.worker : DEBUG : Step 159061, finished rewards 26.32, envs finished 1
2026-01-17 13:35:34,632 : agent.on_policy : DEBUG : Mean Losses: [5.375572115182877]
2026-01-17 13:35:34,711 : worker.worker : DEBUG : Step 159093, finished rewards 0.15, envs finished 1
2026-01-17 13:35:34,868 : agent.on_policy : DEBUG : Mean Losses: [1.9264615662395954]
2026-01-17 13:35:34,927 : worker.worker : DEBUG : Step 159116, finished rewards 32.43, envs finished 1
2026-01-17 13:35:35,025 : worker.worker : DEBUG : Step 159125, finished rewards 42.34, envs finished 1
2026-01-17 13:35:35,065 : worker.worker : DEBUG : Step 159132, finished rewards 30.28, envs finished 2
2026-01-17 13:35:35,241 : agent.on_policy : DEBUG : Mean Losses: [8.99984596669674]
2026-01-17 13:35:35,339 : worker.worker : DEBUG : Step 159151, finished rewards 21.24, envs finished 1
2026-01-17 13:35:35,365 : worker.worker : DEBUG : Step 159155, finished rewards 32.78, envs finished 1
2026-01-17 13:35:35,531 : agent.on_policy : DEBUG : Mean Losses: [2.4776943046599627]
2026-01-17 13:35:35,611 : worker.worker : DEBUG : Step 159190, finished rewards 20.28, envs finished 1
2026-01-17 13:35:35,638 : worker.worker : DEBUG : Step 159194, finished rewards -25.61, envs finished 1
2026-01-17 13:35:35,825 : agent.on_policy : DEBUG : Mean Losses: [3.6218927651643753]
2026-01-17 13:35:36,104 : worker.worker : DEBUG : Step 159231, finished rewards 14.72, envs finished 1
2026-01-17 13:35:36,180 : agent.on_policy : DEBUG : Mean Losses: [5.362870924174786]
2026-01-17 13:35:36,211 : worker.worker : DEBUG : Step 159238, finished rewards 6.36, envs finished 1
2026-01-17 13:35:36,333 : worker.worker : DEBUG : Step 159253, finished rewards 13.79, envs finished 2
2026-01-17 13:35:36,499 : agent.on_policy : DEBUG : Mean Losses: [5.0447443425655365]
2026-01-17 13:35:36,528 : worker.worker : DEBUG : Step 159272, finished rewards 4.33, envs finished 1
2026-01-17 13:35:36,648 : agent.on_policy : DEBUG : Mean Losses: [3.4919496290385723]
2026-01-17 13:35:36,659 : worker.worker : DEBUG : Step 159298, finished rewards -30.79, envs finished 1
2026-01-17 13:35:36,732 : worker.worker : DEBUG : Step 159303, finished rewards 40.11, envs finished 1
2026-01-17 13:35:36,796 : worker.worker : DEBUG : Step 159314, finished rewards -3.14, envs finished 1
2026-01-17 13:35:36,903 : worker.worker : DEBUG : Step 159326, finished rewards 27.72, envs finished 1
2026-01-17 13:35:37,090 : agent.on_policy : DEBUG : Mean Losses: [6.445498442277312]
2026-01-17 13:35:37,153 : worker.worker : DEBUG : Step 159331, finished rewards 37.06, envs finished 1
2026-01-17 13:35:37,296 : worker.worker : DEBUG : Step 159346, finished rewards 23.55, envs finished 1
2026-01-17 13:35:37,314 : worker.worker : DEBUG : Step 159348, finished rewards -22.20, envs finished 1
2026-01-17 13:35:37,475 : agent.on_policy : DEBUG : Mean Losses: [3.9183446653187275]
2026-01-17 13:35:37,493 : worker.worker : DEBUG : Step 159364, finished rewards 24.18, envs finished 1
2026-01-17 13:35:37,623 : agent.on_policy : DEBUG : Mean Losses: [2.283984187990427]
2026-01-17 13:35:37,737 : worker.worker : DEBUG : Step 159406, finished rewards 25.31, envs finished 1
2026-01-17 13:35:37,747 : worker.worker : DEBUG : Step 159407, finished rewards 10.97, envs finished 1
2026-01-17 13:35:37,764 : worker.worker : DEBUG : Step 159409, finished rewards 32.32, envs finished 1
2026-01-17 13:35:37,836 : worker.worker : DEBUG : Step 159413, finished rewards 11.02, envs finished 1
2026-01-17 13:35:38,022 : agent.on_policy : DEBUG : Mean Losses: [7.233852408826351]
2026-01-17 13:35:38,059 : worker.worker : DEBUG : Step 159429, finished rewards 32.20, envs finished 1
2026-01-17 13:35:38,127 : worker.worker : DEBUG : Step 159440, finished rewards 13.58, envs finished 1
2026-01-17 13:35:38,167 : worker.worker : DEBUG : Step 159447, finished rewards 32.03, envs finished 1
2026-01-17 13:35:38,228 : worker.worker : DEBUG : Step 159454, finished rewards 13.80, envs finished 1
2026-01-17 13:35:38,407 : agent.on_policy : DEBUG : Mean Losses: [4.868519387207925]
2026-01-17 13:35:38,627 : agent.on_policy : DEBUG : Mean Losses: [1.4890127088874578]
2026-01-17 13:35:38,651 : worker.worker : DEBUG : Step 159492, finished rewards 33.79, envs finished 1
2026-01-17 13:35:38,726 : worker.worker : DEBUG : Step 159512, finished rewards 18.31, envs finished 1
2026-01-17 13:35:38,756 : worker.worker : DEBUG : Step 159519, finished rewards 19.50, envs finished 1
2026-01-17 13:35:38,874 : agent.on_policy : DEBUG : Mean Losses: [4.703038722276688]
2026-01-17 13:35:38,893 : worker.worker : DEBUG : Step 159523, finished rewards 7.25, envs finished 1
2026-01-17 13:35:39,093 : worker.worker : DEBUG : Step 159550, finished rewards 21.45, envs finished 1
2026-01-17 13:35:39,150 : agent.on_policy : DEBUG : Mean Losses: [4.1431638691574335]
2026-01-17 13:35:39,157 : worker.worker : DEBUG : Step 159553, finished rewards 2.94, envs finished 1
2026-01-17 13:35:39,388 : agent.on_policy : DEBUG : Mean Losses: [2.737604192458093]
2026-01-17 13:35:39,430 : worker.worker : DEBUG : Step 159596, finished rewards 18.94, envs finished 1
2026-01-17 13:35:39,461 : worker.worker : DEBUG : Step 159602, finished rewards 32.00, envs finished 1
2026-01-17 13:35:39,594 : agent.on_policy : DEBUG : Mean Losses: [5.499269649386406]
2026-01-17 13:35:39,607 : worker.worker : DEBUG : Step 159617, finished rewards 23.75, envs finished 1
2026-01-17 13:35:39,752 : worker.worker : DEBUG : Step 159628, finished rewards 5.65, envs finished 1
2026-01-17 13:35:39,877 : worker.worker : DEBUG : Step 159636, finished rewards 28.46, envs finished 1
2026-01-17 13:35:39,921 : worker.worker : DEBUG : Step 159639, finished rewards 28.97, envs finished 1
2026-01-17 13:35:40,091 : agent.on_policy : DEBUG : Mean Losses: [7.003722049295902]
2026-01-17 13:35:40,138 : worker.worker : DEBUG : Step 159660, finished rewards -32.69, envs finished 1
2026-01-17 13:35:40,285 : agent.on_policy : DEBUG : Mean Losses: [3.165832918137312]
2026-01-17 13:35:40,347 : worker.worker : DEBUG : Step 159683, finished rewards 28.40, envs finished 1
2026-01-17 13:35:40,582 : agent.on_policy : DEBUG : Mean Losses: [3.279753740876913]
2026-01-17 13:35:40,592 : worker.worker : DEBUG : Step 159714, finished rewards 10.84, envs finished 1
2026-01-17 13:35:40,615 : worker.worker : DEBUG : Step 159719, finished rewards 18.25, envs finished 1
2026-01-17 13:35:40,641 : worker.worker : DEBUG : Step 159724, finished rewards 21.48, envs finished 1
2026-01-17 13:35:40,668 : worker.worker : DEBUG : Step 159730, finished rewards 25.01, envs finished 1
2026-01-17 13:35:40,692 : worker.worker : DEBUG : Step 159735, finished rewards 18.60, envs finished 1
2026-01-17 13:35:40,785 : agent.on_policy : DEBUG : Mean Losses: [6.538624823093414]
2026-01-17 13:35:40,957 : worker.worker : DEBUG : Step 159774, finished rewards 25.98, envs finished 1
2026-01-17 13:35:40,966 : worker.worker : DEBUG : Step 159775, finished rewards -62.00, envs finished 1
2026-01-17 13:35:41,033 : agent.on_policy : DEBUG : Mean Losses: [3.308924898505211]
2026-01-17 13:35:41,124 : worker.worker : DEBUG : Step 159795, finished rewards 41.64, envs finished 1
2026-01-17 13:35:41,167 : worker.worker : DEBUG : Step 159797, finished rewards 1.24, envs finished 1
2026-01-17 13:35:41,420 : agent.on_policy : DEBUG : Mean Losses: [4.331904552876949]
2026-01-17 13:35:41,539 : worker.worker : DEBUG : Step 159820, finished rewards 15.40, envs finished 1
2026-01-17 13:35:41,826 : agent.on_policy : DEBUG : Mean Losses: [4.909489747136831]
2026-01-17 13:35:41,835 : worker.worker : DEBUG : Step 159842, finished rewards 42.67, envs finished 1
2026-01-17 13:35:41,856 : worker.worker : DEBUG : Step 159847, finished rewards 4.82, envs finished 1
2026-01-17 13:35:41,925 : worker.worker : DEBUG : Step 159866, finished rewards 11.72, envs finished 2
2026-01-17 13:35:41,932 : worker.worker : DEBUG : Step 159867, finished rewards 43.27, envs finished 1
2026-01-17 13:35:42,055 : agent.on_policy : DEBUG : Mean Losses: [7.327990680932999]
2026-01-17 13:35:42,086 : worker.worker : DEBUG : Step 159875, finished rewards 34.11, envs finished 1
2026-01-17 13:35:42,304 : agent.on_policy : DEBUG : Mean Losses: [2.5996088925749063]
2026-01-17 13:35:42,364 : worker.worker : DEBUG : Step 159918, finished rewards 31.21, envs finished 2
2026-01-17 13:35:42,555 : agent.on_policy : DEBUG : Mean Losses: [4.248541921377182]
2026-01-17 13:35:42,657 : worker.worker : DEBUG : Step 159961, finished rewards 28.67, envs finished 1
2026-01-17 13:35:42,686 : worker.worker : DEBUG : Step 159966, finished rewards 18.95, envs finished 1
2026-01-17 13:35:42,698 : worker.worker : DEBUG : Step 159967, finished rewards 20.21, envs finished 1
2026-01-17 13:35:42,854 : agent.on_policy : DEBUG : Mean Losses: [8.093469500541687]
2026-01-17 13:35:42,862 : worker.worker : DEBUG : Step 159969, finished rewards -51.63, envs finished 1
2026-01-17 13:35:42,982 : worker.worker : DEBUG : Step 159983, finished rewards -8.73, envs finished 1
2026-01-17 13:35:43,021 : worker.worker : DEBUG : Step 159988, finished rewards 10.78, envs finished 1
2026-01-17 13:35:43,131 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:35:43,308 : agent.on_policy : DEBUG : Mean Losses: [4.466331157833338]
2026-01-17 13:35:43,320 : worker.worker : INFO : Step 160000, Avg Reward 17.1067, Max Reward 46.5981, Loss [4.83404238]
2026-01-17 13:35:43,410 : worker.worker : DEBUG : Step 160010, finished rewards 24.55, envs finished 1
2026-01-17 13:35:43,445 : worker.worker : DEBUG : Step 160012, finished rewards 23.67, envs finished 1
2026-01-17 13:35:43,720 : agent.on_policy : DEBUG : Mean Losses: [2.4423562940210104]
2026-01-17 13:35:43,804 : worker.worker : DEBUG : Step 160051, finished rewards 26.07, envs finished 1
2026-01-17 13:35:43,859 : worker.worker : DEBUG : Step 160062, finished rewards 21.37, envs finished 1
2026-01-17 13:35:44,006 : agent.on_policy : DEBUG : Mean Losses: [4.109437257051468]
2026-01-17 13:35:44,022 : worker.worker : DEBUG : Step 160068, finished rewards 23.37, envs finished 1
2026-01-17 13:35:44,028 : worker.worker : DEBUG : Step 160069, finished rewards 17.88, envs finished 1
2026-01-17 13:35:44,221 : worker.worker : DEBUG : Step 160090, finished rewards 35.10, envs finished 1
2026-01-17 13:35:44,273 : worker.worker : DEBUG : Step 160095, finished rewards 32.08, envs finished 1
2026-01-17 13:35:44,368 : agent.on_policy : DEBUG : Mean Losses: [6.1550179198384285]
2026-01-17 13:35:44,723 : agent.on_policy : DEBUG : Mean Losses: [1.5902056843042374]
2026-01-17 13:35:44,747 : worker.worker : DEBUG : Step 160133, finished rewards 10.42, envs finished 1
2026-01-17 13:35:45,023 : agent.on_policy : DEBUG : Mean Losses: [5.9919129610061646]
2026-01-17 13:35:45,024 : worker.worker : DEBUG : Step 160160, finished rewards 42.50, envs finished 1
2026-01-17 13:35:45,075 : worker.worker : DEBUG : Step 160167, finished rewards 17.60, envs finished 1
2026-01-17 13:35:45,160 : worker.worker : DEBUG : Step 160177, finished rewards 10.78, envs finished 1
2026-01-17 13:35:45,205 : worker.worker : DEBUG : Step 160180, finished rewards 17.29, envs finished 1
2026-01-17 13:35:45,231 : worker.worker : DEBUG : Step 160182, finished rewards 0.73, envs finished 1
2026-01-17 13:35:45,294 : worker.worker : DEBUG : Step 160189, finished rewards 22.90, envs finished 1
2026-01-17 13:35:45,495 : agent.on_policy : DEBUG : Mean Losses: [7.517597854137421]
2026-01-17 13:35:45,931 : agent.on_policy : DEBUG : Mean Losses: [0.9146047793328762]
2026-01-17 13:35:45,962 : worker.worker : DEBUG : Step 160229, finished rewards 20.79, envs finished 1
2026-01-17 13:35:46,017 : worker.worker : DEBUG : Step 160238, finished rewards 40.68, envs finished 1
2026-01-17 13:35:46,065 : worker.worker : DEBUG : Step 160245, finished rewards 29.42, envs finished 1
2026-01-17 13:35:46,105 : worker.worker : DEBUG : Step 160251, finished rewards 43.64, envs finished 1
2026-01-17 13:35:46,277 : agent.on_policy : DEBUG : Mean Losses: [8.131922155618668]
2026-01-17 13:35:46,300 : worker.worker : DEBUG : Step 160258, finished rewards 41.64, envs finished 1
2026-01-17 13:35:46,373 : worker.worker : DEBUG : Step 160264, finished rewards 31.46, envs finished 1
2026-01-17 13:35:46,657 : agent.on_policy : DEBUG : Mean Losses: [3.712032437324524]
2026-01-17 13:35:46,715 : worker.worker : DEBUG : Step 160299, finished rewards 42.37, envs finished 1
2026-01-17 13:35:46,773 : worker.worker : DEBUG : Step 160311, finished rewards -6.17, envs finished 1
2026-01-17 13:35:46,970 : agent.on_policy : DEBUG : Mean Losses: [5.114587441086769]
2026-01-17 13:35:46,992 : worker.worker : DEBUG : Step 160324, finished rewards 33.54, envs finished 1
2026-01-17 13:35:47,006 : worker.worker : DEBUG : Step 160326, finished rewards 27.35, envs finished 1
2026-01-17 13:35:47,056 : worker.worker : DEBUG : Step 160335, finished rewards 31.26, envs finished 1
2026-01-17 13:35:47,113 : worker.worker : DEBUG : Step 160346, finished rewards 29.64, envs finished 1
2026-01-17 13:35:47,224 : agent.on_policy : DEBUG : Mean Losses: [5.622451603412628]
2026-01-17 13:35:47,289 : worker.worker : DEBUG : Step 160357, finished rewards -37.44, envs finished 1
2026-01-17 13:35:47,419 : worker.worker : DEBUG : Step 160377, finished rewards 34.81, envs finished 1
2026-01-17 13:35:47,445 : worker.worker : DEBUG : Step 160379, finished rewards 12.27, envs finished 1
2026-01-17 13:35:47,459 : worker.worker : DEBUG : Step 160381, finished rewards 42.52, envs finished 1
2026-01-17 13:35:47,590 : agent.on_policy : DEBUG : Mean Losses: [6.496260054409504]
2026-01-17 13:35:47,719 : worker.worker : DEBUG : Step 160401, finished rewards 35.01, envs finished 1
2026-01-17 13:35:47,903 : agent.on_policy : DEBUG : Mean Losses: [4.524209141731262]
2026-01-17 13:35:47,905 : worker.worker : DEBUG : Step 160416, finished rewards 42.67, envs finished 1
2026-01-17 13:35:47,992 : worker.worker : DEBUG : Step 160436, finished rewards 34.42, envs finished 1
2026-01-17 13:35:48,049 : worker.worker : DEBUG : Step 160447, finished rewards 42.57, envs finished 1
2026-01-17 13:35:48,189 : agent.on_policy : DEBUG : Mean Losses: [5.512597963213921]
2026-01-17 13:35:48,196 : worker.worker : DEBUG : Step 160449, finished rewards 42.53, envs finished 1
2026-01-17 13:35:48,209 : worker.worker : DEBUG : Step 160450, finished rewards 41.29, envs finished 1
2026-01-17 13:35:48,327 : worker.worker : DEBUG : Step 160463, finished rewards 1.60, envs finished 1
2026-01-17 13:35:48,348 : worker.worker : DEBUG : Step 160465, finished rewards 45.97, envs finished 1
2026-01-17 13:35:48,637 : agent.on_policy : DEBUG : Mean Losses: [4.478424824774265]
2026-01-17 13:35:48,703 : worker.worker : DEBUG : Step 160491, finished rewards -24.76, envs finished 1
2026-01-17 13:35:48,935 : agent.on_policy : DEBUG : Mean Losses: [3.216527797281742]
2026-01-17 13:35:48,980 : worker.worker : DEBUG : Step 160523, finished rewards 29.03, envs finished 1
2026-01-17 13:35:49,131 : agent.on_policy : DEBUG : Mean Losses: [5.075451850891113]
2026-01-17 13:35:49,239 : worker.worker : DEBUG : Step 160560, finished rewards 11.02, envs finished 1
2026-01-17 13:35:49,452 : agent.on_policy : DEBUG : Mean Losses: [5.653732247650623]
2026-01-17 13:35:49,477 : worker.worker : DEBUG : Step 160582, finished rewards 25.07, envs finished 1
2026-01-17 13:35:49,500 : worker.worker : DEBUG : Step 160587, finished rewards -7.34, envs finished 1
2026-01-17 13:35:49,546 : worker.worker : DEBUG : Step 160596, finished rewards 0.43, envs finished 1
2026-01-17 13:35:49,584 : worker.worker : DEBUG : Step 160602, finished rewards -2.69, envs finished 1
2026-01-17 13:35:49,684 : agent.on_policy : DEBUG : Mean Losses: [7.406572267413139]
2026-01-17 13:35:49,900 : worker.worker : DEBUG : Step 160631, finished rewards -49.82, envs finished 1
2026-01-17 13:35:50,245 : agent.on_policy : DEBUG : Mean Losses: [2.6818498112261295]
2026-01-17 13:35:50,248 : worker.worker : DEBUG : Step 160640, finished rewards 15.60, envs finished 1
2026-01-17 13:35:50,545 : worker.worker : DEBUG : Step 160667, finished rewards 14.69, envs finished 1
2026-01-17 13:35:50,651 : agent.on_policy : DEBUG : Mean Losses: [2.908181205391884]
2026-01-17 13:35:50,684 : worker.worker : DEBUG : Step 160678, finished rewards 20.92, envs finished 1
2026-01-17 13:35:50,738 : worker.worker : DEBUG : Step 160683, finished rewards 21.18, envs finished 1
2026-01-17 13:35:50,781 : worker.worker : DEBUG : Step 160687, finished rewards 24.98, envs finished 1
2026-01-17 13:35:50,907 : worker.worker : DEBUG : Step 160700, finished rewards 43.44, envs finished 1
2026-01-17 13:35:51,036 : agent.on_policy : DEBUG : Mean Losses: [6.463577628135681]
2026-01-17 13:35:51,039 : worker.worker : DEBUG : Step 160704, finished rewards 45.85, envs finished 1
2026-01-17 13:35:51,232 : worker.worker : DEBUG : Step 160730, finished rewards 79.30, envs finished 1
2026-01-17 13:35:51,405 : agent.on_policy : DEBUG : Mean Losses: [2.928360305726528]
2026-01-17 13:35:51,411 : worker.worker : DEBUG : Step 160737, finished rewards 41.16, envs finished 1
2026-01-17 13:35:51,489 : worker.worker : DEBUG : Step 160743, finished rewards 9.41, envs finished 1
2026-01-17 13:35:51,885 : agent.on_policy : DEBUG : Mean Losses: [5.335267171263695]
2026-01-17 13:35:51,910 : worker.worker : DEBUG : Step 160774, finished rewards 42.78, envs finished 1
2026-01-17 13:35:52,014 : worker.worker : DEBUG : Step 160793, finished rewards 13.91, envs finished 1
2026-01-17 13:35:52,047 : worker.worker : DEBUG : Step 160797, finished rewards 9.95, envs finished 1
2026-01-17 13:35:52,078 : worker.worker : DEBUG : Step 160799, finished rewards 32.23, envs finished 2
2026-01-17 13:35:52,231 : agent.on_policy : DEBUG : Mean Losses: [6.482539415359497]
2026-01-17 13:35:52,288 : worker.worker : DEBUG : Step 160804, finished rewards -0.86, envs finished 1
2026-01-17 13:35:52,717 : agent.on_policy : DEBUG : Mean Losses: [1.9105274081230164]
2026-01-17 13:35:52,743 : worker.worker : DEBUG : Step 160836, finished rewards 23.28, envs finished 1
2026-01-17 13:35:52,794 : worker.worker : DEBUG : Step 160842, finished rewards 18.36, envs finished 1
2026-01-17 13:35:52,902 : worker.worker : DEBUG : Step 160854, finished rewards 34.03, envs finished 1
2026-01-17 13:35:53,007 : worker.worker : DEBUG : Step 160863, finished rewards 42.83, envs finished 1
2026-01-17 13:35:53,174 : agent.on_policy : DEBUG : Mean Losses: [6.222583323717117]
2026-01-17 13:35:53,525 : agent.on_policy : DEBUG : Mean Losses: [2.9259768053889275]
2026-01-17 13:35:53,597 : worker.worker : DEBUG : Step 160910, finished rewards 9.62, envs finished 1
2026-01-17 13:35:53,639 : worker.worker : DEBUG : Step 160917, finished rewards 36.22, envs finished 1
2026-01-17 13:35:53,669 : worker.worker : DEBUG : Step 160920, finished rewards 2.75, envs finished 1
2026-01-17 13:35:53,699 : worker.worker : DEBUG : Step 160922, finished rewards 4.25, envs finished 1
2026-01-17 13:35:53,733 : worker.worker : DEBUG : Step 160924, finished rewards 7.13, envs finished 1
2026-01-17 13:35:53,897 : agent.on_policy : DEBUG : Mean Losses: [8.526114232838154]
2026-01-17 13:35:53,995 : worker.worker : DEBUG : Step 160937, finished rewards 15.92, envs finished 1
2026-01-17 13:35:54,171 : worker.worker : DEBUG : Step 160953, finished rewards 26.54, envs finished 1
2026-01-17 13:35:54,350 : agent.on_policy : DEBUG : Mean Losses: [3.1201706528663635]
2026-01-17 13:35:54,352 : worker.worker : DEBUG : Step 160960, finished rewards 13.43, envs finished 1
2026-01-17 13:35:53,855 : agent.on_policy : DEBUG : Mean Losses: [1.2346828505396843]
2026-01-17 13:35:53,878 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:35:53,913 : worker.worker : DEBUG : Step 161008, finished rewards 25.49, envs finished 1
2026-01-17 13:35:53,921 : worker.worker : DEBUG : Step 161010, finished rewards 20.43, envs finished 1
2026-01-17 13:35:53,970 : worker.worker : DEBUG : Step 161019, finished rewards 21.94, envs finished 1
2026-01-17 13:35:54,105 : agent.on_policy : DEBUG : Mean Losses: [5.640204831957817]
2026-01-17 13:35:54,167 : worker.worker : DEBUG : Step 161027, finished rewards 16.33, envs finished 1
2026-01-17 13:35:54,310 : worker.worker : DEBUG : Step 161044, finished rewards 29.25, envs finished 1
2026-01-17 13:35:54,455 : agent.on_policy : DEBUG : Mean Losses: [4.589213114231825]
2026-01-17 13:35:54,479 : worker.worker : DEBUG : Step 161057, finished rewards 7.45, envs finished 1
2026-01-17 13:35:54,541 : worker.worker : DEBUG : Step 161065, finished rewards -11.65, envs finished 1
2026-01-17 13:35:54,583 : worker.worker : DEBUG : Step 161074, finished rewards 6.88, envs finished 1
2026-01-17 13:35:54,772 : agent.on_policy : DEBUG : Mean Losses: [2.6279933899641037]
2026-01-17 13:35:54,850 : worker.worker : DEBUG : Step 161097, finished rewards 41.32, envs finished 1
2026-01-17 13:35:54,910 : worker.worker : DEBUG : Step 161110, finished rewards 20.02, envs finished 1
2026-01-17 13:35:54,917 : worker.worker : DEBUG : Step 161111, finished rewards 24.30, envs finished 1
2026-01-17 13:35:55,184 : agent.on_policy : DEBUG : Mean Losses: [5.108074851334095]
2026-01-17 13:35:55,288 : worker.worker : DEBUG : Step 161131, finished rewards 28.47, envs finished 1
2026-01-17 13:35:55,430 : worker.worker : DEBUG : Step 161145, finished rewards 40.40, envs finished 1
2026-01-17 13:35:55,599 : agent.on_policy : DEBUG : Mean Losses: [4.95189562253654]
2026-01-17 13:35:55,759 : worker.worker : DEBUG : Step 161174, finished rewards 9.91, envs finished 1
2026-01-17 13:35:55,797 : worker.worker : DEBUG : Step 161182, finished rewards 39.61, envs finished 1
2026-01-17 13:35:55,856 : agent.on_policy : DEBUG : Mean Losses: [5.857749599963427]
2026-01-17 13:35:55,894 : worker.worker : DEBUG : Step 161193, finished rewards -0.16, envs finished 1
2026-01-17 13:35:55,908 : worker.worker : DEBUG : Step 161196, finished rewards 16.83, envs finished 1
2026-01-17 13:35:55,924 : worker.worker : DEBUG : Step 161199, finished rewards 27.61, envs finished 1
2026-01-17 13:35:55,940 : worker.worker : DEBUG : Step 161201, finished rewards 41.25, envs finished 1
2026-01-17 13:35:56,045 : worker.worker : DEBUG : Step 161213, finished rewards 41.95, envs finished 1
2026-01-17 13:35:56,176 : agent.on_policy : DEBUG : Mean Losses: [8.02234586700797]
2026-01-17 13:35:56,200 : worker.worker : DEBUG : Step 161221, finished rewards -0.90, envs finished 1
2026-01-17 13:35:56,423 : agent.on_policy : DEBUG : Mean Losses: [1.4338905084878206]
2026-01-17 13:35:56,498 : worker.worker : DEBUG : Step 161272, finished rewards 25.77, envs finished 1
2026-01-17 13:35:56,628 : agent.on_policy : DEBUG : Mean Losses: [4.9782982766628265]
2026-01-17 13:35:56,647 : worker.worker : DEBUG : Step 161285, finished rewards 26.22, envs finished 1
2026-01-17 13:35:56,675 : worker.worker : DEBUG : Step 161291, finished rewards 24.29, envs finished 1
2026-01-17 13:35:56,700 : worker.worker : DEBUG : Step 161297, finished rewards 18.62, envs finished 1
2026-01-17 13:35:56,740 : worker.worker : DEBUG : Step 161306, finished rewards -4.06, envs finished 1
2026-01-17 13:35:56,805 : agent.on_policy : DEBUG : Mean Losses: [7.241807259619236]
2026-01-17 13:35:56,826 : worker.worker : DEBUG : Step 161316, finished rewards 7.19, envs finished 1
2026-01-17 13:35:56,853 : worker.worker : DEBUG : Step 161322, finished rewards 13.23, envs finished 1
2026-01-17 13:35:57,023 : worker.worker : DEBUG : Step 161343, finished rewards 40.83, envs finished 1
2026-01-17 13:35:57,128 : agent.on_policy : DEBUG : Mean Losses: [4.385069292038679]
2026-01-17 13:35:57,312 : worker.worker : DEBUG : Step 161372, finished rewards 27.84, envs finished 1
2026-01-17 13:35:57,326 : worker.worker : DEBUG : Step 161375, finished rewards -18.30, envs finished 1
2026-01-17 13:35:57,440 : agent.on_policy : DEBUG : Mean Losses: [5.301496580243111]
2026-01-17 13:35:57,600 : worker.worker : DEBUG : Step 161404, finished rewards 26.99, envs finished 1
2026-01-17 13:35:57,669 : agent.on_policy : DEBUG : Mean Losses: [3.9831206426024437]
2026-01-17 13:35:57,677 : worker.worker : DEBUG : Step 161409, finished rewards 28.51, envs finished 1
2026-01-17 13:35:57,707 : worker.worker : DEBUG : Step 161413, finished rewards 6.43, envs finished 1
2026-01-17 13:35:57,770 : worker.worker : DEBUG : Step 161421, finished rewards 6.56, envs finished 1
2026-01-17 13:35:57,823 : worker.worker : DEBUG : Step 161425, finished rewards -7.45, envs finished 1
2026-01-17 13:35:58,051 : agent.on_policy : DEBUG : Mean Losses: [3.755464121699333]
2026-01-17 13:35:58,111 : worker.worker : DEBUG : Step 161448, finished rewards 35.66, envs finished 1
2026-01-17 13:35:58,196 : worker.worker : DEBUG : Step 161461, finished rewards 7.47, envs finished 1
2026-01-17 13:35:58,399 : agent.on_policy : DEBUG : Mean Losses: [3.5112791657447815]
2026-01-17 13:35:58,408 : worker.worker : DEBUG : Step 161473, finished rewards 20.27, envs finished 1
2026-01-17 13:35:58,580 : worker.worker : DEBUG : Step 161489, finished rewards 29.67, envs finished 1
2026-01-17 13:35:58,877 : agent.on_policy : DEBUG : Mean Losses: [4.23382718488574]
2026-01-17 13:35:58,959 : worker.worker : DEBUG : Step 161519, finished rewards 13.89, envs finished 1
2026-01-17 13:35:59,021 : worker.worker : DEBUG : Step 161532, finished rewards 41.65, envs finished 1
2026-01-17 13:35:59,186 : agent.on_policy : DEBUG : Mean Losses: [7.202285453677177]
2026-01-17 13:35:59,216 : worker.worker : DEBUG : Step 161542, finished rewards 22.10, envs finished 1
2026-01-17 13:35:59,230 : worker.worker : DEBUG : Step 161544, finished rewards 41.87, envs finished 1
2026-01-17 13:35:59,331 : worker.worker : DEBUG : Step 161551, finished rewards 2.78, envs finished 1
2026-01-17 13:35:59,495 : worker.worker : DEBUG : Step 161564, finished rewards -17.79, envs finished 1
2026-01-17 13:35:59,757 : agent.on_policy : DEBUG : Mean Losses: [5.292927447706461]
2026-01-17 13:35:59,836 : worker.worker : DEBUG : Step 161586, finished rewards 22.84, envs finished 1
2026-01-17 13:35:59,856 : worker.worker : DEBUG : Step 161590, finished rewards 41.57, envs finished 1
2026-01-17 13:36:00,064 : agent.on_policy : DEBUG : Mean Losses: [3.7951896116137505]
2026-01-17 13:36:00,200 : worker.worker : DEBUG : Step 161614, finished rewards 32.70, envs finished 1
2026-01-17 13:36:00,209 : worker.worker : DEBUG : Step 161615, finished rewards 41.82, envs finished 1
2026-01-17 13:36:00,402 : agent.on_policy : DEBUG : Mean Losses: [6.353061765432358]
2026-01-17 13:36:00,445 : worker.worker : DEBUG : Step 161643, finished rewards 17.09, envs finished 1
2026-01-17 13:36:00,472 : worker.worker : DEBUG : Step 161649, finished rewards 28.02, envs finished 1
2026-01-17 13:36:00,579 : agent.on_policy : DEBUG : Mean Losses: [5.363112509250641]
2026-01-17 13:36:00,618 : worker.worker : DEBUG : Step 161669, finished rewards 32.26, envs finished 1
2026-01-17 13:36:00,776 : worker.worker : DEBUG : Step 161684, finished rewards 41.21, envs finished 1
2026-01-17 13:36:00,909 : agent.on_policy : DEBUG : Mean Losses: [5.688614189624786]
2026-01-17 13:36:00,938 : worker.worker : DEBUG : Step 161697, finished rewards 14.81, envs finished 1
2026-01-17 13:36:01,000 : worker.worker : DEBUG : Step 161707, finished rewards 24.66, envs finished 1
2026-01-17 13:36:01,238 : agent.on_policy : DEBUG : Mean Losses: [3.36998974904418]
2026-01-17 13:36:01,301 : worker.worker : DEBUG : Step 161744, finished rewards 18.24, envs finished 1
2026-01-17 13:36:01,314 : worker.worker : DEBUG : Step 161747, finished rewards -80.08, envs finished 1
2026-01-17 13:36:01,319 : worker.worker : DEBUG : Step 161748, finished rewards 23.25, envs finished 1
2026-01-17 13:36:01,348 : worker.worker : DEBUG : Step 161756, finished rewards 39.95, envs finished 1
2026-01-17 13:36:01,524 : agent.on_policy : DEBUG : Mean Losses: [7.0575772896409035]
2026-01-17 13:36:01,773 : worker.worker : DEBUG : Step 161784, finished rewards 16.08, envs finished 1
2026-01-17 13:36:01,856 : worker.worker : DEBUG : Step 161791, finished rewards 22.51, envs finished 1
2026-01-17 13:36:01,944 : agent.on_policy : DEBUG : Mean Losses: [3.176426127552986]
2026-01-17 13:36:02,039 : worker.worker : DEBUG : Step 161805, finished rewards 21.16, envs finished 1
2026-01-17 13:36:02,179 : worker.worker : DEBUG : Step 161814, finished rewards 42.65, envs finished 1
2026-01-17 13:36:02,405 : agent.on_policy : DEBUG : Mean Losses: [3.6808283776044846]
2026-01-17 13:36:02,435 : worker.worker : DEBUG : Step 161829, finished rewards 17.42, envs finished 1
2026-01-17 13:36:02,506 : worker.worker : DEBUG : Step 161840, finished rewards 24.05, envs finished 1
2026-01-17 13:36:02,555 : worker.worker : DEBUG : Step 161848, finished rewards 24.39, envs finished 1
2026-01-17 13:36:02,610 : worker.worker : DEBUG : Step 161854, finished rewards 42.90, envs finished 1
2026-01-17 13:36:02,734 : agent.on_policy : DEBUG : Mean Losses: [6.637913072481751]
2026-01-17 13:36:02,778 : worker.worker : DEBUG : Step 161861, finished rewards 8.61, envs finished 1
2026-01-17 13:36:03,071 : agent.on_policy : DEBUG : Mean Losses: [2.744449984282255]
2026-01-17 13:36:03,136 : worker.worker : DEBUG : Step 161903, finished rewards 8.71, envs finished 1
2026-01-17 13:36:03,165 : worker.worker : DEBUG : Step 161907, finished rewards 24.89, envs finished 1
2026-01-17 13:36:03,348 : agent.on_policy : DEBUG : Mean Losses: [4.613611117005348]
2026-01-17 13:36:03,350 : worker.worker : DEBUG : Step 161920, finished rewards 33.67, envs finished 1
2026-01-17 13:36:03,357 : worker.worker : DEBUG : Step 161921, finished rewards 24.97, envs finished 1
2026-01-17 13:36:03,503 : worker.worker : DEBUG : Step 161934, finished rewards 27.77, envs finished 1
2026-01-17 13:36:03,625 : worker.worker : DEBUG : Step 161948, finished rewards 24.84, envs finished 1
2026-01-17 13:36:03,749 : agent.on_policy : DEBUG : Mean Losses: [5.029458358883858]
2026-01-17 13:36:03,968 : agent.on_policy : DEBUG : Mean Losses: [2.254557728767395]
2026-01-17 13:36:03,975 : worker.worker : DEBUG : Step 161986, finished rewards 61.09, envs finished 1
2026-01-17 13:36:04,024 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:36:04,030 : worker.worker : DEBUG : Step 161999, finished rewards 24.00, envs finished 1
2026-01-17 13:36:04,066 : worker.worker : DEBUG : Step 162006, finished rewards 30.01, envs finished 1
2026-01-17 13:36:04,080 : worker.worker : DEBUG : Step 162009, finished rewards 13.78, envs finished 1
2026-01-17 13:36:04,163 : agent.on_policy : DEBUG : Mean Losses: [8.16210663318634]
2026-01-17 13:36:04,166 : worker.worker : DEBUG : Step 162016, finished rewards -13.95, envs finished 1
2026-01-17 13:36:04,403 : agent.on_policy : DEBUG : Mean Losses: [2.669509058818221]
2026-01-17 13:36:04,431 : worker.worker : DEBUG : Step 162057, finished rewards 21.88, envs finished 1
2026-01-17 13:36:04,478 : worker.worker : DEBUG : Step 162069, finished rewards 5.77, envs finished 1
2026-01-17 13:36:04,483 : worker.worker : DEBUG : Step 162070, finished rewards 41.99, envs finished 1
2026-01-17 13:36:04,521 : worker.worker : DEBUG : Step 162079, finished rewards 25.13, envs finished 1
2026-01-17 13:36:04,574 : agent.on_policy : DEBUG : Mean Losses: [7.8048679530620575]
2026-01-17 13:36:04,576 : worker.worker : DEBUG : Step 162080, finished rewards 41.84, envs finished 1
2026-01-17 13:36:04,581 : worker.worker : DEBUG : Step 162081, finished rewards -26.21, envs finished 1
2026-01-17 13:36:04,733 : worker.worker : DEBUG : Step 162104, finished rewards 27.53, envs finished 1
2026-01-17 13:36:04,826 : agent.on_policy : DEBUG : Mean Losses: [2.7042613495141268]
2026-01-17 13:36:04,939 : worker.worker : DEBUG : Step 162126, finished rewards 4.26, envs finished 1
2026-01-17 13:36:05,153 : agent.on_policy : DEBUG : Mean Losses: [2.291909635066986]
2026-01-17 13:36:05,279 : worker.worker : DEBUG : Step 162161, finished rewards 26.27, envs finished 1
2026-01-17 13:36:05,309 : worker.worker : DEBUG : Step 162165, finished rewards 28.79, envs finished 1
2026-01-17 13:36:05,343 : worker.worker : DEBUG : Step 162168, finished rewards 46.11, envs finished 1
2026-01-17 13:36:05,582 : agent.on_policy : DEBUG : Mean Losses: [7.909112818539143]
2026-01-17 13:36:05,635 : worker.worker : DEBUG : Step 162185, finished rewards 16.14, envs finished 1
2026-01-17 13:36:05,714 : worker.worker : DEBUG : Step 162188, finished rewards -1.74, envs finished 1
2026-01-17 13:36:05,745 : worker.worker : DEBUG : Step 162193, finished rewards 9.88, envs finished 1
2026-01-17 13:36:05,941 : agent.on_policy : DEBUG : Mean Losses: [4.368006147444248]
2026-01-17 13:36:05,943 : worker.worker : DEBUG : Step 162208, finished rewards 32.57, envs finished 1
2026-01-17 13:36:05,954 : worker.worker : DEBUG : Step 162211, finished rewards -4.14, envs finished 1
2026-01-17 13:36:06,042 : worker.worker : DEBUG : Step 162236, finished rewards 39.70, envs finished 1
2026-01-17 13:36:06,160 : agent.on_policy : DEBUG : Mean Losses: [3.246407598257065]
2026-01-17 13:36:06,261 : worker.worker : DEBUG : Step 162253, finished rewards 27.14, envs finished 1
2026-01-17 13:36:06,352 : worker.worker : DEBUG : Step 162264, finished rewards 35.78, envs finished 1
2026-01-17 13:36:06,506 : agent.on_policy : DEBUG : Mean Losses: [5.395415745675564]
2026-01-17 13:36:06,550 : worker.worker : DEBUG : Step 162285, finished rewards 24.91, envs finished 1
2026-01-17 13:36:06,582 : worker.worker : DEBUG : Step 162292, finished rewards 1.99, envs finished 1
2026-01-17 13:36:06,591 : worker.worker : DEBUG : Step 162294, finished rewards 28.33, envs finished 1
2026-01-17 13:36:06,686 : agent.on_policy : DEBUG : Mean Losses: [5.132704738527536]
2026-01-17 13:36:06,787 : worker.worker : DEBUG : Step 162319, finished rewards 31.59, envs finished 1
2026-01-17 13:36:06,993 : agent.on_policy : DEBUG : Mean Losses: [3.4785748571157455]
2026-01-17 13:36:07,094 : worker.worker : DEBUG : Step 162352, finished rewards 26.78, envs finished 1
2026-01-17 13:36:07,117 : worker.worker : DEBUG : Step 162354, finished rewards 20.90, envs finished 1
2026-01-17 13:36:07,155 : worker.worker : DEBUG : Step 162357, finished rewards -7.01, envs finished 1
2026-01-17 13:36:07,237 : worker.worker : DEBUG : Step 162363, finished rewards 41.05, envs finished 1
2026-01-17 13:36:07,477 : agent.on_policy : DEBUG : Mean Losses: [7.51640510559082]
2026-01-17 13:36:07,482 : worker.worker : DEBUG : Step 162368, finished rewards 32.12, envs finished 1
2026-01-17 13:36:07,608 : worker.worker : DEBUG : Step 162382, finished rewards 26.47, envs finished 1
2026-01-17 13:36:07,809 : agent.on_policy : DEBUG : Mean Losses: [3.9490931667387486]
2026-01-17 13:36:07,925 : worker.worker : DEBUG : Step 162415, finished rewards 46.37, envs finished 1
2026-01-17 13:36:07,935 : worker.worker : DEBUG : Step 162416, finished rewards -46.90, envs finished 1
2026-01-17 13:36:08,034 : worker.worker : DEBUG : Step 162426, finished rewards 40.14, envs finished 1
2026-01-17 13:36:08,235 : agent.on_policy : DEBUG : Mean Losses: [8.726252049207687]
2026-01-17 13:36:08,388 : worker.worker : DEBUG : Step 162444, finished rewards 47.40, envs finished 1
2026-01-17 13:36:08,455 : worker.worker : DEBUG : Step 162449, finished rewards 28.87, envs finished 1
2026-01-17 13:36:08,674 : agent.on_policy : DEBUG : Mean Losses: [5.9061103612184525]
2026-01-17 13:36:08,684 : worker.worker : DEBUG : Step 162466, finished rewards 9.92, envs finished 1
2026-01-17 13:36:08,712 : worker.worker : DEBUG : Step 162472, finished rewards 18.01, envs finished 1
2026-01-17 13:36:08,765 : worker.worker : DEBUG : Step 162486, finished rewards 41.63, envs finished 1
2026-01-17 13:36:08,853 : agent.on_policy : DEBUG : Mean Losses: [5.739926367998123]
2026-01-17 13:36:08,882 : worker.worker : DEBUG : Step 162498, finished rewards 32.02, envs finished 1
2026-01-17 13:36:09,195 : agent.on_policy : DEBUG : Mean Losses: [4.146983178332448]
2026-01-17 13:36:09,226 : worker.worker : DEBUG : Step 162536, finished rewards 25.27, envs finished 1
2026-01-17 13:36:09,268 : worker.worker : DEBUG : Step 162546, finished rewards 3.66, envs finished 1
2026-01-17 13:36:09,290 : worker.worker : DEBUG : Step 162550, finished rewards 20.16, envs finished 1
2026-01-17 13:36:09,411 : agent.on_policy : DEBUG : Mean Losses: [5.277026280760765]
2026-01-17 13:36:09,435 : worker.worker : DEBUG : Step 162565, finished rewards 23.56, envs finished 1
2026-01-17 13:36:09,471 : worker.worker : DEBUG : Step 162567, finished rewards 33.62, envs finished 1
2026-01-17 13:36:09,506 : worker.worker : DEBUG : Step 162569, finished rewards 17.70, envs finished 1
2026-01-17 13:36:09,600 : worker.worker : DEBUG : Step 162587, finished rewards -86.80, envs finished 1
2026-01-17 13:36:09,814 : agent.on_policy : DEBUG : Mean Losses: [4.31988712400198]
2026-01-17 13:36:10,057 : agent.on_policy : DEBUG : Mean Losses: [3.257663056254387]
2026-01-17 13:36:10,069 : worker.worker : DEBUG : Step 162627, finished rewards 4.68, envs finished 1
2026-01-17 13:36:10,094 : worker.worker : DEBUG : Step 162632, finished rewards 32.66, envs finished 1
2026-01-17 13:36:10,122 : worker.worker : DEBUG : Step 162638, finished rewards 33.11, envs finished 2
2026-01-17 13:36:10,246 : agent.on_policy : DEBUG : Mean Losses: [7.712902367115021]
2026-01-17 13:36:10,259 : worker.worker : DEBUG : Step 162658, finished rewards 42.11, envs finished 1
2026-01-17 13:36:10,566 : agent.on_policy : DEBUG : Mean Losses: [4.477114550769329]
2026-01-17 13:36:10,577 : worker.worker : DEBUG : Step 162690, finished rewards -7.94, envs finished 1
2026-01-17 13:36:10,649 : worker.worker : DEBUG : Step 162704, finished rewards -0.48, envs finished 1
2026-01-17 13:36:10,676 : worker.worker : DEBUG : Step 162709, finished rewards 41.90, envs finished 1
2026-01-17 13:36:10,692 : worker.worker : DEBUG : Step 162713, finished rewards -16.89, envs finished 1
2026-01-17 13:36:10,850 : agent.on_policy : DEBUG : Mean Losses: [6.377734888345003]
2026-01-17 13:36:10,877 : worker.worker : DEBUG : Step 162729, finished rewards 19.08, envs finished 1
2026-01-17 13:36:10,909 : worker.worker : DEBUG : Step 162737, finished rewards 20.81, envs finished 1
2026-01-17 13:36:10,949 : worker.worker : DEBUG : Step 162747, finished rewards 27.02, envs finished 1
2026-01-17 13:36:11,013 : agent.on_policy : DEBUG : Mean Losses: [5.435209833085537]
2026-01-17 13:36:11,062 : worker.worker : DEBUG : Step 162765, finished rewards 1.88, envs finished 1
2026-01-17 13:36:11,198 : worker.worker : DEBUG : Step 162783, finished rewards 25.56, envs finished 1
2026-01-17 13:36:11,318 : agent.on_policy : DEBUG : Mean Losses: [3.3986582569777966]
2026-01-17 13:36:11,436 : worker.worker : DEBUG : Step 162796, finished rewards 30.73, envs finished 1
2026-01-17 13:36:11,577 : worker.worker : DEBUG : Step 162811, finished rewards 45.97, envs finished 1
2026-01-17 13:36:11,717 : agent.on_policy : DEBUG : Mean Losses: [4.905365498736501]
2026-01-17 13:36:11,786 : worker.worker : DEBUG : Step 162819, finished rewards 26.81, envs finished 1
2026-01-17 13:36:11,851 : worker.worker : DEBUG : Step 162826, finished rewards 9.68, envs finished 1
2026-01-17 13:36:11,992 : worker.worker : DEBUG : Step 162836, finished rewards -6.52, envs finished 1
2026-01-17 13:36:12,221 : agent.on_policy : DEBUG : Mean Losses: [3.600617028772831]
2026-01-17 13:36:12,253 : worker.worker : DEBUG : Step 162850, finished rewards 10.62, envs finished 1
2026-01-17 13:36:12,519 : agent.on_policy : DEBUG : Mean Losses: [2.0017263274639845]
2026-01-17 13:36:12,540 : worker.worker : DEBUG : Step 162885, finished rewards 11.65, envs finished 1
2026-01-17 13:36:12,548 : worker.worker : DEBUG : Step 162886, finished rewards 17.06, envs finished 1
2026-01-17 13:36:12,628 : worker.worker : DEBUG : Step 162903, finished rewards 37.61, envs finished 1
2026-01-17 13:36:12,789 : agent.on_policy : DEBUG : Mean Losses: [4.718638930469751]
2026-01-17 13:36:12,804 : worker.worker : DEBUG : Step 162914, finished rewards 21.49, envs finished 1
2026-01-17 13:36:12,810 : worker.worker : DEBUG : Step 162915, finished rewards 16.73, envs finished 1
2026-01-17 13:36:12,906 : worker.worker : DEBUG : Step 162924, finished rewards 27.15, envs finished 1
2026-01-17 13:36:12,926 : worker.worker : DEBUG : Step 162928, finished rewards -0.95, envs finished 1
2026-01-17 13:36:13,129 : agent.on_policy : DEBUG : Mean Losses: [4.110441524535418]
2026-01-17 13:36:13,174 : worker.worker : DEBUG : Step 162952, finished rewards 17.52, envs finished 1
2026-01-17 13:36:13,250 : worker.worker : DEBUG : Step 162969, finished rewards 31.60, envs finished 1
2026-01-17 13:36:13,446 : agent.on_policy : DEBUG : Mean Losses: [4.501867514103651]
2026-01-17 13:36:13,466 : worker.worker : DEBUG : Step 162978, finished rewards 45.98, envs finished 1
2026-01-17 13:36:13,589 : worker.worker : DEBUG : Step 162989, finished rewards 15.32, envs finished 1
2026-01-17 13:36:13,692 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:36:13,713 : worker.worker : DEBUG : Step 162999, finished rewards 40.34, envs finished 1
2026-01-17 13:36:13,921 : agent.on_policy : DEBUG : Mean Losses: [6.339494407176971]
2026-01-17 13:36:13,931 : worker.worker : DEBUG : Step 163010, finished rewards 15.37, envs finished 1
2026-01-17 13:36:14,042 : worker.worker : DEBUG : Step 163022, finished rewards 12.69, envs finished 1
2026-01-17 13:36:14,269 : agent.on_policy : DEBUG : Mean Losses: [4.117643065750599]
2026-01-17 13:36:14,312 : worker.worker : DEBUG : Step 163050, finished rewards 32.33, envs finished 1
2026-01-17 13:36:14,351 : worker.worker : DEBUG : Step 163059, finished rewards 1.05, envs finished 1
2026-01-17 13:36:14,521 : agent.on_policy : DEBUG : Mean Losses: [3.4147075414657593]
2026-01-17 13:36:14,542 : worker.worker : DEBUG : Step 163075, finished rewards 28.80, envs finished 1
2026-01-17 13:36:14,552 : worker.worker : DEBUG : Step 163076, finished rewards 1.49, envs finished 1
2026-01-17 13:36:14,596 : worker.worker : DEBUG : Step 163079, finished rewards 41.35, envs finished 1
2026-01-17 13:36:14,670 : worker.worker : DEBUG : Step 163090, finished rewards 25.30, envs finished 1
2026-01-17 13:36:14,839 : agent.on_policy : DEBUG : Mean Losses: [5.4452530816197395]
2026-01-17 13:36:14,852 : worker.worker : DEBUG : Step 163106, finished rewards 29.85, envs finished 1
2026-01-17 13:36:15,106 : agent.on_policy : DEBUG : Mean Losses: [2.2834597453475]
2026-01-17 13:36:15,142 : worker.worker : DEBUG : Step 163142, finished rewards 24.78, envs finished 1
2026-01-17 13:36:15,167 : worker.worker : DEBUG : Step 163146, finished rewards 28.03, envs finished 1
2026-01-17 13:36:15,222 : worker.worker : DEBUG : Step 163156, finished rewards 35.03, envs finished 1
2026-01-17 13:36:15,245 : worker.worker : DEBUG : Step 163158, finished rewards 31.90, envs finished 1
2026-01-17 13:36:15,391 : agent.on_policy : DEBUG : Mean Losses: [7.232675641775131]
2026-01-17 13:36:15,567 : worker.worker : DEBUG : Step 163190, finished rewards 21.97, envs finished 1
2026-01-17 13:36:15,669 : worker.worker : DEBUG : Step 163196, finished rewards 26.07, envs finished 1
2026-01-17 13:36:15,680 : worker.worker : DEBUG : Step 163197, finished rewards 21.55, envs finished 1
2026-01-17 13:36:15,793 : agent.on_policy : DEBUG : Mean Losses: [3.9253396838903427]
2026-01-17 13:36:15,843 : worker.worker : DEBUG : Step 163209, finished rewards 3.60, envs finished 1
2026-01-17 13:36:16,127 : agent.on_policy : DEBUG : Mean Losses: [2.447736309841275]
2026-01-17 13:36:16,181 : worker.worker : DEBUG : Step 163242, finished rewards 21.92, envs finished 1
2026-01-17 13:36:16,189 : worker.worker : DEBUG : Step 163243, finished rewards 19.70, envs finished 1
2026-01-17 13:36:16,353 : worker.worker : DEBUG : Step 163262, finished rewards 18.32, envs finished 1
2026-01-17 13:36:16,419 : agent.on_policy : DEBUG : Mean Losses: [4.959726810455322]
2026-01-17 13:36:16,475 : worker.worker : DEBUG : Step 163277, finished rewards 9.28, envs finished 1
2026-01-17 13:36:16,603 : worker.worker : DEBUG : Step 163289, finished rewards 23.63, envs finished 1
2026-01-17 13:36:16,629 : worker.worker : DEBUG : Step 163293, finished rewards 22.20, envs finished 1
2026-01-17 13:36:16,645 : worker.worker : DEBUG : Step 163295, finished rewards 14.63, envs finished 1
2026-01-17 13:36:16,787 : agent.on_policy : DEBUG : Mean Losses: [5.544243274256587]
2026-01-17 13:36:17,087 : agent.on_policy : DEBUG : Mean Losses: [2.4641518630087376]
2026-01-17 13:36:17,196 : worker.worker : DEBUG : Step 163346, finished rewards 25.56, envs finished 1
2026-01-17 13:36:17,310 : worker.worker : DEBUG : Step 163353, finished rewards -2.63, envs finished 2
2026-01-17 13:36:17,539 : agent.on_policy : DEBUG : Mean Losses: [4.586773827672005]
2026-01-17 13:36:17,564 : worker.worker : DEBUG : Step 163365, finished rewards 39.86, envs finished 1
2026-01-17 13:36:17,580 : worker.worker : DEBUG : Step 163366, finished rewards 41.64, envs finished 1
2026-01-17 13:36:17,674 : worker.worker : DEBUG : Step 163370, finished rewards 12.66, envs finished 1
2026-01-17 13:36:17,748 : worker.worker : DEBUG : Step 163380, finished rewards 16.40, envs finished 1
2026-01-17 13:36:17,757 : worker.worker : DEBUG : Step 163381, finished rewards 24.18, envs finished 1
2026-01-17 13:36:17,934 : agent.on_policy : DEBUG : Mean Losses: [4.988625653088093]
2026-01-17 13:36:18,171 : agent.on_policy : DEBUG : Mean Losses: [1.695278748869896]
2026-01-17 13:36:18,174 : worker.worker : DEBUG : Step 163424, finished rewards 41.78, envs finished 1
2026-01-17 13:36:18,442 : agent.on_policy : DEBUG : Mean Losses: [4.919714100658894]
2026-01-17 13:36:18,452 : worker.worker : DEBUG : Step 163458, finished rewards 35.99, envs finished 1
2026-01-17 13:36:18,464 : worker.worker : DEBUG : Step 163460, finished rewards 10.11, envs finished 1
2026-01-17 13:36:18,477 : worker.worker : DEBUG : Step 163462, finished rewards 19.77, envs finished 1
2026-01-17 13:36:18,536 : worker.worker : DEBUG : Step 163474, finished rewards 15.77, envs finished 1
2026-01-17 13:36:18,589 : worker.worker : DEBUG : Step 163484, finished rewards -2.02, envs finished 1
2026-01-17 13:36:18,598 : worker.worker : DEBUG : Step 163485, finished rewards 15.17, envs finished 1
2026-01-17 13:36:18,741 : agent.on_policy : DEBUG : Mean Losses: [7.056410118937492]
2026-01-17 13:36:18,887 : worker.worker : DEBUG : Step 163508, finished rewards -16.05, envs finished 1
2026-01-17 13:36:18,978 : worker.worker : DEBUG : Step 163516, finished rewards 23.64, envs finished 1
2026-01-17 13:36:19,110 : agent.on_policy : DEBUG : Mean Losses: [2.745978193357587]
2026-01-17 13:36:19,353 : agent.on_policy : DEBUG : Mean Losses: [1.642398794181645]
2026-01-17 13:36:19,370 : worker.worker : DEBUG : Step 163555, finished rewards 41.13, envs finished 1
2026-01-17 13:36:19,380 : worker.worker : DEBUG : Step 163556, finished rewards 24.20, envs finished 1
2026-01-17 13:36:19,412 : worker.worker : DEBUG : Step 163562, finished rewards 17.13, envs finished 1
2026-01-17 13:36:19,434 : worker.worker : DEBUG : Step 163566, finished rewards 15.22, envs finished 1
2026-01-17 13:36:19,470 : worker.worker : DEBUG : Step 163574, finished rewards 26.47, envs finished 1
2026-01-17 13:36:19,569 : agent.on_policy : DEBUG : Mean Losses: [6.112800776958466]
2026-01-17 13:36:19,709 : worker.worker : DEBUG : Step 163605, finished rewards -3.89, envs finished 1
2026-01-17 13:36:19,788 : worker.worker : DEBUG : Step 163610, finished rewards 26.39, envs finished 1
2026-01-17 13:36:20,022 : agent.on_policy : DEBUG : Mean Losses: [3.409097235649824]
2026-01-17 13:36:20,053 : worker.worker : DEBUG : Step 163618, finished rewards 9.70, envs finished 1
2026-01-17 13:36:20,359 : agent.on_policy : DEBUG : Mean Losses: [2.4764438681304455]
2026-01-17 13:36:20,404 : worker.worker : DEBUG : Step 163659, finished rewards 16.46, envs finished 1
2026-01-17 13:36:20,414 : worker.worker : DEBUG : Step 163661, finished rewards 19.65, envs finished 1
2026-01-17 13:36:20,472 : worker.worker : DEBUG : Step 163673, finished rewards 5.04, envs finished 1
2026-01-17 13:36:20,659 : agent.on_policy : DEBUG : Mean Losses: [5.940118610858917]
2026-01-17 13:36:20,688 : worker.worker : DEBUG : Step 163685, finished rewards 3.30, envs finished 1
2026-01-17 13:36:20,715 : worker.worker : DEBUG : Step 163690, finished rewards 28.64, envs finished 1
2026-01-17 13:36:20,749 : worker.worker : DEBUG : Step 163697, finished rewards 16.68, envs finished 2
2026-01-17 13:36:20,851 : agent.on_policy : DEBUG : Mean Losses: [5.124510623514652]
2026-01-17 13:36:20,889 : worker.worker : DEBUG : Step 163720, finished rewards 27.38, envs finished 1
2026-01-17 13:36:21,144 : agent.on_policy : DEBUG : Mean Losses: [2.968250822275877]
2026-01-17 13:36:21,175 : worker.worker : DEBUG : Step 163753, finished rewards 23.89, envs finished 1
2026-01-17 13:36:21,193 : worker.worker : DEBUG : Step 163756, finished rewards 41.76, envs finished 1
2026-01-17 13:36:21,213 : worker.worker : DEBUG : Step 163760, finished rewards 21.45, envs finished 1
2026-01-17 13:36:21,263 : worker.worker : DEBUG : Step 163773, finished rewards 17.12, envs finished 1
2026-01-17 13:36:21,323 : agent.on_policy : DEBUG : Mean Losses: [7.177334293723106]
2026-01-17 13:36:21,354 : worker.worker : DEBUG : Step 163782, finished rewards 28.25, envs finished 1
2026-01-17 13:36:21,390 : worker.worker : DEBUG : Step 163790, finished rewards 21.95, envs finished 1
2026-01-17 13:36:21,417 : worker.worker : DEBUG : Step 163793, finished rewards 17.14, envs finished 1
2026-01-17 13:36:21,706 : agent.on_policy : DEBUG : Mean Losses: [4.001603819429874]
2026-01-17 13:36:21,861 : worker.worker : DEBUG : Step 163826, finished rewards 40.03, envs finished 1
2026-01-17 13:36:22,090 : agent.on_policy : DEBUG : Mean Losses: [3.7940957248210907]
2026-01-17 13:36:22,109 : worker.worker : DEBUG : Step 163842, finished rewards 29.48, envs finished 1
2026-01-17 13:36:22,180 : worker.worker : DEBUG : Step 163849, finished rewards -5.06, envs finished 1
2026-01-17 13:36:22,313 : worker.worker : DEBUG : Step 163866, finished rewards 24.67, envs finished 1
2026-01-17 13:36:22,431 : agent.on_policy : DEBUG : Mean Losses: [5.602260433137417]
2026-01-17 13:36:22,636 : worker.worker : DEBUG : Step 163900, finished rewards 10.87, envs finished 1
2026-01-17 13:36:22,809 : agent.on_policy : DEBUG : Mean Losses: [4.216294310986996]
2026-01-17 13:36:22,977 : worker.worker : DEBUG : Step 163927, finished rewards 2.46, envs finished 1
2026-01-17 13:36:22,990 : worker.worker : DEBUG : Step 163929, finished rewards 20.01, envs finished 1
2026-01-17 13:36:23,007 : worker.worker : DEBUG : Step 163931, finished rewards -11.99, envs finished 1
2026-01-17 13:36:23,097 : agent.on_policy : DEBUG : Mean Losses: [4.509969934821129]
2026-01-17 13:36:23,100 : worker.worker : DEBUG : Step 163936, finished rewards 27.45, envs finished 1
2026-01-17 13:36:23,149 : worker.worker : DEBUG : Step 163948, finished rewards 17.07, envs finished 1
2026-01-17 13:36:23,261 : worker.worker : DEBUG : Step 163960, finished rewards 17.13, envs finished 1
2026-01-17 13:36:23,445 : agent.on_policy : DEBUG : Mean Losses: [2.3752274457365274]
2026-01-17 13:36:23,580 : worker.worker : DEBUG : Step 163982, finished rewards 32.54, envs finished 1
2026-01-17 13:36:22,894 : worker.worker : DEBUG : Step 163988, finished rewards 2.54, envs finished 1
2026-01-17 13:36:22,969 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:36:23,095 : agent.on_policy : DEBUG : Mean Losses: [2.999306909739971]
2026-01-17 13:36:23,432 : agent.on_policy : DEBUG : Mean Losses: [2.541424985975027]
2026-01-17 13:36:23,446 : worker.worker : DEBUG : Step 164035, finished rewards 15.05, envs finished 1
2026-01-17 13:36:23,453 : worker.worker : DEBUG : Step 164036, finished rewards 20.10, envs finished 1
2026-01-17 13:36:23,462 : worker.worker : DEBUG : Step 164037, finished rewards 17.04, envs finished 1
2026-01-17 13:36:23,505 : worker.worker : DEBUG : Step 164045, finished rewards 10.22, envs finished 1
2026-01-17 13:36:23,542 : worker.worker : DEBUG : Step 164053, finished rewards 23.56, envs finished 1
2026-01-17 13:36:23,573 : worker.worker : DEBUG : Step 164060, finished rewards 39.96, envs finished 1
2026-01-17 13:36:23,649 : agent.on_policy : DEBUG : Mean Losses: [7.3191273510456085]
2026-01-17 13:36:23,660 : worker.worker : DEBUG : Step 164066, finished rewards 5.32, envs finished 1
2026-01-17 13:36:23,871 : agent.on_policy : DEBUG : Mean Losses: [2.26691897213459]
2026-01-17 13:36:23,912 : worker.worker : DEBUG : Step 164106, finished rewards 41.77, envs finished 1
2026-01-17 13:36:23,918 : worker.worker : DEBUG : Step 164107, finished rewards 42.64, envs finished 1
2026-01-17 13:36:23,937 : worker.worker : DEBUG : Step 164109, finished rewards -3.01, envs finished 1
2026-01-17 13:36:24,013 : worker.worker : DEBUG : Step 164124, finished rewards 41.40, envs finished 1
2026-01-17 13:36:24,163 : agent.on_policy : DEBUG : Mean Losses: [6.540812849998474]
2026-01-17 13:36:24,175 : worker.worker : DEBUG : Step 164130, finished rewards 45.97, envs finished 1
2026-01-17 13:36:24,396 : agent.on_policy : DEBUG : Mean Losses: [2.880750228650868]
2026-01-17 13:36:24,429 : worker.worker : DEBUG : Step 164170, finished rewards 10.84, envs finished 1
2026-01-17 13:36:24,458 : worker.worker : DEBUG : Step 164176, finished rewards 8.05, envs finished 1
2026-01-17 13:36:24,468 : worker.worker : DEBUG : Step 164177, finished rewards 40.89, envs finished 1
2026-01-17 13:36:24,499 : worker.worker : DEBUG : Step 164182, finished rewards -17.47, envs finished 1
2026-01-17 13:36:24,584 : agent.on_policy : DEBUG : Mean Losses: [5.83335766941309]
2026-01-17 13:36:24,652 : worker.worker : DEBUG : Step 164207, finished rewards 21.62, envs finished 1
2026-01-17 13:36:24,729 : worker.worker : DEBUG : Step 164213, finished rewards 31.94, envs finished 1
2026-01-17 13:36:24,991 : agent.on_policy : DEBUG : Mean Losses: [4.104144170880318]
2026-01-17 13:36:25,036 : worker.worker : DEBUG : Step 164230, finished rewards 16.44, envs finished 1
2026-01-17 13:36:25,104 : worker.worker : DEBUG : Step 164240, finished rewards 46.04, envs finished 1
2026-01-17 13:36:25,154 : worker.worker : DEBUG : Step 164248, finished rewards 42.48, envs finished 1
2026-01-17 13:36:25,289 : agent.on_policy : DEBUG : Mean Losses: [6.641110852360725]
2026-01-17 13:36:25,637 : agent.on_policy : DEBUG : Mean Losses: [3.31205602735281]
2026-01-17 13:36:25,676 : worker.worker : DEBUG : Step 164298, finished rewards 31.21, envs finished 1
2026-01-17 13:36:25,684 : worker.worker : DEBUG : Step 164299, finished rewards 11.32, envs finished 1
2026-01-17 13:36:25,702 : worker.worker : DEBUG : Step 164302, finished rewards 22.42, envs finished 1
2026-01-17 13:36:25,717 : worker.worker : DEBUG : Step 164304, finished rewards 2.48, envs finished 1
2026-01-17 13:36:25,730 : worker.worker : DEBUG : Step 164306, finished rewards -29.52, envs finished 1
2026-01-17 13:36:25,764 : worker.worker : DEBUG : Step 164312, finished rewards 39.92, envs finished 1
2026-01-17 13:36:25,849 : agent.on_policy : DEBUG : Mean Losses: [9.254693269729614]
2026-01-17 13:36:25,892 : worker.worker : DEBUG : Step 164330, finished rewards 19.61, envs finished 1
2026-01-17 13:36:26,093 : worker.worker : DEBUG : Step 164350, finished rewards 17.43, envs finished 1
2026-01-17 13:36:26,278 : agent.on_policy : DEBUG : Mean Losses: [3.2664858140051365]
2026-01-17 13:36:26,379 : worker.worker : DEBUG : Step 164370, finished rewards 45.95, envs finished 1
2026-01-17 13:36:26,556 : agent.on_policy : DEBUG : Mean Losses: [5.161561585962772]
2026-01-17 13:36:26,559 : worker.worker : DEBUG : Step 164384, finished rewards 29.38, envs finished 1
2026-01-17 13:36:26,675 : worker.worker : DEBUG : Step 164401, finished rewards 20.64, envs finished 1
2026-01-17 13:36:26,786 : worker.worker : DEBUG : Step 164410, finished rewards 14.98, envs finished 1
2026-01-17 13:36:26,914 : agent.on_policy : DEBUG : Mean Losses: [5.385127998888493]
2026-01-17 13:36:26,936 : worker.worker : DEBUG : Step 164418, finished rewards 16.75, envs finished 1
2026-01-17 13:36:27,076 : worker.worker : DEBUG : Step 164433, finished rewards 31.97, envs finished 1
2026-01-17 13:36:27,099 : worker.worker : DEBUG : Step 164436, finished rewards 21.29, envs finished 1
2026-01-17 13:36:27,271 : agent.on_policy : DEBUG : Mean Losses: [4.358921907842159]
2026-01-17 13:36:27,305 : worker.worker : DEBUG : Step 164454, finished rewards -0.03, envs finished 1
2026-01-17 13:36:27,457 : worker.worker : DEBUG : Step 164473, finished rewards 16.17, envs finished 1
2026-01-17 13:36:27,610 : agent.on_policy : DEBUG : Mean Losses: [4.071709588170052]
2026-01-17 13:36:27,687 : worker.worker : DEBUG : Step 164493, finished rewards 11.81, envs finished 1
2026-01-17 13:36:27,764 : worker.worker : DEBUG : Step 164496, finished rewards 22.13, envs finished 1
2026-01-17 13:36:27,779 : worker.worker : DEBUG : Step 164498, finished rewards 27.54, envs finished 1
2026-01-17 13:36:27,906 : worker.worker : DEBUG : Step 164507, finished rewards 40.89, envs finished 1
2026-01-17 13:36:28,002 : agent.on_policy : DEBUG : Mean Losses: [6.503314983099699]
2026-01-17 13:36:28,322 : agent.on_policy : DEBUG : Mean Losses: [2.3496944718062878]
2026-01-17 13:36:28,329 : worker.worker : DEBUG : Step 164545, finished rewards 0.55, envs finished 1
2026-01-17 13:36:28,403 : worker.worker : DEBUG : Step 164561, finished rewards 46.37, envs finished 1
2026-01-17 13:36:28,425 : worker.worker : DEBUG : Step 164566, finished rewards 7.29, envs finished 2
2026-01-17 13:36:28,438 : worker.worker : DEBUG : Step 164568, finished rewards 22.92, envs finished 1
2026-01-17 13:36:28,603 : agent.on_policy : DEBUG : Mean Losses: [9.282179698348045]
2026-01-17 13:36:28,714 : worker.worker : DEBUG : Step 164589, finished rewards 23.18, envs finished 1
2026-01-17 13:36:28,920 : agent.on_policy : DEBUG : Mean Losses: [2.365617837756872]
2026-01-17 13:36:29,026 : worker.worker : DEBUG : Step 164618, finished rewards 14.87, envs finished 1
2026-01-17 13:36:29,146 : worker.worker : DEBUG : Step 164630, finished rewards 29.16, envs finished 1
2026-01-17 13:36:29,208 : worker.worker : DEBUG : Step 164639, finished rewards 33.73, envs finished 1
2026-01-17 13:36:29,429 : agent.on_policy : DEBUG : Mean Losses: [5.11266852542758]
2026-01-17 13:36:29,610 : worker.worker : DEBUG : Step 164658, finished rewards -5.54, envs finished 1
2026-01-17 13:36:29,635 : worker.worker : DEBUG : Step 164659, finished rewards 23.20, envs finished 1
2026-01-17 13:36:29,938 : agent.on_policy : DEBUG : Mean Losses: [4.623247996903956]
2026-01-17 13:36:29,955 : worker.worker : DEBUG : Step 164675, finished rewards 13.04, envs finished 1
2026-01-17 13:36:30,149 : worker.worker : DEBUG : Step 164700, finished rewards 11.82, envs finished 1
2026-01-17 13:36:30,341 : agent.on_policy : DEBUG : Mean Losses: [3.008278526365757]
2026-01-17 13:36:30,426 : worker.worker : DEBUG : Step 164712, finished rewards 23.01, envs finished 1
2026-01-17 13:36:30,464 : worker.worker : DEBUG : Step 164721, finished rewards -17.68, envs finished 1
2026-01-17 13:36:30,542 : worker.worker : DEBUG : Step 164731, finished rewards 25.64, envs finished 1
2026-01-17 13:36:30,857 : agent.on_policy : DEBUG : Mean Losses: [5.532912213355303]
2026-01-17 13:36:30,868 : worker.worker : DEBUG : Step 164737, finished rewards 36.40, envs finished 1
2026-01-17 13:36:30,894 : worker.worker : DEBUG : Step 164740, finished rewards 9.66, envs finished 1
2026-01-17 13:36:30,934 : worker.worker : DEBUG : Step 164746, finished rewards 42.48, envs finished 1
2026-01-17 13:36:31,010 : worker.worker : DEBUG : Step 164761, finished rewards 18.90, envs finished 1
2026-01-17 13:36:31,328 : agent.on_policy : DEBUG : Mean Losses: [3.363683946430683]
2026-01-17 13:36:31,483 : worker.worker : DEBUG : Step 164782, finished rewards 43.22, envs finished 1
2026-01-17 13:36:31,544 : worker.worker : DEBUG : Step 164784, finished rewards 46.43, envs finished 1
2026-01-17 13:36:31,706 : worker.worker : DEBUG : Step 164794, finished rewards 46.63, envs finished 1
2026-01-17 13:36:31,975 : agent.on_policy : DEBUG : Mean Losses: [6.742115505039692]
2026-01-17 13:36:32,583 : agent.on_policy : DEBUG : Mean Losses: [1.8365085646510124]
2026-01-17 13:36:32,874 : worker.worker : DEBUG : Step 164859, finished rewards 9.88, envs finished 2
2026-01-17 13:36:32,981 : agent.on_policy : DEBUG : Mean Losses: [5.534494787454605]
2026-01-17 13:36:32,995 : worker.worker : DEBUG : Step 164865, finished rewards -30.12, envs finished 1
2026-01-17 13:36:33,078 : worker.worker : DEBUG : Step 164870, finished rewards -4.13, envs finished 1
2026-01-17 13:36:33,189 : worker.worker : DEBUG : Step 164875, finished rewards 26.05, envs finished 1
2026-01-17 13:36:33,244 : worker.worker : DEBUG : Step 164880, finished rewards 28.98, envs finished 1
2026-01-17 13:36:33,357 : worker.worker : DEBUG : Step 164887, finished rewards 25.55, envs finished 1
2026-01-17 13:36:33,623 : agent.on_policy : DEBUG : Mean Losses: [5.109946659766138]
2026-01-17 13:36:33,720 : worker.worker : DEBUG : Step 164908, finished rewards -14.12, envs finished 1
2026-01-17 13:36:34,154 : agent.on_policy : DEBUG : Mean Losses: [1.2970308475196362]
2026-01-17 13:36:34,455 : worker.worker : DEBUG : Step 164955, finished rewards 21.90, envs finished 2
2026-01-17 13:36:34,658 : agent.on_policy : DEBUG : Mean Losses: [4.078380934894085]
2026-01-17 13:36:34,825 : worker.worker : DEBUG : Step 164974, finished rewards 19.00, envs finished 1
2026-01-17 13:36:34,895 : worker.worker : DEBUG : Step 164978, finished rewards 25.01, envs finished 1
2026-01-17 13:36:35,225 : agent.on_policy : DEBUG : Mean Losses: [4.980478764511645]
2026-01-17 13:36:35,271 : worker.worker : DEBUG : Step 164995, finished rewards 7.42, envs finished 1
2026-01-17 13:36:35,305 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:36:35,393 : worker.worker : INFO : Step 165000, Avg Reward 20.5223, Max Reward 79.3049, Loss [4.65836955]
2026-01-17 13:36:35,450 : worker.worker : DEBUG : Step 165007, finished rewards 2.69, envs finished 1
2026-01-17 13:36:35,515 : worker.worker : DEBUG : Step 165016, finished rewards 12.18, envs finished 1
2026-01-17 13:36:35,827 : agent.on_policy : DEBUG : Mean Losses: [5.24904865026474]
2026-01-17 13:36:35,847 : worker.worker : DEBUG : Step 165025, finished rewards 22.51, envs finished 2
2026-01-17 13:36:36,347 : agent.on_policy : DEBUG : Mean Losses: [2.326174633577466]
2026-01-17 13:36:36,383 : worker.worker : DEBUG : Step 165062, finished rewards 27.03, envs finished 1
2026-01-17 13:36:36,433 : worker.worker : DEBUG : Step 165067, finished rewards 39.76, envs finished 1
2026-01-17 13:36:36,497 : worker.worker : DEBUG : Step 165072, finished rewards 22.58, envs finished 1
2026-01-17 13:36:36,531 : worker.worker : DEBUG : Step 165075, finished rewards 4.25, envs finished 1
2026-01-17 13:36:36,909 : agent.on_policy : DEBUG : Mean Losses: [7.14689589291811]
2026-01-17 13:36:36,989 : worker.worker : DEBUG : Step 165104, finished rewards 26.43, envs finished 1
2026-01-17 13:36:37,196 : agent.on_policy : DEBUG : Mean Losses: [3.6015674620866776]
2026-01-17 13:36:37,372 : worker.worker : DEBUG : Step 165129, finished rewards 16.94, envs finished 1
2026-01-17 13:36:37,412 : worker.worker : DEBUG : Step 165131, finished rewards 17.44, envs finished 1
2026-01-17 13:36:37,695 : agent.on_policy : DEBUG : Mean Losses: [4.788682088255882]
2026-01-17 13:36:37,740 : worker.worker : DEBUG : Step 165158, finished rewards 28.74, envs finished 1
2026-01-17 13:36:37,764 : worker.worker : DEBUG : Step 165161, finished rewards 26.54, envs finished 2
2026-01-17 13:36:37,791 : worker.worker : DEBUG : Step 165164, finished rewards 18.41, envs finished 1
2026-01-17 13:36:37,930 : worker.worker : DEBUG : Step 165183, finished rewards 13.75, envs finished 1
2026-01-17 13:36:38,131 : agent.on_policy : DEBUG : Mean Losses: [5.5856434144079685]
2026-01-17 13:36:38,199 : worker.worker : DEBUG : Step 165190, finished rewards 28.38, envs finished 1
2026-01-17 13:36:38,470 : worker.worker : DEBUG : Step 165208, finished rewards 33.57, envs finished 1
2026-01-17 13:36:38,763 : agent.on_policy : DEBUG : Mean Losses: [3.8703140914440155]
2026-01-17 13:36:38,827 : worker.worker : DEBUG : Step 165226, finished rewards 24.39, envs finished 1
2026-01-17 13:36:38,864 : worker.worker : DEBUG : Step 165231, finished rewards 42.81, envs finished 1
2026-01-17 13:36:38,951 : worker.worker : DEBUG : Step 165240, finished rewards 32.55, envs finished 1
2026-01-17 13:36:39,221 : agent.on_policy : DEBUG : Mean Losses: [5.517059937119484]
2026-01-17 13:36:39,362 : worker.worker : DEBUG : Step 165267, finished rewards 16.59, envs finished 1
2026-01-17 13:36:39,754 : agent.on_policy : DEBUG : Mean Losses: [2.605508878827095]
2026-01-17 13:36:40,069 : worker.worker : DEBUG : Step 165303, finished rewards 7.23, envs finished 1
2026-01-17 13:36:40,361 : agent.on_policy : DEBUG : Mean Losses: [5.714951783418655]
2026-01-17 13:36:40,407 : worker.worker : DEBUG : Step 165315, finished rewards 27.10, envs finished 1
2026-01-17 13:36:40,425 : worker.worker : DEBUG : Step 165316, finished rewards 15.87, envs finished 1
2026-01-17 13:36:40,445 : worker.worker : DEBUG : Step 165317, finished rewards 34.88, envs finished 1
2026-01-17 13:36:40,468 : worker.worker : DEBUG : Step 165318, finished rewards 2.40, envs finished 1
2026-01-17 13:36:40,739 : worker.worker : DEBUG : Step 165342, finished rewards -38.38, envs finished 1
2026-01-17 13:36:40,929 : agent.on_policy : DEBUG : Mean Losses: [5.327066944912076]
2026-01-17 13:36:41,162 : worker.worker : DEBUG : Step 165370, finished rewards 17.58, envs finished 1
2026-01-17 13:36:41,319 : agent.on_policy : DEBUG : Mean Losses: [1.9659563153982162]
2026-01-17 13:36:41,421 : worker.worker : DEBUG : Step 165386, finished rewards 32.00, envs finished 1
2026-01-17 13:36:41,457 : worker.worker : DEBUG : Step 165389, finished rewards 42.45, envs finished 1
2026-01-17 13:36:41,512 : worker.worker : DEBUG : Step 165397, finished rewards 34.06, envs finished 1
2026-01-17 13:36:41,683 : agent.on_policy : DEBUG : Mean Losses: [7.5044015645980835]
2026-01-17 13:36:41,816 : worker.worker : DEBUG : Step 165421, finished rewards 17.43, envs finished 1
2026-01-17 13:36:41,844 : worker.worker : DEBUG : Step 165424, finished rewards 16.35, envs finished 1
2026-01-17 13:36:42,086 : worker.worker : DEBUG : Step 165438, finished rewards 22.20, envs finished 1
2026-01-17 13:36:42,307 : agent.on_policy : DEBUG : Mean Losses: [6.6391424760222435]
2026-01-17 13:36:42,481 : worker.worker : DEBUG : Step 165456, finished rewards 42.94, envs finished 1
2026-01-17 13:36:42,667 : worker.worker : DEBUG : Step 165468, finished rewards 41.06, envs finished 1
2026-01-17 13:36:42,715 : worker.worker : DEBUG : Step 165471, finished rewards -32.31, envs finished 1
2026-01-17 13:36:43,043 : agent.on_policy : DEBUG : Mean Losses: [6.547500805929303]
2026-01-17 13:36:43,096 : worker.worker : DEBUG : Step 165480, finished rewards 25.11, envs finished 1
2026-01-17 13:36:43,231 : worker.worker : DEBUG : Step 165502, finished rewards 46.12, envs finished 1
2026-01-17 13:36:43,395 : agent.on_policy : DEBUG : Mean Losses: [5.691292725503445]
2026-01-17 13:36:43,492 : worker.worker : DEBUG : Step 165517, finished rewards 0.38, envs finished 1
2026-01-17 13:36:43,554 : worker.worker : DEBUG : Step 165525, finished rewards 41.84, envs finished 1
2026-01-17 13:36:43,899 : agent.on_policy : DEBUG : Mean Losses: [5.545888174325228]
2026-01-17 13:36:44,004 : worker.worker : DEBUG : Step 165554, finished rewards 39.12, envs finished 1
2026-01-17 13:36:44,045 : worker.worker : DEBUG : Step 165559, finished rewards 27.57, envs finished 1
2026-01-17 13:36:44,267 : agent.on_policy : DEBUG : Mean Losses: [6.167945474386215]
2026-01-17 13:36:44,299 : worker.worker : DEBUG : Step 165573, finished rewards 8.83, envs finished 1
2026-01-17 13:36:44,452 : worker.worker : DEBUG : Step 165587, finished rewards -10.50, envs finished 1
2026-01-17 13:36:44,585 : worker.worker : DEBUG : Step 165595, finished rewards 36.58, envs finished 1
2026-01-17 13:36:44,846 : agent.on_policy : DEBUG : Mean Losses: [6.077605199068785]
2026-01-17 13:36:44,857 : worker.worker : DEBUG : Step 165601, finished rewards 2.80, envs finished 1
2026-01-17 13:36:45,119 : worker.worker : DEBUG : Step 165625, finished rewards 2.06, envs finished 1
2026-01-17 13:36:45,537 : agent.on_policy : DEBUG : Mean Losses: [4.761533198878169]
2026-01-17 13:36:45,677 : worker.worker : DEBUG : Step 165644, finished rewards 42.31, envs finished 1
2026-01-17 13:36:45,900 : worker.worker : DEBUG : Step 165657, finished rewards 41.49, envs finished 1
2026-01-17 13:36:46,044 : worker.worker : DEBUG : Step 165661, finished rewards 15.79, envs finished 1
2026-01-17 13:36:46,382 : agent.on_policy : DEBUG : Mean Losses: [7.077854804694653]
2026-01-17 13:36:46,682 : worker.worker : DEBUG : Step 165680, finished rewards -26.37, envs finished 1
2026-01-17 13:36:46,844 : worker.worker : DEBUG : Step 165687, finished rewards 28.32, envs finished 1
2026-01-17 13:36:47,484 : agent.on_policy : DEBUG : Mean Losses: [5.262276278808713]
2026-01-17 13:36:47,612 : worker.worker : DEBUG : Step 165704, finished rewards 14.81, envs finished 1
2026-01-17 13:36:47,831 : worker.worker : DEBUG : Step 165714, finished rewards 41.98, envs finished 1
2026-01-17 13:36:48,003 : worker.worker : DEBUG : Step 165718, finished rewards -10.61, envs finished 1
2026-01-17 13:36:48,203 : worker.worker : DEBUG : Step 165726, finished rewards 19.67, envs finished 1
2026-01-17 13:36:48,968 : agent.on_policy : DEBUG : Mean Losses: [4.771193386986852]
2026-01-17 13:36:49,041 : worker.worker : DEBUG : Step 165735, finished rewards 33.90, envs finished 1
2026-01-17 13:36:49,541 : agent.on_policy : DEBUG : Mean Losses: [2.2661967668682337]
2026-01-17 13:36:49,715 : worker.worker : DEBUG : Step 165774, finished rewards 23.80, envs finished 1
2026-01-17 13:36:50,043 : worker.worker : DEBUG : Step 165786, finished rewards 32.66, envs finished 1
2026-01-17 13:36:50,071 : worker.worker : DEBUG : Step 165787, finished rewards 27.84, envs finished 2
2026-01-17 13:36:50,800 : agent.on_policy : DEBUG : Mean Losses: [7.26480158418417]
2026-01-17 13:36:50,859 : worker.worker : DEBUG : Step 165797, finished rewards 41.79, envs finished 1
2026-01-17 13:36:51,038 : worker.worker : DEBUG : Step 165810, finished rewards 10.21, envs finished 1
2026-01-17 13:36:51,058 : worker.worker : DEBUG : Step 165811, finished rewards 21.28, envs finished 1
2026-01-17 13:36:51,500 : agent.on_policy : DEBUG : Mean Losses: [4.727616421878338]
2026-01-17 13:36:51,576 : worker.worker : DEBUG : Step 165828, finished rewards 24.69, envs finished 1
2026-01-17 13:36:52,263 : agent.on_policy : DEBUG : Mean Losses: [2.007136542350054]
2026-01-17 13:36:52,320 : worker.worker : DEBUG : Step 165861, finished rewards 27.72, envs finished 1
2026-01-17 13:36:52,552 : worker.worker : DEBUG : Step 165879, finished rewards 24.49, envs finished 1
2026-01-17 13:36:52,589 : worker.worker : DEBUG : Step 165881, finished rewards 21.53, envs finished 1
2026-01-17 13:36:52,802 : agent.on_policy : DEBUG : Mean Losses: [6.0073987022042274]
2026-01-17 13:36:52,812 : worker.worker : DEBUG : Step 165889, finished rewards 18.70, envs finished 1
2026-01-17 13:36:52,831 : worker.worker : DEBUG : Step 165891, finished rewards 35.03, envs finished 1
2026-01-17 13:36:52,524 : worker.worker : DEBUG : Step 165897, finished rewards 21.91, envs finished 1
2026-01-17 13:36:52,515 : agent.on_policy : DEBUG : Mean Losses: [3.3826605854555964]
2026-01-17 13:36:52,692 : worker.worker : DEBUG : Step 165941, finished rewards 10.40, envs finished 1
2026-01-17 13:36:52,766 : worker.worker : DEBUG : Step 165945, finished rewards 45.87, envs finished 1
2026-01-17 13:36:52,811 : worker.worker : DEBUG : Step 165946, finished rewards -5.93, envs finished 1
2026-01-17 13:36:53,278 : agent.on_policy : DEBUG : Mean Losses: [5.688577821478248]
2026-01-17 13:36:53,304 : worker.worker : DEBUG : Step 165954, finished rewards 24.20, envs finished 1
2026-01-17 13:36:53,796 : agent.on_policy : DEBUG : Mean Losses: [2.8374441023916006]
2026-01-17 13:36:53,842 : worker.worker : DEBUG : Step 165989, finished rewards 25.92, envs finished 1
2026-01-17 13:36:53,914 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:36:54,114 : worker.worker : DEBUG : Step 166011, finished rewards 26.45, envs finished 2
2026-01-17 13:36:54,341 : agent.on_policy : DEBUG : Mean Losses: [5.807104021310806]
2026-01-17 13:36:54,363 : worker.worker : DEBUG : Step 166017, finished rewards 46.41, envs finished 1
2026-01-17 13:36:54,438 : worker.worker : DEBUG : Step 166025, finished rewards -7.59, envs finished 1
2026-01-17 13:36:54,470 : worker.worker : DEBUG : Step 166029, finished rewards -5.98, envs finished 1
2026-01-17 13:36:54,839 : agent.on_policy : DEBUG : Mean Losses: [3.5880957320332527]
2026-01-17 13:36:55,072 : worker.worker : DEBUG : Step 166069, finished rewards 2.15, envs finished 1
2026-01-17 13:36:55,141 : worker.worker : DEBUG : Step 166077, finished rewards 27.28, envs finished 1
2026-01-17 13:36:55,275 : agent.on_policy : DEBUG : Mean Losses: [4.412133201956749]
2026-01-17 13:36:55,389 : worker.worker : DEBUG : Step 166087, finished rewards 43.02, envs finished 1
2026-01-17 13:36:55,418 : worker.worker : DEBUG : Step 166089, finished rewards 45.80, envs finished 1
2026-01-17 13:36:55,534 : worker.worker : DEBUG : Step 166100, finished rewards 41.85, envs finished 1
2026-01-17 13:36:55,929 : agent.on_policy : DEBUG : Mean Losses: [5.582623891532421]
2026-01-17 13:36:56,039 : worker.worker : DEBUG : Step 166118, finished rewards 13.70, envs finished 1
2026-01-17 13:36:56,129 : worker.worker : DEBUG : Step 166123, finished rewards 11.46, envs finished 1
2026-01-17 13:36:56,603 : agent.on_policy : DEBUG : Mean Losses: [3.151539981365204]
2026-01-17 13:36:56,658 : worker.worker : DEBUG : Step 166153, finished rewards 36.35, envs finished 1
2026-01-17 13:36:56,745 : worker.worker : DEBUG : Step 166166, finished rewards -15.02, envs finished 1
2026-01-17 13:36:57,057 : agent.on_policy : DEBUG : Mean Losses: [4.273401901125908]
2026-01-17 13:36:57,097 : worker.worker : DEBUG : Step 166178, finished rewards 35.09, envs finished 1
2026-01-17 13:36:57,277 : worker.worker : DEBUG : Step 166196, finished rewards 12.04, envs finished 1
2026-01-17 13:36:57,363 : worker.worker : DEBUG : Step 166204, finished rewards 7.10, envs finished 1
2026-01-17 13:36:57,614 : agent.on_policy : DEBUG : Mean Losses: [4.61952268704772]
2026-01-17 13:36:57,639 : worker.worker : DEBUG : Step 166210, finished rewards 13.71, envs finished 2
2026-01-17 13:36:57,665 : worker.worker : DEBUG : Step 166211, finished rewards 23.71, envs finished 1
2026-01-17 13:36:58,069 : agent.on_policy : DEBUG : Mean Losses: [2.7514986814931035]
2026-01-17 13:36:58,120 : worker.worker : DEBUG : Step 166249, finished rewards 40.77, envs finished 1
2026-01-17 13:36:58,267 : worker.worker : DEBUG : Step 166267, finished rewards 41.07, envs finished 1
2026-01-17 13:36:58,472 : agent.on_policy : DEBUG : Mean Losses: [6.771950297057629]
2026-01-17 13:36:58,476 : worker.worker : DEBUG : Step 166272, finished rewards 15.33, envs finished 1
2026-01-17 13:36:58,650 : worker.worker : DEBUG : Step 166291, finished rewards 33.68, envs finished 1
2026-01-17 13:36:58,657 : worker.worker : DEBUG : Step 166292, finished rewards -5.61, envs finished 1
2026-01-17 13:36:58,708 : worker.worker : DEBUG : Step 166297, finished rewards 28.02, envs finished 1
2026-01-17 13:36:58,754 : worker.worker : DEBUG : Step 166303, finished rewards 23.65, envs finished 1
2026-01-17 13:36:58,910 : agent.on_policy : DEBUG : Mean Losses: [6.119195744395256]
2026-01-17 13:36:59,119 : worker.worker : DEBUG : Step 166323, finished rewards 3.90, envs finished 1
2026-01-17 13:36:59,207 : worker.worker : DEBUG : Step 166331, finished rewards 46.04, envs finished 1
2026-01-17 13:36:59,376 : agent.on_policy : DEBUG : Mean Losses: [4.379529409110546]
2026-01-17 13:36:59,437 : worker.worker : DEBUG : Step 166339, finished rewards 27.02, envs finished 1
2026-01-17 13:36:59,486 : worker.worker : DEBUG : Step 166342, finished rewards 42.53, envs finished 1
2026-01-17 13:36:59,676 : worker.worker : DEBUG : Step 166355, finished rewards 46.16, envs finished 1
2026-01-17 13:36:59,834 : worker.worker : DEBUG : Step 166364, finished rewards 41.45, envs finished 1
2026-01-17 13:37:00,065 : agent.on_policy : DEBUG : Mean Losses: [5.631988286972046]
2026-01-17 13:37:00,376 : agent.on_policy : DEBUG : Mean Losses: [4.42194989323616]
2026-01-17 13:37:00,436 : worker.worker : DEBUG : Step 166409, finished rewards 31.13, envs finished 2
2026-01-17 13:37:00,456 : worker.worker : DEBUG : Step 166411, finished rewards 41.16, envs finished 1
2026-01-17 13:37:00,474 : worker.worker : DEBUG : Step 166412, finished rewards 42.56, envs finished 1
2026-01-17 13:37:00,880 : agent.on_policy : DEBUG : Mean Losses: [7.462368845939636]
2026-01-17 13:37:01,053 : worker.worker : DEBUG : Step 166446, finished rewards -13.57, envs finished 1
2026-01-17 13:37:01,168 : worker.worker : DEBUG : Step 166451, finished rewards 29.54, envs finished 1
2026-01-17 13:37:01,185 : worker.worker : DEBUG : Step 166452, finished rewards -16.31, envs finished 1
2026-01-17 13:37:01,571 : agent.on_policy : DEBUG : Mean Losses: [6.047763429582119]
2026-01-17 13:37:01,780 : worker.worker : DEBUG : Step 166479, finished rewards 8.19, envs finished 1
2026-01-17 13:37:02,050 : agent.on_policy : DEBUG : Mean Losses: [3.777451604604721]
2026-01-17 13:37:02,069 : worker.worker : DEBUG : Step 166499, finished rewards 26.36, envs finished 1
2026-01-17 13:37:02,138 : worker.worker : DEBUG : Step 166514, finished rewards 19.58, envs finished 1
2026-01-17 13:37:02,378 : agent.on_policy : DEBUG : Mean Losses: [3.9067806527018547]
2026-01-17 13:37:02,481 : worker.worker : DEBUG : Step 166544, finished rewards 24.13, envs finished 1
2026-01-17 13:37:02,489 : worker.worker : DEBUG : Step 166545, finished rewards -6.89, envs finished 1
2026-01-17 13:37:02,516 : worker.worker : DEBUG : Step 166548, finished rewards 20.35, envs finished 2
2026-01-17 13:37:02,738 : agent.on_policy : DEBUG : Mean Losses: [5.22136514633894]
2026-01-17 13:37:02,757 : worker.worker : DEBUG : Step 166563, finished rewards -19.62, envs finished 1
2026-01-17 13:37:02,802 : worker.worker : DEBUG : Step 166571, finished rewards 41.36, envs finished 1
2026-01-17 13:37:02,816 : worker.worker : DEBUG : Step 166573, finished rewards 21.64, envs finished 1
2026-01-17 13:37:03,054 : agent.on_policy : DEBUG : Mean Losses: [2.959305051714182]
2026-01-17 13:37:03,254 : worker.worker : DEBUG : Step 166617, finished rewards 22.49, envs finished 1
2026-01-17 13:37:03,530 : agent.on_policy : DEBUG : Mean Losses: [2.918084405362606]
2026-01-17 13:37:03,631 : worker.worker : DEBUG : Step 166638, finished rewards 24.57, envs finished 1
2026-01-17 13:37:03,655 : worker.worker : DEBUG : Step 166641, finished rewards 33.60, envs finished 1
2026-01-17 13:37:03,908 : agent.on_policy : DEBUG : Mean Losses: [6.679568946361542]
2026-01-17 13:37:03,910 : worker.worker : DEBUG : Step 166656, finished rewards 13.86, envs finished 1
2026-01-17 13:37:03,953 : worker.worker : DEBUG : Step 166665, finished rewards 24.39, envs finished 1
2026-01-17 13:37:03,977 : worker.worker : DEBUG : Step 166668, finished rewards 5.53, envs finished 1
2026-01-17 13:37:04,027 : worker.worker : DEBUG : Step 166674, finished rewards 18.77, envs finished 1
2026-01-17 13:37:04,253 : agent.on_policy : DEBUG : Mean Losses: [4.2340150233358145]
2026-01-17 13:37:04,284 : worker.worker : DEBUG : Step 166693, finished rewards -4.79, envs finished 1
2026-01-17 13:37:04,675 : agent.on_policy : DEBUG : Mean Losses: [1.9458846729248762]
2026-01-17 13:37:04,866 : worker.worker : DEBUG : Step 166734, finished rewards 23.23, envs finished 1
2026-01-17 13:37:04,951 : worker.worker : DEBUG : Step 166739, finished rewards 31.85, envs finished 1
2026-01-17 13:37:05,018 : worker.worker : DEBUG : Step 166749, finished rewards 33.47, envs finished 1
2026-01-17 13:37:05,157 : agent.on_policy : DEBUG : Mean Losses: [6.629552811384201]
2026-01-17 13:37:05,159 : worker.worker : DEBUG : Step 166752, finished rewards 28.32, envs finished 1
2026-01-17 13:37:05,350 : worker.worker : DEBUG : Step 166768, finished rewards -0.89, envs finished 1
2026-01-17 13:37:05,451 : worker.worker : DEBUG : Step 166775, finished rewards 20.87, envs finished 1
2026-01-17 13:37:05,660 : agent.on_policy : DEBUG : Mean Losses: [2.9996151570230722]
2026-01-17 13:37:05,686 : worker.worker : DEBUG : Step 166789, finished rewards 21.81, envs finished 1
2026-01-17 13:37:06,005 : agent.on_policy : DEBUG : Mean Losses: [2.2746664229780436]
2026-01-17 13:37:06,125 : worker.worker : DEBUG : Step 166844, finished rewards 10.24, envs finished 1
2026-01-17 13:37:06,319 : agent.on_policy : DEBUG : Mean Losses: [3.900959149003029]
2026-01-17 13:37:06,411 : worker.worker : DEBUG : Step 166856, finished rewards 28.12, envs finished 1
2026-01-17 13:37:06,557 : worker.worker : DEBUG : Step 166869, finished rewards 4.97, envs finished 1
2026-01-17 13:37:06,582 : worker.worker : DEBUG : Step 166871, finished rewards 5.06, envs finished 1
2026-01-17 13:37:06,782 : agent.on_policy : DEBUG : Mean Losses: [5.256930291652679]
2026-01-17 13:37:06,784 : worker.worker : DEBUG : Step 166880, finished rewards 14.18, envs finished 1
2026-01-17 13:37:06,797 : worker.worker : DEBUG : Step 166882, finished rewards 24.15, envs finished 1
2026-01-17 13:37:06,939 : worker.worker : DEBUG : Step 166893, finished rewards 7.24, envs finished 1
2026-01-17 13:37:07,223 : agent.on_policy : DEBUG : Mean Losses: [2.111377215012908]
2026-01-17 13:37:07,334 : worker.worker : DEBUG : Step 166924, finished rewards 71.32, envs finished 1
2026-01-17 13:37:07,372 : worker.worker : DEBUG : Step 166927, finished rewards 41.87, envs finished 1
2026-01-17 13:37:07,393 : worker.worker : DEBUG : Step 166928, finished rewards 31.09, envs finished 1
2026-01-17 13:37:07,771 : agent.on_policy : DEBUG : Mean Losses: [5.191164635121822]
2026-01-17 13:37:07,789 : worker.worker : DEBUG : Step 166949, finished rewards 34.37, envs finished 1
2026-01-17 13:37:07,802 : worker.worker : DEBUG : Step 166952, finished rewards 41.49, envs finished 1
2026-01-17 13:37:07,970 : agent.on_policy : DEBUG : Mean Losses: [3.2121430560946465]
2026-01-17 13:37:08,014 : worker.worker : DEBUG : Step 166978, finished rewards 21.84, envs finished 1
2026-01-17 13:37:08,109 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:37:08,117 : worker.worker : DEBUG : Step 167000, finished rewards 11.17, envs finished 1
2026-01-17 13:37:08,151 : worker.worker : DEBUG : Step 167004, finished rewards 35.29, envs finished 1
2026-01-17 13:37:08,313 : agent.on_policy : DEBUG : Mean Losses: [6.032426938414574]
2026-01-17 13:37:08,442 : worker.worker : DEBUG : Step 167022, finished rewards -13.75, envs finished 1
2026-01-17 13:37:08,453 : worker.worker : DEBUG : Step 167024, finished rewards 39.94, envs finished 1
2026-01-17 13:37:08,649 : agent.on_policy : DEBUG : Mean Losses: [4.91951238643378]
2026-01-17 13:37:08,651 : worker.worker : DEBUG : Step 167040, finished rewards 9.77, envs finished 1
2026-01-17 13:37:08,734 : worker.worker : DEBUG : Step 167048, finished rewards 41.52, envs finished 1
2026-01-17 13:37:08,766 : worker.worker : DEBUG : Step 167051, finished rewards 19.94, envs finished 1
2026-01-17 13:37:08,889 : worker.worker : DEBUG : Step 167060, finished rewards -2.53, envs finished 1
2026-01-17 13:37:09,035 : agent.on_policy : DEBUG : Mean Losses: [3.9457034319639206]
2026-01-17 13:37:09,349 : agent.on_policy : DEBUG : Mean Losses: [2.7401986569166183]
2026-01-17 13:37:09,353 : worker.worker : DEBUG : Step 167104, finished rewards 20.02, envs finished 1
2026-01-17 13:37:09,370 : worker.worker : DEBUG : Step 167107, finished rewards 31.93, envs finished 1
2026-01-17 13:37:09,389 : worker.worker : DEBUG : Step 167110, finished rewards 27.03, envs finished 1
2026-01-17 13:37:09,454 : worker.worker : DEBUG : Step 167126, finished rewards -3.44, envs finished 1
2026-01-17 13:37:09,574 : agent.on_policy : DEBUG : Mean Losses: [5.309140237048268]
2026-01-17 13:37:09,644 : worker.worker : DEBUG : Step 167144, finished rewards 17.72, envs finished 1
2026-01-17 13:37:09,878 : worker.worker : DEBUG : Step 167167, finished rewards 20.02, envs finished 1
2026-01-17 13:37:10,048 : agent.on_policy : DEBUG : Mean Losses: [4.288001120090485]
2026-01-17 13:37:10,178 : worker.worker : DEBUG : Step 167186, finished rewards -8.07, envs finished 1
2026-01-17 13:37:10,201 : worker.worker : DEBUG : Step 167189, finished rewards -0.07, envs finished 1
2026-01-17 13:37:10,249 : worker.worker : DEBUG : Step 167192, finished rewards 29.95, envs finished 1
2026-01-17 13:37:10,344 : agent.on_policy : DEBUG : Mean Losses: [5.477085888385773]
2026-01-17 13:37:10,499 : worker.worker : DEBUG : Step 167219, finished rewards 25.41, envs finished 1
2026-01-17 13:37:10,526 : worker.worker : DEBUG : Step 167222, finished rewards 12.99, envs finished 1
2026-01-17 13:37:10,712 : agent.on_policy : DEBUG : Mean Losses: [3.475536063313484]
2026-01-17 13:37:10,729 : worker.worker : DEBUG : Step 167236, finished rewards 3.03, envs finished 1
2026-01-17 13:37:10,780 : worker.worker : DEBUG : Step 167246, finished rewards 35.83, envs finished 1
2026-01-17 13:37:10,830 : worker.worker : DEBUG : Step 167257, finished rewards 10.42, envs finished 1
2026-01-17 13:37:10,994 : agent.on_policy : DEBUG : Mean Losses: [4.1200199676677585]
2026-01-17 13:37:11,040 : worker.worker : DEBUG : Step 167276, finished rewards 25.67, envs finished 1
2026-01-17 13:37:11,144 : worker.worker : DEBUG : Step 167285, finished rewards 32.61, envs finished 1
2026-01-17 13:37:11,151 : worker.worker : DEBUG : Step 167286, finished rewards 46.06, envs finished 1
2026-01-17 13:37:11,198 : worker.worker : DEBUG : Step 167291, finished rewards 17.61, envs finished 1
2026-01-17 13:37:11,332 : agent.on_policy : DEBUG : Mean Losses: [5.247087128460407]
2026-01-17 13:37:11,489 : worker.worker : DEBUG : Step 167312, finished rewards 24.34, envs finished 1
2026-01-17 13:37:11,598 : agent.on_policy : DEBUG : Mean Losses: [2.2397310063242912]
2026-01-17 13:37:11,625 : worker.worker : DEBUG : Step 167333, finished rewards 22.22, envs finished 1
2026-01-17 13:37:11,682 : worker.worker : DEBUG : Step 167337, finished rewards 25.62, envs finished 1
2026-01-17 13:37:11,720 : worker.worker : DEBUG : Step 167341, finished rewards 31.93, envs finished 1
2026-01-17 13:37:11,862 : worker.worker : DEBUG : Step 167359, finished rewards 31.99, envs finished 1
2026-01-17 13:37:11,965 : agent.on_policy : DEBUG : Mean Losses: [4.826544888317585]
2026-01-17 13:37:12,102 : worker.worker : DEBUG : Step 167375, finished rewards 46.79, envs finished 1
2026-01-17 13:37:12,145 : worker.worker : DEBUG : Step 167381, finished rewards 22.35, envs finished 1
2026-01-17 13:37:12,174 : worker.worker : DEBUG : Step 167386, finished rewards 23.66, envs finished 1
2026-01-17 13:37:12,320 : agent.on_policy : DEBUG : Mean Losses: [5.487158490344882]
2026-01-17 13:37:12,468 : worker.worker : DEBUG : Step 167403, finished rewards 41.09, envs finished 1
2026-01-17 13:37:12,521 : worker.worker : DEBUG : Step 167407, finished rewards 2.96, envs finished 1
2026-01-17 13:37:12,873 : agent.on_policy : DEBUG : Mean Losses: [3.675877034664154]
2026-01-17 13:37:12,901 : worker.worker : DEBUG : Step 167428, finished rewards 24.56, envs finished 1
2026-01-17 13:37:13,018 : worker.worker : DEBUG : Step 167451, finished rewards 26.62, envs finished 1
2026-01-17 13:37:13,167 : agent.on_policy : DEBUG : Mean Losses: [4.636758282780647]
2026-01-17 13:37:13,243 : worker.worker : DEBUG : Step 167467, finished rewards 37.98, envs finished 2
2026-01-17 13:37:13,303 : worker.worker : DEBUG : Step 167471, finished rewards 22.69, envs finished 1
2026-01-17 13:37:13,324 : worker.worker : DEBUG : Step 167474, finished rewards 27.54, envs finished 1
2026-01-17 13:37:13,336 : worker.worker : DEBUG : Step 167475, finished rewards -7.19, envs finished 1
2026-01-17 13:37:13,571 : agent.on_policy : DEBUG : Mean Losses: [7.975865714251995]
2026-01-17 13:37:13,601 : worker.worker : DEBUG : Step 167494, finished rewards 28.69, envs finished 1
2026-01-17 13:37:13,912 : agent.on_policy : DEBUG : Mean Losses: [2.6168706826865673]
2026-01-17 13:37:13,925 : worker.worker : DEBUG : Step 167522, finished rewards 41.66, envs finished 1
2026-01-17 13:37:14,009 : worker.worker : DEBUG : Step 167536, finished rewards 13.48, envs finished 1
2026-01-17 13:37:14,039 : worker.worker : DEBUG : Step 167542, finished rewards 37.23, envs finished 1
2026-01-17 13:37:14,225 : agent.on_policy : DEBUG : Mean Losses: [5.704875081777573]
2026-01-17 13:37:14,246 : worker.worker : DEBUG : Step 167557, finished rewards 26.30, envs finished 1
2026-01-17 13:37:14,340 : worker.worker : DEBUG : Step 167568, finished rewards 21.55, envs finished 1
2026-01-17 13:37:14,348 : worker.worker : DEBUG : Step 167569, finished rewards 22.20, envs finished 2
2026-01-17 13:37:14,579 : agent.on_policy : DEBUG : Mean Losses: [4.888857960700989]
2026-01-17 13:37:14,595 : worker.worker : DEBUG : Step 167587, finished rewards 23.30, envs finished 1
2026-01-17 13:37:14,681 : worker.worker : DEBUG : Step 167608, finished rewards 31.18, envs finished 1
2026-01-17 13:37:14,849 : agent.on_policy : DEBUG : Mean Losses: [2.965817240998149]
2026-01-17 13:37:14,894 : worker.worker : DEBUG : Step 167624, finished rewards 30.72, envs finished 2
2026-01-17 13:37:15,126 : agent.on_policy : DEBUG : Mean Losses: [4.403357461094856]
2026-01-17 13:37:15,198 : worker.worker : DEBUG : Step 167665, finished rewards 13.70, envs finished 1
2026-01-17 13:37:15,251 : worker.worker : DEBUG : Step 167678, finished rewards 26.37, envs finished 1
2026-01-17 13:37:15,370 : agent.on_policy : DEBUG : Mean Losses: [4.7087010852992535]
2026-01-17 13:37:15,385 : worker.worker : DEBUG : Step 167682, finished rewards 9.68, envs finished 1
2026-01-17 13:37:15,503 : worker.worker : DEBUG : Step 167692, finished rewards 30.09, envs finished 1
2026-01-17 13:37:15,616 : worker.worker : DEBUG : Step 167701, finished rewards 36.79, envs finished 1
2026-01-17 13:37:15,803 : agent.on_policy : DEBUG : Mean Losses: [5.751959502696991]
2026-01-17 13:37:15,822 : worker.worker : DEBUG : Step 167715, finished rewards -11.96, envs finished 1
2026-01-17 13:37:15,943 : worker.worker : DEBUG : Step 167726, finished rewards -23.05, envs finished 1
2026-01-17 13:37:15,985 : worker.worker : DEBUG : Step 167732, finished rewards 15.01, envs finished 1
2026-01-17 13:37:16,184 : agent.on_policy : DEBUG : Mean Losses: [2.769360687583685]
2026-01-17 13:37:16,282 : worker.worker : DEBUG : Step 167765, finished rewards 28.51, envs finished 1
2026-01-17 13:37:16,316 : worker.worker : DEBUG : Step 167773, finished rewards 26.56, envs finished 1
2026-01-17 13:37:16,454 : agent.on_policy : DEBUG : Mean Losses: [4.252359893172979]
2026-01-17 13:37:16,522 : worker.worker : DEBUG : Step 167794, finished rewards 17.92, envs finished 1
2026-01-17 13:37:16,528 : worker.worker : DEBUG : Step 167795, finished rewards 22.33, envs finished 1
2026-01-17 13:37:16,575 : worker.worker : DEBUG : Step 167803, finished rewards 34.66, envs finished 1
2026-01-17 13:37:16,728 : agent.on_policy : DEBUG : Mean Losses: [5.531031917780638]
2026-01-17 13:37:16,758 : worker.worker : DEBUG : Step 167818, finished rewards 17.64, envs finished 1
2026-01-17 13:37:16,867 : agent.on_policy : DEBUG : Mean Losses: [2.056127608753741]
2026-01-17 13:37:17,131 : worker.worker : DEBUG : Step 167864, finished rewards 42.57, envs finished 1
2026-01-17 13:37:17,157 : worker.worker : DEBUG : Step 167867, finished rewards 45.83, envs finished 1
2026-01-17 13:37:17,236 : agent.on_policy : DEBUG : Mean Losses: [7.28005213662982]
2026-01-17 13:37:17,238 : worker.worker : DEBUG : Step 167872, finished rewards -6.82, envs finished 1
2026-01-17 13:37:17,372 : worker.worker : DEBUG : Step 167889, finished rewards 7.29, envs finished 1
2026-01-17 13:37:17,393 : worker.worker : DEBUG : Step 167891, finished rewards 18.18, envs finished 1
2026-01-17 13:37:17,489 : worker.worker : DEBUG : Step 167899, finished rewards 15.75, envs finished 1
2026-01-17 13:37:17,500 : worker.worker : DEBUG : Step 167901, finished rewards -7.18, envs finished 1
2026-01-17 13:37:17,650 : agent.on_policy : DEBUG : Mean Losses: [5.094339042901993]
2026-01-17 13:37:17,807 : worker.worker : DEBUG : Step 167919, finished rewards 19.48, envs finished 1
2026-01-17 13:37:18,032 : agent.on_policy : DEBUG : Mean Losses: [1.3165830802172422]
2026-01-17 13:37:18,102 : worker.worker : DEBUG : Step 167954, finished rewards 27.78, envs finished 1
2026-01-17 13:37:18,108 : worker.worker : DEBUG : Step 167955, finished rewards 45.92, envs finished 1
2026-01-17 13:37:18,133 : worker.worker : DEBUG : Step 167960, finished rewards 41.39, envs finished 1
2026-01-17 13:37:18,151 : worker.worker : DEBUG : Step 167964, finished rewards 19.05, envs finished 1
2026-01-17 13:37:18,271 : agent.on_policy : DEBUG : Mean Losses: [6.682298548519611]
2026-01-17 13:37:18,274 : worker.worker : DEBUG : Step 167968, finished rewards 21.98, envs finished 1
2026-01-17 13:37:18,454 : worker.worker : DEBUG : Step 167991, finished rewards 25.83, envs finished 1
2026-01-17 13:37:18,494 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:37:18,555 : agent.on_policy : DEBUG : Mean Losses: [4.251062534749508]
2026-01-17 13:37:18,775 : agent.on_policy : DEBUG : Mean Losses: [1.8165738582611084]
2026-01-17 13:37:18,820 : worker.worker : DEBUG : Step 168044, finished rewards -6.72, envs finished 1
2026-01-17 13:37:18,833 : worker.worker : DEBUG : Step 168046, finished rewards 36.85, envs finished 1
2026-01-17 13:37:18,878 : worker.worker : DEBUG : Step 168056, finished rewards 21.67, envs finished 1
2026-01-17 13:37:18,968 : agent.on_policy : DEBUG : Mean Losses: [7.715072810649872]
2026-01-17 13:37:18,988 : worker.worker : DEBUG : Step 168068, finished rewards 8.88, envs finished 1
2026-01-17 13:37:19,009 : worker.worker : DEBUG : Step 168073, finished rewards 32.29, envs finished 1
2026-01-17 13:37:19,063 : worker.worker : DEBUG : Step 168077, finished rewards -12.72, envs finished 1
2026-01-17 13:37:19,115 : worker.worker : DEBUG : Step 168082, finished rewards 4.30, envs finished 1
2026-01-17 13:37:19,296 : agent.on_policy : DEBUG : Mean Losses: [5.115374386310577]
2026-01-17 13:37:19,400 : worker.worker : DEBUG : Step 168107, finished rewards 21.61, envs finished 2
2026-01-17 13:37:19,536 : worker.worker : DEBUG : Step 168126, finished rewards 42.82, envs finished 1
2026-01-17 13:37:19,657 : agent.on_policy : DEBUG : Mean Losses: [5.18867751210928]
2026-01-17 13:37:19,734 : worker.worker : DEBUG : Step 168138, finished rewards 26.01, envs finished 1
2026-01-17 13:37:19,774 : worker.worker : DEBUG : Step 168143, finished rewards 42.53, envs finished 1
2026-01-17 13:37:19,958 : agent.on_policy : DEBUG : Mean Losses: [3.992204200476408]
2026-01-17 13:37:19,965 : worker.worker : DEBUG : Step 168160, finished rewards 24.00, envs finished 1
2026-01-17 13:37:20,117 : worker.worker : DEBUG : Step 168174, finished rewards 21.59, envs finished 1
2026-01-17 13:37:20,412 : agent.on_policy : DEBUG : Mean Losses: [2.7413758523762226]
2026-01-17 13:37:20,433 : worker.worker : DEBUG : Step 168197, finished rewards 26.29, envs finished 1
2026-01-17 13:37:20,442 : worker.worker : DEBUG : Step 168199, finished rewards 25.58, envs finished 1
2026-01-17 13:37:20,462 : worker.worker : DEBUG : Step 168203, finished rewards 35.13, envs finished 1
2026-01-17 13:37:20,526 : worker.worker : DEBUG : Step 168218, finished rewards 1.46, envs finished 1
2026-01-17 13:37:20,608 : agent.on_policy : DEBUG : Mean Losses: [6.631631635129452]
2026-01-17 13:37:20,854 : worker.worker : DEBUG : Step 168245, finished rewards 12.52, envs finished 1
2026-01-17 13:37:20,894 : worker.worker : DEBUG : Step 168250, finished rewards 25.48, envs finished 1
2026-01-17 13:37:21,090 : agent.on_policy : DEBUG : Mean Losses: [3.441833086311817]
2026-01-17 13:37:21,146 : worker.worker : DEBUG : Step 168266, finished rewards 23.51, envs finished 1
2026-01-17 13:37:21,163 : worker.worker : DEBUG : Step 168269, finished rewards 1.34, envs finished 1
2026-01-17 13:37:21,305 : worker.worker : DEBUG : Step 168287, finished rewards 25.31, envs finished 1
2026-01-17 13:37:21,438 : agent.on_policy : DEBUG : Mean Losses: [4.559752561151981]
2026-01-17 13:37:21,584 : worker.worker : DEBUG : Step 168301, finished rewards 16.28, envs finished 1
2026-01-17 13:37:21,668 : worker.worker : DEBUG : Step 168309, finished rewards 15.56, envs finished 1
2026-01-17 13:37:21,846 : agent.on_policy : DEBUG : Mean Losses: [2.6527471356093884]
2026-01-17 13:37:21,958 : worker.worker : DEBUG : Step 168335, finished rewards 4.53, envs finished 1
2026-01-17 13:37:21,727 : worker.worker : DEBUG : Step 168351, finished rewards 30.48, envs finished 1
2026-01-17 13:37:21,456 : agent.on_policy : DEBUG : Mean Losses: [4.213310901075602]
2026-01-17 13:37:21,460 : worker.worker : DEBUG : Step 168352, finished rewards 18.85, envs finished 1
2026-01-17 13:37:21,516 : worker.worker : DEBUG : Step 168365, finished rewards 20.33, envs finished 1
2026-01-17 13:37:21,541 : worker.worker : DEBUG : Step 168371, finished rewards -0.62, envs finished 1
2026-01-17 13:37:21,706 : agent.on_policy : DEBUG : Mean Losses: [3.4257551226764917]
2026-01-17 13:37:21,740 : worker.worker : DEBUG : Step 168394, finished rewards 13.55, envs finished 1
2026-01-17 13:37:21,759 : worker.worker : DEBUG : Step 168398, finished rewards 20.55, envs finished 1
2026-01-17 13:37:21,998 : agent.on_policy : DEBUG : Mean Losses: [4.121979229152203]
2026-01-17 13:37:22,047 : worker.worker : DEBUG : Step 168422, finished rewards 42.13, envs finished 1
2026-01-17 13:37:22,070 : worker.worker : DEBUG : Step 168425, finished rewards 11.49, envs finished 1
2026-01-17 13:37:22,322 : agent.on_policy : DEBUG : Mean Losses: [3.5842140391469]
2026-01-17 13:37:22,379 : worker.worker : DEBUG : Step 168460, finished rewards 4.33, envs finished 1
2026-01-17 13:37:22,556 : agent.on_policy : DEBUG : Mean Losses: [4.589056819677353]
2026-01-17 13:37:22,579 : worker.worker : DEBUG : Step 168485, finished rewards 28.08, envs finished 1
2026-01-17 13:37:22,591 : worker.worker : DEBUG : Step 168488, finished rewards 5.54, envs finished 1
2026-01-17 13:37:22,653 : worker.worker : DEBUG : Step 168503, finished rewards -11.01, envs finished 1
2026-01-17 13:37:22,694 : worker.worker : DEBUG : Step 168510, finished rewards 11.95, envs finished 1
2026-01-17 13:37:22,873 : agent.on_policy : DEBUG : Mean Losses: [5.788964636623859]
2026-01-17 13:37:22,890 : worker.worker : DEBUG : Step 168514, finished rewards -10.89, envs finished 1
2026-01-17 13:37:23,017 : worker.worker : DEBUG : Step 168528, finished rewards 16.99, envs finished 1
2026-01-17 13:37:23,151 : worker.worker : DEBUG : Step 168539, finished rewards 36.18, envs finished 1
2026-01-17 13:37:23,345 : agent.on_policy : DEBUG : Mean Losses: [4.083069786429405]
2026-01-17 13:37:23,380 : worker.worker : DEBUG : Step 168546, finished rewards 5.53, envs finished 1
2026-01-17 13:37:23,533 : worker.worker : DEBUG : Step 168561, finished rewards 37.88, envs finished 1
2026-01-17 13:37:23,783 : agent.on_policy : DEBUG : Mean Losses: [3.987028829753399]
2026-01-17 13:37:23,826 : worker.worker : DEBUG : Step 168581, finished rewards 23.73, envs finished 1
2026-01-17 13:37:23,902 : worker.worker : DEBUG : Step 168589, finished rewards 30.90, envs finished 1
2026-01-17 13:37:23,951 : worker.worker : DEBUG : Step 168597, finished rewards 27.85, envs finished 1
2026-01-17 13:37:24,150 : agent.on_policy : DEBUG : Mean Losses: [5.417693380266428]
2026-01-17 13:37:24,316 : worker.worker : DEBUG : Step 168633, finished rewards 41.21, envs finished 1
2026-01-17 13:37:24,342 : worker.worker : DEBUG : Step 168639, finished rewards 10.87, envs finished 1
2026-01-17 13:37:24,400 : agent.on_policy : DEBUG : Mean Losses: [4.3402217123657465]
2026-01-17 13:37:24,425 : worker.worker : DEBUG : Step 168645, finished rewards 3.50, envs finished 1
2026-01-17 13:37:24,581 : worker.worker : DEBUG : Step 168669, finished rewards 27.65, envs finished 1
2026-01-17 13:37:24,737 : agent.on_policy : DEBUG : Mean Losses: [4.336155524477363]
2026-01-17 13:37:24,748 : worker.worker : DEBUG : Step 168674, finished rewards -4.47, envs finished 1
2026-01-17 13:37:24,865 : worker.worker : DEBUG : Step 168691, finished rewards 17.79, envs finished 1
2026-01-17 13:37:24,964 : worker.worker : DEBUG : Step 168702, finished rewards 14.47, envs finished 1
2026-01-17 13:37:24,973 : worker.worker : DEBUG : Step 168703, finished rewards 45.70, envs finished 1
2026-01-17 13:37:25,107 : agent.on_policy : DEBUG : Mean Losses: [6.416082521900535]
2026-01-17 13:37:25,115 : worker.worker : DEBUG : Step 168705, finished rewards -25.70, envs finished 1
2026-01-17 13:37:25,248 : worker.worker : DEBUG : Step 168717, finished rewards 31.41, envs finished 1
2026-01-17 13:37:25,459 : agent.on_policy : DEBUG : Mean Losses: [2.5419708359986544]
2026-01-17 13:37:25,594 : agent.on_policy : DEBUG : Mean Losses: [2.150372087955475]
2026-01-17 13:37:25,709 : worker.worker : DEBUG : Step 168783, finished rewards 8.10, envs finished 1
2026-01-17 13:37:25,736 : worker.worker : DEBUG : Step 168786, finished rewards 11.86, envs finished 1
2026-01-17 13:37:25,753 : worker.worker : DEBUG : Step 168787, finished rewards 21.65, envs finished 1
2026-01-17 13:37:25,796 : worker.worker : DEBUG : Step 168788, finished rewards 32.16, envs finished 1
2026-01-17 13:37:25,940 : agent.on_policy : DEBUG : Mean Losses: [9.80712902545929]
2026-01-17 13:37:25,971 : worker.worker : DEBUG : Step 168802, finished rewards 18.42, envs finished 1
2026-01-17 13:37:26,031 : worker.worker : DEBUG : Step 168807, finished rewards -17.88, envs finished 1
2026-01-17 13:37:26,065 : worker.worker : DEBUG : Step 168811, finished rewards 13.56, envs finished 1
2026-01-17 13:37:26,085 : worker.worker : DEBUG : Step 168814, finished rewards 21.96, envs finished 1
2026-01-17 13:37:26,281 : agent.on_policy : DEBUG : Mean Losses: [4.528436832129955]
2026-01-17 13:37:26,369 : worker.worker : DEBUG : Step 168857, finished rewards 41.93, envs finished 1
2026-01-17 13:37:26,513 : agent.on_policy : DEBUG : Mean Losses: [2.7085498701781034]
2026-01-17 13:37:26,655 : worker.worker : DEBUG : Step 168887, finished rewards 35.99, envs finished 1
2026-01-17 13:37:26,669 : worker.worker : DEBUG : Step 168889, finished rewards 28.09, envs finished 1
2026-01-17 13:37:26,722 : worker.worker : DEBUG : Step 168895, finished rewards 12.23, envs finished 1
2026-01-17 13:37:26,941 : agent.on_policy : DEBUG : Mean Losses: [7.216723263263702]
2026-01-17 13:37:26,977 : worker.worker : DEBUG : Step 168901, finished rewards 5.25, envs finished 2
2026-01-17 13:37:27,070 : worker.worker : DEBUG : Step 168915, finished rewards 14.31, envs finished 1
2026-01-17 13:37:27,288 : agent.on_policy : DEBUG : Mean Losses: [4.816969575360417]
2026-01-17 13:37:27,293 : worker.worker : DEBUG : Step 168928, finished rewards 42.13, envs finished 1
2026-01-17 13:37:27,329 : worker.worker : DEBUG : Step 168934, finished rewards 10.12, envs finished 1
2026-01-17 13:37:27,610 : agent.on_policy : DEBUG : Mean Losses: [2.8626243732869625]
2026-01-17 13:37:27,613 : worker.worker : DEBUG : Step 168960, finished rewards 41.96, envs finished 1
2026-01-17 13:37:27,725 : worker.worker : DEBUG : Step 168987, finished rewards 25.78, envs finished 1
2026-01-17 13:37:27,846 : agent.on_policy : DEBUG : Mean Losses: [4.346783265471458]
2026-01-17 13:37:27,861 : worker.worker : DEBUG : Step 168995, finished rewards 10.61, envs finished 1
2026-01-17 13:37:27,889 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:37:27,947 : worker.worker : DEBUG : Step 169004, finished rewards 17.22, envs finished 1
2026-01-17 13:37:28,050 : worker.worker : DEBUG : Step 169022, finished rewards 26.08, envs finished 2
2026-01-17 13:37:28,207 : agent.on_policy : DEBUG : Mean Losses: [5.62707882001996]
2026-01-17 13:37:28,385 : worker.worker : DEBUG : Step 169048, finished rewards -13.97, envs finished 1
2026-01-17 13:37:28,554 : agent.on_policy : DEBUG : Mean Losses: [3.015905063599348]
2026-01-17 13:37:28,697 : worker.worker : DEBUG : Step 169084, finished rewards 8.30, envs finished 1
2026-01-17 13:37:28,733 : worker.worker : DEBUG : Step 169086, finished rewards 46.08, envs finished 1
2026-01-17 13:37:28,822 : agent.on_policy : DEBUG : Mean Losses: [5.90913141425699]
2026-01-17 13:37:28,825 : worker.worker : DEBUG : Step 169088, finished rewards 16.74, envs finished 1
2026-01-17 13:37:28,862 : worker.worker : DEBUG : Step 169096, finished rewards 25.39, envs finished 1
2026-01-17 13:37:29,206 : agent.on_policy : DEBUG : Mean Losses: [3.3810600973665714]
2026-01-17 13:37:29,212 : worker.worker : DEBUG : Step 169120, finished rewards 19.85, envs finished 1
2026-01-17 13:37:29,225 : worker.worker : DEBUG : Step 169122, finished rewards -58.51, envs finished 1
2026-01-17 13:37:29,250 : worker.worker : DEBUG : Step 169126, finished rewards 2.44, envs finished 1
2026-01-17 13:37:29,380 : agent.on_policy : DEBUG : Mean Losses: [2.9781870134174824]
2026-01-17 13:37:29,385 : worker.worker : DEBUG : Step 169152, finished rewards 46.24, envs finished 1
2026-01-17 13:37:29,537 : worker.worker : DEBUG : Step 169166, finished rewards 40.86, envs finished 1
2026-01-17 13:37:29,729 : worker.worker : DEBUG : Step 169178, finished rewards 22.51, envs finished 1
2026-01-17 13:37:29,795 : worker.worker : DEBUG : Step 169183, finished rewards 19.87, envs finished 1
2026-01-17 13:37:29,977 : agent.on_policy : DEBUG : Mean Losses: [6.281138703227043]
2026-01-17 13:37:29,996 : worker.worker : DEBUG : Step 169186, finished rewards -3.81, envs finished 1
2026-01-17 13:37:30,108 : worker.worker : DEBUG : Step 169207, finished rewards 33.15, envs finished 1
2026-01-17 13:37:30,265 : agent.on_policy : DEBUG : Mean Losses: [3.610322707798332]
2026-01-17 13:37:30,280 : worker.worker : DEBUG : Step 169220, finished rewards 22.25, envs finished 1
2026-01-17 13:37:30,441 : worker.worker : DEBUG : Step 169236, finished rewards 7.69, envs finished 1
2026-01-17 13:37:30,449 : worker.worker : DEBUG : Step 169237, finished rewards 41.20, envs finished 1
2026-01-17 13:37:30,730 : agent.on_policy : DEBUG : Mean Losses: [5.22384044341743]
2026-01-17 13:37:30,767 : worker.worker : DEBUG : Step 169252, finished rewards 19.93, envs finished 1
2026-01-17 13:37:30,777 : worker.worker : DEBUG : Step 169253, finished rewards 41.13, envs finished 1
2026-01-17 13:37:30,806 : worker.worker : DEBUG : Step 169257, finished rewards 40.78, envs finished 1
2026-01-17 13:37:30,930 : worker.worker : DEBUG : Step 169275, finished rewards 21.85, envs finished 1
2026-01-17 13:37:31,097 : agent.on_policy : DEBUG : Mean Losses: [4.670024372637272]
2026-01-17 13:37:31,307 : worker.worker : DEBUG : Step 169309, finished rewards 18.69, envs finished 1
2026-01-17 13:37:31,364 : agent.on_policy : DEBUG : Mean Losses: [2.39787688665092]
2026-01-17 13:37:31,399 : worker.worker : DEBUG : Step 169322, finished rewards 17.63, envs finished 1
2026-01-17 13:37:31,451 : worker.worker : DEBUG : Step 169333, finished rewards 36.37, envs finished 1
2026-01-17 13:37:31,523 : worker.worker : DEBUG : Step 169338, finished rewards 19.01, envs finished 1
2026-01-17 13:37:31,537 : worker.worker : DEBUG : Step 169339, finished rewards 30.75, envs finished 1
2026-01-17 13:37:31,682 : agent.on_policy : DEBUG : Mean Losses: [6.8276763670146465]
2026-01-17 13:37:31,732 : worker.worker : DEBUG : Step 169353, finished rewards 5.17, envs finished 1
2026-01-17 13:37:31,998 : agent.on_policy : DEBUG : Mean Losses: [2.8186488710343838]
2026-01-17 13:37:32,036 : worker.worker : DEBUG : Step 169384, finished rewards -1.92, envs finished 1
2026-01-17 13:37:32,223 : worker.worker : DEBUG : Step 169406, finished rewards 31.56, envs finished 1
2026-01-17 13:37:32,377 : agent.on_policy : DEBUG : Mean Losses: [4.8556161522865295]
2026-01-17 13:37:32,432 : worker.worker : DEBUG : Step 169411, finished rewards -8.23, envs finished 1
2026-01-17 13:37:32,462 : worker.worker : DEBUG : Step 169412, finished rewards 16.82, envs finished 1
2026-01-17 13:37:32,501 : worker.worker : DEBUG : Step 169416, finished rewards 34.11, envs finished 1
2026-01-17 13:37:32,653 : worker.worker : DEBUG : Step 169428, finished rewards 21.33, envs finished 1
2026-01-17 13:37:32,965 : agent.on_policy : DEBUG : Mean Losses: [5.312908720225096]
2026-01-17 13:37:33,083 : worker.worker : DEBUG : Step 169453, finished rewards 8.78, envs finished 1
2026-01-17 13:37:33,198 : worker.worker : DEBUG : Step 169462, finished rewards 14.01, envs finished 1
2026-01-17 13:37:33,262 : worker.worker : DEBUG : Step 169467, finished rewards 31.99, envs finished 1
2026-01-17 13:37:33,412 : agent.on_policy : DEBUG : Mean Losses: [3.8555102050304413]
2026-01-17 13:37:33,427 : worker.worker : DEBUG : Step 169475, finished rewards 45.66, envs finished 1
2026-01-17 13:37:33,560 : worker.worker : DEBUG : Step 169490, finished rewards 31.09, envs finished 1
2026-01-17 13:37:33,669 : worker.worker : DEBUG : Step 169499, finished rewards 32.26, envs finished 1
2026-01-17 13:37:33,676 : worker.worker : DEBUG : Step 169500, finished rewards 27.38, envs finished 1
2026-01-17 13:37:33,859 : agent.on_policy : DEBUG : Mean Losses: [5.78080540150404]
2026-01-17 13:37:33,928 : worker.worker : DEBUG : Step 169512, finished rewards 31.23, envs finished 1
2026-01-17 13:37:34,178 : agent.on_policy : DEBUG : Mean Losses: [2.5520126027986407]
2026-01-17 13:37:34,182 : worker.worker : DEBUG : Step 169536, finished rewards 31.71, envs finished 1
2026-01-17 13:37:34,225 : worker.worker : DEBUG : Step 169546, finished rewards 36.30, envs finished 1
2026-01-17 13:37:34,507 : agent.on_policy : DEBUG : Mean Losses: [3.117147073149681]
2026-01-17 13:37:34,517 : worker.worker : DEBUG : Step 169568, finished rewards 23.44, envs finished 1
2026-01-17 13:37:34,531 : worker.worker : DEBUG : Step 169569, finished rewards 16.86, envs finished 1
2026-01-17 13:37:34,681 : worker.worker : DEBUG : Step 169592, finished rewards 23.22, envs finished 1
2026-01-17 13:37:34,879 : agent.on_policy : DEBUG : Mean Losses: [5.209741421043873]
2026-01-17 13:37:34,952 : worker.worker : DEBUG : Step 169614, finished rewards 36.30, envs finished 1
2026-01-17 13:37:34,983 : worker.worker : DEBUG : Step 169621, finished rewards 10.17, envs finished 1
2026-01-17 13:37:35,158 : agent.on_policy : DEBUG : Mean Losses: [5.306298568844795]
2026-01-17 13:37:35,189 : worker.worker : DEBUG : Step 169640, finished rewards -6.10, envs finished 1
2026-01-17 13:37:35,247 : worker.worker : DEBUG : Step 169645, finished rewards 20.78, envs finished 1
2026-01-17 13:37:35,463 : agent.on_policy : DEBUG : Mean Losses: [4.296056751161814]
2026-01-17 13:37:35,479 : worker.worker : DEBUG : Step 169668, finished rewards -36.18, envs finished 1
2026-01-17 13:37:35,560 : worker.worker : DEBUG : Step 169690, finished rewards 4.36, envs finished 1
2026-01-17 13:37:35,569 : worker.worker : DEBUG : Step 169692, finished rewards 2.51, envs finished 1
2026-01-17 13:37:35,707 : agent.on_policy : DEBUG : Mean Losses: [3.906464036554098]
2026-01-17 13:37:35,753 : worker.worker : DEBUG : Step 169707, finished rewards 25.39, envs finished 1
2026-01-17 13:37:35,872 : worker.worker : DEBUG : Step 169722, finished rewards 17.59, envs finished 1
2026-01-17 13:37:36,029 : agent.on_policy : DEBUG : Mean Losses: [5.234921671450138]
2026-01-17 13:37:36,040 : worker.worker : DEBUG : Step 169730, finished rewards 25.58, envs finished 1
2026-01-17 13:37:36,053 : worker.worker : DEBUG : Step 169731, finished rewards 28.45, envs finished 1
2026-01-17 13:37:36,509 : agent.on_policy : DEBUG : Mean Losses: [3.579051837325096]
2026-01-17 13:37:36,515 : worker.worker : DEBUG : Step 169761, finished rewards 41.47, envs finished 1
2026-01-17 13:37:36,526 : worker.worker : DEBUG : Step 169763, finished rewards 21.62, envs finished 1
2026-01-17 13:37:36,575 : worker.worker : DEBUG : Step 169772, finished rewards -34.12, envs finished 1
2026-01-17 13:37:36,620 : worker.worker : DEBUG : Step 169784, finished rewards 22.93, envs finished 1
2026-01-17 13:37:36,779 : agent.on_policy : DEBUG : Mean Losses: [4.639675244688988]
2026-01-17 13:37:36,892 : worker.worker : DEBUG : Step 169812, finished rewards 18.35, envs finished 1
2026-01-17 13:37:36,913 : worker.worker : DEBUG : Step 169816, finished rewards 28.01, envs finished 1
2026-01-17 13:37:36,998 : worker.worker : DEBUG : Step 169823, finished rewards 17.08, envs finished 1
2026-01-17 13:37:37,153 : agent.on_policy : DEBUG : Mean Losses: [4.433176681399345]
2026-01-17 13:37:37,196 : worker.worker : DEBUG : Step 169833, finished rewards 39.63, envs finished 1
2026-01-17 13:37:37,306 : worker.worker : DEBUG : Step 169842, finished rewards 9.47, envs finished 1
2026-01-17 13:37:37,331 : worker.worker : DEBUG : Step 169845, finished rewards 32.61, envs finished 1
2026-01-17 13:37:37,486 : agent.on_policy : DEBUG : Mean Losses: [5.013705231249332]
2026-01-17 13:37:37,558 : worker.worker : DEBUG : Step 169876, finished rewards 15.62, envs finished 1
2026-01-17 13:37:37,725 : agent.on_policy : DEBUG : Mean Losses: [1.9377828426659107]
2026-01-17 13:37:37,754 : worker.worker : DEBUG : Step 169894, finished rewards 35.35, envs finished 1
2026-01-17 13:37:37,766 : worker.worker : DEBUG : Step 169896, finished rewards 10.41, envs finished 1
2026-01-17 13:37:37,845 : worker.worker : DEBUG : Step 169911, finished rewards 27.39, envs finished 1
2026-01-17 13:37:38,013 : agent.on_policy : DEBUG : Mean Losses: [5.980638951063156]
2026-01-17 13:37:38,040 : worker.worker : DEBUG : Step 169927, finished rewards 32.38, envs finished 1
2026-01-17 13:37:38,065 : worker.worker : DEBUG : Step 169931, finished rewards 25.57, envs finished 1
2026-01-17 13:37:38,144 : worker.worker : DEBUG : Step 169935, finished rewards 17.50, envs finished 1
2026-01-17 13:37:38,212 : worker.worker : DEBUG : Step 169947, finished rewards 40.12, envs finished 1
2026-01-17 13:37:38,385 : agent.on_policy : DEBUG : Mean Losses: [6.892933769151568]
2026-01-17 13:37:38,478 : worker.worker : DEBUG : Step 169959, finished rewards -12.22, envs finished 1
2026-01-17 13:37:38,610 : worker.worker : DEBUG : Step 169977, finished rewards 32.30, envs finished 1
2026-01-17 13:37:38,631 : worker.worker : DEBUG : Step 169980, finished rewards 31.55, envs finished 1
2026-01-17 13:37:38,853 : agent.on_policy : DEBUG : Mean Losses: [4.5014916844666]
2026-01-17 13:37:38,958 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:37:39,032 : worker.worker : INFO : Step 170000, Avg Reward 20.6449, Max Reward 71.3177, Loss [4.58411752]
2026-01-17 13:37:39,225 : agent.on_policy : DEBUG : Mean Losses: [4.617534123361111]
2026-01-17 13:37:39,288 : worker.worker : DEBUG : Step 170033, finished rewards 19.59, envs finished 1
2026-01-17 13:37:39,307 : worker.worker : DEBUG : Step 170038, finished rewards 4.31, envs finished 1
2026-01-17 13:37:39,476 : agent.on_policy : DEBUG : Mean Losses: [6.359455794095993]
2026-01-17 13:37:39,497 : worker.worker : DEBUG : Step 170053, finished rewards -2.07, envs finished 1
2026-01-17 13:37:39,610 : worker.worker : DEBUG : Step 170067, finished rewards -4.09, envs finished 1
2026-01-17 13:37:39,618 : worker.worker : DEBUG : Step 170069, finished rewards 4.82, envs finished 1
2026-01-17 13:37:39,843 : agent.on_policy : DEBUG : Mean Losses: [4.808721676468849]
2026-01-17 13:37:39,977 : worker.worker : DEBUG : Step 170092, finished rewards 8.57, envs finished 2
2026-01-17 13:37:40,129 : worker.worker : DEBUG : Step 170106, finished rewards -8.55, envs finished 1
2026-01-17 13:37:40,285 : agent.on_policy : DEBUG : Mean Losses: [3.2337528839707375]
2026-01-17 13:37:40,463 : worker.worker : DEBUG : Step 170138, finished rewards 18.70, envs finished 1
2026-01-17 13:37:40,466 : worker.worker : DEBUG : Step 170139, finished rewards 29.20, envs finished 1
2026-01-17 13:37:40,624 : agent.on_policy : DEBUG : Mean Losses: [5.446568377315998]
2026-01-17 13:37:40,859 : agent.on_policy : DEBUG : Mean Losses: [3.9846874121576548]
2026-01-17 13:37:40,860 : worker.worker : DEBUG : Step 170176, finished rewards 12.96, envs finished 1
2026-01-17 13:37:40,866 : worker.worker : DEBUG : Step 170178, finished rewards 40.68, envs finished 1
2026-01-17 13:37:40,877 : worker.worker : DEBUG : Step 170180, finished rewards 18.92, envs finished 2
2026-01-17 13:37:41,115 : agent.on_policy : DEBUG : Mean Losses: [4.786703065037727]
2026-01-17 13:37:41,126 : worker.worker : DEBUG : Step 170210, finished rewards 42.07, envs finished 1
2026-01-17 13:37:41,132 : worker.worker : DEBUG : Step 170211, finished rewards 14.16, envs finished 1
2026-01-17 13:37:41,450 : agent.on_policy : DEBUG : Mean Losses: [2.6337522082030773]
2026-01-17 13:37:41,522 : worker.worker : DEBUG : Step 170255, finished rewards 7.70, envs finished 1
2026-01-17 13:37:41,531 : worker.worker : DEBUG : Step 170257, finished rewards 36.88, envs finished 1
2026-01-17 13:37:41,549 : worker.worker : DEBUG : Step 170260, finished rewards -21.62, envs finished 1
2026-01-17 13:37:41,570 : worker.worker : DEBUG : Step 170264, finished rewards 27.96, envs finished 1
2026-01-17 13:37:41,735 : agent.on_policy : DEBUG : Mean Losses: [5.950932405889034]
2026-01-17 13:37:41,740 : worker.worker : DEBUG : Step 170273, finished rewards 21.29, envs finished 1
2026-01-17 13:37:41,745 : worker.worker : DEBUG : Step 170274, finished rewards 22.38, envs finished 1
2026-01-17 13:37:41,963 : worker.worker : DEBUG : Step 170298, finished rewards 27.93, envs finished 1
2026-01-17 13:37:42,058 : agent.on_policy : DEBUG : Mean Losses: [3.1935145230963826]
2026-01-17 13:37:42,085 : worker.worker : DEBUG : Step 170311, finished rewards 17.73, envs finished 1
2026-01-17 13:37:42,165 : worker.worker : DEBUG : Step 170319, finished rewards 46.11, envs finished 1
2026-01-17 13:37:42,376 : agent.on_policy : DEBUG : Mean Losses: [4.314987383782864]
2026-01-17 13:37:42,508 : worker.worker : DEBUG : Step 170350, finished rewards 24.96, envs finished 1
2026-01-17 13:37:42,767 : agent.on_policy : DEBUG : Mean Losses: [4.42449589446187]
2026-01-17 13:37:42,770 : worker.worker : DEBUG : Step 170368, finished rewards 22.62, envs finished 1
2026-01-17 13:37:42,903 : worker.worker : DEBUG : Step 170378, finished rewards 16.34, envs finished 1
2026-01-17 13:37:43,085 : worker.worker : DEBUG : Step 170396, finished rewards 8.38, envs finished 1
2026-01-17 13:37:43,154 : agent.on_policy : DEBUG : Mean Losses: [4.500554013997316]
2026-01-17 13:37:43,187 : worker.worker : DEBUG : Step 170409, finished rewards 11.60, envs finished 1
2026-01-17 13:37:43,245 : worker.worker : DEBUG : Step 170420, finished rewards 42.67, envs finished 1
2026-01-17 13:37:43,264 : worker.worker : DEBUG : Step 170421, finished rewards -10.00, envs finished 1
2026-01-17 13:37:43,489 : agent.on_policy : DEBUG : Mean Losses: [4.948334017768502]
2026-01-17 13:37:43,527 : worker.worker : DEBUG : Step 170438, finished rewards 7.39, envs finished 1
2026-01-17 13:37:43,640 : worker.worker : DEBUG : Step 170448, finished rewards 19.86, envs finished 1
2026-01-17 13:37:43,871 : agent.on_policy : DEBUG : Mean Losses: [3.274035641923547]
2026-01-17 13:37:43,883 : worker.worker : DEBUG : Step 170466, finished rewards 41.08, envs finished 1
2026-01-17 13:37:44,158 : worker.worker : DEBUG : Step 170492, finished rewards 41.11, envs finished 1
2026-01-17 13:37:44,164 : worker.worker : DEBUG : Step 170493, finished rewards 12.25, envs finished 1
2026-01-17 13:37:44,233 : agent.on_policy : DEBUG : Mean Losses: [4.995673403143883]
2026-01-17 13:37:44,234 : worker.worker : DEBUG : Step 170496, finished rewards 0.49, envs finished 1
2026-01-17 13:37:44,285 : worker.worker : DEBUG : Step 170510, finished rewards 41.07, envs finished 1
2026-01-17 13:37:44,351 : worker.worker : DEBUG : Step 170518, finished rewards 31.86, envs finished 2
2026-01-17 13:37:44,529 : agent.on_policy : DEBUG : Mean Losses: [5.1132060457021]
2026-01-17 13:37:44,575 : worker.worker : DEBUG : Step 170537, finished rewards 40.92, envs finished 1
2026-01-17 13:37:44,593 : worker.worker : DEBUG : Step 170541, finished rewards -4.22, envs finished 1
2026-01-17 13:37:44,747 : agent.on_policy : DEBUG : Mean Losses: [3.3988707810640335]
2026-01-17 13:37:44,867 : worker.worker : DEBUG : Step 170577, finished rewards 31.00, envs finished 1
2026-01-17 13:37:44,926 : worker.worker : DEBUG : Step 170585, finished rewards 23.52, envs finished 1
2026-01-17 13:37:44,964 : worker.worker : DEBUG : Step 170588, finished rewards 37.00, envs finished 1
2026-01-17 13:37:44,975 : worker.worker : DEBUG : Step 170590, finished rewards 24.10, envs finished 1
2026-01-17 13:37:45,120 : agent.on_policy : DEBUG : Mean Losses: [6.922919819131494]
2026-01-17 13:37:45,263 : worker.worker : DEBUG : Step 170611, finished rewards 22.71, envs finished 1
2026-01-17 13:37:45,297 : worker.worker : DEBUG : Step 170618, finished rewards 19.97, envs finished 1
2026-01-17 13:37:45,455 : agent.on_policy : DEBUG : Mean Losses: [3.347808852791786]
2026-01-17 13:37:45,676 : agent.on_policy : DEBUG : Mean Losses: [2.7936217226088047]
2026-01-17 13:37:45,757 : worker.worker : DEBUG : Step 170680, finished rewards -16.02, envs finished 1
2026-01-17 13:37:45,770 : worker.worker : DEBUG : Step 170683, finished rewards 6.57, envs finished 2
2026-01-17 13:37:45,904 : agent.on_policy : DEBUG : Mean Losses: [6.119668945670128]
2026-01-17 13:37:45,916 : worker.worker : DEBUG : Step 170691, finished rewards 20.95, envs finished 1
2026-01-17 13:37:45,956 : worker.worker : DEBUG : Step 170695, finished rewards 9.75, envs finished 1
2026-01-17 13:37:46,325 : agent.on_policy : DEBUG : Mean Losses: [5.160862974822521]
2026-01-17 13:37:46,345 : worker.worker : DEBUG : Step 170723, finished rewards -0.07, envs finished 1
2026-01-17 13:37:46,389 : worker.worker : DEBUG : Step 170726, finished rewards 7.71, envs finished 1
2026-01-17 13:37:46,437 : worker.worker : DEBUG : Step 170732, finished rewards 9.67, envs finished 1
2026-01-17 13:37:46,506 : worker.worker : DEBUG : Step 170751, finished rewards 40.91, envs finished 1
2026-01-17 13:37:46,558 : agent.on_policy : DEBUG : Mean Losses: [6.1103052869439125]
2026-01-17 13:37:46,566 : worker.worker : DEBUG : Step 170753, finished rewards 43.22, envs finished 1
2026-01-17 13:37:46,667 : worker.worker : DEBUG : Step 170762, finished rewards 40.95, envs finished 1
2026-01-17 13:37:46,768 : worker.worker : DEBUG : Step 170775, finished rewards 24.42, envs finished 1
2026-01-17 13:37:46,909 : agent.on_policy : DEBUG : Mean Losses: [4.626947537064552]
2026-01-17 13:37:46,941 : worker.worker : DEBUG : Step 170786, finished rewards 25.78, envs finished 1
2026-01-17 13:37:47,088 : worker.worker : DEBUG : Step 170796, finished rewards 42.63, envs finished 1
2026-01-17 13:37:47,145 : worker.worker : DEBUG : Step 170804, finished rewards 40.07, envs finished 1
2026-01-17 13:37:47,189 : worker.worker : DEBUG : Step 170813, finished rewards 26.70, envs finished 1
2026-01-17 13:37:47,336 : agent.on_policy : DEBUG : Mean Losses: [4.950691379606724]
2026-01-17 13:37:47,570 : agent.on_policy : DEBUG : Mean Losses: [2.3593754339963198]
2026-01-17 13:37:47,597 : worker.worker : DEBUG : Step 170854, finished rewards 16.62, envs finished 1
2026-01-17 13:37:47,649 : worker.worker : DEBUG : Step 170867, finished rewards 42.38, envs finished 1
2026-01-17 13:37:47,654 : worker.worker : DEBUG : Step 170868, finished rewards 3.87, envs finished 1
2026-01-17 13:37:47,681 : worker.worker : DEBUG : Step 170875, finished rewards 21.99, envs finished 1
2026-01-17 13:37:47,806 : agent.on_policy : DEBUG : Mean Losses: [6.92136824131012]
2026-01-17 13:37:47,809 : worker.worker : DEBUG : Step 170880, finished rewards 7.17, envs finished 1
2026-01-17 13:37:47,859 : worker.worker : DEBUG : Step 170891, finished rewards 14.68, envs finished 1
2026-01-17 13:37:47,895 : worker.worker : DEBUG : Step 170896, finished rewards 24.41, envs finished 1
2026-01-17 13:37:48,136 : agent.on_policy : DEBUG : Mean Losses: [3.0263376012444496]
2026-01-17 13:37:48,251 : worker.worker : DEBUG : Step 170925, finished rewards 42.15, envs finished 1
2026-01-17 13:37:48,380 : worker.worker : DEBUG : Step 170937, finished rewards 3.31, envs finished 1
2026-01-17 13:37:48,391 : worker.worker : DEBUG : Step 170939, finished rewards 40.89, envs finished 1
2026-01-17 13:37:48,531 : agent.on_policy : DEBUG : Mean Losses: [5.300129100680351]
2026-01-17 13:37:48,741 : worker.worker : DEBUG : Step 170971, finished rewards 25.08, envs finished 1
2026-01-17 13:37:48,873 : agent.on_policy : DEBUG : Mean Losses: [4.390651077032089]
2026-01-17 13:37:48,972 : worker.worker : DEBUG : Step 170986, finished rewards 21.71, envs finished 1
2026-01-17 13:37:49,023 : worker.worker : DEBUG : Step 170993, finished rewards 5.04, envs finished 1
2026-01-17 13:37:49,102 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:37:49,220 : worker.worker : DEBUG : Step 171006, finished rewards 30.23, envs finished 1
2026-01-17 13:37:49,551 : agent.on_policy : DEBUG : Mean Losses: [5.170508299022913]
2026-01-17 13:37:49,576 : worker.worker : DEBUG : Step 171014, finished rewards 5.19, envs finished 1
2026-01-17 13:37:49,771 : agent.on_policy : DEBUG : Mean Losses: [3.1763559887185693]
2026-01-17 13:37:49,816 : worker.worker : DEBUG : Step 171050, finished rewards 14.99, envs finished 1
2026-01-17 13:37:49,836 : worker.worker : DEBUG : Step 171054, finished rewards -0.94, envs finished 1
2026-01-17 13:37:49,953 : agent.on_policy : DEBUG : Mean Losses: [7.1374969482421875]
2026-01-17 13:37:50,008 : worker.worker : DEBUG : Step 171078, finished rewards 16.62, envs finished 2
2026-01-17 13:37:50,117 : worker.worker : DEBUG : Step 171088, finished rewards 6.11, envs finished 1
2026-01-17 13:37:50,201 : worker.worker : DEBUG : Step 171092, finished rewards 12.64, envs finished 1
2026-01-17 13:37:50,808 : agent.on_policy : DEBUG : Mean Losses: [6.710304572246969]
2026-01-17 13:37:50,811 : worker.worker : DEBUG : Step 171104, finished rewards 25.39, envs finished 1
2026-01-17 13:37:50,840 : worker.worker : DEBUG : Step 171109, finished rewards 7.85, envs finished 1
2026-01-17 13:37:51,044 : worker.worker : DEBUG : Step 171134, finished rewards 31.22, envs finished 1
2026-01-17 13:37:51,216 : agent.on_policy : DEBUG : Mean Losses: [3.669815918430686]
2026-01-17 13:37:50,963 : worker.worker : DEBUG : Step 171149, finished rewards 40.56, envs finished 1
2026-01-17 13:37:50,621 : worker.worker : DEBUG : Step 171158, finished rewards 35.48, envs finished 1
2026-01-17 13:37:50,765 : agent.on_policy : DEBUG : Mean Losses: [4.613677807152271]
2026-01-17 13:37:50,868 : worker.worker : DEBUG : Step 171178, finished rewards -0.29, envs finished 1
2026-01-17 13:37:50,947 : worker.worker : DEBUG : Step 171188, finished rewards 20.13, envs finished 1
2026-01-17 13:37:51,157 : agent.on_policy : DEBUG : Mean Losses: [3.7089255824685097]
2026-01-17 13:37:51,187 : worker.worker : DEBUG : Step 171204, finished rewards 20.82, envs finished 1
2026-01-17 13:37:51,227 : worker.worker : DEBUG : Step 171211, finished rewards 17.10, envs finished 1
2026-01-17 13:37:51,243 : worker.worker : DEBUG : Step 171213, finished rewards 10.37, envs finished 1
2026-01-17 13:37:51,343 : worker.worker : DEBUG : Step 171226, finished rewards 25.97, envs finished 1
2026-01-17 13:37:51,361 : worker.worker : DEBUG : Step 171229, finished rewards 40.64, envs finished 1
2026-01-17 13:37:51,574 : agent.on_policy : DEBUG : Mean Losses: [5.564682237803936]
2026-01-17 13:37:51,829 : agent.on_policy : DEBUG : Mean Losses: [2.8386936858296394]
2026-01-17 13:37:51,831 : worker.worker : DEBUG : Step 171264, finished rewards 7.79, envs finished 1
2026-01-17 13:37:51,879 : worker.worker : DEBUG : Step 171274, finished rewards 21.10, envs finished 1
2026-01-17 13:37:52,102 : agent.on_policy : DEBUG : Mean Losses: [4.163048379123211]
2026-01-17 13:37:52,137 : worker.worker : DEBUG : Step 171300, finished rewards 40.47, envs finished 1
2026-01-17 13:37:52,265 : worker.worker : DEBUG : Step 171322, finished rewards 19.62, envs finished 1
2026-01-17 13:37:52,298 : worker.worker : DEBUG : Step 171326, finished rewards 18.98, envs finished 1
2026-01-17 13:37:52,493 : agent.on_policy : DEBUG : Mean Losses: [6.702646378427744]
2026-01-17 13:37:52,511 : worker.worker : DEBUG : Step 171331, finished rewards 6.35, envs finished 1
2026-01-17 13:37:52,767 : agent.on_policy : DEBUG : Mean Losses: [3.0729959085583687]
2026-01-17 13:37:52,771 : worker.worker : DEBUG : Step 171360, finished rewards 28.58, envs finished 1
2026-01-17 13:37:52,778 : worker.worker : DEBUG : Step 171361, finished rewards -32.83, envs finished 1
2026-01-17 13:37:52,830 : worker.worker : DEBUG : Step 171368, finished rewards -26.47, envs finished 1
2026-01-17 13:37:52,930 : worker.worker : DEBUG : Step 171384, finished rewards 10.78, envs finished 1
2026-01-17 13:37:53,114 : agent.on_policy : DEBUG : Mean Losses: [4.0106834545731544]
2026-01-17 13:37:53,259 : worker.worker : DEBUG : Step 171402, finished rewards 17.91, envs finished 1
2026-01-17 13:37:53,322 : worker.worker : DEBUG : Step 171408, finished rewards 27.93, envs finished 1
2026-01-17 13:37:53,586 : agent.on_policy : DEBUG : Mean Losses: [4.1080522537231445]
2026-01-17 13:37:53,609 : worker.worker : DEBUG : Step 171429, finished rewards 21.37, envs finished 1
2026-01-17 13:37:53,656 : worker.worker : DEBUG : Step 171438, finished rewards 14.11, envs finished 1
2026-01-17 13:37:53,819 : agent.on_policy : DEBUG : Mean Losses: [4.22198511660099]
2026-01-17 13:37:54,028 : worker.worker : DEBUG : Step 171474, finished rewards 25.80, envs finished 1
2026-01-17 13:37:54,330 : agent.on_policy : DEBUG : Mean Losses: [5.68502114340663]
2026-01-17 13:37:54,381 : worker.worker : DEBUG : Step 171492, finished rewards 31.43, envs finished 1
2026-01-17 13:37:54,615 : worker.worker : DEBUG : Step 171519, finished rewards 26.66, envs finished 1
2026-01-17 13:37:54,686 : agent.on_policy : DEBUG : Mean Losses: [5.952021326869726]
2026-01-17 13:37:54,688 : worker.worker : DEBUG : Step 171520, finished rewards 6.10, envs finished 1
2026-01-17 13:37:54,711 : worker.worker : DEBUG : Step 171524, finished rewards -4.53, envs finished 1
2026-01-17 13:37:54,757 : worker.worker : DEBUG : Step 171533, finished rewards -33.70, envs finished 1
2026-01-17 13:37:55,172 : agent.on_policy : DEBUG : Mean Losses: [4.353371134027839]
2026-01-17 13:37:55,218 : worker.worker : DEBUG : Step 171561, finished rewards -30.57, envs finished 1
2026-01-17 13:37:55,231 : worker.worker : DEBUG : Step 171562, finished rewards 41.36, envs finished 1
2026-01-17 13:37:55,366 : agent.on_policy : DEBUG : Mean Losses: [4.703000172972679]
2026-01-17 13:37:55,375 : worker.worker : DEBUG : Step 171585, finished rewards 9.52, envs finished 1
2026-01-17 13:37:55,463 : worker.worker : DEBUG : Step 171595, finished rewards 42.38, envs finished 1
2026-01-17 13:37:55,602 : worker.worker : DEBUG : Step 171613, finished rewards 11.92, envs finished 1
2026-01-17 13:37:55,621 : worker.worker : DEBUG : Step 171615, finished rewards 21.64, envs finished 1
2026-01-17 13:37:55,777 : agent.on_policy : DEBUG : Mean Losses: [5.553830102086067]
2026-01-17 13:37:55,814 : worker.worker : DEBUG : Step 171626, finished rewards 14.97, envs finished 1
2026-01-17 13:37:56,133 : agent.on_policy : DEBUG : Mean Losses: [2.7675418090075254]
2026-01-17 13:37:56,135 : worker.worker : DEBUG : Step 171648, finished rewards 46.90, envs finished 1
2026-01-17 13:37:56,207 : worker.worker : DEBUG : Step 171667, finished rewards 16.83, envs finished 1
2026-01-17 13:37:56,367 : agent.on_policy : DEBUG : Mean Losses: [3.4214490884914994]
2026-01-17 13:37:56,385 : worker.worker : DEBUG : Step 171683, finished rewards 41.00, envs finished 1
2026-01-17 13:37:56,405 : worker.worker : DEBUG : Step 171687, finished rewards 39.75, envs finished 1
2026-01-17 13:37:56,422 : worker.worker : DEBUG : Step 171690, finished rewards 21.86, envs finished 1
2026-01-17 13:37:56,454 : worker.worker : DEBUG : Step 171697, finished rewards 40.40, envs finished 1
2026-01-17 13:37:56,509 : worker.worker : DEBUG : Step 171707, finished rewards 21.80, envs finished 1
2026-01-17 13:37:56,572 : agent.on_policy : DEBUG : Mean Losses: [6.287298060953617]
2026-01-17 13:37:56,610 : worker.worker : DEBUG : Step 171718, finished rewards 41.13, envs finished 1
2026-01-17 13:37:56,683 : worker.worker : DEBUG : Step 171726, finished rewards 19.91, envs finished 1
2026-01-17 13:37:56,859 : agent.on_policy : DEBUG : Mean Losses: [2.8628297932446003]
2026-01-17 13:37:56,944 : worker.worker : DEBUG : Step 171767, finished rewards 41.45, envs finished 1
2026-01-17 13:37:56,954 : worker.worker : DEBUG : Step 171769, finished rewards 17.75, envs finished 1
2026-01-17 13:37:57,106 : agent.on_policy : DEBUG : Mean Losses: [5.367933362722397]
2026-01-17 13:37:57,247 : worker.worker : DEBUG : Step 171796, finished rewards 13.03, envs finished 1
2026-01-17 13:37:57,257 : worker.worker : DEBUG : Step 171797, finished rewards 33.65, envs finished 1
2026-01-17 13:37:57,429 : agent.on_policy : DEBUG : Mean Losses: [5.528599865734577]
2026-01-17 13:37:57,543 : worker.worker : DEBUG : Step 171825, finished rewards 23.05, envs finished 1
2026-01-17 13:37:57,731 : agent.on_policy : DEBUG : Mean Losses: [4.348029878921807]
2026-01-17 13:37:57,797 : worker.worker : DEBUG : Step 171846, finished rewards 34.94, envs finished 1
2026-01-17 13:37:57,908 : worker.worker : DEBUG : Step 171862, finished rewards 23.21, envs finished 1
2026-01-17 13:37:57,955 : worker.worker : DEBUG : Step 171865, finished rewards -30.84, envs finished 1
2026-01-17 13:37:58,072 : agent.on_policy : DEBUG : Mean Losses: [5.844586566090584]
2026-01-17 13:37:58,129 : worker.worker : DEBUG : Step 171880, finished rewards -35.69, envs finished 1
2026-01-17 13:37:58,149 : worker.worker : DEBUG : Step 171881, finished rewards -19.63, envs finished 1
2026-01-17 13:37:58,302 : worker.worker : DEBUG : Step 171898, finished rewards 18.28, envs finished 1
2026-01-17 13:37:58,389 : agent.on_policy : DEBUG : Mean Losses: [4.23822820559144]
2026-01-17 13:37:58,510 : worker.worker : DEBUG : Step 171915, finished rewards 9.35, envs finished 1
2026-01-17 13:37:58,531 : worker.worker : DEBUG : Step 171916, finished rewards 40.84, envs finished 1
2026-01-17 13:37:58,806 : agent.on_policy : DEBUG : Mean Losses: [5.509501323103905]
2026-01-17 13:37:58,809 : worker.worker : DEBUG : Step 171936, finished rewards 40.68, envs finished 1
2026-01-17 13:37:58,986 : worker.worker : DEBUG : Step 171967, finished rewards -7.96, envs finished 1
2026-01-17 13:37:59,038 : agent.on_policy : DEBUG : Mean Losses: [4.256690099835396]
2026-01-17 13:37:59,059 : worker.worker : DEBUG : Step 171973, finished rewards 23.28, envs finished 1
2026-01-17 13:37:59,128 : worker.worker : DEBUG : Step 171990, finished rewards 1.15, envs finished 1
2026-01-17 13:37:59,208 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:37:59,316 : agent.on_policy : DEBUG : Mean Losses: [3.640952989459038]
2026-01-17 13:37:59,334 : worker.worker : DEBUG : Step 172001, finished rewards 22.07, envs finished 2
2026-01-17 13:37:59,363 : worker.worker : DEBUG : Step 172006, finished rewards 14.03, envs finished 1
2026-01-17 13:37:59,547 : worker.worker : DEBUG : Step 172024, finished rewards 11.62, envs finished 1
2026-01-17 13:37:59,826 : agent.on_policy : DEBUG : Mean Losses: [3.528701950330287]
2026-01-17 13:37:59,882 : worker.worker : DEBUG : Step 172038, finished rewards 20.17, envs finished 1
2026-01-17 13:38:00,100 : agent.on_policy : DEBUG : Mean Losses: [2.6052573919296265]
2026-01-17 13:38:00,137 : worker.worker : DEBUG : Step 172075, finished rewards 29.51, envs finished 1
2026-01-17 13:38:00,203 : worker.worker : DEBUG : Step 172087, finished rewards 15.88, envs finished 1
2026-01-17 13:38:00,376 : agent.on_policy : DEBUG : Mean Losses: [4.997976340353489]
2026-01-17 13:38:00,414 : worker.worker : DEBUG : Step 172107, finished rewards 14.74, envs finished 1
2026-01-17 13:38:00,445 : worker.worker : DEBUG : Step 172114, finished rewards 8.78, envs finished 1
2026-01-17 13:38:00,476 : worker.worker : DEBUG : Step 172122, finished rewards 31.17, envs finished 1
2026-01-17 13:38:00,547 : agent.on_policy : DEBUG : Mean Losses: [7.214604899287224]
2026-01-17 13:38:00,580 : worker.worker : DEBUG : Step 172136, finished rewards -10.05, envs finished 1
2026-01-17 13:38:00,609 : worker.worker : DEBUG : Step 172143, finished rewards 5.87, envs finished 1
2026-01-17 13:38:00,660 : worker.worker : DEBUG : Step 172147, finished rewards -11.98, envs finished 1
2026-01-17 13:38:00,715 : worker.worker : DEBUG : Step 172153, finished rewards 36.31, envs finished 1
2026-01-17 13:38:00,861 : agent.on_policy : DEBUG : Mean Losses: [5.719014581292868]
2026-01-17 13:38:01,130 : agent.on_policy : DEBUG : Mean Losses: [1.0520222280174494]
2026-01-17 13:38:01,160 : worker.worker : DEBUG : Step 172199, finished rewards 26.52, envs finished 2
2026-01-17 13:38:01,216 : worker.worker : DEBUG : Step 172210, finished rewards 6.02, envs finished 1
2026-01-17 13:38:01,253 : worker.worker : DEBUG : Step 172216, finished rewards 40.37, envs finished 1
2026-01-17 13:38:01,425 : agent.on_policy : DEBUG : Mean Losses: [5.431948438286781]
2026-01-17 13:38:01,433 : worker.worker : DEBUG : Step 172225, finished rewards 16.63, envs finished 1
2026-01-17 13:38:01,449 : worker.worker : DEBUG : Step 172228, finished rewards 23.52, envs finished 1
2026-01-17 13:38:01,532 : worker.worker : DEBUG : Step 172236, finished rewards 26.28, envs finished 1
2026-01-17 13:38:01,722 : agent.on_policy : DEBUG : Mean Losses: [3.1044435878284276]
2026-01-17 13:38:01,827 : worker.worker : DEBUG : Step 172270, finished rewards 40.65, envs finished 1
2026-01-17 13:38:01,942 : worker.worker : DEBUG : Step 172284, finished rewards 2.17, envs finished 1
2026-01-17 13:38:02,063 : agent.on_policy : DEBUG : Mean Losses: [3.703249763697386]
2026-01-17 13:38:02,196 : worker.worker : DEBUG : Step 172302, finished rewards 16.99, envs finished 1
2026-01-17 13:38:02,218 : worker.worker : DEBUG : Step 172303, finished rewards 23.67, envs finished 1
2026-01-17 13:38:02,611 : agent.on_policy : DEBUG : Mean Losses: [3.419948760420084]
2026-01-17 13:38:02,705 : worker.worker : DEBUG : Step 172327, finished rewards 16.02, envs finished 2
2026-01-17 13:38:02,983 : agent.on_policy : DEBUG : Mean Losses: [5.786425657570362]
2026-01-17 13:38:02,985 : worker.worker : DEBUG : Step 172352, finished rewards 6.28, envs finished 1
2026-01-17 13:38:03,013 : worker.worker : DEBUG : Step 172355, finished rewards 40.92, envs finished 1
2026-01-17 13:38:03,098 : worker.worker : DEBUG : Step 172365, finished rewards 4.41, envs finished 1
2026-01-17 13:38:03,339 : agent.on_policy : DEBUG : Mean Losses: [4.008509768173099]
2026-01-17 13:38:03,353 : worker.worker : DEBUG : Step 172386, finished rewards 31.44, envs finished 1
2026-01-17 13:38:03,366 : worker.worker : DEBUG : Step 172388, finished rewards 8.27, envs finished 1
2026-01-17 13:38:03,470 : worker.worker : DEBUG : Step 172410, finished rewards 15.87, envs finished 1
2026-01-17 13:38:03,645 : agent.on_policy : DEBUG : Mean Losses: [3.6216310933232307]
2026-01-17 13:38:03,797 : worker.worker : DEBUG : Step 172441, finished rewards 28.13, envs finished 1
2026-01-17 13:38:03,855 : agent.on_policy : DEBUG : Mean Losses: [4.973698526620865]
2026-01-17 13:38:03,885 : worker.worker : DEBUG : Step 172459, finished rewards 23.76, envs finished 1
2026-01-17 13:38:03,891 : worker.worker : DEBUG : Step 172460, finished rewards 12.15, envs finished 1
2026-01-17 13:38:03,912 : worker.worker : DEBUG : Step 172467, finished rewards -8.52, envs finished 1
2026-01-17 13:38:03,938 : worker.worker : DEBUG : Step 172476, finished rewards 25.74, envs finished 1
2026-01-17 13:38:03,983 : agent.on_policy : DEBUG : Mean Losses: [6.925105772912502]
2026-01-17 13:38:03,988 : worker.worker : DEBUG : Step 172481, finished rewards 40.80, envs finished 1
2026-01-17 13:38:04,038 : worker.worker : DEBUG : Step 172496, finished rewards -29.59, envs finished 1
2026-01-17 13:38:04,262 : agent.on_policy : DEBUG : Mean Losses: [2.711424548178911]
2026-01-17 13:38:04,351 : worker.worker : DEBUG : Step 172540, finished rewards 20.15, envs finished 1
2026-01-17 13:38:04,451 : agent.on_policy : DEBUG : Mean Losses: [3.586718834936619]
2026-01-17 13:38:04,498 : worker.worker : DEBUG : Step 172548, finished rewards 39.54, envs finished 1
2026-01-17 13:38:04,647 : worker.worker : DEBUG : Step 172564, finished rewards 21.10, envs finished 1
2026-01-17 13:38:04,661 : worker.worker : DEBUG : Step 172566, finished rewards 15.65, envs finished 1
2026-01-17 13:38:04,761 : worker.worker : DEBUG : Step 172575, finished rewards 24.65, envs finished 1
2026-01-17 13:38:04,890 : agent.on_policy : DEBUG : Mean Losses: [6.442242056131363]
2026-01-17 13:38:05,041 : worker.worker : DEBUG : Step 172601, finished rewards 15.98, envs finished 1
2026-01-17 13:38:05,173 : agent.on_policy : DEBUG : Mean Losses: [3.5821174047887325]
2026-01-17 13:38:05,176 : worker.worker : DEBUG : Step 172608, finished rewards -1.54, envs finished 1
2026-01-17 13:38:05,300 : worker.worker : DEBUG : Step 172624, finished rewards 33.01, envs finished 1
2026-01-17 13:38:05,441 : worker.worker : DEBUG : Step 172639, finished rewards 46.17, envs finished 1
2026-01-17 13:38:05,561 : agent.on_policy : DEBUG : Mean Losses: [4.996804917231202]
2026-01-17 13:38:05,798 : worker.worker : DEBUG : Step 172664, finished rewards 20.56, envs finished 1
2026-01-17 13:38:05,842 : worker.worker : DEBUG : Step 172670, finished rewards 16.82, envs finished 1
2026-01-17 13:38:05,941 : agent.on_policy : DEBUG : Mean Losses: [4.410511266440153]
2026-01-17 13:38:05,944 : worker.worker : DEBUG : Step 172672, finished rewards 46.00, envs finished 1
2026-01-17 13:38:06,119 : worker.worker : DEBUG : Step 172695, finished rewards 41.89, envs finished 1
2026-01-17 13:38:06,214 : agent.on_policy : DEBUG : Mean Losses: [3.985991207882762]
2026-01-17 13:38:06,260 : worker.worker : DEBUG : Step 172712, finished rewards 40.66, envs finished 1
2026-01-17 13:38:06,300 : worker.worker : DEBUG : Step 172715, finished rewards 9.93, envs finished 1
2026-01-17 13:38:06,388 : worker.worker : DEBUG : Step 172727, finished rewards 52.23, envs finished 1
2026-01-17 13:38:06,538 : agent.on_policy : DEBUG : Mean Losses: [4.242817483842373]
2026-01-17 13:38:06,595 : worker.worker : DEBUG : Step 172750, finished rewards 33.97, envs finished 1
2026-01-17 13:38:06,837 : agent.on_policy : DEBUG : Mean Losses: [2.7573227137327194]
2026-01-17 13:38:06,854 : worker.worker : DEBUG : Step 172771, finished rewards 37.30, envs finished 1
2026-01-17 13:38:06,867 : worker.worker : DEBUG : Step 172773, finished rewards 11.01, envs finished 1
2026-01-17 13:38:06,884 : worker.worker : DEBUG : Step 172776, finished rewards 19.53, envs finished 1
2026-01-17 13:38:06,927 : worker.worker : DEBUG : Step 172786, finished rewards 41.92, envs finished 1
2026-01-17 13:38:07,027 : agent.on_policy : DEBUG : Mean Losses: [4.53217448759824]
2026-01-17 13:38:07,033 : worker.worker : DEBUG : Step 172801, finished rewards 26.52, envs finished 1
2026-01-17 13:38:07,161 : worker.worker : DEBUG : Step 172820, finished rewards 25.05, envs finished 1
2026-01-17 13:38:07,200 : worker.worker : DEBUG : Step 172826, finished rewards 35.93, envs finished 1
2026-01-17 13:38:07,389 : agent.on_policy : DEBUG : Mean Losses: [4.225649196654558]
2026-01-17 13:38:07,547 : worker.worker : DEBUG : Step 172847, finished rewards 42.13, envs finished 1
2026-01-17 13:38:07,659 : agent.on_policy : DEBUG : Mean Losses: [3.2574164494872093]
2026-01-17 13:38:07,747 : worker.worker : DEBUG : Step 172876, finished rewards 14.51, envs finished 1
2026-01-17 13:38:07,801 : worker.worker : DEBUG : Step 172884, finished rewards 18.51, envs finished 1
2026-01-17 13:38:07,821 : worker.worker : DEBUG : Step 172886, finished rewards 28.88, envs finished 1
2026-01-17 13:38:07,861 : worker.worker : DEBUG : Step 172889, finished rewards 22.20, envs finished 1
2026-01-17 13:38:08,085 : agent.on_policy : DEBUG : Mean Losses: [9.01417277008295]
2026-01-17 13:38:08,097 : worker.worker : DEBUG : Step 172898, finished rewards 41.56, envs finished 1
2026-01-17 13:38:08,150 : worker.worker : DEBUG : Step 172913, finished rewards 23.55, envs finished 1
2026-01-17 13:38:08,263 : agent.on_policy : DEBUG : Mean Losses: [2.6995598785579205]
2026-01-17 13:38:08,313 : worker.worker : DEBUG : Step 172939, finished rewards -26.60, envs finished 1
2026-01-17 13:38:08,318 : worker.worker : DEBUG : Step 172940, finished rewards 25.38, envs finished 1
2026-01-17 13:38:08,344 : worker.worker : DEBUG : Step 172948, finished rewards 46.21, envs finished 1
2026-01-17 13:38:08,383 : worker.worker : DEBUG : Step 172957, finished rewards 42.19, envs finished 1
2026-01-17 13:38:08,547 : agent.on_policy : DEBUG : Mean Losses: [6.794636055827141]
2026-01-17 13:38:08,565 : worker.worker : DEBUG : Step 172960, finished rewards 42.02, envs finished 1
2026-01-17 13:38:08,602 : worker.worker : DEBUG : Step 172963, finished rewards 27.51, envs finished 1
2026-01-17 13:38:08,684 : worker.worker : DEBUG : Step 172991, finished rewards 25.42, envs finished 1
2026-01-17 13:38:08,725 : agent.on_policy : DEBUG : Mean Losses: [2.1716630291193724]
2026-01-17 13:38:08,748 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:38:08,757 : worker.worker : DEBUG : Step 173000, finished rewards 27.40, envs finished 1
2026-01-17 13:38:08,770 : worker.worker : DEBUG : Step 173004, finished rewards 45.97, envs finished 1
2026-01-17 13:38:08,869 : agent.on_policy : DEBUG : Mean Losses: [4.97438482940197]
2026-01-17 13:38:08,898 : worker.worker : DEBUG : Step 173029, finished rewards 41.38, envs finished 1
2026-01-17 13:38:09,065 : worker.worker : DEBUG : Step 173052, finished rewards 9.48, envs finished 1
2026-01-17 13:38:09,071 : worker.worker : DEBUG : Step 173053, finished rewards 23.64, envs finished 1
2026-01-17 13:38:09,129 : agent.on_policy : DEBUG : Mean Losses: [4.00423501059413]
2026-01-17 13:38:09,143 : worker.worker : DEBUG : Step 173060, finished rewards 10.77, envs finished 1
2026-01-17 13:38:09,366 : agent.on_policy : DEBUG : Mean Losses: [2.7503406777977943]
2026-01-17 13:38:09,375 : worker.worker : DEBUG : Step 173090, finished rewards 3.21, envs finished 1
2026-01-17 13:38:09,465 : worker.worker : DEBUG : Step 173113, finished rewards 4.47, envs finished 1
2026-01-17 13:38:09,473 : worker.worker : DEBUG : Step 173115, finished rewards 7.87, envs finished 1
2026-01-17 13:38:09,613 : agent.on_policy : DEBUG : Mean Losses: [3.5590650141239166]
2026-01-17 13:38:09,630 : worker.worker : DEBUG : Step 173122, finished rewards 8.28, envs finished 1
2026-01-17 13:38:09,873 : worker.worker : DEBUG : Step 173145, finished rewards 7.67, envs finished 1
2026-01-17 13:38:10,138 : agent.on_policy : DEBUG : Mean Losses: [2.995509128086269]
2026-01-17 13:38:10,147 : worker.worker : DEBUG : Step 173152, finished rewards 24.14, envs finished 1
2026-01-17 13:38:10,305 : worker.worker : DEBUG : Step 173166, finished rewards 9.28, envs finished 1
2026-01-17 13:38:10,434 : worker.worker : DEBUG : Step 173177, finished rewards 45.86, envs finished 1
2026-01-17 13:38:10,618 : agent.on_policy : DEBUG : Mean Losses: [5.796690300107002]
2026-01-17 13:38:10,639 : worker.worker : DEBUG : Step 173188, finished rewards -4.68, envs finished 1
2026-01-17 13:38:11,020 : agent.on_policy : DEBUG : Mean Losses: [3.1996620148420334]
2026-01-17 13:38:11,024 : worker.worker : DEBUG : Step 173216, finished rewards 41.35, envs finished 1
2026-01-17 13:38:11,044 : worker.worker : DEBUG : Step 173219, finished rewards -1.46, envs finished 1
2026-01-17 13:38:11,084 : worker.worker : DEBUG : Step 173226, finished rewards 17.12, envs finished 1
2026-01-17 13:38:11,136 : worker.worker : DEBUG : Step 173237, finished rewards 41.68, envs finished 1
2026-01-17 13:38:11,147 : worker.worker : DEBUG : Step 173239, finished rewards 4.57, envs finished 1
2026-01-17 13:38:11,346 : agent.on_policy : DEBUG : Mean Losses: [5.861346140503883]
2026-01-17 13:38:11,406 : worker.worker : DEBUG : Step 173261, finished rewards 30.65, envs finished 1
2026-01-17 13:38:11,441 : worker.worker : DEBUG : Step 173268, finished rewards 7.30, envs finished 1
2026-01-17 13:38:11,682 : agent.on_policy : DEBUG : Mean Losses: [4.302210137248039]
2026-01-17 13:38:11,830 : worker.worker : DEBUG : Step 173302, finished rewards 46.62, envs finished 1
2026-01-17 13:38:11,835 : worker.worker : DEBUG : Step 173303, finished rewards 32.54, envs finished 1
2026-01-17 13:38:11,855 : worker.worker : DEBUG : Step 173307, finished rewards 34.11, envs finished 1
2026-01-17 13:38:11,867 : worker.worker : DEBUG : Step 173309, finished rewards 15.43, envs finished 1
2026-01-17 13:38:11,930 : agent.on_policy : DEBUG : Mean Losses: [7.256884396076202]
2026-01-17 13:38:11,948 : worker.worker : DEBUG : Step 173316, finished rewards 33.59, envs finished 1
2026-01-17 13:38:11,996 : worker.worker : DEBUG : Step 173328, finished rewards 17.08, envs finished 1
2026-01-17 13:38:12,179 : agent.on_policy : DEBUG : Mean Losses: [2.983570158481598]
2026-01-17 13:38:12,202 : worker.worker : DEBUG : Step 173351, finished rewards 31.47, envs finished 1
2026-01-17 13:38:12,341 : agent.on_policy : DEBUG : Mean Losses: [3.4213703349232674]
2026-01-17 13:38:12,381 : worker.worker : DEBUG : Step 173379, finished rewards 40.78, envs finished 1
2026-01-17 13:38:12,496 : worker.worker : DEBUG : Step 173401, finished rewards 19.28, envs finished 1
2026-01-17 13:38:12,507 : worker.worker : DEBUG : Step 173403, finished rewards 18.50, envs finished 1
2026-01-17 13:38:12,528 : worker.worker : DEBUG : Step 173406, finished rewards 19.39, envs finished 1
2026-01-17 13:38:12,652 : agent.on_policy : DEBUG : Mean Losses: [6.586202867329121]
2026-01-17 13:38:12,673 : worker.worker : DEBUG : Step 173411, finished rewards 30.18, envs finished 1
2026-01-17 13:38:12,800 : worker.worker : DEBUG : Step 173422, finished rewards 41.78, envs finished 1
2026-01-17 13:38:12,992 : worker.worker : DEBUG : Step 173438, finished rewards 8.89, envs finished 1
2026-01-17 13:38:13,103 : agent.on_policy : DEBUG : Mean Losses: [4.460768969729543]
2026-01-17 13:38:13,178 : worker.worker : DEBUG : Step 173450, finished rewards 42.28, envs finished 1
2026-01-17 13:38:13,290 : worker.worker : DEBUG : Step 173462, finished rewards -48.85, envs finished 1
2026-01-17 13:38:13,497 : agent.on_policy : DEBUG : Mean Losses: [3.5973485931754112]
2026-01-17 13:38:13,689 : worker.worker : DEBUG : Step 173493, finished rewards 25.46, envs finished 1
2026-01-17 13:38:13,727 : worker.worker : DEBUG : Step 173498, finished rewards 33.40, envs finished 2
2026-01-17 13:38:13,844 : agent.on_policy : DEBUG : Mean Losses: [5.872410777956247]
2026-01-17 13:38:14,037 : worker.worker : DEBUG : Step 173525, finished rewards 7.40, envs finished 1
2026-01-17 13:38:14,052 : worker.worker : DEBUG : Step 173526, finished rewards 3.11, envs finished 1
2026-01-17 13:38:14,120 : worker.worker : DEBUG : Step 173530, finished rewards 25.46, envs finished 1
2026-01-17 13:38:14,224 : agent.on_policy : DEBUG : Mean Losses: [5.55953086540103]
2026-01-17 13:38:14,483 : worker.worker : DEBUG : Step 173566, finished rewards 16.84, envs finished 1
2026-01-17 13:38:14,549 : agent.on_policy : DEBUG : Mean Losses: [3.389742719940841]
2026-01-17 13:38:14,578 : worker.worker : DEBUG : Step 173575, finished rewards -1.05, envs finished 1
2026-01-17 13:38:14,595 : worker.worker : DEBUG : Step 173578, finished rewards 35.10, envs finished 1
2026-01-17 13:38:14,652 : worker.worker : DEBUG : Step 173586, finished rewards 24.51, envs finished 1
2026-01-17 13:38:14,863 : agent.on_policy : DEBUG : Mean Losses: [4.628348231315613]
2026-01-17 13:38:15,079 : worker.worker : DEBUG : Step 173625, finished rewards 9.62, envs finished 2
2026-01-17 13:38:15,153 : worker.worker : DEBUG : Step 173631, finished rewards 12.11, envs finished 1
2026-01-17 13:38:15,217 : agent.on_policy : DEBUG : Mean Losses: [4.909610355272889]
2026-01-17 13:38:15,320 : worker.worker : DEBUG : Step 173645, finished rewards 40.99, envs finished 1
2026-01-17 13:38:15,337 : worker.worker : DEBUG : Step 173647, finished rewards 34.02, envs finished 1
2026-01-17 13:38:15,521 : agent.on_policy : DEBUG : Mean Losses: [4.783816698938608]
2026-01-17 13:38:15,545 : worker.worker : DEBUG : Step 173671, finished rewards 10.18, envs finished 1
2026-01-17 13:38:15,560 : worker.worker : DEBUG : Step 173672, finished rewards 23.05, envs finished 1
2026-01-17 13:38:15,595 : worker.worker : DEBUG : Step 173675, finished rewards 25.60, envs finished 1
2026-01-17 13:38:15,656 : worker.worker : DEBUG : Step 173690, finished rewards 45.39, envs finished 1
2026-01-17 13:38:15,722 : agent.on_policy : DEBUG : Mean Losses: [5.711485635489225]
2026-01-17 13:38:15,904 : worker.worker : DEBUG : Step 173725, finished rewards 24.22, envs finished 1
2026-01-17 13:38:15,967 : agent.on_policy : DEBUG : Mean Losses: [3.404028121381998]
2026-01-17 13:38:15,997 : worker.worker : DEBUG : Step 173735, finished rewards 27.24, envs finished 1
2026-01-17 13:38:16,016 : worker.worker : DEBUG : Step 173739, finished rewards 45.93, envs finished 1
2026-01-17 13:38:16,155 : worker.worker : DEBUG : Step 173755, finished rewards 31.70, envs finished 1
2026-01-17 13:38:16,328 : agent.on_policy : DEBUG : Mean Losses: [6.611105002462864]
2026-01-17 13:38:16,338 : worker.worker : DEBUG : Step 173762, finished rewards 6.77, envs finished 1
2026-01-17 13:38:16,446 : worker.worker : DEBUG : Step 173775, finished rewards 30.98, envs finished 1
2026-01-17 13:38:16,455 : worker.worker : DEBUG : Step 173776, finished rewards -19.25, envs finished 1
2026-01-17 13:38:16,548 : worker.worker : DEBUG : Step 173784, finished rewards 11.96, envs finished 1
2026-01-17 13:38:16,711 : agent.on_policy : DEBUG : Mean Losses: [4.042335029691458]
2026-01-17 13:38:16,884 : worker.worker : DEBUG : Step 173822, finished rewards 29.25, envs finished 1
2026-01-17 13:38:17,000 : agent.on_policy : DEBUG : Mean Losses: [3.4301963038742542]
2026-01-17 13:38:17,015 : worker.worker : DEBUG : Step 173825, finished rewards 46.60, envs finished 1
2026-01-17 13:38:17,114 : worker.worker : DEBUG : Step 173832, finished rewards 14.05, envs finished 1
2026-01-17 13:38:17,274 : worker.worker : DEBUG : Step 173855, finished rewards 42.04, envs finished 1
2026-01-17 13:38:17,397 : agent.on_policy : DEBUG : Mean Losses: [4.914164155721664]
2026-01-17 13:38:17,508 : worker.worker : DEBUG : Step 173868, finished rewards 23.92, envs finished 1
2026-01-17 13:38:17,527 : worker.worker : DEBUG : Step 173871, finished rewards 8.89, envs finished 1
2026-01-17 13:38:17,543 : worker.worker : DEBUG : Step 173873, finished rewards 23.65, envs finished 1
2026-01-17 13:38:17,644 : worker.worker : DEBUG : Step 173884, finished rewards 9.68, envs finished 1
2026-01-17 13:38:17,868 : agent.on_policy : DEBUG : Mean Losses: [4.900077946484089]
2026-01-17 13:38:18,071 : worker.worker : DEBUG : Step 173916, finished rewards 24.06, envs finished 1
2026-01-17 13:38:18,150 : agent.on_policy : DEBUG : Mean Losses: [2.2913915403187275]
2026-01-17 13:38:18,163 : worker.worker : DEBUG : Step 173923, finished rewards 24.53, envs finished 1
2026-01-17 13:38:18,309 : worker.worker : DEBUG : Step 173941, finished rewards 42.81, envs finished 1
2026-01-17 13:38:18,485 : agent.on_policy : DEBUG : Mean Losses: [5.038505911827087]
2026-01-17 13:38:18,488 : worker.worker : DEBUG : Step 173952, finished rewards 21.84, envs finished 1
2026-01-17 13:38:18,508 : worker.worker : DEBUG : Step 173954, finished rewards 29.13, envs finished 1
2026-01-17 13:38:18,565 : worker.worker : DEBUG : Step 173956, finished rewards 7.37, envs finished 1
2026-01-17 13:38:18,616 : worker.worker : DEBUG : Step 173960, finished rewards 27.70, envs finished 1
2026-01-17 13:38:18,699 : worker.worker : DEBUG : Step 173967, finished rewards 31.65, envs finished 1
2026-01-17 13:38:19,030 : agent.on_policy : DEBUG : Mean Losses: [4.20991500094533]
2026-01-17 13:38:19,136 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:38:19,358 : agent.on_policy : DEBUG : Mean Losses: [1.1542467698454857]
2026-01-17 13:38:19,395 : worker.worker : DEBUG : Step 174020, finished rewards 34.12, envs finished 1
2026-01-17 13:38:19,454 : worker.worker : DEBUG : Step 174024, finished rewards 16.18, envs finished 2
2026-01-17 13:38:19,663 : agent.on_policy : DEBUG : Mean Losses: [4.374962478876114]
2026-01-17 13:38:19,691 : worker.worker : DEBUG : Step 174054, finished rewards 28.69, envs finished 1
2026-01-17 13:38:19,703 : worker.worker : DEBUG : Step 174056, finished rewards 21.28, envs finished 1
2026-01-17 13:38:19,753 : worker.worker : DEBUG : Step 174069, finished rewards 13.60, envs finished 1
2026-01-17 13:38:19,802 : worker.worker : DEBUG : Step 174079, finished rewards 1.16, envs finished 1
2026-01-17 13:38:19,921 : agent.on_policy : DEBUG : Mean Losses: [4.242395401000977]
2026-01-17 13:38:19,989 : worker.worker : DEBUG : Step 174092, finished rewards 17.14, envs finished 1
2026-01-17 13:38:20,322 : agent.on_policy : DEBUG : Mean Losses: [3.1340855676680803]
2026-01-17 13:38:20,353 : worker.worker : DEBUG : Step 174116, finished rewards 24.46, envs finished 1
2026-01-17 13:38:20,443 : worker.worker : DEBUG : Step 174134, finished rewards 33.69, envs finished 1
2026-01-17 13:38:19,826 : agent.on_policy : DEBUG : Mean Losses: [5.830071598291397]
2026-01-17 13:38:19,853 : worker.worker : DEBUG : Step 174150, finished rewards 23.17, envs finished 1
2026-01-17 13:38:19,903 : worker.worker : DEBUG : Step 174154, finished rewards -10.17, envs finished 1
2026-01-17 13:38:20,016 : worker.worker : DEBUG : Step 174170, finished rewards -7.67, envs finished 1
2026-01-17 13:38:20,023 : worker.worker : DEBUG : Step 174171, finished rewards 16.38, envs finished 1
2026-01-17 13:38:20,224 : agent.on_policy : DEBUG : Mean Losses: [5.701348215341568]
2026-01-17 13:38:20,282 : worker.worker : DEBUG : Step 174182, finished rewards 18.01, envs finished 1
2026-01-17 13:38:20,336 : worker.worker : DEBUG : Step 174194, finished rewards 28.23, envs finished 1
2026-01-17 13:38:20,555 : agent.on_policy : DEBUG : Mean Losses: [2.7324276603758335]
2026-01-17 13:38:20,793 : agent.on_policy : DEBUG : Mean Losses: [3.833162099123001]
2026-01-17 13:38:20,805 : worker.worker : DEBUG : Step 174242, finished rewards -1.39, envs finished 1
2026-01-17 13:38:20,829 : worker.worker : DEBUG : Step 174246, finished rewards 46.26, envs finished 1
2026-01-17 13:38:20,850 : worker.worker : DEBUG : Step 174250, finished rewards 28.76, envs finished 2
2026-01-17 13:38:20,860 : worker.worker : DEBUG : Step 174251, finished rewards 35.37, envs finished 1
2026-01-17 13:38:20,945 : worker.worker : DEBUG : Step 174266, finished rewards 39.57, envs finished 1
2026-01-17 13:38:20,962 : worker.worker : DEBUG : Step 174268, finished rewards -5.07, envs finished 1
2026-01-17 13:38:20,975 : worker.worker : DEBUG : Step 174269, finished rewards 5.42, envs finished 1
2026-01-17 13:38:21,134 : agent.on_policy : DEBUG : Mean Losses: [7.953153043985367]
2026-01-17 13:38:21,490 : agent.on_policy : DEBUG : Mean Losses: [0.8144454024732113]
2026-01-17 13:38:21,544 : worker.worker : DEBUG : Step 174318, finished rewards 38.35, envs finished 1
2026-01-17 13:38:21,710 : agent.on_policy : DEBUG : Mean Losses: [4.548572592437267]
2026-01-17 13:38:21,721 : worker.worker : DEBUG : Step 174337, finished rewards 40.57, envs finished 1
2026-01-17 13:38:21,749 : worker.worker : DEBUG : Step 174341, finished rewards 24.73, envs finished 1
2026-01-17 13:38:21,764 : worker.worker : DEBUG : Step 174344, finished rewards 19.63, envs finished 1
2026-01-17 13:38:21,838 : worker.worker : DEBUG : Step 174362, finished rewards 23.22, envs finished 1
2026-01-17 13:38:22,000 : agent.on_policy : DEBUG : Mean Losses: [5.086410373449326]
2026-01-17 13:38:22,059 : worker.worker : DEBUG : Step 174377, finished rewards 4.88, envs finished 1
2026-01-17 13:38:22,175 : worker.worker : DEBUG : Step 174396, finished rewards 12.24, envs finished 1
2026-01-17 13:38:22,332 : agent.on_policy : DEBUG : Mean Losses: [2.5206113308668137]
2026-01-17 13:38:22,510 : worker.worker : DEBUG : Step 174418, finished rewards 21.54, envs finished 1
2026-01-17 13:38:22,766 : agent.on_policy : DEBUG : Mean Losses: [4.820131961256266]
2026-01-17 13:38:22,846 : worker.worker : DEBUG : Step 174453, finished rewards 14.91, envs finished 1
2026-01-17 13:38:22,853 : worker.worker : DEBUG : Step 174454, finished rewards 25.03, envs finished 1
2026-01-17 13:38:23,053 : agent.on_policy : DEBUG : Mean Losses: [5.322633467614651]
2026-01-17 13:38:23,062 : worker.worker : DEBUG : Step 174465, finished rewards 43.15, envs finished 1
2026-01-17 13:38:23,076 : worker.worker : DEBUG : Step 174467, finished rewards 0.35, envs finished 1
2026-01-17 13:38:23,270 : worker.worker : DEBUG : Step 174486, finished rewards -18.81, envs finished 1
2026-01-17 13:38:23,434 : agent.on_policy : DEBUG : Mean Losses: [3.6374057419598103]
2026-01-17 13:38:23,502 : worker.worker : DEBUG : Step 174500, finished rewards 7.91, envs finished 1
2026-01-17 13:38:23,533 : worker.worker : DEBUG : Step 174505, finished rewards 72.90, envs finished 1
2026-01-17 13:38:23,685 : worker.worker : DEBUG : Step 174524, finished rewards 16.49, envs finished 1
2026-01-17 13:38:23,815 : agent.on_policy : DEBUG : Mean Losses: [5.194293513894081]
2026-01-17 13:38:23,899 : worker.worker : DEBUG : Step 174536, finished rewards 41.88, envs finished 1
2026-01-17 13:38:23,937 : worker.worker : DEBUG : Step 174543, finished rewards 26.69, envs finished 1
2026-01-17 13:38:23,964 : worker.worker : DEBUG : Step 174546, finished rewards 32.93, envs finished 1
2026-01-17 13:38:24,221 : agent.on_policy : DEBUG : Mean Losses: [4.780623607337475]
2026-01-17 13:38:24,235 : worker.worker : DEBUG : Step 174563, finished rewards 13.15, envs finished 1
2026-01-17 13:38:24,244 : worker.worker : DEBUG : Step 174564, finished rewards 46.15, envs finished 1
2026-01-17 13:38:24,346 : worker.worker : DEBUG : Step 174588, finished rewards 15.39, envs finished 1
2026-01-17 13:38:24,489 : agent.on_policy : DEBUG : Mean Losses: [3.439508756622672]
2026-01-17 13:38:24,512 : worker.worker : DEBUG : Step 174596, finished rewards 35.86, envs finished 1
2026-01-17 13:38:24,732 : agent.on_policy : DEBUG : Mean Losses: [3.7648873403668404]
2026-01-17 13:38:24,742 : worker.worker : DEBUG : Step 174626, finished rewards 34.66, envs finished 1
2026-01-17 13:38:24,751 : worker.worker : DEBUG : Step 174627, finished rewards 13.57, envs finished 1
2026-01-17 13:38:24,759 : worker.worker : DEBUG : Step 174628, finished rewards 46.18, envs finished 1
2026-01-17 13:38:24,768 : worker.worker : DEBUG : Step 174629, finished rewards 22.97, envs finished 1
2026-01-17 13:38:24,937 : agent.on_policy : DEBUG : Mean Losses: [5.692455433309078]
2026-01-17 13:38:25,079 : worker.worker : DEBUG : Step 174666, finished rewards 41.38, envs finished 1
2026-01-17 13:38:25,183 : worker.worker : DEBUG : Step 174678, finished rewards 23.92, envs finished 2
2026-01-17 13:38:25,414 : agent.on_policy : DEBUG : Mean Losses: [6.0819657146930695]
2026-01-17 13:38:25,426 : worker.worker : DEBUG : Step 174690, finished rewards 46.27, envs finished 1
2026-01-17 13:38:25,512 : worker.worker : DEBUG : Step 174696, finished rewards -2.25, envs finished 1
2026-01-17 13:38:25,527 : worker.worker : DEBUG : Step 174698, finished rewards 42.64, envs finished 1
2026-01-17 13:38:25,537 : worker.worker : DEBUG : Step 174699, finished rewards 43.00, envs finished 1
2026-01-17 13:38:25,783 : agent.on_policy : DEBUG : Mean Losses: [4.577067095786333]
2026-01-17 13:38:25,808 : worker.worker : DEBUG : Step 174724, finished rewards 26.73, envs finished 1
2026-01-17 13:38:25,864 : worker.worker : DEBUG : Step 174738, finished rewards 39.50, envs finished 1
2026-01-17 13:38:26,038 : agent.on_policy : DEBUG : Mean Losses: [3.2597313970327377]
2026-01-17 13:38:26,146 : worker.worker : DEBUG : Step 174768, finished rewards 41.01, envs finished 1
2026-01-17 13:38:26,158 : worker.worker : DEBUG : Step 174770, finished rewards 25.83, envs finished 1
2026-01-17 13:38:26,248 : worker.worker : DEBUG : Step 174778, finished rewards 21.81, envs finished 1
2026-01-17 13:38:26,271 : worker.worker : DEBUG : Step 174783, finished rewards 28.28, envs finished 1
2026-01-17 13:38:26,388 : agent.on_policy : DEBUG : Mean Losses: [6.086681172251701]
2026-01-17 13:38:26,410 : worker.worker : DEBUG : Step 174788, finished rewards 21.61, envs finished 1
2026-01-17 13:38:26,556 : worker.worker : DEBUG : Step 174803, finished rewards 36.15, envs finished 1
2026-01-17 13:38:26,717 : agent.on_policy : DEBUG : Mean Losses: [2.5957996640354395]
2026-01-17 13:38:26,796 : worker.worker : DEBUG : Step 174838, finished rewards 21.18, envs finished 1
2026-01-17 13:38:26,817 : worker.worker : DEBUG : Step 174842, finished rewards 45.92, envs finished 1
2026-01-17 13:38:26,977 : agent.on_policy : DEBUG : Mean Losses: [6.291498877108097]
2026-01-17 13:38:26,984 : worker.worker : DEBUG : Step 174848, finished rewards 12.39, envs finished 1
2026-01-17 13:38:27,012 : worker.worker : DEBUG : Step 174852, finished rewards 45.93, envs finished 1
2026-01-17 13:38:27,287 : agent.on_policy : DEBUG : Mean Losses: [3.5891029704362154]
2026-01-17 13:38:27,299 : worker.worker : DEBUG : Step 174882, finished rewards 9.62, envs finished 1
2026-01-17 13:38:27,377 : worker.worker : DEBUG : Step 174898, finished rewards 16.18, envs finished 1
2026-01-17 13:38:27,387 : worker.worker : DEBUG : Step 174899, finished rewards 21.16, envs finished 1
2026-01-17 13:38:27,427 : worker.worker : DEBUG : Step 174906, finished rewards 45.85, envs finished 1
2026-01-17 13:38:27,582 : agent.on_policy : DEBUG : Mean Losses: [7.096165992319584]
2026-01-17 13:38:27,589 : worker.worker : DEBUG : Step 174913, finished rewards 11.39, envs finished 1
2026-01-17 13:38:27,816 : agent.on_policy : DEBUG : Mean Losses: [2.8167462460696697]
2026-01-17 13:38:27,820 : worker.worker : DEBUG : Step 174944, finished rewards 13.90, envs finished 1
2026-01-17 13:38:28,085 : agent.on_policy : DEBUG : Mean Losses: [3.6044380366802216]
2026-01-17 13:38:28,094 : worker.worker : DEBUG : Step 174977, finished rewards 46.05, envs finished 1
2026-01-17 13:38:28,132 : worker.worker : DEBUG : Step 174983, finished rewards 31.03, envs finished 1
2026-01-17 13:38:28,200 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:38:28,212 : worker.worker : INFO : Step 175000, Avg Reward 21.1757, Max Reward 72.8950, Loss [4.49188634]
2026-01-17 13:38:28,217 : worker.worker : DEBUG : Step 175001, finished rewards 16.28, envs finished 1
2026-01-17 13:38:28,223 : worker.worker : DEBUG : Step 175002, finished rewards -10.83, envs finished 1
2026-01-17 13:38:28,364 : agent.on_policy : DEBUG : Mean Losses: [6.067565470933914]
2026-01-17 13:38:28,365 : worker.worker : DEBUG : Step 175008, finished rewards -0.05, envs finished 1
2026-01-17 13:38:28,516 : worker.worker : DEBUG : Step 175024, finished rewards 33.86, envs finished 1
2026-01-17 13:38:28,558 : worker.worker : DEBUG : Step 175028, finished rewards 8.65, envs finished 1
2026-01-17 13:38:28,805 : agent.on_policy : DEBUG : Mean Losses: [3.382507760077715]
2026-01-17 13:38:28,926 : worker.worker : DEBUG : Step 175053, finished rewards 36.04, envs finished 2
2026-01-17 13:38:29,129 : agent.on_policy : DEBUG : Mean Losses: [4.022565390914679]
2026-01-17 13:38:29,135 : worker.worker : DEBUG : Step 175073, finished rewards 21.74, envs finished 1
2026-01-17 13:38:29,297 : worker.worker : DEBUG : Step 175096, finished rewards 39.59, envs finished 1
2026-01-17 13:38:29,311 : worker.worker : DEBUG : Step 175100, finished rewards 41.31, envs finished 1
2026-01-17 13:38:29,368 : agent.on_policy : DEBUG : Mean Losses: [5.875008195638657]
2026-01-17 13:38:29,381 : worker.worker : DEBUG : Step 175107, finished rewards 22.02, envs finished 1
2026-01-17 13:38:29,442 : worker.worker : DEBUG : Step 175123, finished rewards 42.93, envs finished 1
2026-01-17 13:38:29,736 : agent.on_policy : DEBUG : Mean Losses: [2.899257255718112]
2026-01-17 13:38:29,760 : worker.worker : DEBUG : Step 175141, finished rewards 27.82, envs finished 1
2026-01-17 13:38:29,893 : worker.worker : DEBUG : Step 175165, finished rewards 24.75, envs finished 1
2026-01-17 13:38:30,036 : agent.on_policy : DEBUG : Mean Losses: [3.707739941775799]
2026-01-17 13:38:30,122 : worker.worker : DEBUG : Step 175196, finished rewards 19.28, envs finished 1
2026-01-17 13:38:30,299 : agent.on_policy : DEBUG : Mean Losses: [3.0647034011781216]
2026-01-17 13:38:30,348 : worker.worker : DEBUG : Step 175208, finished rewards 18.57, envs finished 1
2026-01-17 13:38:30,352 : worker.worker : DEBUG : Step 175209, finished rewards 99.19, envs finished 1
2026-01-17 13:38:30,525 : worker.worker : DEBUG : Step 175230, finished rewards -2.35, envs finished 1
2026-01-17 13:38:30,583 : agent.on_policy : DEBUG : Mean Losses: [4.602086957544088]
2026-01-17 13:38:30,600 : worker.worker : DEBUG : Step 175236, finished rewards 10.49, envs finished 1
2026-01-17 13:38:30,826 : agent.on_policy : DEBUG : Mean Losses: [2.7784636449068785]
2026-01-17 13:38:30,886 : worker.worker : DEBUG : Step 175270, finished rewards 16.26, envs finished 1
2026-01-17 13:38:31,055 : worker.worker : DEBUG : Step 175287, finished rewards -18.56, envs finished 1
2026-01-17 13:38:31,094 : worker.worker : DEBUG : Step 175292, finished rewards 23.61, envs finished 1
2026-01-17 13:38:31,225 : agent.on_policy : DEBUG : Mean Losses: [4.336205638945103]
2026-01-17 13:38:31,394 : worker.worker : DEBUG : Step 175311, finished rewards 17.91, envs finished 1
2026-01-17 13:38:31,407 : worker.worker : DEBUG : Step 175313, finished rewards 31.75, envs finished 1
2026-01-17 13:38:31,518 : worker.worker : DEBUG : Step 175321, finished rewards 20.74, envs finished 1
2026-01-17 13:38:31,741 : agent.on_policy : DEBUG : Mean Losses: [4.553612496703863]
2026-01-17 13:38:31,753 : worker.worker : DEBUG : Step 175330, finished rewards 23.32, envs finished 1
2026-01-17 13:38:31,809 : worker.worker : DEBUG : Step 175342, finished rewards 39.71, envs finished 1
2026-01-17 13:38:32,078 : agent.on_policy : DEBUG : Mean Losses: [3.099481713026762]
2026-01-17 13:38:32,161 : worker.worker : DEBUG : Step 175382, finished rewards 35.26, envs finished 1
2026-01-17 13:38:32,176 : worker.worker : DEBUG : Step 175385, finished rewards 39.63, envs finished 1
2026-01-17 13:38:32,385 : agent.on_policy : DEBUG : Mean Losses: [5.877819158136845]
2026-01-17 13:38:32,451 : worker.worker : DEBUG : Step 175399, finished rewards 28.20, envs finished 1
2026-01-17 13:38:32,551 : worker.worker : DEBUG : Step 175409, finished rewards 7.72, envs finished 1
2026-01-17 13:38:32,858 : agent.on_policy : DEBUG : Mean Losses: [4.379862431436777]
2026-01-17 13:38:32,985 : worker.worker : DEBUG : Step 175443, finished rewards 18.41, envs finished 1
2026-01-17 13:38:33,063 : worker.worker : DEBUG : Step 175453, finished rewards 42.50, envs finished 1
2026-01-17 13:38:33,200 : agent.on_policy : DEBUG : Mean Losses: [4.468045115470886]
2026-01-17 13:38:33,213 : worker.worker : DEBUG : Step 175458, finished rewards -10.88, envs finished 1
2026-01-17 13:38:33,297 : worker.worker : DEBUG : Step 175465, finished rewards 32.85, envs finished 1
2026-01-17 13:38:33,327 : worker.worker : DEBUG : Step 175470, finished rewards 41.43, envs finished 1
2026-01-17 13:38:33,576 : agent.on_policy : DEBUG : Mean Losses: [4.625509906560183]
2026-01-17 13:38:33,582 : worker.worker : DEBUG : Step 175489, finished rewards -24.05, envs finished 1
2026-01-17 13:38:33,605 : worker.worker : DEBUG : Step 175494, finished rewards 30.93, envs finished 1
2026-01-17 13:38:33,653 : worker.worker : DEBUG : Step 175503, finished rewards 22.34, envs finished 1
2026-01-17 13:38:33,744 : worker.worker : DEBUG : Step 175519, finished rewards 39.07, envs finished 1
2026-01-17 13:38:33,892 : agent.on_policy : DEBUG : Mean Losses: [4.909967590123415]
2026-01-17 13:38:33,968 : worker.worker : DEBUG : Step 175536, finished rewards 42.37, envs finished 1
2026-01-17 13:38:34,061 : worker.worker : DEBUG : Step 175549, finished rewards 33.27, envs finished 1
2026-01-17 13:38:34,189 : agent.on_policy : DEBUG : Mean Losses: [5.396552875638008]
2026-01-17 13:38:34,196 : worker.worker : DEBUG : Step 175553, finished rewards 45.76, envs finished 1
2026-01-17 13:38:34,297 : worker.worker : DEBUG : Step 175561, finished rewards 11.47, envs finished 1
2026-01-17 13:38:34,318 : worker.worker : DEBUG : Step 175564, finished rewards 42.98, envs finished 1
2026-01-17 13:38:34,526 : agent.on_policy : DEBUG : Mean Losses: [4.30522745847702]
2026-01-17 13:38:34,625 : worker.worker : DEBUG : Step 175610, finished rewards 39.89, envs finished 1
2026-01-17 13:38:34,780 : agent.on_policy : DEBUG : Mean Losses: [4.484080426394939]
2026-01-17 13:38:35,045 : worker.worker : DEBUG : Step 175636, finished rewards 51.80, envs finished 2
2026-01-17 13:38:35,099 : worker.worker : DEBUG : Step 175643, finished rewards 83.47, envs finished 1
2026-01-17 13:38:35,275 : agent.on_policy : DEBUG : Mean Losses: [8.179950576275587]
2026-01-17 13:38:35,319 : worker.worker : DEBUG : Step 175653, finished rewards 19.84, envs finished 1
2026-01-17 13:38:35,358 : worker.worker : DEBUG : Step 175655, finished rewards 4.33, envs finished 1
2026-01-17 13:38:35,483 : worker.worker : DEBUG : Step 175678, finished rewards 25.41, envs finished 1
2026-01-17 13:38:35,625 : agent.on_policy : DEBUG : Mean Losses: [4.077429257333279]
2026-01-17 13:38:35,659 : worker.worker : DEBUG : Step 175685, finished rewards 3.86, envs finished 1
2026-01-17 13:38:35,955 : agent.on_policy : DEBUG : Mean Losses: [3.7796634696424007]
2026-01-17 13:38:35,968 : worker.worker : DEBUG : Step 175714, finished rewards 41.67, envs finished 1
2026-01-17 13:38:35,993 : worker.worker : DEBUG : Step 175719, finished rewards 13.30, envs finished 1
2026-01-17 13:38:36,023 : worker.worker : DEBUG : Step 175724, finished rewards 41.54, envs finished 1
2026-01-17 13:38:36,073 : worker.worker : DEBUG : Step 175733, finished rewards 23.13, envs finished 1
2026-01-17 13:38:36,127 : worker.worker : DEBUG : Step 175742, finished rewards 46.06, envs finished 1
2026-01-17 13:38:36,188 : agent.on_policy : DEBUG : Mean Losses: [6.970771282911301]
2026-01-17 13:38:36,226 : worker.worker : DEBUG : Step 175751, finished rewards 8.73, envs finished 1
2026-01-17 13:38:36,313 : worker.worker : DEBUG : Step 175760, finished rewards 17.16, envs finished 1
2026-01-17 13:38:36,537 : agent.on_policy : DEBUG : Mean Losses: [2.8203900400549173]
2026-01-17 13:38:36,761 : agent.on_policy : DEBUG : Mean Losses: [2.8890891298651695]
2026-01-17 13:38:36,766 : worker.worker : DEBUG : Step 175809, finished rewards 5.98, envs finished 1
2026-01-17 13:38:36,779 : worker.worker : DEBUG : Step 175812, finished rewards 23.70, envs finished 1
2026-01-17 13:38:36,792 : worker.worker : DEBUG : Step 175815, finished rewards 46.11, envs finished 1
2026-01-17 13:38:36,825 : worker.worker : DEBUG : Step 175822, finished rewards 21.67, envs finished 1
2026-01-17 13:38:36,859 : worker.worker : DEBUG : Step 175830, finished rewards 6.20, envs finished 1
2026-01-17 13:38:36,893 : worker.worker : DEBUG : Step 175838, finished rewards 15.13, envs finished 1
2026-01-17 13:38:36,954 : agent.on_policy : DEBUG : Mean Losses: [7.6873767003417015]
2026-01-17 13:38:36,974 : worker.worker : DEBUG : Step 175845, finished rewards 15.39, envs finished 1
2026-01-17 13:38:37,044 : worker.worker : DEBUG : Step 175862, finished rewards 21.89, envs finished 1
2026-01-17 13:38:37,207 : agent.on_policy : DEBUG : Mean Losses: [2.199697505682707]
2026-01-17 13:38:37,333 : worker.worker : DEBUG : Step 175889, finished rewards 33.36, envs finished 1
2026-01-17 13:38:37,474 : worker.worker : DEBUG : Step 175902, finished rewards 27.24, envs finished 1
2026-01-17 13:38:37,584 : agent.on_policy : DEBUG : Mean Losses: [4.434800632297993]
2026-01-17 13:38:37,640 : worker.worker : DEBUG : Step 175911, finished rewards 18.87, envs finished 1
2026-01-17 13:38:37,853 : agent.on_policy : DEBUG : Mean Losses: [3.7478941194713116]
2026-01-17 13:38:37,871 : worker.worker : DEBUG : Step 175940, finished rewards 22.48, envs finished 1
2026-01-17 13:38:37,901 : worker.worker : DEBUG : Step 175946, finished rewards 15.96, envs finished 1
2026-01-17 13:38:37,939 : worker.worker : DEBUG : Step 175953, finished rewards 29.37, envs finished 1
2026-01-17 13:38:37,947 : worker.worker : DEBUG : Step 175955, finished rewards -3.74, envs finished 1
2026-01-17 13:38:37,971 : worker.worker : DEBUG : Step 175959, finished rewards 2.34, envs finished 1
2026-01-17 13:38:38,062 : agent.on_policy : DEBUG : Mean Losses: [5.842347323894501]
2026-01-17 13:38:38,204 : worker.worker : DEBUG : Step 175993, finished rewards 16.79, envs finished 1
2026-01-17 13:38:38,219 : worker.worker : DEBUG : Step 175995, finished rewards 31.73, envs finished 1
2026-01-17 13:38:38,244 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:38:38,395 : agent.on_policy : DEBUG : Mean Losses: [3.607886664569378]
2026-01-17 13:38:38,537 : worker.worker : DEBUG : Step 176016, finished rewards 41.04, envs finished 1
2026-01-17 13:38:38,837 : agent.on_policy : DEBUG : Mean Losses: [3.320028431713581]
2026-01-17 13:38:38,887 : worker.worker : DEBUG : Step 176042, finished rewards 51.99, envs finished 1
2026-01-17 13:38:39,002 : worker.worker : DEBUG : Step 176051, finished rewards 11.20, envs finished 1
2026-01-17 13:38:39,048 : worker.worker : DEBUG : Step 176059, finished rewards 17.67, envs finished 1
2026-01-17 13:38:39,182 : agent.on_policy : DEBUG : Mean Losses: [5.9707885310053825]
2026-01-17 13:38:39,323 : worker.worker : DEBUG : Step 176083, finished rewards 22.15, envs finished 2
2026-01-17 13:38:39,427 : agent.on_policy : DEBUG : Mean Losses: [3.8444183468818665]
2026-01-17 13:38:39,438 : worker.worker : DEBUG : Step 176098, finished rewards 24.75, envs finished 2
2026-01-17 13:38:39,601 : worker.worker : DEBUG : Step 176117, finished rewards 37.08, envs finished 1
2026-01-17 13:38:39,798 : agent.on_policy : DEBUG : Mean Losses: [4.053052710369229]
2026-01-17 13:38:39,808 : worker.worker : DEBUG : Step 176130, finished rewards 40.38, envs finished 1
2026-01-17 13:38:39,828 : worker.worker : DEBUG : Step 176133, finished rewards 32.70, envs finished 1
2026-01-17 13:38:39,932 : worker.worker : DEBUG : Step 176146, finished rewards 46.73, envs finished 1
2026-01-17 13:38:40,051 : worker.worker : DEBUG : Step 176154, finished rewards 40.46, envs finished 1
2026-01-17 13:38:40,225 : agent.on_policy : DEBUG : Mean Losses: [6.841585787013173]
2026-01-17 13:38:40,306 : worker.worker : DEBUG : Step 176177, finished rewards 35.94, envs finished 1
2026-01-17 13:38:40,385 : worker.worker : DEBUG : Step 176183, finished rewards -1.94, envs finished 1
2026-01-17 13:38:40,594 : agent.on_policy : DEBUG : Mean Losses: [4.075857006013393]
2026-01-17 13:38:40,647 : worker.worker : DEBUG : Step 176203, finished rewards 15.42, envs finished 1
2026-01-17 13:38:40,691 : worker.worker : DEBUG : Step 176212, finished rewards 33.57, envs finished 1
2026-01-17 13:38:40,732 : worker.worker : DEBUG : Step 176219, finished rewards 29.36, envs finished 1
2026-01-17 13:38:40,772 : worker.worker : DEBUG : Step 176223, finished rewards 14.30, envs finished 1
2026-01-17 13:38:40,876 : agent.on_policy : DEBUG : Mean Losses: [4.383671937510371]
2026-01-17 13:38:40,924 : worker.worker : DEBUG : Step 176233, finished rewards 32.75, envs finished 1
2026-01-17 13:38:41,029 : worker.worker : DEBUG : Step 176239, finished rewards 23.71, envs finished 1
2026-01-17 13:38:41,210 : agent.on_policy : DEBUG : Mean Losses: [3.2952797915786505]
2026-01-17 13:38:41,397 : worker.worker : DEBUG : Step 176283, finished rewards 41.53, envs finished 1
2026-01-17 13:38:41,487 : agent.on_policy : DEBUG : Mean Losses: [4.017478205263615]
2026-01-17 13:38:41,496 : worker.worker : DEBUG : Step 176289, finished rewards 13.94, envs finished 1
2026-01-17 13:38:41,517 : worker.worker : DEBUG : Step 176292, finished rewards 5.66, envs finished 1
2026-01-17 13:38:41,546 : worker.worker : DEBUG : Step 176296, finished rewards 25.45, envs finished 1
2026-01-17 13:38:41,704 : worker.worker : DEBUG : Step 176310, finished rewards 27.28, envs finished 1
2026-01-17 13:38:41,861 : agent.on_policy : DEBUG : Mean Losses: [4.6113419234752655]
2026-01-17 13:38:41,866 : worker.worker : DEBUG : Step 176321, finished rewards 27.47, envs finished 1
2026-01-17 13:38:41,970 : worker.worker : DEBUG : Step 176345, finished rewards 14.63, envs finished 1
2026-01-17 13:38:42,113 : agent.on_policy : DEBUG : Mean Losses: [2.8266118615865707]
2026-01-17 13:38:42,264 : worker.worker : DEBUG : Step 176374, finished rewards -24.80, envs finished 1
2026-01-17 13:38:42,556 : agent.on_policy : DEBUG : Mean Losses: [3.7955327928066254]
2026-01-17 13:38:42,573 : worker.worker : DEBUG : Step 176387, finished rewards 24.13, envs finished 1
2026-01-17 13:38:42,588 : worker.worker : DEBUG : Step 176388, finished rewards 23.85, envs finished 1
2026-01-17 13:38:42,696 : worker.worker : DEBUG : Step 176397, finished rewards 16.00, envs finished 1
2026-01-17 13:38:42,839 : worker.worker : DEBUG : Step 176410, finished rewards 20.44, envs finished 1
2026-01-17 13:38:43,006 : agent.on_policy : DEBUG : Mean Losses: [5.093807261437178]
2026-01-17 13:38:43,074 : worker.worker : DEBUG : Step 176425, finished rewards 27.60, envs finished 1
2026-01-17 13:38:43,199 : worker.worker : DEBUG : Step 176437, finished rewards 24.86, envs finished 1
2026-01-17 13:38:43,512 : agent.on_policy : DEBUG : Mean Losses: [3.0384718105196953]
2026-01-17 13:38:43,548 : worker.worker : DEBUG : Step 176452, finished rewards -26.31, envs finished 1
2026-01-17 13:38:43,637 : worker.worker : DEBUG : Step 176459, finished rewards 29.39, envs finished 1
2026-01-17 13:38:43,780 : worker.worker : DEBUG : Step 176474, finished rewards 29.03, envs finished 1
2026-01-17 13:38:43,955 : agent.on_policy : DEBUG : Mean Losses: [3.908012866973877]
2026-01-17 13:38:44,024 : worker.worker : DEBUG : Step 176495, finished rewards 23.27, envs finished 1
2026-01-17 13:38:44,032 : worker.worker : DEBUG : Step 176496, finished rewards 14.25, envs finished 1
2026-01-17 13:38:44,235 : agent.on_policy : DEBUG : Mean Losses: [4.672506757080555]
2026-01-17 13:38:44,240 : worker.worker : DEBUG : Step 176513, finished rewards 38.99, envs finished 1
2026-01-17 13:38:44,430 : worker.worker : DEBUG : Step 176537, finished rewards 12.11, envs finished 1
2026-01-17 13:38:44,437 : worker.worker : DEBUG : Step 176538, finished rewards 28.53, envs finished 1
2026-01-17 13:38:44,511 : agent.on_policy : DEBUG : Mean Losses: [4.322444666177034]
2026-01-17 13:38:44,581 : worker.worker : DEBUG : Step 176559, finished rewards -18.60, envs finished 1
2026-01-17 13:38:44,624 : worker.worker : DEBUG : Step 176562, finished rewards 27.94, envs finished 1
2026-01-17 13:38:44,681 : worker.worker : DEBUG : Step 176568, finished rewards 14.13, envs finished 1
2026-01-17 13:38:44,889 : agent.on_policy : DEBUG : Mean Losses: [5.24866759032011]
2026-01-17 13:38:44,957 : worker.worker : DEBUG : Step 176592, finished rewards 21.48, envs finished 1
2026-01-17 13:38:44,983 : worker.worker : DEBUG : Step 176597, finished rewards 31.73, envs finished 1
2026-01-17 13:38:45,000 : worker.worker : DEBUG : Step 176601, finished rewards 46.53, envs finished 1
2026-01-17 13:38:45,030 : worker.worker : DEBUG : Step 176606, finished rewards 10.05, envs finished 1
2026-01-17 13:38:45,147 : agent.on_policy : DEBUG : Mean Losses: [6.818136032670736]
2026-01-17 13:38:45,305 : worker.worker : DEBUG : Step 176632, finished rewards 46.04, envs finished 1
2026-01-17 13:38:45,450 : agent.on_policy : DEBUG : Mean Losses: [3.6920174099504948]
2026-01-17 13:38:45,507 : worker.worker : DEBUG : Step 176653, finished rewards 24.91, envs finished 1
2026-01-17 13:38:45,536 : worker.worker : DEBUG : Step 176661, finished rewards 46.11, envs finished 1
2026-01-17 13:38:45,725 : agent.on_policy : DEBUG : Mean Losses: [5.368957668542862]
2026-01-17 13:38:45,733 : worker.worker : DEBUG : Step 176673, finished rewards 10.91, envs finished 1
2026-01-17 13:38:45,864 : worker.worker : DEBUG : Step 176690, finished rewards 29.85, envs finished 2
2026-01-17 13:38:45,915 : worker.worker : DEBUG : Step 176694, finished rewards 18.15, envs finished 1
2026-01-17 13:38:46,105 : agent.on_policy : DEBUG : Mean Losses: [4.690254107117653]
2026-01-17 13:38:46,107 : worker.worker : DEBUG : Step 176704, finished rewards 39.55, envs finished 1
2026-01-17 13:38:46,192 : worker.worker : DEBUG : Step 176723, finished rewards -28.94, envs finished 1
2026-01-17 13:38:46,247 : worker.worker : DEBUG : Step 176732, finished rewards 40.73, envs finished 1
2026-01-17 13:38:46,272 : worker.worker : DEBUG : Step 176734, finished rewards 34.28, envs finished 1
2026-01-17 13:38:46,395 : agent.on_policy : DEBUG : Mean Losses: [4.954452212899923]
2026-01-17 13:38:46,569 : worker.worker : DEBUG : Step 176761, finished rewards 40.91, envs finished 1
2026-01-17 13:38:46,578 : worker.worker : DEBUG : Step 176762, finished rewards 40.18, envs finished 1
2026-01-17 13:38:46,663 : agent.on_policy : DEBUG : Mean Losses: [5.44217574596405]
2026-01-17 13:38:46,668 : worker.worker : DEBUG : Step 176769, finished rewards 20.47, envs finished 1
2026-01-17 13:38:46,884 : worker.worker : DEBUG : Step 176795, finished rewards 39.65, envs finished 1
2026-01-17 13:38:46,951 : worker.worker : DEBUG : Step 176798, finished rewards 19.00, envs finished 1
2026-01-17 13:38:47,049 : agent.on_policy : DEBUG : Mean Losses: [3.6168872751295567]
2026-01-17 13:38:47,079 : worker.worker : DEBUG : Step 176807, finished rewards 16.86, envs finished 1
2026-01-17 13:38:47,353 : agent.on_policy : DEBUG : Mean Losses: [2.2901602163910866]
2026-01-17 13:38:47,372 : worker.worker : DEBUG : Step 176837, finished rewards 16.82, envs finished 1
2026-01-17 13:38:47,427 : worker.worker : DEBUG : Step 176854, finished rewards 24.47, envs finished 1
2026-01-17 13:38:47,431 : worker.worker : DEBUG : Step 176855, finished rewards 7.96, envs finished 1
2026-01-17 13:38:47,516 : agent.on_policy : DEBUG : Mean Losses: [4.341178521513939]
2026-01-17 13:38:47,558 : worker.worker : DEBUG : Step 176867, finished rewards 15.02, envs finished 1
2026-01-17 13:38:47,820 : agent.on_policy : DEBUG : Mean Losses: [3.423044053837657]
2026-01-17 13:38:47,829 : worker.worker : DEBUG : Step 176898, finished rewards 25.19, envs finished 1
2026-01-17 13:38:47,835 : worker.worker : DEBUG : Step 176899, finished rewards 0.95, envs finished 1
2026-01-17 13:38:47,929 : worker.worker : DEBUG : Step 176924, finished rewards 4.73, envs finished 1
2026-01-17 13:38:47,939 : worker.worker : DEBUG : Step 176926, finished rewards 41.25, envs finished 1
2026-01-17 13:38:48,083 : agent.on_policy : DEBUG : Mean Losses: [5.273807138204575]
2026-01-17 13:38:48,138 : worker.worker : DEBUG : Step 176941, finished rewards 16.34, envs finished 1
2026-01-17 13:38:48,150 : worker.worker : DEBUG : Step 176942, finished rewards -7.23, envs finished 1
2026-01-17 13:38:48,224 : worker.worker : DEBUG : Step 176946, finished rewards 25.23, envs finished 1
2026-01-17 13:38:48,413 : agent.on_policy : DEBUG : Mean Losses: [3.588050997816026]
2026-01-17 13:38:48,451 : worker.worker : DEBUG : Step 176969, finished rewards 17.63, envs finished 1
2026-01-17 13:38:48,793 : agent.on_policy : DEBUG : Mean Losses: [2.3449418619275093]
2026-01-17 13:38:48,813 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:38:48,867 : worker.worker : DEBUG : Step 177014, finished rewards 26.20, envs finished 1
2026-01-17 13:38:48,889 : worker.worker : DEBUG : Step 177019, finished rewards 6.59, envs finished 1
2026-01-17 13:38:48,970 : agent.on_policy : DEBUG : Mean Losses: [5.494315266609192]
2026-01-17 13:38:49,021 : worker.worker : DEBUG : Step 177026, finished rewards 18.94, envs finished 1
2026-01-17 13:38:49,069 : worker.worker : DEBUG : Step 177033, finished rewards 25.41, envs finished 1
2026-01-17 13:38:49,125 : worker.worker : DEBUG : Step 177038, finished rewards 21.62, envs finished 1
2026-01-17 13:38:49,149 : worker.worker : DEBUG : Step 177039, finished rewards -6.70, envs finished 1
2026-01-17 13:38:49,271 : worker.worker : DEBUG : Step 177053, finished rewards 29.54, envs finished 1
2026-01-17 13:38:49,367 : agent.on_policy : DEBUG : Mean Losses: [6.7339978204108775]
2026-01-17 13:38:49,477 : worker.worker : DEBUG : Step 177070, finished rewards 3.93, envs finished 1
2026-01-17 13:38:49,663 : agent.on_policy : DEBUG : Mean Losses: [1.3537145275622606]
2026-01-17 13:38:49,707 : worker.worker : DEBUG : Step 177098, finished rewards 34.28, envs finished 1
2026-01-17 13:38:49,019 : worker.worker : DEBUG : Step 177115, finished rewards 32.13, envs finished 1
2026-01-17 13:38:49,109 : agent.on_policy : DEBUG : Mean Losses: [4.592712014913559]
2026-01-17 13:38:49,115 : worker.worker : DEBUG : Step 177121, finished rewards 24.16, envs finished 1
2026-01-17 13:38:49,130 : worker.worker : DEBUG : Step 177124, finished rewards 28.52, envs finished 1
2026-01-17 13:38:49,196 : worker.worker : DEBUG : Step 177132, finished rewards 25.36, envs finished 1
2026-01-17 13:38:49,552 : agent.on_policy : DEBUG : Mean Losses: [4.674576010555029]
2026-01-17 13:38:49,792 : agent.on_policy : DEBUG : Mean Losses: [2.947770118713379]
2026-01-17 13:38:49,795 : worker.worker : DEBUG : Step 177184, finished rewards -1.70, envs finished 1
2026-01-17 13:38:49,834 : worker.worker : DEBUG : Step 177192, finished rewards 42.07, envs finished 1
2026-01-17 13:38:49,852 : worker.worker : DEBUG : Step 177196, finished rewards 34.05, envs finished 1
2026-01-17 13:38:49,866 : worker.worker : DEBUG : Step 177198, finished rewards 19.40, envs finished 1
2026-01-17 13:38:49,894 : worker.worker : DEBUG : Step 177203, finished rewards 53.47, envs finished 1
2026-01-17 13:38:49,931 : worker.worker : DEBUG : Step 177211, finished rewards 28.28, envs finished 1
2026-01-17 13:38:49,949 : worker.worker : DEBUG : Step 177214, finished rewards 54.51, envs finished 1
2026-01-17 13:38:50,018 : agent.on_policy : DEBUG : Mean Losses: [7.678599625825882]
2026-01-17 13:38:50,054 : worker.worker : DEBUG : Step 177223, finished rewards 33.73, envs finished 1
2026-01-17 13:38:50,421 : agent.on_policy : DEBUG : Mean Losses: [1.8279476799070835]
2026-01-17 13:38:50,445 : worker.worker : DEBUG : Step 177255, finished rewards 42.27, envs finished 1
2026-01-17 13:38:50,608 : worker.worker : DEBUG : Step 177278, finished rewards 45.80, envs finished 1
2026-01-17 13:38:50,657 : agent.on_policy : DEBUG : Mean Losses: [5.419463932514191]
2026-01-17 13:38:50,659 : worker.worker : DEBUG : Step 177280, finished rewards 31.42, envs finished 1
2026-01-17 13:38:50,667 : worker.worker : DEBUG : Step 177282, finished rewards 40.77, envs finished 1
2026-01-17 13:38:50,683 : worker.worker : DEBUG : Step 177285, finished rewards 27.80, envs finished 1
2026-01-17 13:38:50,693 : worker.worker : DEBUG : Step 177287, finished rewards 33.67, envs finished 1
2026-01-17 13:38:50,726 : worker.worker : DEBUG : Step 177294, finished rewards 26.16, envs finished 1
2026-01-17 13:38:50,884 : agent.on_policy : DEBUG : Mean Losses: [3.754062071442604]
2026-01-17 13:38:51,198 : agent.on_policy : DEBUG : Mean Losses: [3.5199485011398792]
2026-01-17 13:38:51,227 : worker.worker : DEBUG : Step 177352, finished rewards 42.13, envs finished 1
2026-01-17 13:38:51,273 : worker.worker : DEBUG : Step 177364, finished rewards -12.29, envs finished 1
2026-01-17 13:38:51,512 : agent.on_policy : DEBUG : Mean Losses: [6.020436555147171]
2026-01-17 13:38:51,561 : worker.worker : DEBUG : Step 177379, finished rewards 0.40, envs finished 1
2026-01-17 13:38:51,600 : worker.worker : DEBUG : Step 177382, finished rewards 32.56, envs finished 1
2026-01-17 13:38:51,689 : worker.worker : DEBUG : Step 177402, finished rewards 8.38, envs finished 1
2026-01-17 13:38:51,707 : worker.worker : DEBUG : Step 177406, finished rewards 13.71, envs finished 1
2026-01-17 13:38:51,832 : agent.on_policy : DEBUG : Mean Losses: [5.925412535667419]
2026-01-17 13:38:51,835 : worker.worker : DEBUG : Step 177408, finished rewards 10.95, envs finished 1
2026-01-17 13:38:52,026 : worker.worker : DEBUG : Step 177438, finished rewards -21.36, envs finished 1
2026-01-17 13:38:52,201 : agent.on_policy : DEBUG : Mean Losses: [2.725096672773361]
2026-01-17 13:38:52,387 : worker.worker : DEBUG : Step 177461, finished rewards 32.17, envs finished 1
2026-01-17 13:38:52,497 : worker.worker : DEBUG : Step 177470, finished rewards 3.94, envs finished 1
2026-01-17 13:38:52,671 : agent.on_policy : DEBUG : Mean Losses: [4.789088286459446]
2026-01-17 13:38:52,679 : worker.worker : DEBUG : Step 177473, finished rewards 11.94, envs finished 1
2026-01-17 13:38:52,701 : worker.worker : DEBUG : Step 177476, finished rewards 24.96, envs finished 1
2026-01-17 13:38:52,867 : worker.worker : DEBUG : Step 177503, finished rewards 23.87, envs finished 1
2026-01-17 13:38:52,947 : agent.on_policy : DEBUG : Mean Losses: [3.3667262718081474]
2026-01-17 13:38:52,974 : worker.worker : DEBUG : Step 177508, finished rewards 16.66, envs finished 1
2026-01-17 13:38:53,207 : worker.worker : DEBUG : Step 177533, finished rewards 23.29, envs finished 2
2026-01-17 13:38:53,289 : agent.on_policy : DEBUG : Mean Losses: [5.766371006146073]
2026-01-17 13:38:53,538 : agent.on_policy : DEBUG : Mean Losses: [3.889692470431328]
2026-01-17 13:38:53,540 : worker.worker : DEBUG : Step 177568, finished rewards 24.11, envs finished 1
2026-01-17 13:38:53,564 : worker.worker : DEBUG : Step 177574, finished rewards 16.48, envs finished 1
2026-01-17 13:38:53,575 : worker.worker : DEBUG : Step 177576, finished rewards 2.39, envs finished 1
2026-01-17 13:38:53,586 : worker.worker : DEBUG : Step 177578, finished rewards 17.48, envs finished 1
2026-01-17 13:38:53,594 : worker.worker : DEBUG : Step 177579, finished rewards 41.50, envs finished 1
2026-01-17 13:38:53,726 : agent.on_policy : DEBUG : Mean Losses: [5.173715814948082]
2026-01-17 13:38:53,860 : worker.worker : DEBUG : Step 177618, finished rewards 6.60, envs finished 1
2026-01-17 13:38:54,050 : agent.on_policy : DEBUG : Mean Losses: [3.0667736250907183]
2026-01-17 13:38:54,053 : worker.worker : DEBUG : Step 177632, finished rewards 45.80, envs finished 1
2026-01-17 13:38:54,125 : worker.worker : DEBUG : Step 177649, finished rewards 41.44, envs finished 1
2026-01-17 13:38:54,183 : worker.worker : DEBUG : Step 177663, finished rewards 26.44, envs finished 1
2026-01-17 13:38:54,348 : agent.on_policy : DEBUG : Mean Losses: [4.743007622659206]
2026-01-17 13:38:54,365 : worker.worker : DEBUG : Step 177668, finished rewards -0.70, envs finished 1
2026-01-17 13:38:54,381 : worker.worker : DEBUG : Step 177671, finished rewards -6.65, envs finished 1
2026-01-17 13:38:54,494 : worker.worker : DEBUG : Step 177682, finished rewards 16.32, envs finished 1
2026-01-17 13:38:54,604 : worker.worker : DEBUG : Step 177692, finished rewards 9.52, envs finished 1
2026-01-17 13:38:54,682 : agent.on_policy : DEBUG : Mean Losses: [5.197390664368868]
2026-01-17 13:38:54,879 : worker.worker : DEBUG : Step 177716, finished rewards 31.37, envs finished 1
2026-01-17 13:38:55,159 : agent.on_policy : DEBUG : Mean Losses: [2.5049731442704797]
2026-01-17 13:38:55,179 : worker.worker : DEBUG : Step 177732, finished rewards 31.98, envs finished 1
2026-01-17 13:38:55,202 : worker.worker : DEBUG : Step 177733, finished rewards 16.53, envs finished 1
2026-01-17 13:38:55,312 : worker.worker : DEBUG : Step 177751, finished rewards 30.97, envs finished 2
2026-01-17 13:38:55,346 : worker.worker : DEBUG : Step 177756, finished rewards 36.31, envs finished 2
2026-01-17 13:38:55,507 : agent.on_policy : DEBUG : Mean Losses: [8.386798672378063]
2026-01-17 13:38:55,786 : worker.worker : DEBUG : Step 177782, finished rewards 20.08, envs finished 1
2026-01-17 13:38:55,910 : agent.on_policy : DEBUG : Mean Losses: [1.4809961132705212]
2026-01-17 13:38:56,013 : worker.worker : DEBUG : Step 177803, finished rewards 28.56, envs finished 1
2026-01-17 13:38:56,187 : worker.worker : DEBUG : Step 177817, finished rewards 31.83, envs finished 1
2026-01-17 13:38:56,372 : agent.on_policy : DEBUG : Mean Losses: [4.0752023458480835]
2026-01-17 13:38:56,389 : worker.worker : DEBUG : Step 177826, finished rewards 23.15, envs finished 1
2026-01-17 13:38:56,536 : worker.worker : DEBUG : Step 177839, finished rewards 31.90, envs finished 1
2026-01-17 13:38:56,599 : worker.worker : DEBUG : Step 177843, finished rewards 24.38, envs finished 1
2026-01-17 13:38:56,654 : worker.worker : DEBUG : Step 177849, finished rewards 24.46, envs finished 1
2026-01-17 13:38:56,671 : worker.worker : DEBUG : Step 177851, finished rewards 20.11, envs finished 1
2026-01-17 13:38:56,684 : worker.worker : DEBUG : Step 177852, finished rewards 40.91, envs finished 1
2026-01-17 13:38:56,835 : agent.on_policy : DEBUG : Mean Losses: [8.1767911426723]
2026-01-17 13:38:56,949 : worker.worker : DEBUG : Step 177867, finished rewards 45.84, envs finished 1
2026-01-17 13:38:57,202 : agent.on_policy : DEBUG : Mean Losses: [2.157397050410509]
2026-01-17 13:38:57,287 : worker.worker : DEBUG : Step 177907, finished rewards 26.19, envs finished 1
2026-01-17 13:38:57,334 : worker.worker : DEBUG : Step 177915, finished rewards 39.82, envs finished 1
2026-01-17 13:38:57,352 : worker.worker : DEBUG : Step 177917, finished rewards 25.25, envs finished 1
2026-01-17 13:38:57,542 : agent.on_policy : DEBUG : Mean Losses: [4.769028179347515]
2026-01-17 13:38:57,876 : agent.on_policy : DEBUG : Mean Losses: [3.6953473910689354]
2026-01-17 13:38:57,904 : worker.worker : DEBUG : Step 177956, finished rewards 26.61, envs finished 1
2026-01-17 13:38:57,963 : worker.worker : DEBUG : Step 177963, finished rewards 13.30, envs finished 1
2026-01-17 13:38:58,150 : worker.worker : DEBUG : Step 177980, finished rewards 1.63, envs finished 1
2026-01-17 13:38:58,170 : worker.worker : DEBUG : Step 177981, finished rewards -4.67, envs finished 1
2026-01-17 13:38:58,306 : agent.on_policy : DEBUG : Mean Losses: [5.891299810260534]
2026-01-17 13:38:58,321 : worker.worker : DEBUG : Step 177985, finished rewards 41.25, envs finished 1
2026-01-17 13:38:58,484 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:38:58,782 : agent.on_policy : DEBUG : Mean Losses: [2.0323277451097965]
2026-01-17 13:38:58,833 : worker.worker : DEBUG : Step 178020, finished rewards 27.77, envs finished 2
2026-01-17 13:38:58,845 : worker.worker : DEBUG : Step 178021, finished rewards 16.30, envs finished 1
2026-01-17 13:38:59,015 : worker.worker : DEBUG : Step 178040, finished rewards 57.07, envs finished 1
2026-01-17 13:38:59,048 : worker.worker : DEBUG : Step 178044, finished rewards 45.83, envs finished 1
2026-01-17 13:38:59,152 : agent.on_policy : DEBUG : Mean Losses: [7.335732534527779]
2026-01-17 13:38:59,173 : worker.worker : DEBUG : Step 178050, finished rewards 26.93, envs finished 1
2026-01-17 13:38:59,346 : worker.worker : DEBUG : Step 178064, finished rewards 32.54, envs finished 1
2026-01-17 13:38:59,789 : agent.on_policy : DEBUG : Mean Losses: [2.7597300484776497]
2026-01-17 13:38:59,938 : worker.worker : DEBUG : Step 178095, finished rewards 12.06, envs finished 1
2026-01-17 13:39:00,059 : worker.worker : DEBUG : Step 178109, finished rewards 27.10, envs finished 1
2026-01-17 13:39:00,237 : agent.on_policy : DEBUG : Mean Losses: [5.007909711450338]
2026-01-17 13:39:00,251 : worker.worker : DEBUG : Step 178115, finished rewards 30.58, envs finished 2
2026-01-17 13:39:00,444 : worker.worker : DEBUG : Step 178135, finished rewards 41.26, envs finished 1
2026-01-17 13:39:00,642 : agent.on_policy : DEBUG : Mean Losses: [6.195794351398945]
2026-01-17 13:39:00,712 : worker.worker : DEBUG : Step 178161, finished rewards 1.11, envs finished 1
2026-01-17 13:39:00,924 : agent.on_policy : DEBUG : Mean Losses: [4.044075675308704]
2026-01-17 13:39:00,940 : worker.worker : DEBUG : Step 178180, finished rewards 2.85, envs finished 1
2026-01-17 13:39:00,951 : worker.worker : DEBUG : Step 178182, finished rewards 27.33, envs finished 1
2026-01-17 13:39:01,010 : worker.worker : DEBUG : Step 178194, finished rewards 3.22, envs finished 2
2026-01-17 13:39:01,061 : worker.worker : DEBUG : Step 178205, finished rewards 43.07, envs finished 1
2026-01-17 13:39:01,070 : worker.worker : DEBUG : Step 178206, finished rewards 25.07, envs finished 1
2026-01-17 13:39:01,237 : agent.on_policy : DEBUG : Mean Losses: [6.8984657153487206]
2026-01-17 13:39:01,252 : worker.worker : DEBUG : Step 178210, finished rewards 22.21, envs finished 1
2026-01-17 13:39:01,556 : agent.on_policy : DEBUG : Mean Losses: [1.2535342425107956]
2026-01-17 13:39:01,664 : worker.worker : DEBUG : Step 178266, finished rewards 39.76, envs finished 1
2026-01-17 13:39:01,869 : agent.on_policy : DEBUG : Mean Losses: [4.482467815279961]
2026-01-17 13:39:01,877 : worker.worker : DEBUG : Step 178272, finished rewards 25.96, envs finished 2
2026-01-17 13:39:01,984 : worker.worker : DEBUG : Step 178282, finished rewards 28.72, envs finished 1
2026-01-17 13:39:02,023 : worker.worker : DEBUG : Step 178285, finished rewards 35.98, envs finished 1
2026-01-17 13:39:02,050 : worker.worker : DEBUG : Step 178287, finished rewards 37.57, envs finished 1
2026-01-17 13:39:02,312 : agent.on_policy : DEBUG : Mean Losses: [4.536193497478962]
2026-01-17 13:39:02,332 : worker.worker : DEBUG : Step 178308, finished rewards 18.46, envs finished 1
2026-01-17 13:39:02,410 : worker.worker : DEBUG : Step 178322, finished rewards 26.07, envs finished 1
2026-01-17 13:39:02,522 : worker.worker : DEBUG : Step 178335, finished rewards 43.28, envs finished 1
2026-01-17 13:39:02,718 : agent.on_policy : DEBUG : Mean Losses: [4.55447481572628]
2026-01-17 13:39:03,036 : worker.worker : DEBUG : Step 178364, finished rewards 23.37, envs finished 1
2026-01-17 13:39:03,103 : worker.worker : DEBUG : Step 178367, finished rewards 28.75, envs finished 1
2026-01-17 13:39:03,289 : agent.on_policy : DEBUG : Mean Losses: [4.063718559220433]
2026-01-17 13:39:03,328 : worker.worker : DEBUG : Step 178370, finished rewards 20.31, envs finished 1
2026-01-17 13:39:03,531 : agent.on_policy : DEBUG : Mean Losses: [3.205851212143898]
2026-01-17 13:39:03,567 : worker.worker : DEBUG : Step 178407, finished rewards 29.87, envs finished 1
2026-01-17 13:39:03,580 : worker.worker : DEBUG : Step 178409, finished rewards -2.49, envs finished 1
2026-01-17 13:39:03,593 : worker.worker : DEBUG : Step 178411, finished rewards 0.67, envs finished 1
2026-01-17 13:39:03,703 : worker.worker : DEBUG : Step 178431, finished rewards 5.65, envs finished 1
2026-01-17 13:39:03,834 : agent.on_policy : DEBUG : Mean Losses: [4.484044089913368]
2026-01-17 13:39:03,988 : worker.worker : DEBUG : Step 178447, finished rewards 32.06, envs finished 1
2026-01-17 13:39:04,068 : worker.worker : DEBUG : Step 178461, finished rewards -0.61, envs finished 1
2026-01-17 13:39:04,172 : agent.on_policy : DEBUG : Mean Losses: [3.4219780173152685]
2026-01-17 13:39:04,189 : worker.worker : DEBUG : Step 178464, finished rewards 20.25, envs finished 1
2026-01-17 13:39:04,279 : worker.worker : DEBUG : Step 178478, finished rewards 42.09, envs finished 1
2026-01-17 13:39:04,402 : worker.worker : DEBUG : Step 178489, finished rewards 11.39, envs finished 1
2026-01-17 13:39:04,458 : worker.worker : DEBUG : Step 178494, finished rewards 28.71, envs finished 1
2026-01-17 13:39:04,636 : agent.on_policy : DEBUG : Mean Losses: [5.180411268025637]
2026-01-17 13:39:04,787 : worker.worker : DEBUG : Step 178512, finished rewards 26.07, envs finished 2
2026-01-17 13:39:04,988 : worker.worker : DEBUG : Step 178527, finished rewards 33.93, envs finished 1
2026-01-17 13:39:05,082 : agent.on_policy : DEBUG : Mean Losses: [3.799821075052023]
2026-01-17 13:39:05,220 : worker.worker : DEBUG : Step 178546, finished rewards 32.88, envs finished 1
2026-01-17 13:39:05,418 : agent.on_policy : DEBUG : Mean Losses: [2.978822779841721]
2026-01-17 13:39:05,424 : worker.worker : DEBUG : Step 178560, finished rewards 32.78, envs finished 1
2026-01-17 13:39:05,470 : worker.worker : DEBUG : Step 178567, finished rewards 15.14, envs finished 1
2026-01-17 13:39:05,719 : agent.on_policy : DEBUG : Mean Losses: [4.621072139590979]
2026-01-17 13:39:05,755 : worker.worker : DEBUG : Step 178600, finished rewards 17.48, envs finished 1
2026-01-17 13:39:05,785 : worker.worker : DEBUG : Step 178605, finished rewards 24.64, envs finished 1
2026-01-17 13:39:05,816 : worker.worker : DEBUG : Step 178609, finished rewards 10.60, envs finished 1
2026-01-17 13:39:05,880 : worker.worker : DEBUG : Step 178621, finished rewards 27.85, envs finished 1
2026-01-17 13:39:06,058 : agent.on_policy : DEBUG : Mean Losses: [5.1712606102228165]
2026-01-17 13:39:06,141 : worker.worker : DEBUG : Step 178637, finished rewards 34.99, envs finished 1
2026-01-17 13:39:06,198 : worker.worker : DEBUG : Step 178648, finished rewards 31.16, envs finished 1
2026-01-17 13:39:06,377 : agent.on_policy : DEBUG : Mean Losses: [4.634137351065874]
2026-01-17 13:39:06,479 : worker.worker : DEBUG : Step 178664, finished rewards -11.95, envs finished 1
2026-01-17 13:39:06,569 : worker.worker : DEBUG : Step 178675, finished rewards 15.82, envs finished 1
2026-01-17 13:39:06,603 : worker.worker : DEBUG : Step 178676, finished rewards 41.72, envs finished 1
2026-01-17 13:39:06,937 : agent.on_policy : DEBUG : Mean Losses: [4.183903953060508]
2026-01-17 13:39:06,963 : worker.worker : DEBUG : Step 178689, finished rewards 26.78, envs finished 1
2026-01-17 13:39:07,029 : worker.worker : DEBUG : Step 178697, finished rewards 26.79, envs finished 1
2026-01-17 13:39:07,198 : worker.worker : DEBUG : Step 178718, finished rewards 42.48, envs finished 1
2026-01-17 13:39:07,303 : agent.on_policy : DEBUG : Mean Losses: [5.052115021273494]
2026-01-17 13:39:07,649 : worker.worker : DEBUG : Step 178745, finished rewards 42.34, envs finished 1
2026-01-17 13:39:07,788 : agent.on_policy : DEBUG : Mean Losses: [4.0638248026371]
2026-01-17 13:39:07,933 : worker.worker : DEBUG : Step 178766, finished rewards 9.03, envs finished 1
2026-01-17 13:39:07,993 : worker.worker : DEBUG : Step 178771, finished rewards 15.13, envs finished 1
2026-01-17 13:39:08,024 : worker.worker : DEBUG : Step 178773, finished rewards -17.31, envs finished 1
2026-01-17 13:39:08,078 : worker.worker : DEBUG : Step 178780, finished rewards 16.82, envs finished 1
2026-01-17 13:39:08,128 : worker.worker : DEBUG : Step 178783, finished rewards 22.31, envs finished 1
2026-01-17 13:39:08,261 : agent.on_policy : DEBUG : Mean Losses: [6.402577668428421]
2026-01-17 13:39:08,623 : worker.worker : DEBUG : Step 178809, finished rewards 46.03, envs finished 1
2026-01-17 13:39:08,651 : worker.worker : DEBUG : Step 178812, finished rewards 22.42, envs finished 1
2026-01-17 13:39:08,843 : agent.on_policy : DEBUG : Mean Losses: [4.4527434799820185]
2026-01-17 13:39:09,126 : agent.on_policy : DEBUG : Mean Losses: [1.9611851014196873]
2026-01-17 13:39:09,185 : worker.worker : DEBUG : Step 178860, finished rewards 27.35, envs finished 1
2026-01-17 13:39:09,216 : worker.worker : DEBUG : Step 178866, finished rewards 32.33, envs finished 1
2026-01-17 13:39:09,254 : worker.worker : DEBUG : Step 178871, finished rewards 17.71, envs finished 1
2026-01-17 13:39:09,472 : agent.on_policy : DEBUG : Mean Losses: [6.340721487998962]
2026-01-17 13:39:09,509 : worker.worker : DEBUG : Step 178886, finished rewards 10.02, envs finished 1
2026-01-17 13:39:09,565 : worker.worker : DEBUG : Step 178897, finished rewards 29.33, envs finished 1
2026-01-17 13:39:09,771 : agent.on_policy : DEBUG : Mean Losses: [3.5686155166476965]
2026-01-17 13:39:09,822 : worker.worker : DEBUG : Step 178918, finished rewards -6.85, envs finished 1
2026-01-17 13:39:09,978 : worker.worker : DEBUG : Step 178936, finished rewards 6.69, envs finished 1
2026-01-17 13:39:10,046 : worker.worker : DEBUG : Step 178942, finished rewards 31.76, envs finished 1
2026-01-17 13:39:10,267 : agent.on_policy : DEBUG : Mean Losses: [4.491360064595938]
2026-01-17 13:39:10,298 : worker.worker : DEBUG : Step 178950, finished rewards 34.25, envs finished 1
2026-01-17 13:39:10,342 : worker.worker : DEBUG : Step 178960, finished rewards 23.52, envs finished 1
2026-01-17 13:39:10,375 : worker.worker : DEBUG : Step 178967, finished rewards 54.43, envs finished 1
2026-01-17 13:39:10,472 : agent.on_policy : DEBUG : Mean Losses: [4.253513518255204]
2026-01-17 13:39:10,516 : worker.worker : DEBUG : Step 178985, finished rewards 26.67, envs finished 1
2026-01-17 13:39:10,591 : worker.worker : DEBUG : Step 178989, finished rewards 42.14, envs finished 1
2026-01-17 13:39:10,639 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:39:10,664 : worker.worker : DEBUG : Step 179002, finished rewards 7.09, envs finished 1
2026-01-17 13:39:10,738 : worker.worker : DEBUG : Step 179006, finished rewards 46.36, envs finished 1
2026-01-17 13:39:10,925 : agent.on_policy : DEBUG : Mean Losses: [6.28530303016305]
2026-01-17 13:39:11,015 : worker.worker : DEBUG : Step 179031, finished rewards 46.14, envs finished 1
2026-01-17 13:39:11,196 : agent.on_policy : DEBUG : Mean Losses: [4.776280552148819]
2026-01-17 13:39:11,258 : worker.worker : DEBUG : Step 179053, finished rewards 11.16, envs finished 1
2026-01-17 13:39:11,361 : worker.worker : DEBUG : Step 179065, finished rewards 7.34, envs finished 1
2026-01-17 13:39:11,540 : agent.on_policy : DEBUG : Mean Losses: [4.562989503145218]
2026-01-17 13:39:11,596 : worker.worker : DEBUG : Step 179079, finished rewards 25.48, envs finished 1
2026-01-17 13:39:11,623 : worker.worker : DEBUG : Step 179081, finished rewards 2.45, envs finished 1
2026-01-17 13:39:11,777 : worker.worker : DEBUG : Step 179096, finished rewards 11.91, envs finished 1
2026-01-17 13:39:12,020 : agent.on_policy : DEBUG : Mean Losses: [5.41204225923866]
2026-01-17 13:39:12,298 : agent.on_policy : DEBUG : Mean Losses: [2.781206913292408]
2026-01-17 13:39:12,322 : worker.worker : DEBUG : Step 179142, finished rewards 46.78, envs finished 1
2026-01-17 13:39:12,331 : worker.worker : DEBUG : Step 179144, finished rewards -3.24, envs finished 1
2026-01-17 13:39:12,343 : worker.worker : DEBUG : Step 179146, finished rewards 23.80, envs finished 1
2026-01-17 13:39:12,353 : worker.worker : DEBUG : Step 179147, finished rewards 12.48, envs finished 1
2026-01-17 13:39:12,376 : worker.worker : DEBUG : Step 179151, finished rewards 28.95, envs finished 1
2026-01-17 13:39:12,405 : worker.worker : DEBUG : Step 179157, finished rewards -6.66, envs finished 1
2026-01-17 13:39:12,504 : agent.on_policy : DEBUG : Mean Losses: [7.014222234487534]
2026-01-17 13:39:12,599 : worker.worker : DEBUG : Step 179181, finished rewards 29.25, envs finished 1
2026-01-17 13:39:12,852 : agent.on_policy : DEBUG : Mean Losses: [2.1305497121065855]
2026-01-17 13:39:12,966 : worker.worker : DEBUG : Step 179210, finished rewards 0.09, envs finished 1
2026-01-17 13:39:12,997 : worker.worker : DEBUG : Step 179214, finished rewards 42.55, envs finished 1
2026-01-17 13:39:13,141 : worker.worker : DEBUG : Step 179229, finished rewards 28.94, envs finished 1
2026-01-17 13:39:13,304 : agent.on_policy : DEBUG : Mean Losses: [4.688533574342728]
2026-01-17 13:39:13,315 : worker.worker : DEBUG : Step 179234, finished rewards 32.28, envs finished 1
2026-01-17 13:39:13,338 : worker.worker : DEBUG : Step 179238, finished rewards 24.55, envs finished 1
2026-01-17 13:39:13,391 : worker.worker : DEBUG : Step 179241, finished rewards 31.45, envs finished 1
2026-01-17 13:39:13,420 : worker.worker : DEBUG : Step 179242, finished rewards 22.77, envs finished 1
2026-01-17 13:39:13,726 : agent.on_policy : DEBUG : Mean Losses: [3.5169360996223986]
2026-01-17 13:39:13,874 : worker.worker : DEBUG : Step 179295, finished rewards 11.90, envs finished 1
2026-01-17 13:39:14,043 : agent.on_policy : DEBUG : Mean Losses: [3.3515403419733047]
2026-01-17 13:39:14,060 : worker.worker : DEBUG : Step 179298, finished rewards 45.91, envs finished 1
2026-01-17 13:39:14,069 : worker.worker : DEBUG : Step 179299, finished rewards 42.91, envs finished 1
2026-01-17 13:39:14,098 : worker.worker : DEBUG : Step 179301, finished rewards 25.28, envs finished 1
2026-01-17 13:39:14,236 : worker.worker : DEBUG : Step 179320, finished rewards 15.44, envs finished 1
2026-01-17 13:39:14,382 : agent.on_policy : DEBUG : Mean Losses: [4.547542680054903]
2026-01-17 13:39:14,402 : worker.worker : DEBUG : Step 179333, finished rewards 23.56, envs finished 1
2026-01-17 13:39:14,463 : worker.worker : DEBUG : Step 179348, finished rewards 15.37, envs finished 1
2026-01-17 13:39:14,497 : worker.worker : DEBUG : Step 179355, finished rewards 6.03, envs finished 1
2026-01-17 13:39:14,658 : agent.on_policy : DEBUG : Mean Losses: [3.497704431414604]
2026-01-17 13:39:14,702 : worker.worker : DEBUG : Step 179369, finished rewards 40.33, envs finished 1
2026-01-17 13:39:14,851 : worker.worker : DEBUG : Step 179390, finished rewards 24.77, envs finished 1
2026-01-17 13:39:14,910 : agent.on_policy : DEBUG : Mean Losses: [3.848397597670555]
2026-01-17 13:39:14,936 : worker.worker : DEBUG : Step 179397, finished rewards 17.52, envs finished 1
2026-01-17 13:39:14,951 : worker.worker : DEBUG : Step 179399, finished rewards 18.63, envs finished 1
2026-01-17 13:39:15,099 : worker.worker : DEBUG : Step 179418, finished rewards 20.23, envs finished 1
2026-01-17 13:39:15,243 : agent.on_policy : DEBUG : Mean Losses: [3.5482407584786415]
2026-01-17 13:39:15,316 : worker.worker : DEBUG : Step 179442, finished rewards 22.55, envs finished 1
2026-01-17 13:39:15,462 : worker.worker : DEBUG : Step 179451, finished rewards 22.31, envs finished 1
2026-01-17 13:39:15,641 : agent.on_policy : DEBUG : Mean Losses: [3.604664348065853]
2026-01-17 13:39:15,738 : worker.worker : DEBUG : Step 179462, finished rewards 2.44, envs finished 1
2026-01-17 13:39:16,084 : agent.on_policy : DEBUG : Mean Losses: [3.11258415132761]
2026-01-17 13:39:16,303 : worker.worker : DEBUG : Step 179517, finished rewards 2.57, envs finished 1
2026-01-17 13:39:16,328 : worker.worker : DEBUG : Step 179519, finished rewards 19.99, envs finished 1
2026-01-17 13:39:16,393 : agent.on_policy : DEBUG : Mean Losses: [6.791525021195412]
2026-01-17 13:39:16,396 : worker.worker : DEBUG : Step 179520, finished rewards 3.18, envs finished 1
2026-01-17 13:39:16,454 : worker.worker : DEBUG : Step 179533, finished rewards -2.70, envs finished 1
2026-01-17 13:39:16,657 : agent.on_policy : DEBUG : Mean Losses: [4.564885303378105]
2026-01-17 13:39:16,661 : worker.worker : DEBUG : Step 179552, finished rewards 9.74, envs finished 1
2026-01-17 13:39:16,703 : worker.worker : DEBUG : Step 179561, finished rewards 11.73, envs finished 1
2026-01-17 13:39:16,830 : agent.on_policy : DEBUG : Mean Losses: [3.480132255703211]
2026-01-17 13:39:16,931 : worker.worker : DEBUG : Step 179594, finished rewards -8.44, envs finished 1
2026-01-17 13:39:16,984 : worker.worker : DEBUG : Step 179603, finished rewards 29.02, envs finished 1
2026-01-17 13:39:17,027 : worker.worker : DEBUG : Step 179606, finished rewards 29.14, envs finished 1
2026-01-17 13:39:17,124 : agent.on_policy : DEBUG : Mean Losses: [6.193471938371658]
2026-01-17 13:39:17,127 : worker.worker : DEBUG : Step 179616, finished rewards 21.03, envs finished 1
2026-01-17 13:39:17,156 : worker.worker : DEBUG : Step 179625, finished rewards 46.03, envs finished 1
2026-01-17 13:39:17,211 : worker.worker : DEBUG : Step 179644, finished rewards 18.09, envs finished 2
2026-01-17 13:39:17,257 : agent.on_policy : DEBUG : Mean Losses: [5.566814914345741]
2026-01-17 13:39:17,319 : worker.worker : DEBUG : Step 179669, finished rewards 47.29, envs finished 1
2026-01-17 13:39:17,343 : worker.worker : DEBUG : Step 179675, finished rewards 33.20, envs finished 1
2026-01-17 13:39:17,503 : agent.on_policy : DEBUG : Mean Losses: [5.7083119144663215]
2026-01-17 13:39:17,596 : worker.worker : DEBUG : Step 179687, finished rewards 42.35, envs finished 1
2026-01-17 13:39:17,688 : worker.worker : DEBUG : Step 179698, finished rewards -90.37, envs finished 1
2026-01-17 13:39:17,937 : agent.on_policy : DEBUG : Mean Losses: [4.160589672625065]
2026-01-17 13:39:18,026 : worker.worker : DEBUG : Step 179737, finished rewards 24.38, envs finished 1
2026-01-17 13:39:18,037 : worker.worker : DEBUG : Step 179739, finished rewards -3.79, envs finished 1
2026-01-17 13:39:18,189 : agent.on_policy : DEBUG : Mean Losses: [6.537323115393519]
2026-01-17 13:39:18,227 : worker.worker : DEBUG : Step 179751, finished rewards 5.54, envs finished 1
2026-01-17 13:39:18,261 : worker.worker : DEBUG : Step 179755, finished rewards 12.39, envs finished 1
2026-01-17 13:39:18,313 : worker.worker : DEBUG : Step 179757, finished rewards 27.60, envs finished 1
2026-01-17 13:39:18,393 : worker.worker : DEBUG : Step 179775, finished rewards 26.99, envs finished 1
2026-01-17 13:39:18,559 : agent.on_policy : DEBUG : Mean Losses: [4.708060257136822]
2026-01-17 13:39:18,721 : worker.worker : DEBUG : Step 179794, finished rewards 0.46, envs finished 1
2026-01-17 13:39:18,757 : worker.worker : DEBUG : Step 179798, finished rewards 21.52, envs finished 1
2026-01-17 13:39:18,886 : agent.on_policy : DEBUG : Mean Losses: [4.217783864587545]
2026-01-17 13:39:18,698 : worker.worker : DEBUG : Step 179828, finished rewards 24.74, envs finished 1
2026-01-17 13:39:18,711 : worker.worker : DEBUG : Step 179829, finished rewards 33.19, envs finished 2
2026-01-17 13:39:18,757 : worker.worker : DEBUG : Step 179839, finished rewards 31.14, envs finished 1
2026-01-17 13:39:18,811 : agent.on_policy : DEBUG : Mean Losses: [6.0159450098872185]
2026-01-17 13:39:18,815 : worker.worker : DEBUG : Step 179840, finished rewards 27.36, envs finished 1
2026-01-17 13:39:18,978 : worker.worker : DEBUG : Step 179870, finished rewards 20.60, envs finished 1
2026-01-17 13:39:19,038 : agent.on_policy : DEBUG : Mean Losses: [2.3501661848276854]
2026-01-17 13:39:19,103 : worker.worker : DEBUG : Step 179889, finished rewards 22.67, envs finished 1
2026-01-17 13:39:19,269 : agent.on_policy : DEBUG : Mean Losses: [2.7993312664330006]
2026-01-17 13:39:19,546 : worker.worker : DEBUG : Step 179930, finished rewards 26.94, envs finished 1
2026-01-17 13:39:19,578 : worker.worker : DEBUG : Step 179934, finished rewards 15.31, envs finished 1
2026-01-17 13:39:19,592 : worker.worker : DEBUG : Step 179935, finished rewards 12.79, envs finished 1
2026-01-17 13:39:19,719 : agent.on_policy : DEBUG : Mean Losses: [6.692893445491791]
2026-01-17 13:39:20,076 : agent.on_policy : DEBUG : Mean Losses: [2.67524117231369]
2026-01-17 13:39:20,087 : worker.worker : DEBUG : Step 179970, finished rewards 18.84, envs finished 1
2026-01-17 13:39:20,107 : worker.worker : DEBUG : Step 179974, finished rewards -10.61, envs finished 2
2026-01-17 13:39:20,188 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:39:20,237 : agent.on_policy : DEBUG : Mean Losses: [3.548517018556595]
2026-01-17 13:39:20,247 : worker.worker : INFO : Step 180000, Avg Reward 22.7704, Max Reward 99.1867, Loss [4.42138821]
2026-01-17 13:39:20,285 : worker.worker : DEBUG : Step 180002, finished rewards 7.94, envs finished 1
2026-01-17 13:39:20,590 : agent.on_policy : DEBUG : Mean Losses: [3.546934261918068]
2026-01-17 13:39:20,594 : worker.worker : DEBUG : Step 180033, finished rewards 20.63, envs finished 1
2026-01-17 13:39:20,622 : worker.worker : DEBUG : Step 180040, finished rewards 12.85, envs finished 1
2026-01-17 13:39:20,662 : worker.worker : DEBUG : Step 180051, finished rewards 35.06, envs finished 1
2026-01-17 13:39:20,755 : agent.on_policy : DEBUG : Mean Losses: [5.45117948949337]
2026-01-17 13:39:20,789 : worker.worker : DEBUG : Step 180073, finished rewards -9.95, envs finished 1
2026-01-17 13:39:20,883 : worker.worker : DEBUG : Step 180082, finished rewards 21.76, envs finished 2
2026-01-17 13:39:21,057 : agent.on_policy : DEBUG : Mean Losses: [5.194857157766819]
2026-01-17 13:39:21,088 : worker.worker : DEBUG : Step 180101, finished rewards -85.21, envs finished 1
2026-01-17 13:39:21,119 : worker.worker : DEBUG : Step 180103, finished rewards 41.46, envs finished 1
2026-01-17 13:39:21,164 : worker.worker : DEBUG : Step 180111, finished rewards 40.99, envs finished 1
2026-01-17 13:39:21,268 : agent.on_policy : DEBUG : Mean Losses: [6.5905499793589115]
2026-01-17 13:39:21,422 : worker.worker : DEBUG : Step 180149, finished rewards -29.57, envs finished 1
2026-01-17 13:39:21,465 : worker.worker : DEBUG : Step 180157, finished rewards 13.18, envs finished 1
2026-01-17 13:39:21,633 : agent.on_policy : DEBUG : Mean Losses: [4.02808029204607]
2026-01-17 13:39:21,815 : worker.worker : DEBUG : Step 180187, finished rewards 30.11, envs finished 1
2026-01-17 13:39:21,822 : worker.worker : DEBUG : Step 180188, finished rewards 31.10, envs finished 1
2026-01-17 13:39:21,968 : agent.on_policy : DEBUG : Mean Losses: [6.162702918052673]
2026-01-17 13:39:21,981 : worker.worker : DEBUG : Step 180195, finished rewards 11.57, envs finished 1
2026-01-17 13:39:22,087 : worker.worker : DEBUG : Step 180207, finished rewards 20.91, envs finished 1
2026-01-17 13:39:22,149 : worker.worker : DEBUG : Step 180216, finished rewards -2.30, envs finished 1
2026-01-17 13:39:22,291 : agent.on_policy : DEBUG : Mean Losses: [4.28397629596293]
2026-01-17 13:39:22,423 : worker.worker : DEBUG : Step 180241, finished rewards 26.22, envs finished 1
2026-01-17 13:39:22,631 : agent.on_policy : DEBUG : Mean Losses: [3.5431416034698486]
2026-01-17 13:39:22,657 : worker.worker : DEBUG : Step 180262, finished rewards 16.52, envs finished 1
2026-01-17 13:39:22,914 : agent.on_policy : DEBUG : Mean Losses: [4.743720211088657]
2026-01-17 13:39:22,934 : worker.worker : DEBUG : Step 180293, finished rewards 17.15, envs finished 1
2026-01-17 13:39:22,963 : worker.worker : DEBUG : Step 180299, finished rewards 32.13, envs finished 1
2026-01-17 13:39:22,973 : worker.worker : DEBUG : Step 180301, finished rewards -77.35, envs finished 1
2026-01-17 13:39:22,990 : worker.worker : DEBUG : Step 180305, finished rewards 21.77, envs finished 1
2026-01-17 13:39:23,020 : worker.worker : DEBUG : Step 180312, finished rewards 15.71, envs finished 1
2026-01-17 13:39:23,025 : worker.worker : DEBUG : Step 180313, finished rewards 4.86, envs finished 1
2026-01-17 13:39:23,120 : agent.on_policy : DEBUG : Mean Losses: [7.612559497356415]
2026-01-17 13:39:23,397 : worker.worker : DEBUG : Step 180349, finished rewards 12.66, envs finished 1
2026-01-17 13:39:23,490 : agent.on_policy : DEBUG : Mean Losses: [1.719370786100626]
2026-01-17 13:39:23,658 : agent.on_policy : DEBUG : Mean Losses: [2.4447436220943928]
2026-01-17 13:39:23,696 : worker.worker : DEBUG : Step 180393, finished rewards 23.54, envs finished 1
2026-01-17 13:39:23,727 : worker.worker : DEBUG : Step 180401, finished rewards 11.54, envs finished 1
2026-01-17 13:39:23,752 : worker.worker : DEBUG : Step 180409, finished rewards 16.88, envs finished 1
2026-01-17 13:39:23,756 : worker.worker : DEBUG : Step 180410, finished rewards 14.24, envs finished 1
2026-01-17 13:39:23,808 : agent.on_policy : DEBUG : Mean Losses: [5.525381609797478]
2026-01-17 13:39:23,809 : worker.worker : DEBUG : Step 180416, finished rewards 16.06, envs finished 1
2026-01-17 13:39:23,875 : worker.worker : DEBUG : Step 180431, finished rewards 10.94, envs finished 1
2026-01-17 13:39:23,884 : worker.worker : DEBUG : Step 180432, finished rewards 32.29, envs finished 1
2026-01-17 13:39:23,964 : worker.worker : DEBUG : Step 180438, finished rewards -6.74, envs finished 1
2026-01-17 13:39:24,134 : agent.on_policy : DEBUG : Mean Losses: [3.8299213061109185]
2026-01-17 13:39:24,224 : worker.worker : DEBUG : Step 180475, finished rewards 32.19, envs finished 1
2026-01-17 13:39:24,370 : agent.on_policy : DEBUG : Mean Losses: [2.327072538435459]
2026-01-17 13:39:24,429 : worker.worker : DEBUG : Step 180493, finished rewards 31.33, envs finished 1
2026-01-17 13:39:24,546 : worker.worker : DEBUG : Step 180509, finished rewards 42.01, envs finished 1
2026-01-17 13:39:24,718 : agent.on_policy : DEBUG : Mean Losses: [5.839435525238514]
2026-01-17 13:39:24,728 : worker.worker : DEBUG : Step 180513, finished rewards 32.29, envs finished 1
2026-01-17 13:39:24,899 : worker.worker : DEBUG : Step 180530, finished rewards 23.57, envs finished 1
2026-01-17 13:39:25,113 : agent.on_policy : DEBUG : Mean Losses: [4.053924351930618]
2026-01-17 13:39:25,114 : worker.worker : DEBUG : Step 180544, finished rewards 2.12, envs finished 2
2026-01-17 13:39:25,182 : worker.worker : DEBUG : Step 180563, finished rewards 27.93, envs finished 1
2026-01-17 13:39:25,338 : agent.on_policy : DEBUG : Mean Losses: [3.464683654718101]
2026-01-17 13:39:25,387 : worker.worker : DEBUG : Step 180586, finished rewards 13.59, envs finished 1
2026-01-17 13:39:25,419 : worker.worker : DEBUG : Step 180593, finished rewards 47.21, envs finished 1
2026-01-17 13:39:25,464 : worker.worker : DEBUG : Step 180604, finished rewards 25.79, envs finished 1
2026-01-17 13:39:25,471 : worker.worker : DEBUG : Step 180605, finished rewards 9.77, envs finished 1
2026-01-17 13:39:25,539 : agent.on_policy : DEBUG : Mean Losses: [7.198135334998369]
2026-01-17 13:39:25,636 : worker.worker : DEBUG : Step 180627, finished rewards 46.28, envs finished 1
2026-01-17 13:39:25,877 : agent.on_policy : DEBUG : Mean Losses: [4.930799026042223]
2026-01-17 13:39:25,904 : worker.worker : DEBUG : Step 180645, finished rewards 19.79, envs finished 1
2026-01-17 13:39:25,913 : worker.worker : DEBUG : Step 180646, finished rewards -4.71, envs finished 1
2026-01-17 13:39:25,984 : worker.worker : DEBUG : Step 180663, finished rewards 9.59, envs finished 1
2026-01-17 13:39:25,989 : worker.worker : DEBUG : Step 180664, finished rewards 41.59, envs finished 1
2026-01-17 13:39:26,141 : agent.on_policy : DEBUG : Mean Losses: [6.024569168686867]
2026-01-17 13:39:26,395 : agent.on_policy : DEBUG : Mean Losses: [1.811541873961687]
2026-01-17 13:39:26,396 : worker.worker : DEBUG : Step 180704, finished rewards 21.37, envs finished 1
2026-01-17 13:39:26,416 : worker.worker : DEBUG : Step 180709, finished rewards 14.85, envs finished 1
2026-01-17 13:39:26,430 : worker.worker : DEBUG : Step 180712, finished rewards 8.02, envs finished 1
2026-01-17 13:39:26,483 : worker.worker : DEBUG : Step 180726, finished rewards 46.56, envs finished 1
2026-01-17 13:39:26,493 : worker.worker : DEBUG : Step 180729, finished rewards 31.03, envs finished 1
2026-01-17 13:39:26,601 : agent.on_policy : DEBUG : Mean Losses: [7.070071848575026]
2026-01-17 13:39:26,619 : worker.worker : DEBUG : Step 180737, finished rewards 16.19, envs finished 1
2026-01-17 13:39:26,687 : worker.worker : DEBUG : Step 180750, finished rewards 18.05, envs finished 1
2026-01-17 13:39:26,691 : worker.worker : DEBUG : Step 180751, finished rewards 28.08, envs finished 1
2026-01-17 13:39:26,787 : agent.on_policy : DEBUG : Mean Losses: [2.0179379959590733]
2026-01-17 13:39:26,803 : worker.worker : DEBUG : Step 180773, finished rewards 46.25, envs finished 1
2026-01-17 13:39:26,902 : agent.on_policy : DEBUG : Mean Losses: [2.9792601093649864]
2026-01-17 13:39:26,936 : worker.worker : DEBUG : Step 180809, finished rewards 17.50, envs finished 1
2026-01-17 13:39:26,947 : worker.worker : DEBUG : Step 180812, finished rewards 32.02, envs finished 1
2026-01-17 13:39:27,022 : worker.worker : DEBUG : Step 180818, finished rewards 25.30, envs finished 1
2026-01-17 13:39:27,057 : worker.worker : DEBUG : Step 180820, finished rewards 14.65, envs finished 1
2026-01-17 13:39:27,087 : worker.worker : DEBUG : Step 180827, finished rewards 35.14, envs finished 1
2026-01-17 13:39:27,101 : worker.worker : DEBUG : Step 180829, finished rewards 24.04, envs finished 1
2026-01-17 13:39:27,273 : agent.on_policy : DEBUG : Mean Losses: [8.935492128133774]
2026-01-17 13:39:27,420 : worker.worker : DEBUG : Step 180843, finished rewards 24.34, envs finished 1
2026-01-17 13:39:27,627 : agent.on_policy : DEBUG : Mean Losses: [1.346370148472488]
2026-01-17 13:39:27,645 : worker.worker : DEBUG : Step 180869, finished rewards 22.28, envs finished 1
2026-01-17 13:39:27,754 : worker.worker : DEBUG : Step 180881, finished rewards 40.04, envs finished 1
2026-01-17 13:39:27,940 : agent.on_policy : DEBUG : Mean Losses: [3.3400786109268665]
2026-01-17 13:39:27,992 : worker.worker : DEBUG : Step 180903, finished rewards 32.17, envs finished 1
2026-01-17 13:39:28,049 : worker.worker : DEBUG : Step 180911, finished rewards 24.15, envs finished 1
2026-01-17 13:39:28,073 : worker.worker : DEBUG : Step 180914, finished rewards 34.34, envs finished 2
2026-01-17 13:39:28,264 : agent.on_policy : DEBUG : Mean Losses: [6.851409614086151]
2026-01-17 13:39:28,274 : worker.worker : DEBUG : Step 180930, finished rewards 7.69, envs finished 1
2026-01-17 13:39:28,331 : worker.worker : DEBUG : Step 180947, finished rewards 4.80, envs finished 1
2026-01-17 13:39:28,590 : agent.on_policy : DEBUG : Mean Losses: [2.7102902345359325]
2026-01-17 13:39:28,708 : worker.worker : DEBUG : Step 180974, finished rewards 23.66, envs finished 1
2026-01-17 13:39:28,715 : worker.worker : DEBUG : Step 180975, finished rewards 14.98, envs finished 1
2026-01-17 13:39:28,722 : worker.worker : DEBUG : Step 180976, finished rewards 39.09, envs finished 1
2026-01-17 13:39:28,907 : agent.on_policy : DEBUG : Mean Losses: [5.201032862067223]
2026-01-17 13:39:28,927 : worker.worker : DEBUG : Step 180996, finished rewards 32.76, envs finished 1
2026-01-17 13:39:28,935 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:39:29,001 : worker.worker : DEBUG : Step 181003, finished rewards 25.25, envs finished 1
2026-01-17 13:39:29,050 : worker.worker : DEBUG : Step 181007, finished rewards 23.56, envs finished 1
2026-01-17 13:39:29,280 : agent.on_policy : DEBUG : Mean Losses: [3.8197231963276863]
2026-01-17 13:39:29,336 : worker.worker : DEBUG : Step 181039, finished rewards 24.99, envs finished 1
2026-01-17 13:39:29,370 : worker.worker : DEBUG : Step 181046, finished rewards 41.27, envs finished 1
2026-01-17 13:39:29,533 : agent.on_policy : DEBUG : Mean Losses: [4.377503424882889]
2026-01-17 13:39:29,680 : worker.worker : DEBUG : Step 181079, finished rewards -15.76, envs finished 1
2026-01-17 13:39:29,707 : worker.worker : DEBUG : Step 181084, finished rewards 29.21, envs finished 1
2026-01-17 13:39:29,714 : worker.worker : DEBUG : Step 181085, finished rewards 13.00, envs finished 1
2026-01-17 13:39:29,890 : agent.on_policy : DEBUG : Mean Losses: [5.30952936783433]
2026-01-17 13:39:29,891 : worker.worker : DEBUG : Step 181088, finished rewards 8.16, envs finished 1
2026-01-17 13:39:30,113 : worker.worker : DEBUG : Step 181108, finished rewards 17.20, envs finished 1
2026-01-17 13:39:30,228 : worker.worker : DEBUG : Step 181117, finished rewards 11.22, envs finished 1
2026-01-17 13:39:30,366 : agent.on_policy : DEBUG : Mean Losses: [3.5616536252200603]
2026-01-17 13:39:30,663 : worker.worker : DEBUG : Step 181150, finished rewards 16.27, envs finished 1
2026-01-17 13:39:30,833 : agent.on_policy : DEBUG : Mean Losses: [3.46375772356987]
2026-01-17 13:39:30,895 : worker.worker : DEBUG : Step 181162, finished rewards 2.79, envs finished 1
2026-01-17 13:39:30,991 : worker.worker : DEBUG : Step 181171, finished rewards 28.80, envs finished 1
2026-01-17 13:39:30,997 : worker.worker : DEBUG : Step 181172, finished rewards 45.96, envs finished 1
2026-01-17 13:39:31,162 : agent.on_policy : DEBUG : Mean Losses: [7.153892233967781]
2026-01-17 13:39:31,193 : worker.worker : DEBUG : Step 181190, finished rewards 17.87, envs finished 1
2026-01-17 13:39:31,282 : worker.worker : DEBUG : Step 181200, finished rewards 8.52, envs finished 1
2026-01-17 13:39:31,324 : worker.worker : DEBUG : Step 181210, finished rewards 0.79, envs finished 1
2026-01-17 13:39:31,488 : agent.on_policy : DEBUG : Mean Losses: [3.401198672130704]
2026-01-17 13:39:31,578 : worker.worker : DEBUG : Step 181243, finished rewards 41.32, envs finished 1
2026-01-17 13:39:31,582 : worker.worker : DEBUG : Step 181244, finished rewards 24.68, envs finished 1
2026-01-17 13:39:31,732 : agent.on_policy : DEBUG : Mean Losses: [5.7418759148567915]
2026-01-17 13:39:31,766 : worker.worker : DEBUG : Step 181251, finished rewards 27.27, envs finished 1
2026-01-17 13:39:31,891 : worker.worker : DEBUG : Step 181261, finished rewards 25.42, envs finished 1
2026-01-17 13:39:32,085 : worker.worker : DEBUG : Step 181278, finished rewards -15.64, envs finished 1
2026-01-17 13:39:32,106 : worker.worker : DEBUG : Step 181279, finished rewards 25.84, envs finished 1
2026-01-17 13:39:32,270 : agent.on_policy : DEBUG : Mean Losses: [5.037959452718496]
2026-01-17 13:39:32,289 : worker.worker : DEBUG : Step 181282, finished rewards 32.35, envs finished 1
2026-01-17 13:39:32,462 : worker.worker : DEBUG : Step 181301, finished rewards 26.63, envs finished 1
2026-01-17 13:39:32,653 : agent.on_policy : DEBUG : Mean Losses: [3.832971453666687]
2026-01-17 13:39:32,667 : worker.worker : DEBUG : Step 181315, finished rewards 41.37, envs finished 1
2026-01-17 13:39:32,700 : worker.worker : DEBUG : Step 181321, finished rewards 42.56, envs finished 1
2026-01-17 13:39:32,811 : worker.worker : DEBUG : Step 181341, finished rewards 46.76, envs finished 1
2026-01-17 13:39:32,963 : agent.on_policy : DEBUG : Mean Losses: [5.5417186096310616]
2026-01-17 13:39:33,016 : worker.worker : DEBUG : Step 181352, finished rewards 42.41, envs finished 1
2026-01-17 13:39:33,257 : agent.on_policy : DEBUG : Mean Losses: [3.966900698840618]
2026-01-17 13:39:33,281 : worker.worker : DEBUG : Step 181380, finished rewards 19.40, envs finished 1
2026-01-17 13:39:33,343 : worker.worker : DEBUG : Step 181392, finished rewards 2.93, envs finished 1
2026-01-17 13:39:33,355 : worker.worker : DEBUG : Step 181394, finished rewards 24.66, envs finished 1
2026-01-17 13:39:33,556 : agent.on_policy : DEBUG : Mean Losses: [4.981009975075722]
2026-01-17 13:39:33,558 : worker.worker : DEBUG : Step 181408, finished rewards -18.14, envs finished 1
2026-01-17 13:39:33,590 : worker.worker : DEBUG : Step 181415, finished rewards 17.10, envs finished 1
2026-01-17 13:39:33,816 : agent.on_policy : DEBUG : Mean Losses: [3.586206369102001]
2026-01-17 13:39:33,927 : worker.worker : DEBUG : Step 181448, finished rewards -2.10, envs finished 1
2026-01-17 13:39:33,967 : worker.worker : DEBUG : Step 181450, finished rewards 16.03, envs finished 1
2026-01-17 13:39:34,211 : agent.on_policy : DEBUG : Mean Losses: [3.3087817765772343]
2026-01-17 13:39:34,269 : worker.worker : DEBUG : Step 181479, finished rewards 20.05, envs finished 1
2026-01-17 13:39:34,344 : worker.worker : DEBUG : Step 181487, finished rewards 23.10, envs finished 1
2026-01-17 13:39:34,483 : worker.worker : DEBUG : Step 181497, finished rewards 15.81, envs finished 1
2026-01-17 13:39:34,501 : worker.worker : DEBUG : Step 181499, finished rewards 25.51, envs finished 1
2026-01-17 13:39:34,550 : worker.worker : DEBUG : Step 181503, finished rewards 28.29, envs finished 1
2026-01-17 13:39:34,646 : agent.on_policy : DEBUG : Mean Losses: [6.606413967907429]
2026-01-17 13:39:34,773 : worker.worker : DEBUG : Step 181518, finished rewards -22.12, envs finished 1
2026-01-17 13:39:34,960 : agent.on_policy : DEBUG : Mean Losses: [1.9247070010751486]
2026-01-17 13:39:35,067 : worker.worker : DEBUG : Step 181546, finished rewards 21.27, envs finished 1
2026-01-17 13:39:35,081 : worker.worker : DEBUG : Step 181549, finished rewards 19.55, envs finished 1
2026-01-17 13:39:35,269 : agent.on_policy : DEBUG : Mean Losses: [4.237534910440445]
2026-01-17 13:39:35,290 : worker.worker : DEBUG : Step 181573, finished rewards 42.87, envs finished 1
2026-01-17 13:39:35,296 : worker.worker : DEBUG : Step 181574, finished rewards 27.42, envs finished 1
2026-01-17 13:39:35,377 : worker.worker : DEBUG : Step 181595, finished rewards 7.21, envs finished 1
2026-01-17 13:39:35,451 : agent.on_policy : DEBUG : Mean Losses: [5.001086808741093]
2026-01-17 13:39:35,570 : worker.worker : DEBUG : Step 181611, finished rewards 8.82, envs finished 1
2026-01-17 13:39:35,647 : worker.worker : DEBUG : Step 181616, finished rewards 5.91, envs finished 1
2026-01-17 13:39:35,925 : agent.on_policy : DEBUG : Mean Losses: [3.3648268282413483]
2026-01-17 13:39:35,972 : worker.worker : DEBUG : Step 181639, finished rewards 32.82, envs finished 1
2026-01-17 13:39:36,076 : worker.worker : DEBUG : Step 181662, finished rewards 27.86, envs finished 1
2026-01-17 13:39:36,230 : agent.on_policy : DEBUG : Mean Losses: [3.2501771077513695]
2026-01-17 13:39:36,341 : worker.worker : DEBUG : Step 181676, finished rewards 18.82, envs finished 1
2026-01-17 13:39:36,412 : worker.worker : DEBUG : Step 181691, finished rewards 34.26, envs finished 1
2026-01-17 13:39:36,432 : worker.worker : DEBUG : Step 181695, finished rewards 34.67, envs finished 1
2026-01-17 13:39:36,569 : agent.on_policy : DEBUG : Mean Losses: [6.059990961104631]
2026-01-17 13:39:36,633 : worker.worker : DEBUG : Step 181701, finished rewards 68.31, envs finished 1
2026-01-17 13:39:37,084 : agent.on_policy : DEBUG : Mean Losses: [2.964080784469843]
2026-01-17 13:39:37,122 : worker.worker : DEBUG : Step 181737, finished rewards 24.39, envs finished 1
2026-01-17 13:39:37,156 : worker.worker : DEBUG : Step 181742, finished rewards 98.64, envs finished 1
2026-01-17 13:39:37,219 : worker.worker : DEBUG : Step 181758, finished rewards -27.75, envs finished 1
2026-01-17 13:39:37,284 : agent.on_policy : DEBUG : Mean Losses: [5.252623111009598]
2026-01-17 13:39:37,300 : worker.worker : DEBUG : Step 181762, finished rewards 41.57, envs finished 1
2026-01-17 13:39:37,355 : worker.worker : DEBUG : Step 181765, finished rewards 15.62, envs finished 1
2026-01-17 13:39:37,634 : agent.on_policy : DEBUG : Mean Losses: [3.0596951814368367]
2026-01-17 13:39:37,652 : worker.worker : DEBUG : Step 181796, finished rewards 6.51, envs finished 1
2026-01-17 13:39:37,665 : worker.worker : DEBUG : Step 181798, finished rewards 21.35, envs finished 1
2026-01-17 13:39:37,738 : worker.worker : DEBUG : Step 181815, finished rewards 21.98, envs finished 1
2026-01-17 13:39:37,778 : worker.worker : DEBUG : Step 181823, finished rewards 28.16, envs finished 1
2026-01-17 13:39:37,912 : agent.on_policy : DEBUG : Mean Losses: [3.9761766642332077]
2026-01-17 13:39:37,939 : worker.worker : DEBUG : Step 181829, finished rewards 28.20, envs finished 1
2026-01-17 13:39:38,088 : worker.worker : DEBUG : Step 181845, finished rewards 28.13, envs finished 1
2026-01-17 13:39:38,282 : agent.on_policy : DEBUG : Mean Losses: [4.176845669746399]
2026-01-17 13:39:38,433 : worker.worker : DEBUG : Step 181877, finished rewards 5.64, envs finished 1
2026-01-17 13:39:38,483 : worker.worker : DEBUG : Step 181887, finished rewards 2.23, envs finished 1
2026-01-17 13:39:38,594 : agent.on_policy : DEBUG : Mean Losses: [6.251822508871555]
2026-01-17 13:39:38,673 : worker.worker : DEBUG : Step 181893, finished rewards 42.65, envs finished 1
2026-01-17 13:39:38,732 : worker.worker : DEBUG : Step 181900, finished rewards 30.09, envs finished 1
2026-01-17 13:39:38,828 : worker.worker : DEBUG : Step 181907, finished rewards 21.47, envs finished 1
2026-01-17 13:39:38,859 : worker.worker : DEBUG : Step 181912, finished rewards 10.10, envs finished 1
2026-01-17 13:39:39,051 : agent.on_policy : DEBUG : Mean Losses: [4.205290712416172]
2026-01-17 13:39:39,098 : worker.worker : DEBUG : Step 181924, finished rewards 34.93, envs finished 1
2026-01-17 13:39:39,172 : worker.worker : DEBUG : Step 181932, finished rewards 16.65, envs finished 1
2026-01-17 13:39:39,563 : agent.on_policy : DEBUG : Mean Losses: [2.327075444161892]
2026-01-17 13:39:39,660 : worker.worker : DEBUG : Step 181971, finished rewards 46.11, envs finished 1
2026-01-17 13:39:39,761 : worker.worker : DEBUG : Step 181983, finished rewards 40.66, envs finished 1
2026-01-17 13:39:39,873 : agent.on_policy : DEBUG : Mean Losses: [6.967175826430321]
2026-01-17 13:39:39,876 : worker.worker : DEBUG : Step 181984, finished rewards 26.39, envs finished 1
2026-01-17 13:39:39,882 : worker.worker : DEBUG : Step 181985, finished rewards 29.09, envs finished 1
2026-01-17 13:39:39,918 : worker.worker : DEBUG : Step 181987, finished rewards 8.68, envs finished 1
2026-01-17 13:39:40,063 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:39:40,421 : agent.on_policy : DEBUG : Mean Losses: [2.8011577213183045]
2026-01-17 13:39:40,428 : worker.worker : DEBUG : Step 182017, finished rewards 28.09, envs finished 1
2026-01-17 13:39:40,434 : worker.worker : DEBUG : Step 182018, finished rewards -3.67, envs finished 1
2026-01-17 13:39:40,487 : worker.worker : DEBUG : Step 182029, finished rewards 22.25, envs finished 1
2026-01-17 13:39:40,507 : worker.worker : DEBUG : Step 182034, finished rewards 46.68, envs finished 1
2026-01-17 13:39:40,695 : agent.on_policy : DEBUG : Mean Losses: [4.373869489878416]
2026-01-17 13:39:40,698 : worker.worker : DEBUG : Step 182048, finished rewards 46.47, envs finished 1
2026-01-17 13:39:40,709 : worker.worker : DEBUG : Step 182050, finished rewards 46.37, envs finished 1
2026-01-17 13:39:40,792 : worker.worker : DEBUG : Step 182066, finished rewards 34.19, envs finished 1
2026-01-17 13:39:40,967 : agent.on_policy : DEBUG : Mean Losses: [3.114119827747345]
2026-01-17 13:39:40,971 : worker.worker : DEBUG : Step 182080, finished rewards 46.97, envs finished 1
2026-01-17 13:39:41,150 : worker.worker : DEBUG : Step 182105, finished rewards 28.42, envs finished 1
2026-01-17 13:39:41,222 : agent.on_policy : DEBUG : Mean Losses: [4.308087706565857]
2026-01-17 13:39:41,224 : worker.worker : DEBUG : Step 182112, finished rewards 6.85, envs finished 1
2026-01-17 13:39:41,292 : worker.worker : DEBUG : Step 182129, finished rewards 46.26, envs finished 1
2026-01-17 13:39:41,362 : worker.worker : DEBUG : Step 182133, finished rewards 16.96, envs finished 1
2026-01-17 13:39:41,415 : worker.worker : DEBUG : Step 182143, finished rewards 15.12, envs finished 1
2026-01-17 13:39:41,538 : agent.on_policy : DEBUG : Mean Losses: [6.54427395388484]
2026-01-17 13:39:41,563 : worker.worker : DEBUG : Step 182148, finished rewards 21.44, envs finished 1
2026-01-17 13:39:41,724 : worker.worker : DEBUG : Step 182168, finished rewards 7.74, envs finished 1
2026-01-17 13:39:41,868 : agent.on_policy : DEBUG : Mean Losses: [3.267327081412077]
2026-01-17 13:39:41,878 : worker.worker : DEBUG : Step 182178, finished rewards 20.29, envs finished 1
2026-01-17 13:39:41,988 : worker.worker : DEBUG : Step 182200, finished rewards 41.32, envs finished 1
2026-01-17 13:39:42,033 : worker.worker : DEBUG : Step 182206, finished rewards 23.30, envs finished 1
2026-01-17 13:39:42,207 : agent.on_policy : DEBUG : Mean Losses: [5.3694957830011845]
2026-01-17 13:39:42,307 : worker.worker : DEBUG : Step 182217, finished rewards 30.97, envs finished 1
2026-01-17 13:39:42,353 : worker.worker : DEBUG : Step 182220, finished rewards 9.17, envs finished 1
2026-01-17 13:39:42,392 : worker.worker : DEBUG : Step 182227, finished rewards 30.00, envs finished 1
2026-01-17 13:39:42,554 : agent.on_policy : DEBUG : Mean Losses: [4.701811823993921]
2026-01-17 13:39:42,569 : worker.worker : DEBUG : Step 182244, finished rewards 37.58, envs finished 1
2026-01-17 13:39:42,595 : worker.worker : DEBUG : Step 182250, finished rewards 18.66, envs finished 1
2026-01-17 13:39:42,687 : worker.worker : DEBUG : Step 182271, finished rewards 41.74, envs finished 1
2026-01-17 13:39:42,775 : agent.on_policy : DEBUG : Mean Losses: [4.265938591212034]
2026-01-17 13:39:43,042 : worker.worker : DEBUG : Step 182295, finished rewards 7.53, envs finished 1
2026-01-17 13:39:43,106 : worker.worker : DEBUG : Step 182298, finished rewards 25.38, envs finished 1
2026-01-17 13:39:43,304 : agent.on_policy : DEBUG : Mean Losses: [4.911134704947472]
2026-01-17 13:39:43,352 : worker.worker : DEBUG : Step 182307, finished rewards 28.20, envs finished 1
2026-01-17 13:39:43,386 : worker.worker : DEBUG : Step 182313, finished rewards 28.12, envs finished 1
2026-01-17 13:39:43,671 : agent.on_policy : DEBUG : Mean Losses: [4.757073778659105]
2026-01-17 13:39:43,719 : worker.worker : DEBUG : Step 182343, finished rewards 39.61, envs finished 1
2026-01-17 13:39:43,754 : worker.worker : DEBUG : Step 182349, finished rewards 20.47, envs finished 2
2026-01-17 13:39:43,821 : worker.worker : DEBUG : Step 182362, finished rewards 45.98, envs finished 1
2026-01-17 13:39:43,828 : worker.worker : DEBUG : Step 182363, finished rewards -10.62, envs finished 1
2026-01-17 13:39:43,984 : agent.on_policy : DEBUG : Mean Losses: [6.584985628724098]
2026-01-17 13:39:44,094 : worker.worker : DEBUG : Step 182388, finished rewards 24.29, envs finished 1
2026-01-17 13:39:44,117 : worker.worker : DEBUG : Step 182391, finished rewards 31.48, envs finished 1
2026-01-17 13:39:44,285 : agent.on_policy : DEBUG : Mean Losses: [3.7613818403333426]
2026-01-17 13:39:44,315 : worker.worker : DEBUG : Step 182407, finished rewards 22.76, envs finished 1
2026-01-17 13:39:44,376 : worker.worker : DEBUG : Step 182420, finished rewards 41.63, envs finished 1
2026-01-17 13:39:44,537 : agent.on_policy : DEBUG : Mean Losses: [3.4234673138707876]
2026-01-17 13:39:44,604 : worker.worker : DEBUG : Step 182443, finished rewards 21.10, envs finished 2
2026-01-17 13:39:44,702 : worker.worker : DEBUG : Step 182457, finished rewards 22.40, envs finished 1
2026-01-17 13:39:44,739 : worker.worker : DEBUG : Step 182459, finished rewards 41.98, envs finished 1
2026-01-17 13:39:44,852 : agent.on_policy : DEBUG : Mean Losses: [5.050220124423504]
2026-01-17 13:39:44,858 : worker.worker : DEBUG : Step 182465, finished rewards 17.85, envs finished 1
2026-01-17 13:39:45,031 : worker.worker : DEBUG : Step 182484, finished rewards 46.16, envs finished 1
2026-01-17 13:39:45,083 : worker.worker : DEBUG : Step 182494, finished rewards 28.25, envs finished 1
2026-01-17 13:39:45,149 : agent.on_policy : DEBUG : Mean Losses: [4.7298258896917105]
2026-01-17 13:39:45,270 : worker.worker : DEBUG : Step 182507, finished rewards 8.01, envs finished 1
2026-01-17 13:39:45,513 : agent.on_policy : DEBUG : Mean Losses: [2.3165439423173666]
2026-01-17 13:39:45,557 : worker.worker : DEBUG : Step 182531, finished rewards 26.50, envs finished 1
2026-01-17 13:39:45,670 : worker.worker : DEBUG : Step 182546, finished rewards 18.60, envs finished 1
2026-01-17 13:39:45,867 : agent.on_policy : DEBUG : Mean Losses: [3.2665310129523277]
2026-01-17 13:39:45,893 : worker.worker : DEBUG : Step 182562, finished rewards 15.82, envs finished 1
2026-01-17 13:39:45,910 : worker.worker : DEBUG : Step 182563, finished rewards 15.48, envs finished 1
2026-01-17 13:39:45,991 : worker.worker : DEBUG : Step 182568, finished rewards 17.54, envs finished 1
2026-01-17 13:39:46,053 : worker.worker : DEBUG : Step 182577, finished rewards 23.13, envs finished 1
2026-01-17 13:39:46,066 : worker.worker : DEBUG : Step 182578, finished rewards 41.63, envs finished 1
2026-01-17 13:39:46,163 : worker.worker : DEBUG : Step 182585, finished rewards 25.92, envs finished 1
2026-01-17 13:39:46,360 : agent.on_policy : DEBUG : Mean Losses: [5.444536551833153]
2026-01-17 13:39:46,384 : worker.worker : DEBUG : Step 182595, finished rewards 45.80, envs finished 1
2026-01-17 13:39:46,696 : agent.on_policy : DEBUG : Mean Losses: [1.405049366876483]
2026-01-17 13:39:46,712 : worker.worker : DEBUG : Step 182627, finished rewards 46.01, envs finished 1
2026-01-17 13:39:46,798 : worker.worker : DEBUG : Step 182642, finished rewards 22.07, envs finished 1
2026-01-17 13:39:46,829 : worker.worker : DEBUG : Step 182648, finished rewards 35.14, envs finished 2
2026-01-17 13:39:47,114 : agent.on_policy : DEBUG : Mean Losses: [6.658049523830414]
2026-01-17 13:39:47,201 : worker.worker : DEBUG : Step 182669, finished rewards 19.77, envs finished 1
2026-01-17 13:39:47,342 : worker.worker : DEBUG : Step 182683, finished rewards 13.87, envs finished 1
2026-01-17 13:39:47,494 : agent.on_policy : DEBUG : Mean Losses: [4.204066574573517]
2026-01-17 13:39:47,667 : worker.worker : DEBUG : Step 182708, finished rewards 1.45, envs finished 1
2026-01-17 13:39:47,796 : agent.on_policy : DEBUG : Mean Losses: [2.4227368868887424]
2026-01-17 13:39:47,946 : worker.worker : DEBUG : Step 182736, finished rewards -9.53, envs finished 1
2026-01-17 13:39:47,988 : worker.worker : DEBUG : Step 182744, finished rewards 6.80, envs finished 1
2026-01-17 13:39:48,082 : agent.on_policy : DEBUG : Mean Losses: [3.85432530939579]
2026-01-17 13:39:48,084 : worker.worker : DEBUG : Step 182752, finished rewards 15.77, envs finished 1
2026-01-17 13:39:48,216 : worker.worker : DEBUG : Step 182764, finished rewards 13.58, envs finished 2
2026-01-17 13:39:48,492 : agent.on_policy : DEBUG : Mean Losses: [3.842916052788496]
2026-01-17 13:39:48,513 : worker.worker : DEBUG : Step 182789, finished rewards 12.49, envs finished 1
2026-01-17 13:39:48,533 : worker.worker : DEBUG : Step 182792, finished rewards 5.35, envs finished 1
2026-01-17 13:39:47,966 : agent.on_policy : DEBUG : Mean Losses: [3.0031323358416557]
2026-01-17 13:39:48,030 : worker.worker : DEBUG : Step 182828, finished rewards 46.05, envs finished 1
2026-01-17 13:39:48,070 : worker.worker : DEBUG : Step 182835, finished rewards 26.28, envs finished 1
2026-01-17 13:39:48,109 : worker.worker : DEBUG : Step 182841, finished rewards 18.16, envs finished 1
2026-01-17 13:39:48,287 : agent.on_policy : DEBUG : Mean Losses: [5.198359549045563]
2026-01-17 13:39:48,290 : worker.worker : DEBUG : Step 182848, finished rewards 20.91, envs finished 1
2026-01-17 13:39:48,402 : worker.worker : DEBUG : Step 182859, finished rewards 23.04, envs finished 1
2026-01-17 13:39:48,567 : worker.worker : DEBUG : Step 182877, finished rewards 27.42, envs finished 1
2026-01-17 13:39:48,736 : agent.on_policy : DEBUG : Mean Losses: [3.9560959488153458]
2026-01-17 13:39:48,841 : worker.worker : DEBUG : Step 182887, finished rewards 22.15, envs finished 1
2026-01-17 13:39:49,122 : agent.on_policy : DEBUG : Mean Losses: [2.923914619255811]
2026-01-17 13:39:49,138 : worker.worker : DEBUG : Step 182915, finished rewards 72.13, envs finished 1
2026-01-17 13:39:49,185 : worker.worker : DEBUG : Step 182924, finished rewards 35.90, envs finished 1
2026-01-17 13:39:49,217 : worker.worker : DEBUG : Step 182930, finished rewards 16.47, envs finished 1
2026-01-17 13:39:49,228 : worker.worker : DEBUG : Step 182932, finished rewards 22.03, envs finished 1
2026-01-17 13:39:49,241 : worker.worker : DEBUG : Step 182934, finished rewards 36.91, envs finished 1
2026-01-17 13:39:49,284 : worker.worker : DEBUG : Step 182941, finished rewards 45.79, envs finished 1
2026-01-17 13:39:49,377 : agent.on_policy : DEBUG : Mean Losses: [9.552979052066803]
2026-01-17 13:39:49,544 : worker.worker : DEBUG : Step 182959, finished rewards 39.52, envs finished 1
2026-01-17 13:39:49,865 : agent.on_policy : DEBUG : Mean Losses: [2.897201245650649]
2026-01-17 13:39:49,878 : worker.worker : DEBUG : Step 182979, finished rewards -6.71, envs finished 1
2026-01-17 13:39:49,958 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:39:50,148 : agent.on_policy : DEBUG : Mean Losses: [3.4027897752821445]
2026-01-17 13:39:50,318 : worker.worker : DEBUG : Step 183024, finished rewards 23.64, envs finished 1
2026-01-17 13:39:50,442 : worker.worker : DEBUG : Step 183031, finished rewards 11.99, envs finished 1
2026-01-17 13:39:50,480 : worker.worker : DEBUG : Step 183035, finished rewards 23.02, envs finished 1
2026-01-17 13:39:50,664 : agent.on_policy : DEBUG : Mean Losses: [6.1738961189985275]
2026-01-17 13:39:50,671 : worker.worker : DEBUG : Step 183040, finished rewards 13.32, envs finished 1
2026-01-17 13:39:50,716 : worker.worker : DEBUG : Step 183044, finished rewards 12.86, envs finished 1
2026-01-17 13:39:50,786 : worker.worker : DEBUG : Step 183048, finished rewards 34.47, envs finished 1
2026-01-17 13:39:50,805 : worker.worker : DEBUG : Step 183050, finished rewards 40.91, envs finished 1
2026-01-17 13:39:50,960 : agent.on_policy : DEBUG : Mean Losses: [4.147437959909439]
2026-01-17 13:39:50,984 : worker.worker : DEBUG : Step 183076, finished rewards -12.85, envs finished 1
2026-01-17 13:39:51,313 : agent.on_policy : DEBUG : Mean Losses: [1.5970720499753952]
2026-01-17 13:39:51,541 : worker.worker : DEBUG : Step 183118, finished rewards 24.40, envs finished 1
2026-01-17 13:39:51,624 : worker.worker : DEBUG : Step 183129, finished rewards 24.23, envs finished 1
2026-01-17 13:39:51,808 : agent.on_policy : DEBUG : Mean Losses: [5.202406592667103]
2026-01-17 13:39:51,845 : worker.worker : DEBUG : Step 183139, finished rewards 22.62, envs finished 1
2026-01-17 13:39:51,909 : worker.worker : DEBUG : Step 183143, finished rewards 6.77, envs finished 1
2026-01-17 13:39:52,041 : worker.worker : DEBUG : Step 183156, finished rewards 17.93, envs finished 1
2026-01-17 13:39:52,121 : worker.worker : DEBUG : Step 183166, finished rewards 25.25, envs finished 1
2026-01-17 13:39:52,320 : agent.on_policy : DEBUG : Mean Losses: [5.569800760596991]
2026-01-17 13:39:52,714 : agent.on_policy : DEBUG : Mean Losses: [2.2903524609282613]
2026-01-17 13:39:52,733 : worker.worker : DEBUG : Step 183202, finished rewards 30.98, envs finished 1
2026-01-17 13:39:52,753 : worker.worker : DEBUG : Step 183205, finished rewards -7.69, envs finished 1
2026-01-17 13:39:52,856 : worker.worker : DEBUG : Step 183224, finished rewards 24.54, envs finished 1
2026-01-17 13:39:52,871 : worker.worker : DEBUG : Step 183227, finished rewards 40.44, envs finished 1
2026-01-17 13:39:53,060 : agent.on_policy : DEBUG : Mean Losses: [6.984033744782209]
2026-01-17 13:39:53,085 : worker.worker : DEBUG : Step 183236, finished rewards 42.74, envs finished 1
2026-01-17 13:39:53,347 : worker.worker : DEBUG : Step 183255, finished rewards 14.67, envs finished 1
2026-01-17 13:39:53,580 : agent.on_policy : DEBUG : Mean Losses: [4.4810143038630486]
2026-01-17 13:39:53,685 : worker.worker : DEBUG : Step 183274, finished rewards 41.44, envs finished 1
2026-01-17 13:39:53,739 : worker.worker : DEBUG : Step 183281, finished rewards -10.78, envs finished 1
2026-01-17 13:39:53,854 : worker.worker : DEBUG : Step 183295, finished rewards 32.20, envs finished 2
2026-01-17 13:39:53,992 : agent.on_policy : DEBUG : Mean Losses: [4.506040170788765]
2026-01-17 13:39:53,996 : worker.worker : DEBUG : Step 183296, finished rewards 39.74, envs finished 1
2026-01-17 13:39:54,114 : worker.worker : DEBUG : Step 183307, finished rewards 41.64, envs finished 1
2026-01-17 13:39:54,132 : worker.worker : DEBUG : Step 183309, finished rewards 33.02, envs finished 1
2026-01-17 13:39:54,427 : agent.on_policy : DEBUG : Mean Losses: [2.321735367178917]
2026-01-17 13:39:54,482 : worker.worker : DEBUG : Step 183340, finished rewards 29.22, envs finished 1
2026-01-17 13:39:54,511 : worker.worker : DEBUG : Step 183346, finished rewards 41.22, envs finished 1
2026-01-17 13:39:54,731 : agent.on_policy : DEBUG : Mean Losses: [3.5890985541045666]
2026-01-17 13:39:54,754 : worker.worker : DEBUG : Step 183367, finished rewards 28.94, envs finished 1
2026-01-17 13:39:54,819 : worker.worker : DEBUG : Step 183372, finished rewards 46.45, envs finished 1
2026-01-17 13:39:54,878 : worker.worker : DEBUG : Step 183379, finished rewards 31.71, envs finished 1
2026-01-17 13:39:54,898 : worker.worker : DEBUG : Step 183382, finished rewards 28.54, envs finished 1
2026-01-17 13:39:55,156 : agent.on_policy : DEBUG : Mean Losses: [5.55713813751936]
2026-01-17 13:39:55,171 : worker.worker : DEBUG : Step 183393, finished rewards 29.42, envs finished 1
2026-01-17 13:39:55,254 : worker.worker : DEBUG : Step 183407, finished rewards 13.77, envs finished 1
2026-01-17 13:39:55,344 : worker.worker : DEBUG : Step 183416, finished rewards 42.88, envs finished 1
2026-01-17 13:39:55,508 : agent.on_policy : DEBUG : Mean Losses: [3.3952336870133877]
2026-01-17 13:39:55,687 : worker.worker : DEBUG : Step 183447, finished rewards 13.74, envs finished 1
2026-01-17 13:39:55,719 : worker.worker : DEBUG : Step 183451, finished rewards 41.38, envs finished 1
2026-01-17 13:39:55,858 : agent.on_policy : DEBUG : Mean Losses: [4.105014560744166]
2026-01-17 13:39:56,137 : worker.worker : DEBUG : Step 183480, finished rewards 13.59, envs finished 1
2026-01-17 13:39:56,318 : agent.on_policy : DEBUG : Mean Losses: [5.023552641272545]
2026-01-17 13:39:56,335 : worker.worker : DEBUG : Step 183491, finished rewards 12.44, envs finished 1
2026-01-17 13:39:56,458 : worker.worker : DEBUG : Step 183506, finished rewards 18.01, envs finished 1
2026-01-17 13:39:56,596 : worker.worker : DEBUG : Step 183517, finished rewards -11.59, envs finished 1
2026-01-17 13:39:56,695 : agent.on_policy : DEBUG : Mean Losses: [6.98251436650753]
2026-01-17 13:39:56,766 : worker.worker : DEBUG : Step 183526, finished rewards 39.00, envs finished 1
2026-01-17 13:39:56,797 : worker.worker : DEBUG : Step 183531, finished rewards -9.08, envs finished 1
2026-01-17 13:39:56,945 : worker.worker : DEBUG : Step 183549, finished rewards 18.47, envs finished 1
2026-01-17 13:39:57,005 : agent.on_policy : DEBUG : Mean Losses: [3.7478662207722664]
2026-01-17 13:39:57,239 : agent.on_policy : DEBUG : Mean Losses: [3.200855053961277]
2026-01-17 13:39:57,287 : worker.worker : DEBUG : Step 183597, finished rewards 40.91, envs finished 1
2026-01-17 13:39:57,299 : worker.worker : DEBUG : Step 183599, finished rewards -33.12, envs finished 1
2026-01-17 13:39:57,322 : worker.worker : DEBUG : Step 183604, finished rewards 14.42, envs finished 1
2026-01-17 13:39:57,343 : worker.worker : DEBUG : Step 183608, finished rewards 25.48, envs finished 1
2026-01-17 13:39:57,427 : agent.on_policy : DEBUG : Mean Losses: [7.24622118473053]
2026-01-17 13:39:57,430 : worker.worker : DEBUG : Step 183616, finished rewards 13.17, envs finished 1
2026-01-17 13:39:57,508 : worker.worker : DEBUG : Step 183631, finished rewards 17.59, envs finished 1
2026-01-17 13:39:57,777 : agent.on_policy : DEBUG : Mean Losses: [2.0845736246556044]
2026-01-17 13:39:57,805 : worker.worker : DEBUG : Step 183655, finished rewards 18.29, envs finished 1
2026-01-17 13:39:57,881 : worker.worker : DEBUG : Step 183675, finished rewards 42.24, envs finished 1
2026-01-17 13:39:57,958 : agent.on_policy : DEBUG : Mean Losses: [3.2833638340234756]
2026-01-17 13:39:58,045 : worker.worker : DEBUG : Step 183689, finished rewards 25.84, envs finished 1
2026-01-17 13:39:58,074 : worker.worker : DEBUG : Step 183694, finished rewards 46.50, envs finished 1
2026-01-17 13:39:58,097 : worker.worker : DEBUG : Step 183697, finished rewards 53.99, envs finished 1
2026-01-17 13:39:58,107 : worker.worker : DEBUG : Step 183698, finished rewards 18.37, envs finished 1
2026-01-17 13:39:58,156 : worker.worker : DEBUG : Step 183700, finished rewards 25.60, envs finished 1
2026-01-17 13:39:58,368 : agent.on_policy : DEBUG : Mean Losses: [6.3702342212200165]
2026-01-17 13:39:58,652 : agent.on_policy : DEBUG : Mean Losses: [1.655061924830079]
2026-01-17 13:39:58,716 : worker.worker : DEBUG : Step 183757, finished rewards 19.88, envs finished 1
2026-01-17 13:39:58,749 : worker.worker : DEBUG : Step 183764, finished rewards 46.03, envs finished 1
2026-01-17 13:39:58,759 : worker.worker : DEBUG : Step 183765, finished rewards 40.93, envs finished 1
2026-01-17 13:39:58,947 : agent.on_policy : DEBUG : Mean Losses: [6.331503629684448]
2026-01-17 13:39:58,958 : worker.worker : DEBUG : Step 183779, finished rewards 26.71, envs finished 1
2026-01-17 13:39:58,965 : worker.worker : DEBUG : Step 183780, finished rewards 17.10, envs finished 1
2026-01-17 13:39:59,083 : worker.worker : DEBUG : Step 183794, finished rewards 21.13, envs finished 1
2026-01-17 13:39:59,281 : agent.on_policy : DEBUG : Mean Losses: [4.084597839042544]
2026-01-17 13:39:59,285 : worker.worker : DEBUG : Step 183808, finished rewards 11.76, envs finished 1
2026-01-17 13:39:59,755 : agent.on_policy : DEBUG : Mean Losses: [2.257288336753845]
2026-01-17 13:39:59,971 : worker.worker : DEBUG : Step 183856, finished rewards 25.75, envs finished 1
2026-01-17 13:40:00,019 : worker.worker : DEBUG : Step 183858, finished rewards 36.89, envs finished 1
2026-01-17 13:40:00,144 : worker.worker : DEBUG : Step 183871, finished rewards 11.89, envs finished 1
2026-01-17 13:40:00,318 : agent.on_policy : DEBUG : Mean Losses: [6.550268091261387]
2026-01-17 13:40:00,347 : worker.worker : DEBUG : Step 183877, finished rewards 32.07, envs finished 1
2026-01-17 13:40:00,371 : worker.worker : DEBUG : Step 183878, finished rewards 88.72, envs finished 1
2026-01-17 13:40:00,408 : worker.worker : DEBUG : Step 183879, finished rewards 40.66, envs finished 1
2026-01-17 13:40:00,524 : worker.worker : DEBUG : Step 183895, finished rewards -5.51, envs finished 1
2026-01-17 13:40:00,549 : worker.worker : DEBUG : Step 183897, finished rewards 6.05, envs finished 1
2026-01-17 13:40:00,723 : agent.on_policy : DEBUG : Mean Losses: [5.249154966324568]
2026-01-17 13:40:01,006 : agent.on_policy : DEBUG : Mean Losses: [1.661747770383954]
2026-01-17 13:40:01,085 : worker.worker : DEBUG : Step 183955, finished rewards 21.97, envs finished 1
2026-01-17 13:40:01,130 : worker.worker : DEBUG : Step 183963, finished rewards 25.42, envs finished 1
2026-01-17 13:40:01,299 : agent.on_policy : DEBUG : Mean Losses: [4.118117555975914]
2026-01-17 13:40:01,360 : worker.worker : DEBUG : Step 183977, finished rewards 20.55, envs finished 1
2026-01-17 13:40:01,565 : worker.worker : DEBUG : Step 183996, finished rewards 8.38, envs finished 1
2026-01-17 13:40:01,598 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:40:01,685 : agent.on_policy : DEBUG : Mean Losses: [3.578752711415291]
2026-01-17 13:40:01,732 : worker.worker : DEBUG : Step 184009, finished rewards 10.81, envs finished 1
2026-01-17 13:40:01,794 : worker.worker : DEBUG : Step 184013, finished rewards 0.89, envs finished 1
2026-01-17 13:40:01,878 : worker.worker : DEBUG : Step 184022, finished rewards 2.85, envs finished 1
2026-01-17 13:40:02,087 : agent.on_policy : DEBUG : Mean Losses: [3.4768190383911133]
2026-01-17 13:40:02,248 : worker.worker : DEBUG : Step 184052, finished rewards 26.28, envs finished 1
2026-01-17 13:40:02,312 : worker.worker : DEBUG : Step 184062, finished rewards 13.92, envs finished 1
2026-01-17 13:40:02,387 : agent.on_policy : DEBUG : Mean Losses: [3.5896117351949215]
2026-01-17 13:40:02,452 : worker.worker : DEBUG : Step 184068, finished rewards 92.62, envs finished 1
2026-01-17 13:40:02,717 : worker.worker : DEBUG : Step 184093, finished rewards 40.50, envs finished 1
2026-01-17 13:40:02,839 : agent.on_policy : DEBUG : Mean Losses: [5.664284996688366]
2026-01-17 13:40:02,891 : worker.worker : DEBUG : Step 184099, finished rewards 16.72, envs finished 1
2026-01-17 13:40:02,962 : worker.worker : DEBUG : Step 184103, finished rewards 0.64, envs finished 1
2026-01-17 13:40:03,074 : worker.worker : DEBUG : Step 184115, finished rewards 17.01, envs finished 1
2026-01-17 13:40:03,566 : agent.on_policy : DEBUG : Mean Losses: [4.928061783313751]
2026-01-17 13:40:03,584 : worker.worker : DEBUG : Step 184129, finished rewards 5.60, envs finished 1
2026-01-17 13:40:03,808 : worker.worker : DEBUG : Step 184153, finished rewards 33.41, envs finished 1
2026-01-17 13:40:03,876 : worker.worker : DEBUG : Step 184158, finished rewards 26.41, envs finished 1
2026-01-17 13:40:04,014 : agent.on_policy : DEBUG : Mean Losses: [4.359945526346564]
2026-01-17 13:40:04,151 : worker.worker : DEBUG : Step 184170, finished rewards 41.95, envs finished 1
2026-01-17 13:40:04,525 : agent.on_policy : DEBUG : Mean Losses: [4.1662924736738205]
2026-01-17 13:40:04,551 : worker.worker : DEBUG : Step 184199, finished rewards 31.06, envs finished 1
2026-01-17 13:40:04,601 : worker.worker : DEBUG : Step 184215, finished rewards 29.50, envs finished 1
2026-01-17 13:40:04,616 : worker.worker : DEBUG : Step 184219, finished rewards 6.69, envs finished 1
2026-01-17 13:40:04,669 : agent.on_policy : DEBUG : Mean Losses: [5.32010031491518]
2026-01-17 13:40:04,684 : worker.worker : DEBUG : Step 184227, finished rewards -21.36, envs finished 1
2026-01-17 13:40:04,756 : worker.worker : DEBUG : Step 184252, finished rewards -23.38, envs finished 1
2026-01-17 13:40:04,761 : worker.worker : DEBUG : Step 184253, finished rewards 21.74, envs finished 1
2026-01-17 13:40:04,808 : agent.on_policy : DEBUG : Mean Losses: [5.453662060201168]
2026-01-17 13:40:04,850 : worker.worker : DEBUG : Step 184267, finished rewards 8.81, envs finished 1
2026-01-17 13:40:05,070 : agent.on_policy : DEBUG : Mean Losses: [4.075640968978405]
2026-01-17 13:40:05,083 : worker.worker : DEBUG : Step 184291, finished rewards 24.74, envs finished 1
2026-01-17 13:40:05,151 : worker.worker : DEBUG : Step 184309, finished rewards 23.16, envs finished 1
2026-01-17 13:40:05,172 : worker.worker : DEBUG : Step 184313, finished rewards 25.40, envs finished 1
2026-01-17 13:40:05,203 : worker.worker : DEBUG : Step 184319, finished rewards 25.00, envs finished 1
2026-01-17 13:40:05,324 : agent.on_policy : DEBUG : Mean Losses: [5.495962142944336]
2026-01-17 13:40:05,484 : worker.worker : DEBUG : Step 184345, finished rewards 23.16, envs finished 1
2026-01-17 13:40:05,551 : agent.on_policy : DEBUG : Mean Losses: [3.7906418666243553]
2026-01-17 13:40:05,569 : worker.worker : DEBUG : Step 184356, finished rewards 45.13, envs finished 1
2026-01-17 13:40:05,602 : worker.worker : DEBUG : Step 184364, finished rewards 15.48, envs finished 1
2026-01-17 13:40:05,707 : worker.worker : DEBUG : Step 184373, finished rewards -13.78, envs finished 1
2026-01-17 13:40:05,749 : worker.worker : DEBUG : Step 184380, finished rewards 19.27, envs finished 1
2026-01-17 13:40:05,897 : agent.on_policy : DEBUG : Mean Losses: [5.417003482580185]
2026-01-17 13:40:06,130 : agent.on_policy : DEBUG : Mean Losses: [3.132202183827758]
2026-01-17 13:40:06,139 : worker.worker : DEBUG : Step 184418, finished rewards 13.02, envs finished 1
2026-01-17 13:40:06,175 : worker.worker : DEBUG : Step 184426, finished rewards 33.08, envs finished 1
2026-01-17 13:40:06,196 : worker.worker : DEBUG : Step 184431, finished rewards 10.00, envs finished 1
2026-01-17 13:40:06,308 : agent.on_policy : DEBUG : Mean Losses: [4.429976306855679]
2026-01-17 13:40:06,316 : worker.worker : DEBUG : Step 184449, finished rewards 22.90, envs finished 1
2026-01-17 13:40:06,337 : worker.worker : DEBUG : Step 184453, finished rewards 56.31, envs finished 1
2026-01-17 13:40:06,541 : worker.worker : DEBUG : Step 184475, finished rewards 9.10, envs finished 1
2026-01-17 13:40:06,706 : agent.on_policy : DEBUG : Mean Losses: [3.554070530459285]
2026-01-17 13:40:06,727 : worker.worker : DEBUG : Step 184484, finished rewards 17.19, envs finished 1
2026-01-17 13:40:06,862 : worker.worker : DEBUG : Step 184500, finished rewards 32.36, envs finished 1
2026-01-17 13:40:07,069 : agent.on_policy : DEBUG : Mean Losses: [3.877896975725889]
2026-01-17 13:40:07,126 : worker.worker : DEBUG : Step 184518, finished rewards 28.40, envs finished 1
2026-01-17 13:40:07,239 : worker.worker : DEBUG : Step 184533, finished rewards 35.03, envs finished 1
2026-01-17 13:40:07,320 : worker.worker : DEBUG : Step 184540, finished rewards 10.55, envs finished 1
2026-01-17 13:40:07,343 : worker.worker : DEBUG : Step 184543, finished rewards -15.52, envs finished 1
2026-01-17 13:40:07,560 : agent.on_policy : DEBUG : Mean Losses: [7.15187687985599]
2026-01-17 13:40:07,734 : worker.worker : DEBUG : Step 184564, finished rewards 46.04, envs finished 1
2026-01-17 13:40:07,786 : worker.worker : DEBUG : Step 184570, finished rewards 28.75, envs finished 1
2026-01-17 13:40:07,900 : agent.on_policy : DEBUG : Mean Losses: [4.738678518682718]
2026-01-17 13:40:08,134 : worker.worker : DEBUG : Step 184604, finished rewards 37.15, envs finished 2
2026-01-17 13:40:08,146 : worker.worker : DEBUG : Step 184605, finished rewards 39.70, envs finished 1
2026-01-17 13:40:08,167 : worker.worker : DEBUG : Step 184607, finished rewards 46.40, envs finished 1
2026-01-17 13:40:08,248 : agent.on_policy : DEBUG : Mean Losses: [8.722629621624947]
2026-01-17 13:40:08,322 : worker.worker : DEBUG : Step 184616, finished rewards -18.56, envs finished 1
2026-01-17 13:40:08,591 : agent.on_policy : DEBUG : Mean Losses: [2.1983509846031666]
2026-01-17 13:40:08,609 : worker.worker : DEBUG : Step 184644, finished rewards 26.50, envs finished 1
2026-01-17 13:40:08,649 : worker.worker : DEBUG : Step 184655, finished rewards 25.91, envs finished 1
2026-01-17 13:40:08,704 : worker.worker : DEBUG : Step 184670, finished rewards 21.77, envs finished 1
2026-01-17 13:40:08,767 : agent.on_policy : DEBUG : Mean Losses: [4.163960311561823]
2026-01-17 13:40:08,783 : worker.worker : DEBUG : Step 184673, finished rewards 41.24, envs finished 1
2026-01-17 13:40:08,942 : worker.worker : DEBUG : Step 184686, finished rewards 34.62, envs finished 1
2026-01-17 13:40:09,049 : worker.worker : DEBUG : Step 184695, finished rewards 27.36, envs finished 1
2026-01-17 13:40:09,213 : agent.on_policy : DEBUG : Mean Losses: [4.852729046717286]
2026-01-17 13:40:09,289 : worker.worker : DEBUG : Step 184711, finished rewards 12.67, envs finished 1
2026-01-17 13:40:09,325 : worker.worker : DEBUG : Step 184712, finished rewards 26.16, envs finished 1
2026-01-17 13:40:09,586 : agent.on_policy : DEBUG : Mean Losses: [3.214458391070366]
2026-01-17 13:40:09,632 : worker.worker : DEBUG : Step 184748, finished rewards 17.84, envs finished 1
2026-01-17 13:40:09,640 : worker.worker : DEBUG : Step 184749, finished rewards 46.49, envs finished 1
2026-01-17 13:40:09,746 : agent.on_policy : DEBUG : Mean Losses: [5.947795525193214]
2026-01-17 13:40:09,884 : worker.worker : DEBUG : Step 184785, finished rewards 13.01, envs finished 1
2026-01-17 13:40:10,208 : agent.on_policy : DEBUG : Mean Losses: [3.2682024464011192]
2026-01-17 13:40:10,222 : worker.worker : DEBUG : Step 184802, finished rewards 26.88, envs finished 1
2026-01-17 13:40:10,307 : worker.worker : DEBUG : Step 184814, finished rewards 6.33, envs finished 1
2026-01-17 13:40:10,325 : worker.worker : DEBUG : Step 184817, finished rewards 16.45, envs finished 1
2026-01-17 13:40:10,538 : agent.on_policy : DEBUG : Mean Losses: [4.289945289492607]
2026-01-17 13:40:10,676 : worker.worker : DEBUG : Step 184845, finished rewards 24.05, envs finished 1
2026-01-17 13:40:10,784 : worker.worker : DEBUG : Step 184856, finished rewards 16.00, envs finished 1
2026-01-17 13:40:10,956 : agent.on_policy : DEBUG : Mean Losses: [3.7117163315415382]
2026-01-17 13:40:10,992 : worker.worker : DEBUG : Step 184874, finished rewards -1.05, envs finished 2
2026-01-17 13:40:11,080 : worker.worker : DEBUG : Step 184882, finished rewards -48.11, envs finished 1
2026-01-17 13:40:11,126 : worker.worker : DEBUG : Step 184889, finished rewards 39.79, envs finished 1
2026-01-17 13:40:11,321 : agent.on_policy : DEBUG : Mean Losses: [7.034881483763456]
2026-01-17 13:40:11,623 : agent.on_policy : DEBUG : Mean Losses: [3.0354842953383923]
2026-01-17 13:40:11,746 : worker.worker : DEBUG : Step 184940, finished rewards -4.28, envs finished 1
2026-01-17 13:40:11,779 : worker.worker : DEBUG : Step 184947, finished rewards 5.51, envs finished 1
2026-01-17 13:40:11,798 : worker.worker : DEBUG : Step 184949, finished rewards 16.63, envs finished 1
2026-01-17 13:40:12,004 : agent.on_policy : DEBUG : Mean Losses: [6.157975733280182]
2026-01-17 13:40:12,054 : worker.worker : DEBUG : Step 184968, finished rewards 11.98, envs finished 1
2026-01-17 13:40:12,203 : agent.on_policy : DEBUG : Mean Losses: [4.337529646232724]
2026-01-17 13:40:12,285 : worker.worker : DEBUG : Step 184996, finished rewards 6.67, envs finished 1
2026-01-17 13:40:12,305 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:40:12,319 : worker.worker : INFO : Step 185000, Avg Reward 22.0978, Max Reward 98.6427, Loss [4.42761003]
2026-01-17 13:40:12,558 : worker.worker : DEBUG : Step 185017, finished rewards -9.79, envs finished 1
2026-01-17 13:40:12,611 : worker.worker : DEBUG : Step 185022, finished rewards -3.38, envs finished 1
2026-01-17 13:40:12,758 : agent.on_policy : DEBUG : Mean Losses: [5.706342164427042]
2026-01-17 13:40:12,780 : worker.worker : DEBUG : Step 185028, finished rewards 33.89, envs finished 1
2026-01-17 13:40:12,970 : worker.worker : DEBUG : Step 185050, finished rewards -21.60, envs finished 1
2026-01-17 13:40:12,987 : worker.worker : DEBUG : Step 185052, finished rewards 30.94, envs finished 1
2026-01-17 13:40:13,037 : worker.worker : DEBUG : Step 185055, finished rewards 14.78, envs finished 1
2026-01-17 13:40:13,218 : agent.on_policy : DEBUG : Mean Losses: [6.0292125307023525]
2026-01-17 13:40:13,304 : worker.worker : DEBUG : Step 185077, finished rewards 15.91, envs finished 2
2026-01-17 13:40:13,509 : agent.on_policy : DEBUG : Mean Losses: [2.5746742710471153]
2026-01-17 13:40:13,780 : worker.worker : DEBUG : Step 185117, finished rewards 24.37, envs finished 2
2026-01-17 13:40:13,968 : agent.on_policy : DEBUG : Mean Losses: [3.7667269576340914]
2026-01-17 13:40:14,084 : worker.worker : DEBUG : Step 185128, finished rewards 20.70, envs finished 1
2026-01-17 13:40:14,123 : worker.worker : DEBUG : Step 185134, finished rewards 31.08, envs finished 1
2026-01-17 13:40:14,222 : worker.worker : DEBUG : Step 185141, finished rewards 46.04, envs finished 1
2026-01-17 13:40:14,301 : worker.worker : DEBUG : Step 185149, finished rewards 23.88, envs finished 1
2026-01-17 13:40:14,462 : agent.on_policy : DEBUG : Mean Losses: [6.391261886805296]
2026-01-17 13:40:14,538 : worker.worker : DEBUG : Step 185159, finished rewards 32.21, envs finished 1
2026-01-17 13:40:14,635 : worker.worker : DEBUG : Step 185167, finished rewards 9.68, envs finished 1
2026-01-17 13:40:14,867 : agent.on_policy : DEBUG : Mean Losses: [2.312784869223833]
2026-01-17 13:40:15,099 : agent.on_policy : DEBUG : Mean Losses: [3.0827704053372145]
2026-01-17 13:40:15,111 : worker.worker : DEBUG : Step 185218, finished rewards 19.00, envs finished 1
2026-01-17 13:40:15,136 : worker.worker : DEBUG : Step 185221, finished rewards 16.44, envs finished 1
2026-01-17 13:40:15,172 : worker.worker : DEBUG : Step 185229, finished rewards 21.44, envs finished 1
2026-01-17 13:40:15,233 : worker.worker : DEBUG : Step 185244, finished rewards 17.96, envs finished 1
2026-01-17 13:40:15,239 : worker.worker : DEBUG : Step 185245, finished rewards 23.00, envs finished 1
2026-01-17 13:40:15,309 : agent.on_policy : DEBUG : Mean Losses: [6.252496749162674]
2026-01-17 13:40:15,409 : worker.worker : DEBUG : Step 185261, finished rewards 21.75, envs finished 1
2026-01-17 13:40:15,450 : worker.worker : DEBUG : Step 185267, finished rewards 10.00, envs finished 2
2026-01-17 13:40:15,794 : agent.on_policy : DEBUG : Mean Losses: [2.8745724763721228]
2026-01-17 13:40:16,061 : agent.on_policy : DEBUG : Mean Losses: [1.8112814538180828]
2026-01-17 13:40:16,062 : worker.worker : DEBUG : Step 185312, finished rewards 31.78, envs finished 1
2026-01-17 13:40:16,100 : worker.worker : DEBUG : Step 185322, finished rewards 18.34, envs finished 1
2026-01-17 13:40:16,136 : worker.worker : DEBUG : Step 185331, finished rewards 46.07, envs finished 1
2026-01-17 13:40:16,143 : worker.worker : DEBUG : Step 185333, finished rewards 16.37, envs finished 1
2026-01-17 13:40:16,163 : worker.worker : DEBUG : Step 185334, finished rewards 25.84, envs finished 1
2026-01-17 13:40:16,256 : agent.on_policy : DEBUG : Mean Losses: [6.370667040348053]
2026-01-17 13:40:16,263 : worker.worker : DEBUG : Step 185346, finished rewards 17.06, envs finished 1
2026-01-17 13:40:16,283 : worker.worker : DEBUG : Step 185351, finished rewards 30.01, envs finished 1
2026-01-17 13:40:16,361 : worker.worker : DEBUG : Step 185359, finished rewards 20.20, envs finished 1
2026-01-17 13:40:16,644 : agent.on_policy : DEBUG : Mean Losses: [2.5608578845858574]
2026-01-17 13:40:16,732 : worker.worker : DEBUG : Step 185400, finished rewards 27.61, envs finished 1
2026-01-17 13:40:16,735 : worker.worker : DEBUG : Step 185401, finished rewards 33.70, envs finished 1
2026-01-17 13:40:16,742 : worker.worker : DEBUG : Step 185403, finished rewards 39.69, envs finished 1
2026-01-17 13:40:16,881 : agent.on_policy : DEBUG : Mean Losses: [5.051605239510536]
2026-01-17 13:40:17,047 : worker.worker : DEBUG : Step 185435, finished rewards 19.21, envs finished 1
2026-01-17 13:40:17,133 : agent.on_policy : DEBUG : Mean Losses: [3.7355328649282455]
2026-01-17 13:40:17,204 : worker.worker : DEBUG : Step 185448, finished rewards 16.79, envs finished 1
2026-01-17 13:40:17,218 : worker.worker : DEBUG : Step 185452, finished rewards 16.46, envs finished 1
2026-01-17 13:40:17,229 : worker.worker : DEBUG : Step 185455, finished rewards 21.89, envs finished 1
2026-01-17 13:40:17,250 : worker.worker : DEBUG : Step 185462, finished rewards -0.02, envs finished 1
2026-01-17 13:40:17,317 : agent.on_policy : DEBUG : Mean Losses: [4.212364636361599]
2026-01-17 13:40:17,347 : worker.worker : DEBUG : Step 185482, finished rewards 36.23, envs finished 1
2026-01-17 13:40:17,418 : worker.worker : DEBUG : Step 185500, finished rewards 21.43, envs finished 1
2026-01-17 13:40:17,423 : worker.worker : DEBUG : Step 185501, finished rewards 19.01, envs finished 1
2026-01-17 13:40:17,481 : agent.on_policy : DEBUG : Mean Losses: [2.85581536218524]
2026-01-17 13:40:17,652 : worker.worker : DEBUG : Step 185526, finished rewards 26.14, envs finished 1
2026-01-17 13:40:17,057 : agent.on_policy : DEBUG : Mean Losses: [2.9160130098462105]
2026-01-17 13:40:17,069 : worker.worker : DEBUG : Step 185539, finished rewards 28.54, envs finished 1
2026-01-17 13:40:17,079 : worker.worker : DEBUG : Step 185541, finished rewards 24.38, envs finished 1
2026-01-17 13:40:17,397 : agent.on_policy : DEBUG : Mean Losses: [4.33214140497148]
2026-01-17 13:40:17,398 : worker.worker : DEBUG : Step 185568, finished rewards 11.87, envs finished 1
2026-01-17 13:40:17,412 : worker.worker : DEBUG : Step 185572, finished rewards 41.26, envs finished 1
2026-01-17 13:40:17,443 : worker.worker : DEBUG : Step 185579, finished rewards 9.45, envs finished 1
2026-01-17 13:40:17,487 : worker.worker : DEBUG : Step 185591, finished rewards 14.18, envs finished 1
2026-01-17 13:40:17,570 : agent.on_policy : DEBUG : Mean Losses: [3.958623431622982]
2026-01-17 13:40:17,600 : worker.worker : DEBUG : Step 185610, finished rewards 40.75, envs finished 1
2026-01-17 13:40:17,625 : worker.worker : DEBUG : Step 185616, finished rewards 7.94, envs finished 1
2026-01-17 13:40:17,729 : worker.worker : DEBUG : Step 185625, finished rewards 19.24, envs finished 1
2026-01-17 13:40:17,901 : agent.on_policy : DEBUG : Mean Losses: [4.046257898211479]
2026-01-17 13:40:17,965 : worker.worker : DEBUG : Step 185643, finished rewards 17.88, envs finished 1
2026-01-17 13:40:18,135 : worker.worker : DEBUG : Step 185662, finished rewards 31.97, envs finished 1
2026-01-17 13:40:18,257 : agent.on_policy : DEBUG : Mean Losses: [3.648440755903721]
2026-01-17 13:40:18,327 : worker.worker : DEBUG : Step 185674, finished rewards 17.88, envs finished 1
2026-01-17 13:40:18,448 : worker.worker : DEBUG : Step 185692, finished rewards 32.62, envs finished 1
2026-01-17 13:40:18,463 : worker.worker : DEBUG : Step 185695, finished rewards -0.38, envs finished 1
2026-01-17 13:40:18,676 : agent.on_policy : DEBUG : Mean Losses: [3.323277112096548]
2026-01-17 13:40:18,973 : agent.on_policy : DEBUG : Mean Losses: [4.151265390217304]
2026-01-17 13:40:18,997 : worker.worker : DEBUG : Step 185736, finished rewards 10.49, envs finished 1
2026-01-17 13:40:19,026 : worker.worker : DEBUG : Step 185744, finished rewards 20.37, envs finished 1
2026-01-17 13:40:19,042 : worker.worker : DEBUG : Step 185748, finished rewards -11.97, envs finished 1
2026-01-17 13:40:19,134 : agent.on_policy : DEBUG : Mean Losses: [4.598730698227882]
2026-01-17 13:40:19,221 : worker.worker : DEBUG : Step 185776, finished rewards 18.44, envs finished 1
2026-01-17 13:40:19,274 : worker.worker : DEBUG : Step 185781, finished rewards 5.71, envs finished 1
2026-01-17 13:40:19,447 : agent.on_policy : DEBUG : Mean Losses: [2.9176330361515284]
2026-01-17 13:40:19,675 : worker.worker : DEBUG : Step 185811, finished rewards 18.10, envs finished 1
2026-01-17 13:40:19,690 : worker.worker : DEBUG : Step 185814, finished rewards 42.52, envs finished 1
2026-01-17 13:40:19,818 : agent.on_policy : DEBUG : Mean Losses: [5.178773708641529]
2026-01-17 13:40:19,910 : worker.worker : DEBUG : Step 185831, finished rewards 23.95, envs finished 1
2026-01-17 13:40:19,954 : worker.worker : DEBUG : Step 185835, finished rewards 65.71, envs finished 1
2026-01-17 13:40:19,989 : worker.worker : DEBUG : Step 185838, finished rewards 27.20, envs finished 1
2026-01-17 13:40:20,020 : worker.worker : DEBUG : Step 185839, finished rewards -8.46, envs finished 1
2026-01-17 13:40:20,210 : worker.worker : DEBUG : Step 185853, finished rewards 41.43, envs finished 1
2026-01-17 13:40:20,444 : agent.on_policy : DEBUG : Mean Losses: [5.043235521763563]
2026-01-17 13:40:20,508 : worker.worker : DEBUG : Step 185867, finished rewards 24.81, envs finished 1
2026-01-17 13:40:20,719 : agent.on_policy : DEBUG : Mean Losses: [2.6348444148898125]
2026-01-17 13:40:20,759 : worker.worker : DEBUG : Step 185901, finished rewards 28.45, envs finished 1
2026-01-17 13:40:20,766 : worker.worker : DEBUG : Step 185903, finished rewards 24.71, envs finished 1
2026-01-17 13:40:20,794 : worker.worker : DEBUG : Step 185909, finished rewards 41.89, envs finished 1
2026-01-17 13:40:20,885 : agent.on_policy : DEBUG : Mean Losses: [6.239780992269516]
2026-01-17 13:40:20,917 : worker.worker : DEBUG : Step 185928, finished rewards 26.51, envs finished 1
2026-01-17 13:40:20,929 : worker.worker : DEBUG : Step 185930, finished rewards 23.51, envs finished 1
2026-01-17 13:40:21,061 : worker.worker : DEBUG : Step 185945, finished rewards 14.56, envs finished 1
2026-01-17 13:40:21,214 : agent.on_policy : DEBUG : Mean Losses: [3.7806396484375]
2026-01-17 13:40:21,236 : worker.worker : DEBUG : Step 185958, finished rewards 17.90, envs finished 1
2026-01-17 13:40:21,244 : worker.worker : DEBUG : Step 185960, finished rewards 24.15, envs finished 1
2026-01-17 13:40:21,271 : worker.worker : DEBUG : Step 185965, finished rewards 45.99, envs finished 1
2026-01-17 13:40:21,393 : agent.on_policy : DEBUG : Mean Losses: [4.652702182531357]
2026-01-17 13:40:21,508 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:40:21,571 : worker.worker : DEBUG : Step 186014, finished rewards 9.41, envs finished 1
2026-01-17 13:40:21,701 : agent.on_policy : DEBUG : Mean Losses: [2.516019321978092]
2026-01-17 13:40:21,758 : worker.worker : DEBUG : Step 186021, finished rewards 35.33, envs finished 2
2026-01-17 13:40:21,809 : worker.worker : DEBUG : Step 186025, finished rewards 21.46, envs finished 1
2026-01-17 13:40:21,831 : worker.worker : DEBUG : Step 186028, finished rewards 5.11, envs finished 1
2026-01-17 13:40:21,871 : worker.worker : DEBUG : Step 186035, finished rewards 43.03, envs finished 1
2026-01-17 13:40:21,909 : worker.worker : DEBUG : Step 186039, finished rewards 33.12, envs finished 1
2026-01-17 13:40:21,992 : worker.worker : DEBUG : Step 186046, finished rewards 21.08, envs finished 1
2026-01-17 13:40:22,070 : agent.on_policy : DEBUG : Mean Losses: [7.552635174244642]
2026-01-17 13:40:22,454 : agent.on_policy : DEBUG : Mean Losses: [1.1111815720796585]
2026-01-17 13:40:22,542 : worker.worker : DEBUG : Step 186097, finished rewards 31.89, envs finished 1
2026-01-17 13:40:22,766 : agent.on_policy : DEBUG : Mean Losses: [5.040067628026009]
2026-01-17 13:40:22,774 : worker.worker : DEBUG : Step 186114, finished rewards 28.19, envs finished 1
2026-01-17 13:40:22,778 : worker.worker : DEBUG : Step 186115, finished rewards 43.54, envs finished 1
2026-01-17 13:40:22,898 : worker.worker : DEBUG : Step 186122, finished rewards 30.35, envs finished 1
2026-01-17 13:40:22,913 : worker.worker : DEBUG : Step 186124, finished rewards 17.93, envs finished 1
2026-01-17 13:40:23,181 : agent.on_policy : DEBUG : Mean Losses: [4.820290625095367]
2026-01-17 13:40:23,183 : worker.worker : DEBUG : Step 186144, finished rewards 13.66, envs finished 1
2026-01-17 13:40:23,192 : worker.worker : DEBUG : Step 186146, finished rewards 10.88, envs finished 1
2026-01-17 13:40:23,285 : worker.worker : DEBUG : Step 186168, finished rewards 41.64, envs finished 1
2026-01-17 13:40:23,486 : agent.on_policy : DEBUG : Mean Losses: [3.264278382062912]
2026-01-17 13:40:23,701 : worker.worker : DEBUG : Step 186203, finished rewards 34.49, envs finished 1
2026-01-17 13:40:24,009 : agent.on_policy : DEBUG : Mean Losses: [4.195148795843124]
2026-01-17 13:40:24,016 : worker.worker : DEBUG : Step 186209, finished rewards 24.79, envs finished 1
2026-01-17 13:40:24,072 : worker.worker : DEBUG : Step 186216, finished rewards 25.40, envs finished 1
2026-01-17 13:40:24,079 : worker.worker : DEBUG : Step 186217, finished rewards 39.02, envs finished 1
2026-01-17 13:40:24,086 : worker.worker : DEBUG : Step 186218, finished rewards 41.17, envs finished 1
2026-01-17 13:40:24,296 : agent.on_policy : DEBUG : Mean Losses: [4.497584030032158]
2026-01-17 13:40:24,326 : worker.worker : DEBUG : Step 186249, finished rewards 5.30, envs finished 1
2026-01-17 13:40:24,371 : worker.worker : DEBUG : Step 186262, finished rewards 25.15, envs finished 1
2026-01-17 13:40:24,454 : agent.on_policy : DEBUG : Mean Losses: [2.7623547464609146]
2026-01-17 13:40:24,498 : worker.worker : DEBUG : Step 186285, finished rewards 32.93, envs finished 1
2026-01-17 13:40:24,628 : worker.worker : DEBUG : Step 186301, finished rewards 25.92, envs finished 1
2026-01-17 13:40:24,775 : agent.on_policy : DEBUG : Mean Losses: [3.8037032186985016]
2026-01-17 13:40:24,802 : worker.worker : DEBUG : Step 186311, finished rewards 24.83, envs finished 1
2026-01-17 13:40:24,903 : worker.worker : DEBUG : Step 186317, finished rewards 20.30, envs finished 1
2026-01-17 13:40:25,010 : worker.worker : DEBUG : Step 186329, finished rewards 12.32, envs finished 1
2026-01-17 13:40:25,105 : agent.on_policy : DEBUG : Mean Losses: [3.3010581210255623]
2026-01-17 13:40:25,125 : worker.worker : DEBUG : Step 186337, finished rewards 27.80, envs finished 1
2026-01-17 13:40:25,242 : worker.worker : DEBUG : Step 186353, finished rewards 25.41, envs finished 1
2026-01-17 13:40:25,426 : agent.on_policy : DEBUG : Mean Losses: [2.8093469589948654]
2026-01-17 13:40:25,442 : worker.worker : DEBUG : Step 186372, finished rewards 28.52, envs finished 1
2026-01-17 13:40:25,634 : agent.on_policy : DEBUG : Mean Losses: [3.628072962164879]
2026-01-17 13:40:25,650 : worker.worker : DEBUG : Step 186400, finished rewards 42.18, envs finished 1
2026-01-17 13:40:25,664 : worker.worker : DEBUG : Step 186401, finished rewards 45.95, envs finished 1
2026-01-17 13:40:25,676 : worker.worker : DEBUG : Step 186403, finished rewards 28.70, envs finished 1
2026-01-17 13:40:25,687 : worker.worker : DEBUG : Step 186405, finished rewards 24.35, envs finished 1
2026-01-17 13:40:25,728 : worker.worker : DEBUG : Step 186412, finished rewards 11.37, envs finished 1
2026-01-17 13:40:25,810 : worker.worker : DEBUG : Step 186424, finished rewards 41.27, envs finished 1
2026-01-17 13:40:26,032 : agent.on_policy : DEBUG : Mean Losses: [4.56374142318964]
2026-01-17 13:40:26,289 : agent.on_policy : DEBUG : Mean Losses: [1.7262004986405373]
2026-01-17 13:40:26,306 : worker.worker : DEBUG : Step 186469, finished rewards 21.15, envs finished 1
2026-01-17 13:40:26,317 : worker.worker : DEBUG : Step 186472, finished rewards 41.57, envs finished 1
2026-01-17 13:40:26,370 : worker.worker : DEBUG : Step 186486, finished rewards 33.71, envs finished 2
2026-01-17 13:40:26,495 : agent.on_policy : DEBUG : Mean Losses: [6.5416755229234695]
2026-01-17 13:40:26,578 : worker.worker : DEBUG : Step 186507, finished rewards 31.71, envs finished 1
2026-01-17 13:40:26,610 : worker.worker : DEBUG : Step 186514, finished rewards 13.82, envs finished 1
2026-01-17 13:40:26,656 : worker.worker : DEBUG : Step 186521, finished rewards 8.29, envs finished 1
2026-01-17 13:40:26,678 : worker.worker : DEBUG : Step 186522, finished rewards -0.11, envs finished 1
2026-01-17 13:40:26,794 : agent.on_policy : DEBUG : Mean Losses: [5.226222302764654]
2026-01-17 13:40:26,969 : worker.worker : DEBUG : Step 186557, finished rewards 26.94, envs finished 1
2026-01-17 13:40:27,038 : agent.on_policy : DEBUG : Mean Losses: [3.6986543089151382]
2026-01-17 13:40:27,057 : worker.worker : DEBUG : Step 186564, finished rewards 37.01, envs finished 1
2026-01-17 13:40:27,062 : worker.worker : DEBUG : Step 186565, finished rewards 24.99, envs finished 1
2026-01-17 13:40:27,308 : agent.on_policy : DEBUG : Mean Losses: [3.0155705846846104]
2026-01-17 13:40:27,356 : worker.worker : DEBUG : Step 186608, finished rewards 23.86, envs finished 1
2026-01-17 13:40:27,376 : worker.worker : DEBUG : Step 186613, finished rewards 25.84, envs finished 1
2026-01-17 13:40:27,399 : worker.worker : DEBUG : Step 186618, finished rewards 14.46, envs finished 1
2026-01-17 13:40:27,477 : agent.on_policy : DEBUG : Mean Losses: [4.385945312678814]
2026-01-17 13:40:27,501 : worker.worker : DEBUG : Step 186630, finished rewards 13.15, envs finished 1
2026-01-17 13:40:27,564 : worker.worker : DEBUG : Step 186642, finished rewards 29.85, envs finished 1
2026-01-17 13:40:27,748 : agent.on_policy : DEBUG : Mean Losses: [3.876480244100094]
2026-01-17 13:40:27,772 : worker.worker : DEBUG : Step 186657, finished rewards 25.52, envs finished 1
2026-01-17 13:40:27,992 : worker.worker : DEBUG : Step 186679, finished rewards 41.62, envs finished 1
2026-01-17 13:40:28,062 : worker.worker : DEBUG : Step 186684, finished rewards 7.44, envs finished 1
2026-01-17 13:40:28,219 : agent.on_policy : DEBUG : Mean Losses: [4.464115172624588]
2026-01-17 13:40:28,375 : worker.worker : DEBUG : Step 186707, finished rewards 24.48, envs finished 1
2026-01-17 13:40:28,504 : agent.on_policy : DEBUG : Mean Losses: [3.8445686157792807]
2026-01-17 13:40:28,561 : worker.worker : DEBUG : Step 186738, finished rewards 32.24, envs finished 1
2026-01-17 13:40:28,631 : agent.on_policy : DEBUG : Mean Losses: [5.893129110336304]
2026-01-17 13:40:28,637 : worker.worker : DEBUG : Step 186753, finished rewards -50.47, envs finished 1
2026-01-17 13:40:28,673 : worker.worker : DEBUG : Step 186766, finished rewards -0.76, envs finished 1
2026-01-17 13:40:28,718 : worker.worker : DEBUG : Step 186781, finished rewards 17.07, envs finished 1
2026-01-17 13:40:29,009 : agent.on_policy : DEBUG : Mean Losses: [4.837514117360115]
2026-01-17 13:40:29,036 : worker.worker : DEBUG : Step 186788, finished rewards 40.18, envs finished 1
2026-01-17 13:40:29,082 : worker.worker : DEBUG : Step 186797, finished rewards 26.62, envs finished 1
2026-01-17 13:40:29,150 : worker.worker : DEBUG : Step 186800, finished rewards 7.49, envs finished 1
2026-01-17 13:40:29,179 : worker.worker : DEBUG : Step 186802, finished rewards 45.96, envs finished 1
2026-01-17 13:40:29,387 : agent.on_policy : DEBUG : Mean Losses: [6.54237174987793]
2026-01-17 13:40:29,428 : worker.worker : DEBUG : Step 186827, finished rewards -60.79, envs finished 1
2026-01-17 13:40:29,441 : worker.worker : DEBUG : Step 186830, finished rewards 45.97, envs finished 1
2026-01-17 13:40:29,554 : agent.on_policy : DEBUG : Mean Losses: [3.7511992640793324]
2026-01-17 13:40:29,565 : worker.worker : DEBUG : Step 186851, finished rewards 20.58, envs finished 1
2026-01-17 13:40:29,715 : worker.worker : DEBUG : Step 186868, finished rewards 41.57, envs finished 1
2026-01-17 13:40:29,850 : worker.worker : DEBUG : Step 186879, finished rewards 35.16, envs finished 1
2026-01-17 13:40:30,050 : agent.on_policy : DEBUG : Mean Losses: [6.087327994406223]
2026-01-17 13:40:30,184 : worker.worker : DEBUG : Step 186888, finished rewards 12.74, envs finished 1
2026-01-17 13:40:30,226 : worker.worker : DEBUG : Step 186895, finished rewards 24.81, envs finished 1
2026-01-17 13:40:30,446 : agent.on_policy : DEBUG : Mean Losses: [3.8808721378445625]
2026-01-17 13:40:30,553 : worker.worker : DEBUG : Step 186934, finished rewards -7.71, envs finished 1
2026-01-17 13:40:30,613 : worker.worker : DEBUG : Step 186942, finished rewards 8.26, envs finished 1
2026-01-17 13:40:30,755 : agent.on_policy : DEBUG : Mean Losses: [4.201113291084766]
2026-01-17 13:40:30,835 : worker.worker : DEBUG : Step 186956, finished rewards 36.21, envs finished 1
2026-01-17 13:40:30,871 : worker.worker : DEBUG : Step 186960, finished rewards 16.95, envs finished 1
2026-01-17 13:40:31,065 : agent.on_policy : DEBUG : Mean Losses: [5.420037347823381]
2026-01-17 13:40:31,067 : worker.worker : DEBUG : Step 186976, finished rewards 12.16, envs finished 1
2026-01-17 13:40:31,080 : worker.worker : DEBUG : Step 186979, finished rewards 30.92, envs finished 1
2026-01-17 13:40:31,092 : worker.worker : DEBUG : Step 186980, finished rewards 25.55, envs finished 1
2026-01-17 13:40:31,218 : worker.worker : DEBUG : Step 186993, finished rewards 17.93, envs finished 1
2026-01-17 13:40:31,289 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:40:31,430 : agent.on_policy : DEBUG : Mean Losses: [3.330407427623868]
2026-01-17 13:40:31,625 : worker.worker : DEBUG : Step 187032, finished rewards 18.21, envs finished 1
2026-01-17 13:40:31,759 : agent.on_policy : DEBUG : Mean Losses: [3.3587168380618095]
2026-01-17 13:40:31,774 : worker.worker : DEBUG : Step 187042, finished rewards 21.83, envs finished 1
2026-01-17 13:40:31,821 : worker.worker : DEBUG : Step 187044, finished rewards 44.94, envs finished 1
2026-01-17 13:40:31,880 : worker.worker : DEBUG : Step 187054, finished rewards 25.31, envs finished 1
2026-01-17 13:40:31,923 : worker.worker : DEBUG : Step 187064, finished rewards 28.79, envs finished 2
2026-01-17 13:40:32,181 : agent.on_policy : DEBUG : Mean Losses: [6.620489150285721]
2026-01-17 13:40:32,259 : worker.worker : DEBUG : Step 187079, finished rewards 20.78, envs finished 1
2026-01-17 13:40:32,616 : agent.on_policy : DEBUG : Mean Losses: [2.838093213737011]
2026-01-17 13:40:32,685 : worker.worker : DEBUG : Step 187112, finished rewards 42.58, envs finished 1
2026-01-17 13:40:32,739 : worker.worker : DEBUG : Step 187117, finished rewards 46.58, envs finished 1
2026-01-17 13:40:32,829 : worker.worker : DEBUG : Step 187122, finished rewards -6.41, envs finished 1
2026-01-17 13:40:32,909 : worker.worker : DEBUG : Step 187128, finished rewards 31.01, envs finished 1
2026-01-17 13:40:32,922 : worker.worker : DEBUG : Step 187130, finished rewards 19.88, envs finished 1
2026-01-17 13:40:33,114 : agent.on_policy : DEBUG : Mean Losses: [7.3936720713973045]
2026-01-17 13:40:33,156 : worker.worker : DEBUG : Step 187147, finished rewards 31.92, envs finished 2
2026-01-17 13:40:33,310 : agent.on_policy : DEBUG : Mean Losses: [3.366553354077041]
2026-01-17 13:40:33,473 : worker.worker : DEBUG : Step 187185, finished rewards 40.68, envs finished 1
2026-01-17 13:40:33,567 : worker.worker : DEBUG : Step 187192, finished rewards 46.11, envs finished 1
2026-01-17 13:40:33,781 : agent.on_policy : DEBUG : Mean Losses: [5.567387290298939]
2026-01-17 13:40:33,807 : worker.worker : DEBUG : Step 187203, finished rewards 30.59, envs finished 1
2026-01-17 13:40:33,909 : worker.worker : DEBUG : Step 187209, finished rewards 33.83, envs finished 1
2026-01-17 13:40:33,959 : worker.worker : DEBUG : Step 187217, finished rewards 42.37, envs finished 1
2026-01-17 13:40:34,064 : agent.on_policy : DEBUG : Mean Losses: [5.1038191167172045]
2026-01-17 13:40:34,066 : worker.worker : DEBUG : Step 187232, finished rewards 11.08, envs finished 1
2026-01-17 13:40:34,095 : worker.worker : DEBUG : Step 187241, finished rewards -13.65, envs finished 1
2026-01-17 13:40:34,101 : worker.worker : DEBUG : Step 187242, finished rewards 24.32, envs finished 1
2026-01-17 13:40:34,198 : agent.on_policy : DEBUG : Mean Losses: [3.4176340587437153]
2026-01-17 13:40:34,204 : worker.worker : DEBUG : Step 187265, finished rewards 32.86, envs finished 1
2026-01-17 13:40:34,270 : worker.worker : DEBUG : Step 187280, finished rewards 26.52, envs finished 1
2026-01-17 13:40:34,397 : worker.worker : DEBUG : Step 187294, finished rewards 36.98, envs finished 1
2026-01-17 13:40:34,567 : agent.on_policy : DEBUG : Mean Losses: [5.05211728811264]
2026-01-17 13:40:34,574 : worker.worker : DEBUG : Step 187297, finished rewards 29.62, envs finished 1
2026-01-17 13:40:34,747 : worker.worker : DEBUG : Step 187324, finished rewards 25.25, envs finished 1
2026-01-17 13:40:34,902 : agent.on_policy : DEBUG : Mean Losses: [3.3007136583328247]
2026-01-17 13:40:34,907 : worker.worker : DEBUG : Step 187329, finished rewards -2.88, envs finished 1
2026-01-17 13:40:34,924 : worker.worker : DEBUG : Step 187333, finished rewards 24.91, envs finished 1
2026-01-17 13:40:34,969 : worker.worker : DEBUG : Step 187344, finished rewards 21.49, envs finished 1
2026-01-17 13:40:35,066 : agent.on_policy : DEBUG : Mean Losses: [4.48911090567708]
2026-01-17 13:40:35,093 : worker.worker : DEBUG : Step 187367, finished rewards 42.79, envs finished 1
2026-01-17 13:40:35,109 : worker.worker : DEBUG : Step 187370, finished rewards 33.67, envs finished 1
2026-01-17 13:40:35,412 : agent.on_policy : DEBUG : Mean Losses: [3.2137087881565094]
2026-01-17 13:40:35,473 : worker.worker : DEBUG : Step 187411, finished rewards -10.58, envs finished 1
2026-01-17 13:40:35,618 : agent.on_policy : DEBUG : Mean Losses: [4.302278846502304]
2026-01-17 13:40:35,632 : worker.worker : DEBUG : Step 187425, finished rewards 6.32, envs finished 1
2026-01-17 13:40:35,652 : worker.worker : DEBUG : Step 187428, finished rewards 19.30, envs finished 1
2026-01-17 13:40:35,697 : worker.worker : DEBUG : Step 187436, finished rewards 22.66, envs finished 1
2026-01-17 13:40:35,703 : worker.worker : DEBUG : Step 187437, finished rewards 23.84, envs finished 1
2026-01-17 13:40:35,763 : worker.worker : DEBUG : Step 187449, finished rewards 3.53, envs finished 1
2026-01-17 13:40:35,864 : agent.on_policy : DEBUG : Mean Losses: [5.762928366661072]
2026-01-17 13:40:35,869 : worker.worker : DEBUG : Step 187456, finished rewards 30.70, envs finished 1
2026-01-17 13:40:35,879 : worker.worker : DEBUG : Step 187458, finished rewards 24.88, envs finished 1
2026-01-17 13:40:36,058 : worker.worker : DEBUG : Step 187483, finished rewards 41.34, envs finished 1
2026-01-17 13:40:36,276 : agent.on_policy : DEBUG : Mean Losses: [2.865494465455413]
2026-01-17 13:40:36,643 : agent.on_policy : DEBUG : Mean Losses: [3.2828701063990593]
2026-01-17 13:40:36,665 : worker.worker : DEBUG : Step 187525, finished rewards 27.90, envs finished 1
2026-01-17 13:40:36,712 : worker.worker : DEBUG : Step 187537, finished rewards 20.71, envs finished 1
2026-01-17 13:40:36,727 : worker.worker : DEBUG : Step 187541, finished rewards 30.96, envs finished 2
2026-01-17 13:40:36,738 : worker.worker : DEBUG : Step 187543, finished rewards 7.14, envs finished 1
2026-01-17 13:40:36,834 : agent.on_policy : DEBUG : Mean Losses: [6.799580812454224]
2026-01-17 13:40:36,883 : worker.worker : DEBUG : Step 187565, finished rewards 31.79, envs finished 1
2026-01-17 13:40:37,134 : agent.on_policy : DEBUG : Mean Losses: [2.989653632044792]
2026-01-17 13:40:37,288 : agent.on_policy : DEBUG : Mean Losses: [2.844550557434559]
2026-01-17 13:40:37,437 : worker.worker : DEBUG : Step 187623, finished rewards 101.09, envs finished 1
2026-01-17 13:40:37,479 : worker.worker : DEBUG : Step 187625, finished rewards 30.37, envs finished 1
2026-01-17 13:40:37,525 : worker.worker : DEBUG : Step 187628, finished rewards 58.02, envs finished 1
2026-01-17 13:40:37,582 : worker.worker : DEBUG : Step 187635, finished rewards 22.69, envs finished 1
2026-01-17 13:40:37,593 : worker.worker : DEBUG : Step 187636, finished rewards 38.75, envs finished 1
2026-01-17 13:40:37,712 : worker.worker : DEBUG : Step 187645, finished rewards 14.59, envs finished 1
2026-01-17 13:40:37,864 : agent.on_policy : DEBUG : Mean Losses: [8.42619502544403]
2026-01-17 13:40:38,078 : agent.on_policy : DEBUG : Mean Losses: [1.8630062825977802]
2026-01-17 13:40:38,086 : worker.worker : DEBUG : Step 187682, finished rewards -8.92, envs finished 1
2026-01-17 13:40:38,122 : worker.worker : DEBUG : Step 187692, finished rewards 45.72, envs finished 1
2026-01-17 13:40:38,149 : worker.worker : DEBUG : Step 187699, finished rewards 46.12, envs finished 1
2026-01-17 13:40:38,173 : worker.worker : DEBUG : Step 187705, finished rewards -20.58, envs finished 1
2026-01-17 13:40:38,252 : agent.on_policy : DEBUG : Mean Losses: [7.346228271722794]
2026-01-17 13:40:38,258 : worker.worker : DEBUG : Step 187713, finished rewards 27.53, envs finished 1
2026-01-17 13:40:38,311 : worker.worker : DEBUG : Step 187726, finished rewards 14.39, envs finished 1
2026-01-17 13:40:38,411 : worker.worker : DEBUG : Step 187732, finished rewards 28.33, envs finished 1
2026-01-17 13:40:38,518 : agent.on_policy : DEBUG : Mean Losses: [5.457719147205353]
2026-01-17 13:40:38,685 : agent.on_policy : DEBUG : Mean Losses: [1.9373038709163666]
2026-01-17 13:40:38,688 : worker.worker : DEBUG : Step 187776, finished rewards 23.19, envs finished 1
2026-01-17 13:40:38,693 : worker.worker : DEBUG : Step 187777, finished rewards 31.02, envs finished 1
2026-01-17 13:40:38,737 : worker.worker : DEBUG : Step 187792, finished rewards 33.69, envs finished 1
2026-01-17 13:40:38,953 : agent.on_policy : DEBUG : Mean Losses: [4.363728992640972]
2026-01-17 13:40:39,043 : worker.worker : DEBUG : Step 187816, finished rewards 11.21, envs finished 1
2026-01-17 13:40:39,093 : worker.worker : DEBUG : Step 187825, finished rewards 24.45, envs finished 1
2026-01-17 13:40:39,182 : worker.worker : DEBUG : Step 187834, finished rewards 16.71, envs finished 1
2026-01-17 13:40:39,343 : agent.on_policy : DEBUG : Mean Losses: [4.974401973187923]
2026-01-17 13:40:39,346 : worker.worker : DEBUG : Step 187840, finished rewards 67.74, envs finished 1
2026-01-17 13:40:39,566 : agent.on_policy : DEBUG : Mean Losses: [2.477357981726527]
2026-01-17 13:40:39,581 : worker.worker : DEBUG : Step 187875, finished rewards 31.62, envs finished 1
2026-01-17 13:40:39,614 : worker.worker : DEBUG : Step 187882, finished rewards 18.51, envs finished 1
2026-01-17 13:40:39,648 : worker.worker : DEBUG : Step 187890, finished rewards 15.32, envs finished 1
2026-01-17 13:40:39,744 : agent.on_policy : DEBUG : Mean Losses: [4.3437750190496445]
2026-01-17 13:40:39,774 : worker.worker : DEBUG : Step 187912, finished rewards 45.86, envs finished 3
2026-01-17 13:40:40,036 : agent.on_policy : DEBUG : Mean Losses: [5.4584145694971085]
2026-01-17 13:40:40,119 : worker.worker : DEBUG : Step 187946, finished rewards 26.28, envs finished 2
2026-01-17 13:40:40,177 : worker.worker : DEBUG : Step 187953, finished rewards 15.75, envs finished 1
2026-01-17 13:40:40,293 : worker.worker : DEBUG : Step 187964, finished rewards 34.18, envs finished 1
2026-01-17 13:40:40,459 : agent.on_policy : DEBUG : Mean Losses: [4.71518974006176]
2026-01-17 13:40:40,537 : worker.worker : DEBUG : Step 187982, finished rewards 43.12, envs finished 1
2026-01-17 13:40:40,621 : worker.worker : DEBUG : Step 187993, finished rewards 16.26, envs finished 1
2026-01-17 13:40:40,672 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:40:40,880 : agent.on_policy : DEBUG : Mean Losses: [3.3737904597073793]
2026-01-17 13:40:41,069 : worker.worker : DEBUG : Step 188014, finished rewards 14.79, envs finished 1
2026-01-17 13:40:41,126 : worker.worker : DEBUG : Step 188016, finished rewards 46.81, envs finished 1
2026-01-17 13:40:41,354 : agent.on_policy : DEBUG : Mean Losses: [4.9532837849110365]
2026-01-17 13:40:41,413 : worker.worker : DEBUG : Step 188036, finished rewards 39.72, envs finished 1
2026-01-17 13:40:41,424 : worker.worker : DEBUG : Step 188037, finished rewards 26.10, envs finished 1
2026-01-17 13:40:41,564 : worker.worker : DEBUG : Step 188049, finished rewards 16.94, envs finished 1
2026-01-17 13:40:41,773 : agent.on_policy : DEBUG : Mean Losses: [3.752879425883293]
2026-01-17 13:40:41,828 : worker.worker : DEBUG : Step 188079, finished rewards 22.28, envs finished 1
2026-01-17 13:40:41,884 : worker.worker : DEBUG : Step 188095, finished rewards 13.59, envs finished 1
2026-01-17 13:40:42,013 : agent.on_policy : DEBUG : Mean Losses: [4.698603555560112]
2026-01-17 13:40:42,049 : worker.worker : DEBUG : Step 188102, finished rewards 27.80, envs finished 1
2026-01-17 13:40:42,145 : worker.worker : DEBUG : Step 188109, finished rewards 54.14, envs finished 1
2026-01-17 13:40:42,349 : agent.on_policy : DEBUG : Mean Losses: [3.9411974400281906]
2026-01-17 13:40:42,370 : worker.worker : DEBUG : Step 188132, finished rewards 32.06, envs finished 1
2026-01-17 13:40:42,466 : worker.worker : DEBUG : Step 188142, finished rewards 17.25, envs finished 1
2026-01-17 13:40:42,487 : worker.worker : DEBUG : Step 188145, finished rewards 21.17, envs finished 1
2026-01-17 13:40:42,535 : worker.worker : DEBUG : Step 188152, finished rewards 40.46, envs finished 1
2026-01-17 13:40:42,759 : agent.on_policy : DEBUG : Mean Losses: [5.282512316480279]
2026-01-17 13:40:42,844 : worker.worker : DEBUG : Step 188181, finished rewards 1.34, envs finished 2
2026-01-17 13:40:43,056 : agent.on_policy : DEBUG : Mean Losses: [5.272742874920368]
2026-01-17 13:40:43,074 : worker.worker : DEBUG : Step 188196, finished rewards 27.65, envs finished 1
2026-01-17 13:40:43,085 : worker.worker : DEBUG : Step 188198, finished rewards 21.44, envs finished 1
2026-01-17 13:40:43,155 : worker.worker : DEBUG : Step 188216, finished rewards 43.86, envs finished 2
2026-01-17 13:40:43,163 : worker.worker : DEBUG : Step 188218, finished rewards 30.97, envs finished 1
2026-01-17 13:40:43,220 : agent.on_policy : DEBUG : Mean Losses: [6.457144320011139]
2026-01-17 13:40:43,341 : agent.on_policy : DEBUG : Mean Losses: [2.276020120829344]
2026-01-17 13:40:43,390 : worker.worker : DEBUG : Step 188265, finished rewards 6.63, envs finished 1
2026-01-17 13:40:43,410 : worker.worker : DEBUG : Step 188268, finished rewards 28.57, envs finished 1
2026-01-17 13:40:43,720 : agent.on_policy : DEBUG : Mean Losses: [4.5952538922429085]
2026-01-17 13:40:43,769 : worker.worker : DEBUG : Step 188298, finished rewards 32.33, envs finished 1
2026-01-17 13:40:43,800 : worker.worker : DEBUG : Step 188303, finished rewards 30.76, envs finished 1
2026-01-17 13:40:43,810 : worker.worker : DEBUG : Step 188305, finished rewards 15.15, envs finished 1
2026-01-17 13:40:43,861 : worker.worker : DEBUG : Step 188313, finished rewards 11.42, envs finished 1
2026-01-17 13:40:43,971 : agent.on_policy : DEBUG : Mean Losses: [5.098466539755464]
2026-01-17 13:40:44,104 : worker.worker : DEBUG : Step 188334, finished rewards 5.35, envs finished 1
2026-01-17 13:40:44,246 : worker.worker : DEBUG : Step 188346, finished rewards 32.87, envs finished 1
2026-01-17 13:40:44,290 : worker.worker : DEBUG : Step 188349, finished rewards 34.09, envs finished 1
2026-01-17 13:40:44,413 : agent.on_policy : DEBUG : Mean Losses: [4.957575768232346]
2026-01-17 13:40:44,606 : worker.worker : DEBUG : Step 188375, finished rewards 64.41, envs finished 2
2026-01-17 13:40:44,730 : agent.on_policy : DEBUG : Mean Losses: [4.584828779101372]
2026-01-17 13:40:44,777 : worker.worker : DEBUG : Step 188388, finished rewards 28.46, envs finished 1
2026-01-17 13:40:44,997 : worker.worker : DEBUG : Step 188404, finished rewards 24.52, envs finished 1
2026-01-17 13:40:45,219 : agent.on_policy : DEBUG : Mean Losses: [2.9606948643922806]
2026-01-17 13:40:45,353 : worker.worker : DEBUG : Step 188431, finished rewards 28.31, envs finished 1
2026-01-17 13:40:45,407 : worker.worker : DEBUG : Step 188440, finished rewards 25.01, envs finished 1
2026-01-17 13:40:45,496 : worker.worker : DEBUG : Step 188446, finished rewards 27.33, envs finished 2
2026-01-17 13:40:45,616 : agent.on_policy : DEBUG : Mean Losses: [7.051228646188974]
2026-01-17 13:40:45,670 : worker.worker : DEBUG : Step 188450, finished rewards -8.61, envs finished 1
2026-01-17 13:40:45,874 : worker.worker : DEBUG : Step 188475, finished rewards 40.51, envs finished 1
2026-01-17 13:40:45,934 : worker.worker : DEBUG : Step 188479, finished rewards 19.08, envs finished 1
2026-01-17 13:40:46,057 : agent.on_policy : DEBUG : Mean Losses: [4.8217422273010015]
2026-01-17 13:40:46,064 : worker.worker : DEBUG : Step 188481, finished rewards 24.78, envs finished 1
2026-01-17 13:40:46,380 : agent.on_policy : DEBUG : Mean Losses: [1.7960657328367233]
2026-01-17 13:40:46,452 : worker.worker : DEBUG : Step 188529, finished rewards 26.35, envs finished 1
2026-01-17 13:40:46,485 : worker.worker : DEBUG : Step 188535, finished rewards 15.74, envs finished 1
2026-01-17 13:40:46,675 : agent.on_policy : DEBUG : Mean Losses: [4.591906197369099]
2026-01-17 13:40:46,726 : worker.worker : DEBUG : Step 188549, finished rewards 17.84, envs finished 1
2026-01-17 13:40:46,839 : worker.worker : DEBUG : Step 188565, finished rewards 26.99, envs finished 1
2026-01-17 13:40:46,898 : worker.worker : DEBUG : Step 188567, finished rewards 4.92, envs finished 1
2026-01-17 13:40:46,361 : agent.on_policy : DEBUG : Mean Losses: [4.555922370404005]
2026-01-17 13:40:46,386 : worker.worker : DEBUG : Step 188580, finished rewards 20.08, envs finished 1
2026-01-17 13:40:46,407 : worker.worker : DEBUG : Step 188583, finished rewards 19.78, envs finished 1
2026-01-17 13:40:46,507 : worker.worker : DEBUG : Step 188602, finished rewards 40.49, envs finished 1
2026-01-17 13:40:46,671 : agent.on_policy : DEBUG : Mean Losses: [4.649434769526124]
2026-01-17 13:40:46,708 : worker.worker : DEBUG : Step 188616, finished rewards -30.62, envs finished 1
2026-01-17 13:40:46,852 : worker.worker : DEBUG : Step 188634, finished rewards 29.64, envs finished 1
2026-01-17 13:40:46,866 : worker.worker : DEBUG : Step 188635, finished rewards 20.12, envs finished 1
2026-01-17 13:40:47,037 : agent.on_policy : DEBUG : Mean Losses: [4.5045216996222734]
2026-01-17 13:40:47,237 : worker.worker : DEBUG : Step 188665, finished rewards 18.92, envs finished 1
2026-01-17 13:40:47,263 : worker.worker : DEBUG : Step 188669, finished rewards 22.00, envs finished 2
2026-01-17 13:40:47,364 : agent.on_policy : DEBUG : Mean Losses: [4.983365900814533]
2026-01-17 13:40:47,531 : worker.worker : DEBUG : Step 188688, finished rewards 28.90, envs finished 1
2026-01-17 13:40:47,870 : agent.on_policy : DEBUG : Mean Losses: [3.9741998575627804]
2026-01-17 13:40:47,900 : worker.worker : DEBUG : Step 188710, finished rewards 36.63, envs finished 1
2026-01-17 13:40:47,943 : worker.worker : DEBUG : Step 188718, finished rewards 16.71, envs finished 1
2026-01-17 13:40:47,968 : worker.worker : DEBUG : Step 188721, finished rewards 28.52, envs finished 1
2026-01-17 13:40:48,148 : agent.on_policy : DEBUG : Mean Losses: [4.5045661479234695]
2026-01-17 13:40:48,166 : worker.worker : DEBUG : Step 188736, finished rewards -14.71, envs finished 1
2026-01-17 13:40:48,266 : worker.worker : DEBUG : Step 188754, finished rewards 30.39, envs finished 1
2026-01-17 13:40:48,275 : worker.worker : DEBUG : Step 188755, finished rewards 23.80, envs finished 1
2026-01-17 13:40:48,293 : worker.worker : DEBUG : Step 188757, finished rewards 27.73, envs finished 1
2026-01-17 13:40:48,493 : agent.on_policy : DEBUG : Mean Losses: [4.324954554438591]
2026-01-17 13:40:48,505 : worker.worker : DEBUG : Step 188770, finished rewards 31.72, envs finished 1
2026-01-17 13:40:48,589 : worker.worker : DEBUG : Step 188792, finished rewards 32.54, envs finished 1
2026-01-17 13:40:48,758 : agent.on_policy : DEBUG : Mean Losses: [2.9163868948817253]
2026-01-17 13:40:48,784 : worker.worker : DEBUG : Step 188805, finished rewards 28.21, envs finished 1
2026-01-17 13:40:48,838 : worker.worker : DEBUG : Step 188810, finished rewards 25.52, envs finished 1
2026-01-17 13:40:49,096 : agent.on_policy : DEBUG : Mean Losses: [3.5246919468045235]
2026-01-17 13:40:49,130 : worker.worker : DEBUG : Step 188837, finished rewards 18.95, envs finished 1
2026-01-17 13:40:49,160 : worker.worker : DEBUG : Step 188842, finished rewards 28.43, envs finished 1
2026-01-17 13:40:49,196 : worker.worker : DEBUG : Step 188849, finished rewards 24.13, envs finished 1
2026-01-17 13:40:49,205 : worker.worker : DEBUG : Step 188850, finished rewards 21.56, envs finished 1
2026-01-17 13:40:49,311 : agent.on_policy : DEBUG : Mean Losses: [5.078000456094742]
2026-01-17 13:40:49,376 : worker.worker : DEBUG : Step 188873, finished rewards 21.66, envs finished 1
2026-01-17 13:40:49,404 : worker.worker : DEBUG : Step 188874, finished rewards 32.65, envs finished 1
2026-01-17 13:40:49,838 : agent.on_policy : DEBUG : Mean Losses: [2.4849389493465424]
2026-01-17 13:40:49,867 : worker.worker : DEBUG : Step 188902, finished rewards 24.39, envs finished 1
2026-01-17 13:40:49,928 : worker.worker : DEBUG : Step 188915, finished rewards 15.89, envs finished 1
2026-01-17 13:40:49,966 : worker.worker : DEBUG : Step 188921, finished rewards 41.18, envs finished 1
2026-01-17 13:40:50,163 : agent.on_policy : DEBUG : Mean Losses: [3.8784202709794044]
2026-01-17 13:40:50,301 : worker.worker : DEBUG : Step 188943, finished rewards 42.57, envs finished 1
2026-01-17 13:40:50,340 : worker.worker : DEBUG : Step 188949, finished rewards 15.01, envs finished 1
2026-01-17 13:40:50,423 : worker.worker : DEBUG : Step 188957, finished rewards 2.69, envs finished 1
2026-01-17 13:40:50,535 : agent.on_policy : DEBUG : Mean Losses: [5.1505719274282455]
2026-01-17 13:40:50,641 : worker.worker : DEBUG : Step 188968, finished rewards 5.62, envs finished 1
2026-01-17 13:40:50,943 : agent.on_policy : DEBUG : Mean Losses: [2.2087384201586246]
2026-01-17 13:40:50,961 : worker.worker : DEBUG : Step 188995, finished rewards 24.96, envs finished 1
2026-01-17 13:40:50,985 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:40:51,054 : worker.worker : DEBUG : Step 189009, finished rewards 8.41, envs finished 1
2026-01-17 13:40:51,140 : worker.worker : DEBUG : Step 189023, finished rewards 14.42, envs finished 1
2026-01-17 13:40:51,253 : agent.on_policy : DEBUG : Mean Losses: [3.316585771739483]
2026-01-17 13:40:51,307 : worker.worker : DEBUG : Step 189031, finished rewards 8.09, envs finished 1
2026-01-17 13:40:51,383 : worker.worker : DEBUG : Step 189038, finished rewards 22.73, envs finished 1
2026-01-17 13:40:51,536 : worker.worker : DEBUG : Step 189054, finished rewards 13.51, envs finished 1
2026-01-17 13:40:51,811 : agent.on_policy : DEBUG : Mean Losses: [3.6074043922126293]
2026-01-17 13:40:51,843 : worker.worker : DEBUG : Step 189059, finished rewards 25.07, envs finished 1
2026-01-17 13:40:51,919 : worker.worker : DEBUG : Step 189072, finished rewards 9.00, envs finished 1
2026-01-17 13:40:52,244 : agent.on_policy : DEBUG : Mean Losses: [1.9903711443766952]
2026-01-17 13:40:52,291 : worker.worker : DEBUG : Step 189098, finished rewards 18.23, envs finished 1
2026-01-17 13:40:52,618 : agent.on_policy : DEBUG : Mean Losses: [2.919203467667103]
2026-01-17 13:40:52,703 : worker.worker : DEBUG : Step 189132, finished rewards 18.51, envs finished 1
2026-01-17 13:40:52,745 : worker.worker : DEBUG : Step 189137, finished rewards 21.47, envs finished 3
2026-01-17 13:40:52,792 : worker.worker : DEBUG : Step 189139, finished rewards -2.89, envs finished 1
2026-01-17 13:40:53,093 : agent.on_policy : DEBUG : Mean Losses: [6.489000454545021]
2026-01-17 13:40:53,221 : worker.worker : DEBUG : Step 189164, finished rewards 25.08, envs finished 1
2026-01-17 13:40:53,416 : worker.worker : DEBUG : Step 189179, finished rewards 16.23, envs finished 1
2026-01-17 13:40:53,629 : agent.on_policy : DEBUG : Mean Losses: [2.6790319830179214]
2026-01-17 13:40:53,656 : worker.worker : DEBUG : Step 189188, finished rewards 26.10, envs finished 1
2026-01-17 13:40:53,989 : agent.on_policy : DEBUG : Mean Losses: [1.862991382367909]
2026-01-17 13:40:54,006 : worker.worker : DEBUG : Step 189220, finished rewards 32.48, envs finished 1
2026-01-17 13:40:54,106 : worker.worker : DEBUG : Step 189240, finished rewards 15.32, envs finished 2
2026-01-17 13:40:54,161 : worker.worker : DEBUG : Step 189246, finished rewards 15.59, envs finished 1
2026-01-17 13:40:54,208 : worker.worker : DEBUG : Step 189247, finished rewards 11.87, envs finished 1
2026-01-17 13:40:54,312 : agent.on_policy : DEBUG : Mean Losses: [5.699123642873019]
2026-01-17 13:40:54,595 : agent.on_policy : DEBUG : Mean Losses: [2.947050671093166]
2026-01-17 13:40:54,624 : worker.worker : DEBUG : Step 189285, finished rewards 21.40, envs finished 1
2026-01-17 13:40:54,647 : worker.worker : DEBUG : Step 189289, finished rewards 17.92, envs finished 1
2026-01-17 13:40:54,751 : worker.worker : DEBUG : Step 189311, finished rewards 45.22, envs finished 1
2026-01-17 13:40:54,881 : agent.on_policy : DEBUG : Mean Losses: [5.220021262764931]
2026-01-17 13:40:54,915 : worker.worker : DEBUG : Step 189318, finished rewards 17.97, envs finished 1
2026-01-17 13:40:54,998 : worker.worker : DEBUG : Step 189325, finished rewards 29.93, envs finished 1
2026-01-17 13:40:55,035 : worker.worker : DEBUG : Step 189327, finished rewards -24.08, envs finished 1
2026-01-17 13:40:55,232 : agent.on_policy : DEBUG : Mean Losses: [5.094314826652408]
2026-01-17 13:40:55,247 : worker.worker : DEBUG : Step 189345, finished rewards 20.42, envs finished 1
2026-01-17 13:40:55,396 : worker.worker : DEBUG : Step 189360, finished rewards 40.81, envs finished 1
2026-01-17 13:40:55,593 : agent.on_policy : DEBUG : Mean Losses: [3.9067362397909164]
2026-01-17 13:40:55,649 : worker.worker : DEBUG : Step 189390, finished rewards -12.02, envs finished 1
2026-01-17 13:40:55,709 : worker.worker : DEBUG : Step 189407, finished rewards 27.13, envs finished 1
2026-01-17 13:40:55,850 : agent.on_policy : DEBUG : Mean Losses: [4.377506699413061]
2026-01-17 13:40:55,913 : worker.worker : DEBUG : Step 189420, finished rewards 23.45, envs finished 1
2026-01-17 13:40:55,950 : worker.worker : DEBUG : Step 189421, finished rewards 23.18, envs finished 1
2026-01-17 13:40:56,034 : worker.worker : DEBUG : Step 189430, finished rewards 9.82, envs finished 1
2026-01-17 13:40:56,221 : agent.on_policy : DEBUG : Mean Losses: [3.9621197432279587]
2026-01-17 13:40:56,306 : worker.worker : DEBUG : Step 189447, finished rewards 18.35, envs finished 1
2026-01-17 13:40:56,587 : worker.worker : DEBUG : Step 189470, finished rewards 14.76, envs finished 1
2026-01-17 13:40:56,743 : agent.on_policy : DEBUG : Mean Losses: [2.0772478096187115]
2026-01-17 13:40:56,844 : worker.worker : DEBUG : Step 189487, finished rewards 19.47, envs finished 1
2026-01-17 13:40:56,884 : worker.worker : DEBUG : Step 189491, finished rewards 18.92, envs finished 1
2026-01-17 13:40:56,931 : worker.worker : DEBUG : Step 189499, finished rewards 29.69, envs finished 2
2026-01-17 13:40:57,089 : agent.on_policy : DEBUG : Mean Losses: [4.883614574559033]
2026-01-17 13:40:57,193 : worker.worker : DEBUG : Step 189514, finished rewards 25.17, envs finished 1
2026-01-17 13:40:57,403 : agent.on_policy : DEBUG : Mean Losses: [2.2307711001485586]
2026-01-17 13:40:57,430 : worker.worker : DEBUG : Step 189543, finished rewards 10.57, envs finished 1
2026-01-17 13:40:57,748 : agent.on_policy : DEBUG : Mean Losses: [4.674779623746872]
2026-01-17 13:40:57,762 : worker.worker : DEBUG : Step 189570, finished rewards 41.94, envs finished 1
2026-01-17 13:40:57,782 : worker.worker : DEBUG : Step 189572, finished rewards 5.37, envs finished 1
2026-01-17 13:40:57,795 : worker.worker : DEBUG : Step 189574, finished rewards 28.13, envs finished 1
2026-01-17 13:40:57,835 : worker.worker : DEBUG : Step 189583, finished rewards 24.40, envs finished 1
2026-01-17 13:40:57,941 : agent.on_policy : DEBUG : Mean Losses: [5.045147181022912]
2026-01-17 13:40:57,953 : worker.worker : DEBUG : Step 189603, finished rewards 16.66, envs finished 1
2026-01-17 13:40:58,073 : worker.worker : DEBUG : Step 189618, finished rewards 17.25, envs finished 1
2026-01-17 13:40:58,112 : worker.worker : DEBUG : Step 189623, finished rewards -9.82, envs finished 1
2026-01-17 13:40:58,358 : agent.on_policy : DEBUG : Mean Losses: [3.2175756860524416]
2026-01-17 13:40:58,607 : agent.on_policy : DEBUG : Mean Losses: [2.906271241605282]
2026-01-17 13:40:58,633 : worker.worker : DEBUG : Step 189669, finished rewards 4.73, envs finished 1
2026-01-17 13:40:58,682 : worker.worker : DEBUG : Step 189680, finished rewards 17.91, envs finished 1
2026-01-17 13:40:58,729 : worker.worker : DEBUG : Step 189691, finished rewards 4.58, envs finished 1
2026-01-17 13:40:58,751 : worker.worker : DEBUG : Step 189694, finished rewards 42.67, envs finished 1
2026-01-17 13:40:58,809 : agent.on_policy : DEBUG : Mean Losses: [7.383062481880188]
2026-01-17 13:40:58,816 : worker.worker : DEBUG : Step 189697, finished rewards 10.64, envs finished 1
2026-01-17 13:40:58,847 : worker.worker : DEBUG : Step 189704, finished rewards 28.56, envs finished 1
2026-01-17 13:40:58,895 : worker.worker : DEBUG : Step 189714, finished rewards -10.12, envs finished 1
2026-01-17 13:40:59,148 : agent.on_policy : DEBUG : Mean Losses: [3.8665333818644285]
2026-01-17 13:40:59,176 : worker.worker : DEBUG : Step 189736, finished rewards 6.38, envs finished 1
2026-01-17 13:40:59,347 : agent.on_policy : DEBUG : Mean Losses: [1.3864722531288862]
2026-01-17 13:40:59,418 : worker.worker : DEBUG : Step 189767, finished rewards 41.07, envs finished 1
2026-01-17 13:40:59,432 : worker.worker : DEBUG : Step 189769, finished rewards 22.03, envs finished 1
2026-01-17 13:40:59,557 : worker.worker : DEBUG : Step 189786, finished rewards 40.19, envs finished 1
2026-01-17 13:40:59,576 : worker.worker : DEBUG : Step 189789, finished rewards 15.03, envs finished 1
2026-01-17 13:40:59,663 : agent.on_policy : DEBUG : Mean Losses: [7.017431825399399]
2026-01-17 13:40:59,726 : worker.worker : DEBUG : Step 189797, finished rewards 24.45, envs finished 1
2026-01-17 13:40:59,739 : worker.worker : DEBUG : Step 189798, finished rewards 18.48, envs finished 1
2026-01-17 13:41:00,228 : agent.on_policy : DEBUG : Mean Losses: [4.356417030096054]
2026-01-17 13:41:00,305 : worker.worker : DEBUG : Step 189841, finished rewards 14.22, envs finished 1
2026-01-17 13:41:00,332 : worker.worker : DEBUG : Step 189846, finished rewards -14.87, envs finished 1
2026-01-17 13:41:00,357 : worker.worker : DEBUG : Step 189850, finished rewards 46.14, envs finished 1
2026-01-17 13:41:00,548 : agent.on_policy : DEBUG : Mean Losses: [7.125647529959679]
2026-01-17 13:41:00,589 : worker.worker : DEBUG : Step 189865, finished rewards 21.81, envs finished 1
2026-01-17 13:41:00,630 : worker.worker : DEBUG : Step 189872, finished rewards 16.33, envs finished 1
2026-01-17 13:41:00,658 : worker.worker : DEBUG : Step 189877, finished rewards 33.84, envs finished 1
2026-01-17 13:41:00,762 : agent.on_policy : DEBUG : Mean Losses: [4.594909146428108]
2026-01-17 13:41:00,783 : worker.worker : DEBUG : Step 189892, finished rewards 23.56, envs finished 1
2026-01-17 13:41:00,971 : worker.worker : DEBUG : Step 189914, finished rewards -0.84, envs finished 1
2026-01-17 13:41:01,201 : agent.on_policy : DEBUG : Mean Losses: [3.174693487584591]
2026-01-17 13:41:01,270 : worker.worker : DEBUG : Step 189923, finished rewards 40.37, envs finished 1
2026-01-17 13:41:01,396 : worker.worker : DEBUG : Step 189934, finished rewards 25.09, envs finished 1
2026-01-17 13:41:01,466 : worker.worker : DEBUG : Step 189937, finished rewards 41.36, envs finished 1
2026-01-17 13:41:01,509 : worker.worker : DEBUG : Step 189943, finished rewards 30.84, envs finished 2
2026-01-17 13:41:01,693 : agent.on_policy : DEBUG : Mean Losses: [6.7251036912202835]
2026-01-17 13:41:01,917 : worker.worker : DEBUG : Step 189980, finished rewards 27.89, envs finished 1
2026-01-17 13:41:01,990 : agent.on_policy : DEBUG : Mean Losses: [2.1366224698722363]
2026-01-17 13:41:02,016 : worker.worker : DEBUG : Step 189991, finished rewards 9.66, envs finished 1
2026-01-17 13:41:02,047 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:41:02,069 : worker.worker : INFO : Step 190000, Avg Reward 22.8897, Max Reward 101.0897, Loss [4.2282777]
2026-01-17 13:41:02,103 : worker.worker : DEBUG : Step 190002, finished rewards 33.70, envs finished 1
2026-01-17 13:41:02,143 : worker.worker : DEBUG : Step 190007, finished rewards 23.60, envs finished 1
2026-01-17 13:41:02,239 : agent.on_policy : DEBUG : Mean Losses: [4.77512700855732]
2026-01-17 13:41:02,309 : worker.worker : DEBUG : Step 190029, finished rewards 24.23, envs finished 1
2026-01-17 13:41:02,551 : agent.on_policy : DEBUG : Mean Losses: [4.178259875625372]
2026-01-17 13:41:02,552 : worker.worker : DEBUG : Step 190048, finished rewards 16.39, envs finished 1
2026-01-17 13:41:02,567 : worker.worker : DEBUG : Step 190051, finished rewards 15.33, envs finished 1
2026-01-17 13:41:02,871 : agent.on_policy : DEBUG : Mean Losses: [2.5782971382141113]
2026-01-17 13:41:02,881 : worker.worker : DEBUG : Step 190082, finished rewards 16.76, envs finished 1
2026-01-17 13:41:02,920 : worker.worker : DEBUG : Step 190090, finished rewards 32.45, envs finished 1
2026-01-17 13:41:03,012 : worker.worker : DEBUG : Step 190109, finished rewards 14.41, envs finished 1
2026-01-17 13:41:03,172 : agent.on_policy : DEBUG : Mean Losses: [5.376161355525255]
2026-01-17 13:41:03,176 : worker.worker : DEBUG : Step 190113, finished rewards 9.82, envs finished 1
2026-01-17 13:41:03,355 : worker.worker : DEBUG : Step 190131, finished rewards -12.11, envs finished 1
2026-01-17 13:41:03,433 : worker.worker : DEBUG : Step 190138, finished rewards 11.17, envs finished 1
2026-01-17 13:41:03,619 : agent.on_policy : DEBUG : Mean Losses: [4.618044517934322]
2026-01-17 13:41:03,677 : worker.worker : DEBUG : Step 190149, finished rewards 18.54, envs finished 1
2026-01-17 13:41:03,815 : worker.worker : DEBUG : Step 190162, finished rewards 41.21, envs finished 1
2026-01-17 13:41:03,843 : worker.worker : DEBUG : Step 190166, finished rewards 7.94, envs finished 1
2026-01-17 13:41:04,024 : agent.on_policy : DEBUG : Mean Losses: [3.9351707557216287]
2026-01-17 13:41:04,111 : worker.worker : DEBUG : Step 190185, finished rewards 18.32, envs finished 1
2026-01-17 13:41:04,249 : worker.worker : DEBUG : Step 190201, finished rewards 24.63, envs finished 1
2026-01-17 13:41:04,280 : worker.worker : DEBUG : Step 190205, finished rewards 25.11, envs finished 1
2026-01-17 13:41:04,355 : agent.on_policy : DEBUG : Mean Losses: [4.145208942703903]
2026-01-17 13:41:04,384 : worker.worker : DEBUG : Step 190210, finished rewards 34.24, envs finished 1
2026-01-17 13:41:04,569 : worker.worker : DEBUG : Step 190226, finished rewards 27.54, envs finished 1
2026-01-17 13:41:04,841 : agent.on_policy : DEBUG : Mean Losses: [2.9586306251585484]
2026-01-17 13:41:04,963 : worker.worker : DEBUG : Step 190252, finished rewards 19.66, envs finished 1
2026-01-17 13:41:04,984 : worker.worker : DEBUG : Step 190256, finished rewards 33.46, envs finished 2
2026-01-17 13:41:05,193 : agent.on_policy : DEBUG : Mean Losses: [6.018901228904724]
2026-01-17 13:41:05,207 : worker.worker : DEBUG : Step 190275, finished rewards 41.20, envs finished 1
2026-01-17 13:41:05,244 : worker.worker : DEBUG : Step 190282, finished rewards 41.29, envs finished 1
2026-01-17 13:41:05,461 : agent.on_policy : DEBUG : Mean Losses: [4.326792135834694]
2026-01-17 13:41:05,541 : worker.worker : DEBUG : Step 190319, finished rewards 23.09, envs finished 1
2026-01-17 13:41:05,556 : worker.worker : DEBUG : Step 190322, finished rewards 41.16, envs finished 1
2026-01-17 13:41:05,670 : worker.worker : DEBUG : Step 190335, finished rewards -5.90, envs finished 1
2026-01-17 13:41:05,776 : agent.on_policy : DEBUG : Mean Losses: [5.104509219527245]
2026-01-17 13:41:05,793 : worker.worker : DEBUG : Step 190339, finished rewards -35.98, envs finished 1
2026-01-17 13:41:06,146 : agent.on_policy : DEBUG : Mean Losses: [3.3755408339202404]
2026-01-17 13:41:06,147 : worker.worker : DEBUG : Step 190368, finished rewards 10.38, envs finished 1
2026-01-17 13:41:06,173 : worker.worker : DEBUG : Step 190372, finished rewards 10.98, envs finished 1
2026-01-17 13:41:06,278 : worker.worker : DEBUG : Step 190390, finished rewards 5.77, envs finished 1
2026-01-17 13:41:06,500 : agent.on_policy : DEBUG : Mean Losses: [4.912504106760025]
2026-01-17 13:41:06,540 : worker.worker : DEBUG : Step 190407, finished rewards 4.92, envs finished 1
2026-01-17 13:41:06,635 : worker.worker : DEBUG : Step 190414, finished rewards 25.71, envs finished 1
2026-01-17 13:41:06,877 : agent.on_policy : DEBUG : Mean Losses: [5.091223981231451]
2026-01-17 13:41:06,883 : worker.worker : DEBUG : Step 190433, finished rewards 12.55, envs finished 1
2026-01-17 13:41:07,000 : worker.worker : DEBUG : Step 190444, finished rewards 14.11, envs finished 1
2026-01-17 13:41:07,229 : agent.on_policy : DEBUG : Mean Losses: [2.9793082922697067]
2026-01-17 13:41:07,462 : worker.worker : DEBUG : Step 190489, finished rewards 14.98, envs finished 1
2026-01-17 13:41:07,494 : worker.worker : DEBUG : Step 190493, finished rewards -7.34, envs finished 1
2026-01-17 13:41:07,608 : agent.on_policy : DEBUG : Mean Losses: [4.301363557577133]
2026-01-17 13:41:07,670 : worker.worker : DEBUG : Step 190502, finished rewards 10.59, envs finished 1
2026-01-17 13:41:07,742 : worker.worker : DEBUG : Step 190508, finished rewards 3.96, envs finished 1
2026-01-17 13:41:07,759 : worker.worker : DEBUG : Step 190511, finished rewards 15.45, envs finished 1
2026-01-17 13:41:07,807 : worker.worker : DEBUG : Step 190518, finished rewards 16.81, envs finished 1
2026-01-17 13:41:08,002 : agent.on_policy : DEBUG : Mean Losses: [4.3172015361487865]
2026-01-17 13:41:08,058 : worker.worker : DEBUG : Step 190535, finished rewards 25.11, envs finished 1
2026-01-17 13:41:08,353 : worker.worker : DEBUG : Step 190557, finished rewards 46.13, envs finished 1
2026-01-17 13:41:08,563 : agent.on_policy : DEBUG : Mean Losses: [5.222209580242634]
2026-01-17 13:41:08,687 : worker.worker : DEBUG : Step 190570, finished rewards -9.35, envs finished 1
2026-01-17 13:41:09,054 : agent.on_policy : DEBUG : Mean Losses: [2.9883530670776963]
2026-01-17 13:41:09,087 : worker.worker : DEBUG : Step 190597, finished rewards 18.58, envs finished 1
2026-01-17 13:41:09,123 : worker.worker : DEBUG : Step 190604, finished rewards 28.24, envs finished 1
2026-01-17 13:41:09,139 : worker.worker : DEBUG : Step 190607, finished rewards 21.70, envs finished 1
2026-01-17 13:41:09,163 : worker.worker : DEBUG : Step 190612, finished rewards 22.38, envs finished 3
2026-01-17 13:41:09,253 : agent.on_policy : DEBUG : Mean Losses: [6.6879123747348785]
2026-01-17 13:41:09,278 : worker.worker : DEBUG : Step 190631, finished rewards 37.66, envs finished 1
2026-01-17 13:41:09,490 : agent.on_policy : DEBUG : Mean Losses: [2.2767643723636866]
2026-01-17 13:41:09,564 : worker.worker : DEBUG : Step 190678, finished rewards 40.35, envs finished 1
2026-01-17 13:41:09,582 : worker.worker : DEBUG : Step 190682, finished rewards 8.67, envs finished 1
2026-01-17 13:41:09,783 : agent.on_policy : DEBUG : Mean Losses: [4.707433272153139]
2026-01-17 13:41:09,906 : worker.worker : DEBUG : Step 190701, finished rewards 16.58, envs finished 1
2026-01-17 13:41:09,921 : worker.worker : DEBUG : Step 190704, finished rewards 22.54, envs finished 2
2026-01-17 13:41:10,018 : worker.worker : DEBUG : Step 190712, finished rewards 21.34, envs finished 1
2026-01-17 13:41:10,054 : worker.worker : DEBUG : Step 190717, finished rewards 17.42, envs finished 1
2026-01-17 13:41:10,221 : agent.on_policy : DEBUG : Mean Losses: [6.086527854204178]
2026-01-17 13:41:10,318 : worker.worker : DEBUG : Step 190728, finished rewards 21.81, envs finished 1
2026-01-17 13:41:10,636 : agent.on_policy : DEBUG : Mean Losses: [1.3392232097685337]
2026-01-17 13:41:10,724 : worker.worker : DEBUG : Step 190776, finished rewards 22.28, envs finished 1
2026-01-17 13:41:10,731 : worker.worker : DEBUG : Step 190778, finished rewards 18.64, envs finished 1
2026-01-17 13:41:10,960 : agent.on_policy : DEBUG : Mean Losses: [3.4106499701738358]
2026-01-17 13:41:11,001 : worker.worker : DEBUG : Step 190794, finished rewards 23.40, envs finished 1
2026-01-17 13:41:11,013 : worker.worker : DEBUG : Step 190796, finished rewards 31.14, envs finished 1
2026-01-17 13:41:11,020 : worker.worker : DEBUG : Step 190797, finished rewards 23.73, envs finished 1
2026-01-17 13:41:11,060 : worker.worker : DEBUG : Step 190807, finished rewards 27.10, envs finished 1
2026-01-17 13:41:11,136 : agent.on_policy : DEBUG : Mean Losses: [7.062505695968866]
2026-01-17 13:41:11,138 : worker.worker : DEBUG : Step 190816, finished rewards 27.66, envs finished 1
2026-01-17 13:41:11,148 : worker.worker : DEBUG : Step 190818, finished rewards 10.94, envs finished 1
2026-01-17 13:41:11,372 : agent.on_policy : DEBUG : Mean Losses: [1.4538678750395775]
2026-01-17 13:41:11,543 : agent.on_policy : DEBUG : Mean Losses: [3.3856685757637024]
2026-01-17 13:41:11,636 : worker.worker : DEBUG : Step 190892, finished rewards 20.35, envs finished 1
2026-01-17 13:41:11,648 : worker.worker : DEBUG : Step 190894, finished rewards 18.35, envs finished 1
2026-01-17 13:41:11,722 : worker.worker : DEBUG : Step 190904, finished rewards 27.01, envs finished 1
2026-01-17 13:41:11,768 : worker.worker : DEBUG : Step 190907, finished rewards 10.66, envs finished 1
2026-01-17 13:41:11,938 : agent.on_policy : DEBUG : Mean Losses: [7.783536970615387]
2026-01-17 13:41:11,981 : worker.worker : DEBUG : Step 190915, finished rewards -8.55, envs finished 1
2026-01-17 13:41:12,092 : worker.worker : DEBUG : Step 190929, finished rewards 15.55, envs finished 1
2026-01-17 13:41:12,157 : worker.worker : DEBUG : Step 190932, finished rewards 0.74, envs finished 1
2026-01-17 13:41:12,366 : agent.on_policy : DEBUG : Mean Losses: [3.9375366158783436]
2026-01-17 13:41:12,522 : worker.worker : DEBUG : Step 190965, finished rewards 42.17, envs finished 1
2026-01-17 13:41:12,616 : agent.on_policy : DEBUG : Mean Losses: [3.3143576085567474]
2026-01-17 13:41:12,745 : worker.worker : DEBUG : Step 190993, finished rewards -24.80, envs finished 1
2026-01-17 13:41:12,797 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:41:12,820 : worker.worker : DEBUG : Step 191000, finished rewards 40.35, envs finished 1
2026-01-17 13:41:12,871 : worker.worker : DEBUG : Step 191003, finished rewards 12.60, envs finished 1
2026-01-17 13:41:13,135 : agent.on_policy : DEBUG : Mean Losses: [6.186288967728615]
2026-01-17 13:41:13,145 : worker.worker : DEBUG : Step 191010, finished rewards 17.84, envs finished 1
2026-01-17 13:41:13,170 : worker.worker : DEBUG : Step 191014, finished rewards 11.65, envs finished 1
2026-01-17 13:41:13,260 : worker.worker : DEBUG : Step 191019, finished rewards 28.06, envs finished 1
2026-01-17 13:41:13,312 : worker.worker : DEBUG : Step 191027, finished rewards 9.15, envs finished 1
2026-01-17 13:41:13,494 : agent.on_policy : DEBUG : Mean Losses: [3.443489241413772]
2026-01-17 13:41:13,520 : worker.worker : DEBUG : Step 191045, finished rewards 34.16, envs finished 1
2026-01-17 13:41:13,793 : agent.on_policy : DEBUG : Mean Losses: [1.630757499486208]
2026-01-17 13:41:13,902 : worker.worker : DEBUG : Step 191095, finished rewards 21.98, envs finished 1
2026-01-17 13:41:13,920 : worker.worker : DEBUG : Step 191098, finished rewards 31.58, envs finished 1
2026-01-17 13:41:14,114 : agent.on_policy : DEBUG : Mean Losses: [5.617376457899809]
2026-01-17 13:41:14,135 : worker.worker : DEBUG : Step 191108, finished rewards 21.99, envs finished 1
2026-01-17 13:41:14,154 : worker.worker : DEBUG : Step 191109, finished rewards 25.75, envs finished 1
2026-01-17 13:41:14,194 : worker.worker : DEBUG : Step 191112, finished rewards 19.27, envs finished 1
2026-01-17 13:41:14,322 : worker.worker : DEBUG : Step 191134, finished rewards 13.67, envs finished 1
2026-01-17 13:41:14,448 : agent.on_policy : DEBUG : Mean Losses: [4.5989353489130735]
2026-01-17 13:41:14,580 : worker.worker : DEBUG : Step 191152, finished rewards 13.86, envs finished 1
2026-01-17 13:41:14,703 : worker.worker : DEBUG : Step 191166, finished rewards -28.56, envs finished 1
2026-01-17 13:41:14,763 : agent.on_policy : DEBUG : Mean Losses: [2.867144104093313]
2026-01-17 13:41:14,927 : worker.worker : DEBUG : Step 191186, finished rewards 25.81, envs finished 1
2026-01-17 13:41:15,198 : agent.on_policy : DEBUG : Mean Losses: [4.5320170456543565]
2026-01-17 13:41:15,277 : worker.worker : DEBUG : Step 191216, finished rewards 4.07, envs finished 1
2026-01-17 13:41:15,287 : worker.worker : DEBUG : Step 191218, finished rewards 31.59, envs finished 1
2026-01-17 13:41:15,308 : worker.worker : DEBUG : Step 191223, finished rewards 13.02, envs finished 1
2026-01-17 13:41:15,314 : worker.worker : DEBUG : Step 191224, finished rewards 41.31, envs finished 1
2026-01-17 13:41:15,351 : worker.worker : DEBUG : Step 191229, finished rewards 5.92, envs finished 1
2026-01-17 13:41:15,507 : agent.on_policy : DEBUG : Mean Losses: [7.574982643127441]
2026-01-17 13:41:15,757 : worker.worker : DEBUG : Step 191262, finished rewards 22.66, envs finished 1
2026-01-17 13:41:15,824 : agent.on_policy : DEBUG : Mean Losses: [3.3773535043001175]
2026-01-17 13:41:15,887 : worker.worker : DEBUG : Step 191281, finished rewards 22.06, envs finished 1
2026-01-17 13:41:15,970 : worker.worker : DEBUG : Step 191287, finished rewards -41.46, envs finished 1
2026-01-17 13:41:15,917 : agent.on_policy : DEBUG : Mean Losses: [4.824490923434496]
2026-01-17 13:41:15,581 : worker.worker : DEBUG : Step 191305, finished rewards 38.64, envs finished 1
2026-01-17 13:41:15,884 : agent.on_policy : DEBUG : Mean Losses: [5.644800037145615]
2026-01-17 13:41:15,889 : worker.worker : DEBUG : Step 191329, finished rewards 9.17, envs finished 1
2026-01-17 13:41:15,934 : worker.worker : DEBUG : Step 191339, finished rewards 9.33, envs finished 1
2026-01-17 13:41:15,957 : worker.worker : DEBUG : Step 191343, finished rewards 6.88, envs finished 1
2026-01-17 13:41:16,013 : worker.worker : DEBUG : Step 191358, finished rewards 42.28, envs finished 1
2026-01-17 13:41:16,066 : agent.on_policy : DEBUG : Mean Losses: [6.600781410932541]
2026-01-17 13:41:16,079 : worker.worker : DEBUG : Step 191363, finished rewards 32.52, envs finished 1
2026-01-17 13:41:16,122 : worker.worker : DEBUG : Step 191368, finished rewards 13.07, envs finished 1
2026-01-17 13:41:16,413 : agent.on_policy : DEBUG : Mean Losses: [3.1372620724141598]
2026-01-17 13:41:16,627 : agent.on_policy : DEBUG : Mean Losses: [3.4685990512371063]
2026-01-17 13:41:16,632 : worker.worker : DEBUG : Step 191425, finished rewards 7.14, envs finished 1
2026-01-17 13:41:16,641 : worker.worker : DEBUG : Step 191427, finished rewards 46.39, envs finished 1
2026-01-17 13:41:16,649 : worker.worker : DEBUG : Step 191428, finished rewards 16.85, envs finished 1
2026-01-17 13:41:16,697 : worker.worker : DEBUG : Step 191439, finished rewards 40.63, envs finished 1
2026-01-17 13:41:16,748 : worker.worker : DEBUG : Step 191451, finished rewards 22.76, envs finished 1
2026-01-17 13:41:16,929 : agent.on_policy : DEBUG : Mean Losses: [7.204786509275436]
2026-01-17 13:41:16,932 : worker.worker : DEBUG : Step 191456, finished rewards 1.64, envs finished 1
2026-01-17 13:41:16,941 : worker.worker : DEBUG : Step 191457, finished rewards 9.22, envs finished 1
2026-01-17 13:41:17,273 : agent.on_policy : DEBUG : Mean Losses: [2.4643624275922775]
2026-01-17 13:41:17,287 : worker.worker : DEBUG : Step 191492, finished rewards 45.90, envs finished 1
2026-01-17 13:41:17,323 : worker.worker : DEBUG : Step 191500, finished rewards -1.44, envs finished 1
2026-01-17 13:41:17,375 : worker.worker : DEBUG : Step 191511, finished rewards 30.09, envs finished 1
2026-01-17 13:41:17,497 : agent.on_policy : DEBUG : Mean Losses: [4.406668774783611]
2026-01-17 13:41:17,578 : worker.worker : DEBUG : Step 191532, finished rewards 14.61, envs finished 1
2026-01-17 13:41:17,586 : worker.worker : DEBUG : Step 191533, finished rewards 23.02, envs finished 1
2026-01-17 13:41:17,597 : worker.worker : DEBUG : Step 191535, finished rewards 31.32, envs finished 1
2026-01-17 13:41:17,788 : agent.on_policy : DEBUG : Mean Losses: [5.300497382879257]
2026-01-17 13:41:17,831 : worker.worker : DEBUG : Step 191558, finished rewards 18.87, envs finished 1
2026-01-17 13:41:17,909 : worker.worker : DEBUG : Step 191565, finished rewards 40.42, envs finished 1
2026-01-17 13:41:17,990 : worker.worker : DEBUG : Step 191579, finished rewards 6.22, envs finished 1
2026-01-17 13:41:18,169 : agent.on_policy : DEBUG : Mean Losses: [5.240419991314411]
2026-01-17 13:41:18,264 : worker.worker : DEBUG : Step 191593, finished rewards 25.35, envs finished 1
2026-01-17 13:41:18,507 : agent.on_policy : DEBUG : Mean Losses: [2.6491748094558716]
2026-01-17 13:41:18,587 : worker.worker : DEBUG : Step 191625, finished rewards 25.38, envs finished 2
2026-01-17 13:41:18,615 : worker.worker : DEBUG : Step 191628, finished rewards 25.02, envs finished 1
2026-01-17 13:41:18,683 : worker.worker : DEBUG : Step 191643, finished rewards 29.11, envs finished 1
2026-01-17 13:41:18,813 : agent.on_policy : DEBUG : Mean Losses: [5.359367370605469]
2026-01-17 13:41:18,918 : worker.worker : DEBUG : Step 191660, finished rewards -7.77, envs finished 1
2026-01-17 13:41:18,968 : worker.worker : DEBUG : Step 191671, finished rewards 17.35, envs finished 1
2026-01-17 13:41:18,976 : worker.worker : DEBUG : Step 191673, finished rewards 24.33, envs finished 1
2026-01-17 13:41:19,037 : worker.worker : DEBUG : Step 191677, finished rewards 31.92, envs finished 1
2026-01-17 13:41:19,189 : agent.on_policy : DEBUG : Mean Losses: [5.246741186827421]
2026-01-17 13:41:19,252 : worker.worker : DEBUG : Step 191688, finished rewards 46.97, envs finished 1
2026-01-17 13:41:19,285 : worker.worker : DEBUG : Step 191696, finished rewards 42.18, envs finished 1
2026-01-17 13:41:19,484 : agent.on_policy : DEBUG : Mean Losses: [3.868682147935033]
2026-01-17 13:41:19,495 : worker.worker : DEBUG : Step 191715, finished rewards 40.75, envs finished 1
2026-01-17 13:41:19,851 : agent.on_policy : DEBUG : Mean Losses: [2.684910111129284]
2026-01-17 13:41:19,945 : worker.worker : DEBUG : Step 191767, finished rewards 42.13, envs finished 1
2026-01-17 13:41:20,137 : agent.on_policy : DEBUG : Mean Losses: [6.952965248376131]
2026-01-17 13:41:20,170 : worker.worker : DEBUG : Step 191777, finished rewards 5.75, envs finished 1
2026-01-17 13:41:20,299 : worker.worker : DEBUG : Step 191789, finished rewards 3.23, envs finished 1
2026-01-17 13:41:20,321 : worker.worker : DEBUG : Step 191790, finished rewards 17.97, envs finished 1
2026-01-17 13:41:20,611 : agent.on_policy : DEBUG : Mean Losses: [5.209825541824102]
2026-01-17 13:41:20,636 : worker.worker : DEBUG : Step 191814, finished rewards -11.81, envs finished 1
2026-01-17 13:41:20,691 : worker.worker : DEBUG : Step 191828, finished rewards -47.46, envs finished 1
2026-01-17 13:41:20,703 : worker.worker : DEBUG : Step 191831, finished rewards -15.93, envs finished 1
2026-01-17 13:41:20,734 : worker.worker : DEBUG : Step 191836, finished rewards 3.31, envs finished 1
2026-01-17 13:41:20,879 : agent.on_policy : DEBUG : Mean Losses: [4.4276248794049025]
2026-01-17 13:41:20,990 : worker.worker : DEBUG : Step 191870, finished rewards 17.37, envs finished 1
2026-01-17 13:41:21,136 : agent.on_policy : DEBUG : Mean Losses: [2.2356385737657547]
2026-01-17 13:41:21,324 : worker.worker : DEBUG : Step 191892, finished rewards 19.03, envs finished 1
2026-01-17 13:41:21,572 : agent.on_policy : DEBUG : Mean Losses: [5.302130226045847]
2026-01-17 13:41:21,588 : worker.worker : DEBUG : Step 191907, finished rewards 36.37, envs finished 1
2026-01-17 13:41:21,604 : worker.worker : DEBUG : Step 191910, finished rewards 33.11, envs finished 1
2026-01-17 13:41:21,679 : worker.worker : DEBUG : Step 191925, finished rewards 10.32, envs finished 1
2026-01-17 13:41:21,695 : worker.worker : DEBUG : Step 191928, finished rewards -14.89, envs finished 1
2026-01-17 13:41:21,848 : agent.on_policy : DEBUG : Mean Losses: [6.348064366728067]
2026-01-17 13:41:21,854 : worker.worker : DEBUG : Step 191937, finished rewards -12.28, envs finished 1
2026-01-17 13:41:21,901 : worker.worker : DEBUG : Step 191950, finished rewards 10.97, envs finished 1
2026-01-17 13:41:21,988 : agent.on_policy : DEBUG : Mean Losses: [4.309899270534515]
2026-01-17 13:41:22,054 : worker.worker : DEBUG : Step 191992, finished rewards 45.98, envs finished 1
2026-01-17 13:41:22,074 : worker.worker : DEBUG : Step 191998, finished rewards 14.53, envs finished 1
2026-01-17 13:41:22,075 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:41:22,121 : agent.on_policy : DEBUG : Mean Losses: [6.372893840074539]
2026-01-17 13:41:22,268 : worker.worker : DEBUG : Step 192022, finished rewards 9.38, envs finished 1
2026-01-17 13:41:22,320 : worker.worker : DEBUG : Step 192027, finished rewards -0.71, envs finished 1
2026-01-17 13:41:22,543 : agent.on_policy : DEBUG : Mean Losses: [5.0284244120121]
2026-01-17 13:41:22,549 : worker.worker : DEBUG : Step 192033, finished rewards 21.07, envs finished 1
2026-01-17 13:41:22,567 : worker.worker : DEBUG : Step 192035, finished rewards 19.59, envs finished 1
2026-01-17 13:41:22,693 : worker.worker : DEBUG : Step 192048, finished rewards 20.53, envs finished 1
2026-01-17 13:41:22,713 : worker.worker : DEBUG : Step 192050, finished rewards 1.72, envs finished 1
2026-01-17 13:41:22,975 : agent.on_policy : DEBUG : Mean Losses: [3.7409460339695215]
2026-01-17 13:41:23,017 : worker.worker : DEBUG : Step 192073, finished rewards 33.51, envs finished 1
2026-01-17 13:41:23,251 : agent.on_policy : DEBUG : Mean Losses: [2.9562797769904137]
2026-01-17 13:41:23,295 : worker.worker : DEBUG : Step 192105, finished rewards 41.33, envs finished 1
2026-01-17 13:41:23,357 : worker.worker : DEBUG : Step 192119, finished rewards 24.65, envs finished 1
2026-01-17 13:41:23,397 : worker.worker : DEBUG : Step 192127, finished rewards 24.92, envs finished 1
2026-01-17 13:41:23,563 : agent.on_policy : DEBUG : Mean Losses: [5.061903759837151]
2026-01-17 13:41:23,596 : worker.worker : DEBUG : Step 192134, finished rewards 9.46, envs finished 1
2026-01-17 13:41:23,616 : worker.worker : DEBUG : Step 192137, finished rewards 0.14, envs finished 1
2026-01-17 13:41:23,733 : worker.worker : DEBUG : Step 192150, finished rewards 18.03, envs finished 1
2026-01-17 13:41:23,750 : worker.worker : DEBUG : Step 192153, finished rewards 15.74, envs finished 1
2026-01-17 13:41:24,035 : agent.on_policy : DEBUG : Mean Losses: [4.847151339054108]
2026-01-17 13:41:24,189 : worker.worker : DEBUG : Step 192181, finished rewards 17.08, envs finished 1
2026-01-17 13:41:24,365 : agent.on_policy : DEBUG : Mean Losses: [1.9979061298072338]
2026-01-17 13:41:24,421 : worker.worker : DEBUG : Step 192205, finished rewards 42.17, envs finished 1
2026-01-17 13:41:24,545 : worker.worker : DEBUG : Step 192215, finished rewards 12.03, envs finished 1
2026-01-17 13:41:24,581 : worker.worker : DEBUG : Step 192222, finished rewards 24.03, envs finished 1
2026-01-17 13:41:24,738 : agent.on_policy : DEBUG : Mean Losses: [5.2175091207027435]
2026-01-17 13:41:24,740 : worker.worker : DEBUG : Step 192224, finished rewards 40.98, envs finished 1
2026-01-17 13:41:24,746 : worker.worker : DEBUG : Step 192225, finished rewards 13.69, envs finished 1
2026-01-17 13:41:25,019 : worker.worker : DEBUG : Step 192248, finished rewards 21.24, envs finished 1
2026-01-17 13:41:25,038 : worker.worker : DEBUG : Step 192251, finished rewards 11.43, envs finished 1
2026-01-17 13:41:25,148 : agent.on_policy : DEBUG : Mean Losses: [3.971873770467937]
2026-01-17 13:41:25,424 : agent.on_policy : DEBUG : Mean Losses: [1.5610755644738674]
2026-01-17 13:41:25,429 : worker.worker : DEBUG : Step 192289, finished rewards 31.41, envs finished 1
2026-01-17 13:41:25,446 : worker.worker : DEBUG : Step 192293, finished rewards 9.53, envs finished 1
2026-01-17 13:41:25,473 : worker.worker : DEBUG : Step 192299, finished rewards 35.36, envs finished 1
2026-01-17 13:41:25,547 : worker.worker : DEBUG : Step 192318, finished rewards 40.82, envs finished 1
2026-01-17 13:41:25,609 : agent.on_policy : DEBUG : Mean Losses: [7.144407168030739]
2026-01-17 13:41:25,634 : worker.worker : DEBUG : Step 192323, finished rewards 20.99, envs finished 1
2026-01-17 13:41:25,775 : worker.worker : DEBUG : Step 192340, finished rewards 26.89, envs finished 1
2026-01-17 13:41:25,868 : worker.worker : DEBUG : Step 192346, finished rewards -1.39, envs finished 1
2026-01-17 13:41:26,041 : agent.on_policy : DEBUG : Mean Losses: [4.1408946849405766]
2026-01-17 13:41:26,172 : worker.worker : DEBUG : Step 192377, finished rewards 7.55, envs finished 2
2026-01-17 13:41:26,191 : worker.worker : DEBUG : Step 192378, finished rewards 33.79, envs finished 1
2026-01-17 13:41:26,269 : agent.on_policy : DEBUG : Mean Losses: [7.1558758690953255]
2026-01-17 13:41:26,308 : worker.worker : DEBUG : Step 192397, finished rewards 33.63, envs finished 1
2026-01-17 13:41:26,334 : worker.worker : DEBUG : Step 192405, finished rewards 10.64, envs finished 1
2026-01-17 13:41:26,396 : agent.on_policy : DEBUG : Mean Losses: [3.247623775154352]
2026-01-17 13:41:26,447 : worker.worker : DEBUG : Step 192435, finished rewards 8.03, envs finished 1
2026-01-17 13:41:26,535 : agent.on_policy : DEBUG : Mean Losses: [3.720658101141453]
2026-01-17 13:41:26,538 : worker.worker : DEBUG : Step 192448, finished rewards 17.91, envs finished 1
2026-01-17 13:41:26,543 : worker.worker : DEBUG : Step 192449, finished rewards 40.76, envs finished 1
2026-01-17 13:41:26,715 : worker.worker : DEBUG : Step 192464, finished rewards 29.39, envs finished 1
2026-01-17 13:41:26,740 : worker.worker : DEBUG : Step 192469, finished rewards 46.25, envs finished 1
2026-01-17 13:41:26,863 : worker.worker : DEBUG : Step 192478, finished rewards 19.39, envs finished 1
2026-01-17 13:41:26,992 : agent.on_policy : DEBUG : Mean Losses: [6.920677147805691]
2026-01-17 13:41:26,999 : worker.worker : DEBUG : Step 192481, finished rewards 3.89, envs finished 1
2026-01-17 13:41:27,232 : agent.on_policy : DEBUG : Mean Losses: [2.2916117357090116]
2026-01-17 13:41:27,304 : worker.worker : DEBUG : Step 192533, finished rewards 31.39, envs finished 1
2026-01-17 13:41:27,477 : agent.on_policy : DEBUG : Mean Losses: [7.413455784320831]
2026-01-17 13:41:27,504 : worker.worker : DEBUG : Step 192551, finished rewards 40.15, envs finished 1
2026-01-17 13:41:27,528 : worker.worker : DEBUG : Step 192557, finished rewards 38.87, envs finished 1
2026-01-17 13:41:27,535 : worker.worker : DEBUG : Step 192558, finished rewards 3.51, envs finished 1
2026-01-17 13:41:27,543 : worker.worker : DEBUG : Step 192559, finished rewards 9.24, envs finished 1
2026-01-17 13:41:27,565 : worker.worker : DEBUG : Step 192563, finished rewards 21.60, envs finished 1
2026-01-17 13:41:27,592 : worker.worker : DEBUG : Step 192568, finished rewards -36.22, envs finished 1
2026-01-17 13:41:27,677 : agent.on_policy : DEBUG : Mean Losses: [7.209650911390781]
2026-01-17 13:41:27,896 : agent.on_policy : DEBUG : Mean Losses: [2.856963261961937]
2026-01-17 13:41:27,929 : worker.worker : DEBUG : Step 192617, finished rewards 31.53, envs finished 1
2026-01-17 13:41:27,935 : worker.worker : DEBUG : Step 192618, finished rewards -13.43, envs finished 1
2026-01-17 13:41:28,051 : agent.on_policy : DEBUG : Mean Losses: [4.275921896100044]
2026-01-17 13:41:28,053 : worker.worker : DEBUG : Step 192640, finished rewards 31.20, envs finished 1
2026-01-17 13:41:28,066 : worker.worker : DEBUG : Step 192643, finished rewards 25.33, envs finished 1
2026-01-17 13:41:28,150 : worker.worker : DEBUG : Step 192650, finished rewards 25.47, envs finished 1
2026-01-17 13:41:28,209 : worker.worker : DEBUG : Step 192655, finished rewards 30.15, envs finished 1
2026-01-17 13:41:28,270 : worker.worker : DEBUG : Step 192663, finished rewards 18.18, envs finished 1
2026-01-17 13:41:28,344 : worker.worker : DEBUG : Step 192670, finished rewards 19.41, envs finished 1
2026-01-17 13:41:28,523 : agent.on_policy : DEBUG : Mean Losses: [4.922625221312046]
2026-01-17 13:41:28,752 : worker.worker : DEBUG : Step 192689, finished rewards 40.85, envs finished 1
2026-01-17 13:41:28,923 : agent.on_policy : DEBUG : Mean Losses: [2.7430723141878843]
2026-01-17 13:41:29,068 : worker.worker : DEBUG : Step 192724, finished rewards 15.76, envs finished 1
2026-01-17 13:41:29,239 : agent.on_policy : DEBUG : Mean Losses: [3.8478424921631813]
2026-01-17 13:41:29,244 : worker.worker : DEBUG : Step 192737, finished rewards 28.23, envs finished 1
2026-01-17 13:41:29,294 : worker.worker : DEBUG : Step 192747, finished rewards 15.29, envs finished 1
2026-01-17 13:41:29,325 : worker.worker : DEBUG : Step 192754, finished rewards 31.71, envs finished 1
2026-01-17 13:41:29,340 : worker.worker : DEBUG : Step 192757, finished rewards 10.69, envs finished 1
2026-01-17 13:41:29,350 : worker.worker : DEBUG : Step 192758, finished rewards 17.61, envs finished 1
2026-01-17 13:41:29,373 : worker.worker : DEBUG : Step 192762, finished rewards 22.57, envs finished 1
2026-01-17 13:41:29,441 : agent.on_policy : DEBUG : Mean Losses: [6.4443307891488075]
2026-01-17 13:41:29,608 : worker.worker : DEBUG : Step 192793, finished rewards 16.82, envs finished 1
2026-01-17 13:41:29,685 : agent.on_policy : DEBUG : Mean Losses: [1.4960765317082405]
2026-01-17 13:41:29,730 : worker.worker : DEBUG : Step 192811, finished rewards 46.12, envs finished 1
2026-01-17 13:41:30,038 : agent.on_policy : DEBUG : Mean Losses: [4.133606683462858]
2026-01-17 13:41:30,045 : worker.worker : DEBUG : Step 192833, finished rewards 40.78, envs finished 1
2026-01-17 13:41:30,101 : worker.worker : DEBUG : Step 192842, finished rewards 31.20, envs finished 1
2026-01-17 13:41:30,132 : worker.worker : DEBUG : Step 192846, finished rewards 3.14, envs finished 1
2026-01-17 13:41:30,147 : worker.worker : DEBUG : Step 192849, finished rewards 22.00, envs finished 1
2026-01-17 13:41:30,158 : worker.worker : DEBUG : Step 192850, finished rewards 24.20, envs finished 1
2026-01-17 13:41:30,356 : agent.on_policy : DEBUG : Mean Losses: [5.7393984496593475]
2026-01-17 13:41:30,363 : worker.worker : DEBUG : Step 192865, finished rewards 39.72, envs finished 1
2026-01-17 13:41:30,447 : worker.worker : DEBUG : Step 192874, finished rewards -5.16, envs finished 1
2026-01-17 13:41:30,490 : worker.worker : DEBUG : Step 192882, finished rewards 41.96, envs finished 1
2026-01-17 13:41:30,742 : agent.on_policy : DEBUG : Mean Losses: [2.6910454891622066]
2026-01-17 13:41:30,838 : worker.worker : DEBUG : Step 192919, finished rewards 29.02, envs finished 1
2026-01-17 13:41:31,005 : agent.on_policy : DEBUG : Mean Losses: [4.797654110938311]
2026-01-17 13:41:31,012 : worker.worker : DEBUG : Step 192929, finished rewards 28.71, envs finished 1
2026-01-17 13:41:31,083 : worker.worker : DEBUG : Step 192936, finished rewards 27.53, envs finished 1
2026-01-17 13:41:31,341 : agent.on_policy : DEBUG : Mean Losses: [4.4936522245407104]
2026-01-17 13:41:31,349 : worker.worker : DEBUG : Step 192961, finished rewards 8.23, envs finished 1
2026-01-17 13:41:31,362 : worker.worker : DEBUG : Step 192962, finished rewards 12.74, envs finished 1
2026-01-17 13:41:31,396 : worker.worker : DEBUG : Step 192970, finished rewards 21.16, envs finished 1
2026-01-17 13:41:31,436 : worker.worker : DEBUG : Step 192980, finished rewards 7.91, envs finished 1
2026-01-17 13:41:31,533 : agent.on_policy : DEBUG : Mean Losses: [5.10688332747668]
2026-01-17 13:41:31,556 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:41:31,566 : worker.worker : DEBUG : Step 192999, finished rewards 42.64, envs finished 1
2026-01-17 13:41:31,701 : worker.worker : DEBUG : Step 193014, finished rewards 21.35, envs finished 1
2026-01-17 13:41:31,712 : worker.worker : DEBUG : Step 193015, finished rewards -9.10, envs finished 1
2026-01-17 13:41:31,911 : agent.on_policy : DEBUG : Mean Losses: [4.728249341249466]
2026-01-17 13:41:32,026 : worker.worker : DEBUG : Step 193049, finished rewards 36.44, envs finished 1
2026-01-17 13:41:32,058 : worker.worker : DEBUG : Step 193054, finished rewards 23.74, envs finished 1
2026-01-17 13:41:32,205 : agent.on_policy : DEBUG : Mean Losses: [4.455089315772057]
2026-01-17 13:41:32,211 : worker.worker : DEBUG : Step 193056, finished rewards 31.65, envs finished 2
2026-01-17 13:41:32,282 : worker.worker : DEBUG : Step 193061, finished rewards -3.79, envs finished 1
2026-01-17 13:41:32,654 : agent.on_policy : DEBUG : Mean Losses: [2.222432555630803]
2026-01-17 13:41:32,702 : worker.worker : DEBUG : Step 193093, finished rewards 24.52, envs finished 1
2026-01-17 13:41:32,773 : worker.worker : DEBUG : Step 193099, finished rewards 30.53, envs finished 1
2026-01-17 13:41:33,055 : agent.on_policy : DEBUG : Mean Losses: [4.842702142894268]
2026-01-17 13:41:33,059 : worker.worker : DEBUG : Step 193120, finished rewards 41.65, envs finished 1
2026-01-17 13:41:33,075 : worker.worker : DEBUG : Step 193122, finished rewards 14.47, envs finished 1
2026-01-17 13:41:33,117 : worker.worker : DEBUG : Step 193127, finished rewards 41.38, envs finished 1
2026-01-17 13:41:33,313 : agent.on_policy : DEBUG : Mean Losses: [3.8363966941833496]
2026-01-17 13:41:33,387 : worker.worker : DEBUG : Step 193161, finished rewards 17.89, envs finished 1
2026-01-17 13:41:33,404 : worker.worker : DEBUG : Step 193163, finished rewards 19.56, envs finished 1
2026-01-17 13:41:33,449 : worker.worker : DEBUG : Step 193169, finished rewards 41.13, envs finished 1
2026-01-17 13:41:33,561 : worker.worker : DEBUG : Step 193175, finished rewards 4.28, envs finished 1
2026-01-17 13:41:33,659 : agent.on_policy : DEBUG : Mean Losses: [5.245537176728249]
2026-01-17 13:41:33,848 : worker.worker : DEBUG : Step 193213, finished rewards 23.42, envs finished 1
2026-01-17 13:41:33,883 : worker.worker : DEBUG : Step 193215, finished rewards 6.20, envs finished 1
2026-01-17 13:41:34,053 : agent.on_policy : DEBUG : Mean Losses: [2.8297930266708136]
2026-01-17 13:41:34,097 : worker.worker : DEBUG : Step 193218, finished rewards 26.28, envs finished 1
2026-01-17 13:41:34,169 : worker.worker : DEBUG : Step 193227, finished rewards 45.91, envs finished 1
2026-01-17 13:41:34,309 : worker.worker : DEBUG : Step 193241, finished rewards 41.21, envs finished 1
2026-01-17 13:41:34,363 : worker.worker : DEBUG : Step 193246, finished rewards 21.98, envs finished 2
2026-01-17 13:41:34,486 : agent.on_policy : DEBUG : Mean Losses: [7.49655593931675]
2026-01-17 13:41:34,720 : agent.on_policy : DEBUG : Mean Losses: [2.4684527227655053]
2026-01-17 13:41:34,785 : worker.worker : DEBUG : Step 193297, finished rewards -4.25, envs finished 1
2026-01-17 13:41:34,941 : agent.on_policy : DEBUG : Mean Losses: [4.363096475601196]
2026-01-17 13:41:34,999 : worker.worker : DEBUG : Step 193327, finished rewards 19.77, envs finished 1
2026-01-17 13:41:35,042 : worker.worker : DEBUG : Step 193338, finished rewards 0.50, envs finished 1
2026-01-17 13:41:35,064 : worker.worker : DEBUG : Step 193343, finished rewards 20.44, envs finished 1
2026-01-17 13:41:35,209 : agent.on_policy : DEBUG : Mean Losses: [7.719201326370239]
2026-01-17 13:41:35,222 : worker.worker : DEBUG : Step 193346, finished rewards 14.59, envs finished 1
2026-01-17 13:41:35,375 : worker.worker : DEBUG : Step 193367, finished rewards -17.06, envs finished 1
2026-01-17 13:41:35,492 : agent.on_policy : DEBUG : Mean Losses: [2.494593221694231]
2026-01-17 13:41:35,543 : worker.worker : DEBUG : Step 193383, finished rewards -7.50, envs finished 1
2026-01-17 13:41:35,606 : worker.worker : DEBUG : Step 193388, finished rewards 25.52, envs finished 1
2026-01-17 13:41:35,829 : agent.on_policy : DEBUG : Mean Losses: [2.563716646283865]
2026-01-17 13:41:35,888 : worker.worker : DEBUG : Step 193414, finished rewards 40.89, envs finished 1
2026-01-17 13:41:35,967 : worker.worker : DEBUG : Step 193420, finished rewards 24.06, envs finished 1
2026-01-17 13:41:36,040 : worker.worker : DEBUG : Step 193431, finished rewards 24.27, envs finished 1
2026-01-17 13:41:36,058 : worker.worker : DEBUG : Step 193432, finished rewards 28.03, envs finished 1
2026-01-17 13:41:36,378 : agent.on_policy : DEBUG : Mean Losses: [5.862584613263607]
2026-01-17 13:41:36,400 : worker.worker : DEBUG : Step 193444, finished rewards 38.50, envs finished 1
2026-01-17 13:41:36,626 : agent.on_policy : DEBUG : Mean Losses: [2.742237917147577]
2026-01-17 13:41:36,634 : worker.worker : DEBUG : Step 193473, finished rewards 132.12, envs finished 1
2026-01-17 13:41:36,661 : worker.worker : DEBUG : Step 193478, finished rewards 46.01, envs finished 1
2026-01-17 13:41:36,756 : worker.worker : DEBUG : Step 193502, finished rewards 9.77, envs finished 1
2026-01-17 13:41:36,849 : agent.on_policy : DEBUG : Mean Losses: [4.784701623022556]
2026-01-17 13:41:36,893 : worker.worker : DEBUG : Step 193507, finished rewards 7.13, envs finished 1
2026-01-17 13:41:36,931 : worker.worker : DEBUG : Step 193514, finished rewards 22.49, envs finished 1
2026-01-17 13:41:36,967 : worker.worker : DEBUG : Step 193518, finished rewards 28.59, envs finished 2
2026-01-17 13:41:37,334 : agent.on_policy : DEBUG : Mean Losses: [3.953423600643873]
2026-01-17 13:41:37,389 : worker.worker : DEBUG : Step 193543, finished rewards 18.94, envs finished 1
2026-01-17 13:41:37,647 : agent.on_policy : DEBUG : Mean Losses: [1.5973674412816763]
2026-01-17 13:41:37,687 : worker.worker : DEBUG : Step 193576, finished rewards 15.97, envs finished 1
2026-01-17 13:41:37,702 : worker.worker : DEBUG : Step 193578, finished rewards 20.55, envs finished 1
2026-01-17 13:41:37,765 : worker.worker : DEBUG : Step 193590, finished rewards 41.25, envs finished 1
2026-01-17 13:41:37,797 : worker.worker : DEBUG : Step 193596, finished rewards 37.08, envs finished 1
2026-01-17 13:41:37,955 : agent.on_policy : DEBUG : Mean Losses: [6.2831162214279175]
2026-01-17 13:41:38,122 : worker.worker : DEBUG : Step 193622, finished rewards 13.04, envs finished 1
2026-01-17 13:41:38,228 : worker.worker : DEBUG : Step 193628, finished rewards -3.05, envs finished 1
2026-01-17 13:41:38,255 : worker.worker : DEBUG : Step 193630, finished rewards 1.25, envs finished 1
2026-01-17 13:41:38,379 : agent.on_policy : DEBUG : Mean Losses: [4.070873601362109]
2026-01-17 13:41:38,512 : worker.worker : DEBUG : Step 193651, finished rewards 13.10, envs finished 1
2026-01-17 13:41:38,797 : agent.on_policy : DEBUG : Mean Losses: [1.5720751341432333]
2026-01-17 13:41:38,898 : worker.worker : DEBUG : Step 193685, finished rewards 11.57, envs finished 1
2026-01-17 13:41:38,919 : worker.worker : DEBUG : Step 193688, finished rewards 11.90, envs finished 1
2026-01-17 13:41:39,099 : agent.on_policy : DEBUG : Mean Losses: [2.776124805212021]
2026-01-17 13:41:39,239 : worker.worker : DEBUG : Step 193709, finished rewards 5.30, envs finished 1
2026-01-17 13:41:39,298 : worker.worker : DEBUG : Step 193720, finished rewards 3.65, envs finished 1
2026-01-17 13:41:39,478 : agent.on_policy : DEBUG : Mean Losses: [5.270934246480465]
2026-01-17 13:41:39,611 : worker.worker : DEBUG : Step 193744, finished rewards 7.44, envs finished 1
2026-01-17 13:41:39,837 : agent.on_policy : DEBUG : Mean Losses: [4.123891958035529]
2026-01-17 13:41:39,982 : worker.worker : DEBUG : Step 193778, finished rewards -20.61, envs finished 1
2026-01-17 13:41:40,048 : worker.worker : DEBUG : Step 193784, finished rewards 12.99, envs finished 1
2026-01-17 13:41:40,089 : worker.worker : DEBUG : Step 193787, finished rewards -24.16, envs finished 1
2026-01-17 13:41:40,228 : agent.on_policy : DEBUG : Mean Losses: [5.770140308886766]
2026-01-17 13:41:40,288 : worker.worker : DEBUG : Step 193797, finished rewards 11.45, envs finished 1
2026-01-17 13:41:40,304 : worker.worker : DEBUG : Step 193799, finished rewards 35.83, envs finished 1
2026-01-17 13:41:40,313 : worker.worker : DEBUG : Step 193800, finished rewards 24.97, envs finished 1
2026-01-17 13:41:40,515 : agent.on_policy : DEBUG : Mean Losses: [3.4793846160173416]
2026-01-17 13:41:40,816 : agent.on_policy : DEBUG : Mean Losses: [2.1923707723617554]
2026-01-17 13:41:40,906 : worker.worker : DEBUG : Step 193875, finished rewards 20.68, envs finished 1
2026-01-17 13:41:40,937 : worker.worker : DEBUG : Step 193878, finished rewards 24.56, envs finished 1
2026-01-17 13:41:40,974 : worker.worker : DEBUG : Step 193881, finished rewards -2.57, envs finished 1
2026-01-17 13:41:40,996 : worker.worker : DEBUG : Step 193882, finished rewards 32.73, envs finished 1
2026-01-17 13:41:41,066 : worker.worker : DEBUG : Step 193887, finished rewards 26.99, envs finished 1
2026-01-17 13:41:41,281 : agent.on_policy : DEBUG : Mean Losses: [7.894075393676758]
2026-01-17 13:41:41,289 : worker.worker : DEBUG : Step 193888, finished rewards 14.28, envs finished 1
2026-01-17 13:41:41,432 : worker.worker : DEBUG : Step 193899, finished rewards 16.96, envs finished 1
2026-01-17 13:41:41,473 : worker.worker : DEBUG : Step 193903, finished rewards 29.52, envs finished 1
2026-01-17 13:41:41,693 : agent.on_policy : DEBUG : Mean Losses: [2.5343805737793446]
2026-01-17 13:41:41,948 : agent.on_policy : DEBUG : Mean Losses: [1.6819059178233147]
2026-01-17 13:41:41,962 : worker.worker : DEBUG : Step 193952, finished rewards 40.50, envs finished 1
2026-01-17 13:41:42,346 : agent.on_policy : DEBUG : Mean Losses: [4.488036777824163]
2026-01-17 13:41:42,357 : worker.worker : DEBUG : Step 193986, finished rewards 15.89, envs finished 1
2026-01-17 13:41:42,364 : worker.worker : DEBUG : Step 193987, finished rewards 19.07, envs finished 1
2026-01-17 13:41:42,428 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:41:42,469 : worker.worker : DEBUG : Step 194005, finished rewards 6.51, envs finished 1
2026-01-17 13:41:42,499 : worker.worker : DEBUG : Step 194009, finished rewards 15.14, envs finished 1
2026-01-17 13:41:42,713 : agent.on_policy : DEBUG : Mean Losses: [5.977425962686539]
2026-01-17 13:41:42,991 : agent.on_policy : DEBUG : Mean Losses: [2.9599442686885595]
2026-01-17 13:41:43,087 : worker.worker : DEBUG : Step 194061, finished rewards 12.81, envs finished 1
2026-01-17 13:41:43,137 : worker.worker : DEBUG : Step 194067, finished rewards -49.55, envs finished 1
2026-01-17 13:41:43,261 : worker.worker : DEBUG : Step 194075, finished rewards 26.41, envs finished 1
2026-01-17 13:41:43,358 : agent.on_policy : DEBUG : Mean Losses: [6.632509768009186]
2026-01-17 13:41:43,366 : worker.worker : DEBUG : Step 194080, finished rewards 36.23, envs finished 1
2026-01-17 13:41:43,406 : worker.worker : DEBUG : Step 194082, finished rewards -66.14, envs finished 1
2026-01-17 13:41:43,548 : worker.worker : DEBUG : Step 194097, finished rewards 9.65, envs finished 1
2026-01-17 13:41:43,801 : agent.on_policy : DEBUG : Mean Losses: [3.6244954261928797]
2026-01-17 13:41:43,873 : worker.worker : DEBUG : Step 194118, finished rewards -68.03, envs finished 1
2026-01-17 13:41:43,941 : worker.worker : DEBUG : Step 194124, finished rewards 7.35, envs finished 1
2026-01-17 13:41:44,198 : agent.on_policy : DEBUG : Mean Losses: [3.8169696033000946]
2026-01-17 13:41:44,210 : worker.worker : DEBUG : Step 194145, finished rewards 31.84, envs finished 1
2026-01-17 13:41:44,289 : worker.worker : DEBUG : Step 194161, finished rewards 45.72, envs finished 1
2026-01-17 13:41:44,496 : agent.on_policy : DEBUG : Mean Losses: [6.046377941966057]
2026-01-17 13:41:44,533 : worker.worker : DEBUG : Step 194180, finished rewards 18.18, envs finished 1
2026-01-17 13:41:44,627 : worker.worker : DEBUG : Step 194189, finished rewards 40.47, envs finished 1
2026-01-17 13:41:44,756 : worker.worker : DEBUG : Step 194202, finished rewards 3.69, envs finished 1
2026-01-17 13:41:44,935 : agent.on_policy : DEBUG : Mean Losses: [4.840078882873058]
2026-01-17 13:41:45,030 : worker.worker : DEBUG : Step 194215, finished rewards 41.36, envs finished 1
2026-01-17 13:41:45,090 : worker.worker : DEBUG : Step 194223, finished rewards 19.47, envs finished 1
2026-01-17 13:41:45,112 : worker.worker : DEBUG : Step 194225, finished rewards -18.75, envs finished 1
2026-01-17 13:41:45,420 : agent.on_policy : DEBUG : Mean Losses: [4.38365837559104]
2026-01-17 13:41:44,727 : worker.worker : DEBUG : Step 194254, finished rewards 45.05, envs finished 1
2026-01-17 13:41:44,877 : worker.worker : DEBUG : Step 194269, finished rewards 14.96, envs finished 1
2026-01-17 13:41:45,066 : agent.on_policy : DEBUG : Mean Losses: [3.750342696905136]
2026-01-17 13:41:45,150 : worker.worker : DEBUG : Step 194283, finished rewards 15.96, envs finished 1
2026-01-17 13:41:45,322 : worker.worker : DEBUG : Step 194298, finished rewards 40.65, envs finished 1
2026-01-17 13:41:45,515 : agent.on_policy : DEBUG : Mean Losses: [4.283217526972294]
2026-01-17 13:41:45,677 : worker.worker : DEBUG : Step 194318, finished rewards 34.06, envs finished 2
2026-01-17 13:41:45,720 : worker.worker : DEBUG : Step 194322, finished rewards 15.19, envs finished 1
2026-01-17 13:41:45,837 : worker.worker : DEBUG : Step 194327, finished rewards 3.08, envs finished 1
2026-01-17 13:41:46,087 : agent.on_policy : DEBUG : Mean Losses: [6.9201512932777405]
2026-01-17 13:41:46,295 : worker.worker : DEBUG : Step 194363, finished rewards 25.72, envs finished 1
2026-01-17 13:41:46,384 : agent.on_policy : DEBUG : Mean Losses: [2.265309888869524]
2026-01-17 13:41:46,533 : worker.worker : DEBUG : Step 194385, finished rewards 22.03, envs finished 1
2026-01-17 13:41:46,779 : agent.on_policy : DEBUG : Mean Losses: [3.447343647480011]
2026-01-17 13:41:46,801 : worker.worker : DEBUG : Step 194403, finished rewards 14.29, envs finished 1
2026-01-17 13:41:46,944 : worker.worker : DEBUG : Step 194418, finished rewards 21.61, envs finished 1
2026-01-17 13:41:47,073 : worker.worker : DEBUG : Step 194428, finished rewards 10.18, envs finished 1
2026-01-17 13:41:47,244 : agent.on_policy : DEBUG : Mean Losses: [4.599807880818844]
2026-01-17 13:41:47,311 : worker.worker : DEBUG : Step 194446, finished rewards 10.73, envs finished 1
2026-01-17 13:41:47,318 : worker.worker : DEBUG : Step 194447, finished rewards 3.17, envs finished 1
2026-01-17 13:41:47,356 : worker.worker : DEBUG : Step 194449, finished rewards 46.14, envs finished 1
2026-01-17 13:41:47,665 : agent.on_policy : DEBUG : Mean Losses: [5.411919839680195]
2026-01-17 13:41:47,691 : worker.worker : DEBUG : Step 194468, finished rewards 14.43, envs finished 1
2026-01-17 13:41:47,771 : worker.worker : DEBUG : Step 194474, finished rewards 42.22, envs finished 1
2026-01-17 13:41:48,067 : agent.on_policy : DEBUG : Mean Losses: [3.1308439671993256]
2026-01-17 13:41:48,193 : worker.worker : DEBUG : Step 194519, finished rewards 41.06, envs finished 1
2026-01-17 13:41:48,530 : agent.on_policy : DEBUG : Mean Losses: [5.042777523398399]
2026-01-17 13:41:48,581 : worker.worker : DEBUG : Step 194535, finished rewards 6.75, envs finished 1
2026-01-17 13:41:48,650 : worker.worker : DEBUG : Step 194546, finished rewards 13.60, envs finished 1
2026-01-17 13:41:48,690 : worker.worker : DEBUG : Step 194550, finished rewards 16.21, envs finished 1
2026-01-17 13:41:49,011 : agent.on_policy : DEBUG : Mean Losses: [5.856477588415146]
2026-01-17 13:41:49,066 : worker.worker : DEBUG : Step 194568, finished rewards -22.06, envs finished 1
2026-01-17 13:41:49,126 : worker.worker : DEBUG : Step 194577, finished rewards 17.72, envs finished 1
2026-01-17 13:41:49,206 : worker.worker : DEBUG : Step 194582, finished rewards 9.32, envs finished 1
2026-01-17 13:41:49,243 : worker.worker : DEBUG : Step 194583, finished rewards 45.76, envs finished 1
2026-01-17 13:41:49,518 : agent.on_policy : DEBUG : Mean Losses: [6.39339753985405]
2026-01-17 13:41:49,663 : worker.worker : DEBUG : Step 194604, finished rewards -15.03, envs finished 1
2026-01-17 13:41:50,121 : agent.on_policy : DEBUG : Mean Losses: [2.3218283001333475]
2026-01-17 13:41:50,486 : agent.on_policy : DEBUG : Mean Losses: [3.7317568510770798]
2026-01-17 13:41:50,490 : worker.worker : DEBUG : Step 194656, finished rewards 27.15, envs finished 1
2026-01-17 13:41:50,581 : worker.worker : DEBUG : Step 194674, finished rewards 25.59, envs finished 1
2026-01-17 13:41:50,602 : worker.worker : DEBUG : Step 194676, finished rewards 41.45, envs finished 1
2026-01-17 13:41:50,736 : worker.worker : DEBUG : Step 194686, finished rewards -4.51, envs finished 1
2026-01-17 13:41:50,816 : agent.on_policy : DEBUG : Mean Losses: [7.246487379074097]
2026-01-17 13:41:50,846 : worker.worker : DEBUG : Step 194690, finished rewards 7.74, envs finished 1
2026-01-17 13:41:50,951 : worker.worker : DEBUG : Step 194694, finished rewards -0.32, envs finished 2
2026-01-17 13:41:51,213 : agent.on_policy : DEBUG : Mean Losses: [2.6588193345814943]
2026-01-17 13:41:51,217 : worker.worker : DEBUG : Step 194720, finished rewards 46.08, envs finished 1
2026-01-17 13:41:51,332 : worker.worker : DEBUG : Step 194749, finished rewards 37.48, envs finished 1
2026-01-17 13:41:51,525 : agent.on_policy : DEBUG : Mean Losses: [3.974378891289234]
2026-01-17 13:41:51,552 : worker.worker : DEBUG : Step 194757, finished rewards 41.47, envs finished 1
2026-01-17 13:41:51,689 : worker.worker : DEBUG : Step 194768, finished rewards 39.38, envs finished 1
2026-01-17 13:41:51,709 : worker.worker : DEBUG : Step 194769, finished rewards 24.26, envs finished 1
2026-01-17 13:41:51,738 : worker.worker : DEBUG : Step 194770, finished rewards 33.83, envs finished 1
2026-01-17 13:41:51,993 : agent.on_policy : DEBUG : Mean Losses: [8.470595955848694]
2026-01-17 13:41:52,038 : worker.worker : DEBUG : Step 194792, finished rewards 40.82, envs finished 1
2026-01-17 13:41:52,097 : worker.worker : DEBUG : Step 194804, finished rewards -0.88, envs finished 1
2026-01-17 13:41:52,288 : agent.on_policy : DEBUG : Mean Losses: [3.796853276900947]
2026-01-17 13:41:52,388 : worker.worker : DEBUG : Step 194835, finished rewards 34.54, envs finished 1
2026-01-17 13:41:52,404 : worker.worker : DEBUG : Step 194837, finished rewards 28.29, envs finished 1
2026-01-17 13:41:52,691 : agent.on_policy : DEBUG : Mean Losses: [4.582321800291538]
2026-01-17 13:41:52,701 : worker.worker : DEBUG : Step 194849, finished rewards 33.20, envs finished 1
2026-01-17 13:41:52,734 : worker.worker : DEBUG : Step 194853, finished rewards 30.45, envs finished 1
2026-01-17 13:41:52,870 : worker.worker : DEBUG : Step 194876, finished rewards 32.06, envs finished 1
2026-01-17 13:41:53,027 : agent.on_policy : DEBUG : Mean Losses: [3.7809876073151827]
2026-01-17 13:41:53,040 : worker.worker : DEBUG : Step 194882, finished rewards 8.36, envs finished 1
2026-01-17 13:41:53,237 : worker.worker : DEBUG : Step 194901, finished rewards 46.15, envs finished 1
2026-01-17 13:41:53,488 : agent.on_policy : DEBUG : Mean Losses: [5.463775089010596]
2026-01-17 13:41:53,515 : worker.worker : DEBUG : Step 194916, finished rewards 53.74, envs finished 1
2026-01-17 13:41:53,531 : worker.worker : DEBUG : Step 194917, finished rewards 9.39, envs finished 1
2026-01-17 13:41:53,570 : worker.worker : DEBUG : Step 194922, finished rewards 28.10, envs finished 1
2026-01-17 13:41:53,599 : worker.worker : DEBUG : Step 194925, finished rewards 36.53, envs finished 1
2026-01-17 13:41:53,903 : agent.on_policy : DEBUG : Mean Losses: [4.483435854315758]
2026-01-17 13:41:54,005 : worker.worker : DEBUG : Step 194953, finished rewards 35.22, envs finished 1
2026-01-17 13:41:54,046 : worker.worker : DEBUG : Step 194959, finished rewards 16.73, envs finished 1
2026-01-17 13:41:54,217 : worker.worker : DEBUG : Step 194974, finished rewards 25.34, envs finished 1
2026-01-17 13:41:54,391 : agent.on_policy : DEBUG : Mean Losses: [3.3266298174858093]
2026-01-17 13:41:54,566 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:41:54,578 : worker.worker : INFO : Step 195000, Avg Reward 19.4003, Max Reward 132.1229, Loss [4.41332745]
2026-01-17 13:41:54,808 : agent.on_policy : DEBUG : Mean Losses: [3.2362819649279118]
2026-01-17 13:41:54,821 : worker.worker : DEBUG : Step 195011, finished rewards 12.73, envs finished 1
2026-01-17 13:41:54,920 : worker.worker : DEBUG : Step 195019, finished rewards 24.43, envs finished 1
2026-01-17 13:41:54,947 : worker.worker : DEBUG : Step 195024, finished rewards 11.83, envs finished 1
2026-01-17 13:41:55,185 : agent.on_policy : DEBUG : Mean Losses: [6.606580697000027]
2026-01-17 13:41:55,186 : worker.worker : DEBUG : Step 195040, finished rewards 28.23, envs finished 1
2026-01-17 13:41:55,191 : worker.worker : DEBUG : Step 195041, finished rewards 2.83, envs finished 1
2026-01-17 13:41:55,213 : worker.worker : DEBUG : Step 195044, finished rewards 41.09, envs finished 1
2026-01-17 13:41:55,293 : worker.worker : DEBUG : Step 195059, finished rewards 18.64, envs finished 1
2026-01-17 13:41:55,533 : agent.on_policy : DEBUG : Mean Losses: [3.8107784865424037]
2026-01-17 13:41:55,789 : agent.on_policy : DEBUG : Mean Losses: [3.4369047805666924]
2026-01-17 13:41:55,790 : worker.worker : DEBUG : Step 195104, finished rewards 24.66, envs finished 1
2026-01-17 13:41:55,822 : worker.worker : DEBUG : Step 195112, finished rewards 41.83, envs finished 1
2026-01-17 13:41:55,883 : worker.worker : DEBUG : Step 195129, finished rewards 27.16, envs finished 1
2026-01-17 13:41:56,111 : agent.on_policy : DEBUG : Mean Losses: [5.202228680253029]
2026-01-17 13:41:56,144 : worker.worker : DEBUG : Step 195142, finished rewards 4.74, envs finished 1
2026-01-17 13:41:56,171 : worker.worker : DEBUG : Step 195148, finished rewards 12.65, envs finished 1
2026-01-17 13:41:56,259 : worker.worker : DEBUG : Step 195165, finished rewards 13.92, envs finished 1
2026-01-17 13:41:56,401 : agent.on_policy : DEBUG : Mean Losses: [5.30318009853363]
2026-01-17 13:41:56,435 : worker.worker : DEBUG : Step 195176, finished rewards 42.95, envs finished 2
2026-01-17 13:41:56,467 : worker.worker : DEBUG : Step 195180, finished rewards -53.88, envs finished 1
2026-01-17 13:41:56,788 : agent.on_policy : DEBUG : Mean Losses: [6.136303126811981]
2026-01-17 13:41:56,795 : worker.worker : DEBUG : Step 195202, finished rewards 38.59, envs finished 1
2026-01-17 13:41:56,911 : worker.worker : DEBUG : Step 195213, finished rewards 41.98, envs finished 1
2026-01-17 13:41:56,970 : worker.worker : DEBUG : Step 195221, finished rewards -18.29, envs finished 1
2026-01-17 13:41:57,020 : worker.worker : DEBUG : Step 195226, finished rewards 36.35, envs finished 1
2026-01-17 13:41:57,142 : agent.on_policy : DEBUG : Mean Losses: [5.838741332292557]
2026-01-17 13:41:57,310 : worker.worker : DEBUG : Step 195252, finished rewards 39.96, envs finished 1
2026-01-17 13:41:57,339 : worker.worker : DEBUG : Step 195258, finished rewards 24.08, envs finished 1
2026-01-17 13:41:57,349 : worker.worker : DEBUG : Step 195260, finished rewards 29.95, envs finished 1
2026-01-17 13:41:57,414 : agent.on_policy : DEBUG : Mean Losses: [6.610313236713409]
2026-01-17 13:41:57,450 : worker.worker : DEBUG : Step 195272, finished rewards 31.90, envs finished 1
2026-01-17 13:41:57,457 : worker.worker : DEBUG : Step 195274, finished rewards 39.80, envs finished 1
2026-01-17 13:41:57,673 : agent.on_policy : DEBUG : Mean Losses: [3.41079268604517]
2026-01-17 13:41:57,732 : worker.worker : DEBUG : Step 195313, finished rewards 24.57, envs finished 1
2026-01-17 13:41:57,914 : agent.on_policy : DEBUG : Mean Losses: [4.457231760025024]
2026-01-17 13:41:57,935 : worker.worker : DEBUG : Step 195333, finished rewards 4.19, envs finished 1
2026-01-17 13:41:57,965 : worker.worker : DEBUG : Step 195340, finished rewards 7.05, envs finished 1
2026-01-17 13:41:58,004 : worker.worker : DEBUG : Step 195348, finished rewards 27.76, envs finished 1
2026-01-17 13:41:58,029 : worker.worker : DEBUG : Step 195353, finished rewards 20.18, envs finished 2
2026-01-17 13:41:58,046 : worker.worker : DEBUG : Step 195357, finished rewards 31.76, envs finished 1
2026-01-17 13:41:58,111 : agent.on_policy : DEBUG : Mean Losses: [7.829797588288784]
2026-01-17 13:41:58,380 : agent.on_policy : DEBUG : Mean Losses: [1.03984528593719]
2026-01-17 13:41:58,444 : worker.worker : DEBUG : Step 195407, finished rewards 23.12, envs finished 1
2026-01-17 13:41:58,465 : worker.worker : DEBUG : Step 195412, finished rewards 40.10, envs finished 1
2026-01-17 13:41:58,629 : agent.on_policy : DEBUG : Mean Losses: [5.650272235274315]
2026-01-17 13:41:58,702 : worker.worker : DEBUG : Step 195431, finished rewards -20.25, envs finished 1
2026-01-17 13:41:58,752 : worker.worker : DEBUG : Step 195439, finished rewards 27.83, envs finished 1
2026-01-17 13:41:58,827 : worker.worker : DEBUG : Step 195446, finished rewards 24.56, envs finished 1
2026-01-17 13:41:58,854 : worker.worker : DEBUG : Step 195448, finished rewards 7.10, envs finished 1
2026-01-17 13:41:58,963 : agent.on_policy : DEBUG : Mean Losses: [6.279860742390156]
2026-01-17 13:41:58,972 : worker.worker : DEBUG : Step 195458, finished rewards 18.48, envs finished 1
2026-01-17 13:41:59,073 : worker.worker : DEBUG : Step 195468, finished rewards 9.76, envs finished 1
2026-01-17 13:41:59,297 : agent.on_policy : DEBUG : Mean Losses: [2.593640113249421]
2026-01-17 13:41:59,414 : worker.worker : DEBUG : Step 195500, finished rewards 28.91, envs finished 1
2026-01-17 13:41:59,634 : agent.on_policy : DEBUG : Mean Losses: [3.835184723138809]
2026-01-17 13:41:59,741 : worker.worker : DEBUG : Step 195532, finished rewards -1.12, envs finished 1
2026-01-17 13:41:59,781 : worker.worker : DEBUG : Step 195540, finished rewards 41.30, envs finished 1
2026-01-17 13:41:59,802 : worker.worker : DEBUG : Step 195544, finished rewards 16.77, envs finished 1
2026-01-17 13:41:59,944 : worker.worker : DEBUG : Step 195551, finished rewards 23.16, envs finished 1
2026-01-17 13:42:00,130 : agent.on_policy : DEBUG : Mean Losses: [7.544866248965263]
2026-01-17 13:42:00,310 : worker.worker : DEBUG : Step 195567, finished rewards 1.78, envs finished 1
2026-01-17 13:42:00,470 : worker.worker : DEBUG : Step 195580, finished rewards -13.12, envs finished 1
2026-01-17 13:42:00,697 : agent.on_policy : DEBUG : Mean Losses: [3.172754807397723]
2026-01-17 13:42:00,867 : worker.worker : DEBUG : Step 195603, finished rewards 18.03, envs finished 1
2026-01-17 13:42:01,071 : agent.on_policy : DEBUG : Mean Losses: [3.2560389935970306]
2026-01-17 13:42:01,139 : worker.worker : DEBUG : Step 195635, finished rewards 52.45, envs finished 1
2026-01-17 13:42:01,153 : worker.worker : DEBUG : Step 195637, finished rewards 42.43, envs finished 1
2026-01-17 13:42:01,185 : worker.worker : DEBUG : Step 195644, finished rewards 20.01, envs finished 2
2026-01-17 13:42:01,346 : agent.on_policy : DEBUG : Mean Losses: [6.740469484589994]
2026-01-17 13:42:01,423 : worker.worker : DEBUG : Step 195662, finished rewards -9.79, envs finished 1
2026-01-17 13:42:01,527 : worker.worker : DEBUG : Step 195676, finished rewards -6.13, envs finished 1
2026-01-17 13:42:01,678 : agent.on_policy : DEBUG : Mean Losses: [3.8789702765643597]
2026-01-17 13:42:01,705 : worker.worker : DEBUG : Step 195686, finished rewards 14.56, envs finished 1
2026-01-17 13:42:01,895 : worker.worker : DEBUG : Step 195707, finished rewards 46.10, envs finished 1
2026-01-17 13:42:01,930 : worker.worker : DEBUG : Step 195708, finished rewards 16.47, envs finished 1
2026-01-17 13:42:02,030 : agent.on_policy : DEBUG : Mean Losses: [7.041410364210606]
2026-01-17 13:42:02,065 : worker.worker : DEBUG : Step 195720, finished rewards 29.13, envs finished 1
2026-01-17 13:42:02,233 : worker.worker : DEBUG : Step 195740, finished rewards 36.63, envs finished 1
2026-01-17 13:42:02,378 : agent.on_policy : DEBUG : Mean Losses: [5.160785689949989]
2026-01-17 13:42:02,430 : worker.worker : DEBUG : Step 195757, finished rewards 41.92, envs finished 1
2026-01-17 13:42:02,434 : worker.worker : DEBUG : Step 195758, finished rewards 7.43, envs finished 1
2026-01-17 13:42:02,618 : agent.on_policy : DEBUG : Mean Losses: [3.792504955083132]
2026-01-17 13:42:02,670 : worker.worker : DEBUG : Step 195789, finished rewards -5.28, envs finished 1
2026-01-17 13:42:02,911 : agent.on_policy : DEBUG : Mean Losses: [3.4209026992321014]
2026-01-17 13:42:02,913 : worker.worker : DEBUG : Step 195808, finished rewards -4.81, envs finished 1
2026-01-17 13:42:02,952 : worker.worker : DEBUG : Step 195812, finished rewards 39.96, envs finished 1
2026-01-17 13:42:03,010 : worker.worker : DEBUG : Step 195821, finished rewards 10.47, envs finished 1
2026-01-17 13:42:03,017 : worker.worker : DEBUG : Step 195822, finished rewards 17.18, envs finished 1
2026-01-17 13:42:03,246 : agent.on_policy : DEBUG : Mean Losses: [4.490347331389785]
2026-01-17 13:42:03,249 : worker.worker : DEBUG : Step 195840, finished rewards 2.60, envs finished 1
2026-01-17 13:42:03,356 : worker.worker : DEBUG : Step 195863, finished rewards 15.47, envs finished 1
2026-01-17 13:42:03,375 : worker.worker : DEBUG : Step 195866, finished rewards 14.89, envs finished 1
2026-01-17 13:42:03,684 : agent.on_policy : DEBUG : Mean Losses: [3.7417506743222475]
2026-01-17 13:42:03,765 : worker.worker : DEBUG : Step 195884, finished rewards 23.21, envs finished 1
2026-01-17 13:42:04,115 : agent.on_policy : DEBUG : Mean Losses: [3.687490237876773]
2026-01-17 13:42:04,126 : worker.worker : DEBUG : Step 195906, finished rewards 25.12, envs finished 1
2026-01-17 13:42:04,175 : worker.worker : DEBUG : Step 195915, finished rewards 23.30, envs finished 1
2026-01-17 13:42:04,182 : worker.worker : DEBUG : Step 195916, finished rewards 22.38, envs finished 1
2026-01-17 13:42:04,232 : worker.worker : DEBUG : Step 195926, finished rewards 6.67, envs finished 1
2026-01-17 13:42:04,322 : agent.on_policy : DEBUG : Mean Losses: [4.47121199965477]
2026-01-17 13:42:04,406 : worker.worker : DEBUG : Step 195943, finished rewards 17.80, envs finished 1
2026-01-17 13:42:04,432 : worker.worker : DEBUG : Step 195947, finished rewards 33.09, envs finished 1
2026-01-17 13:42:04,649 : agent.on_policy : DEBUG : Mean Losses: [3.324518334120512]
2026-01-17 13:42:04,685 : worker.worker : DEBUG : Step 195978, finished rewards 39.96, envs finished 1
2026-01-17 13:42:04,693 : worker.worker : DEBUG : Step 195980, finished rewards 23.18, envs finished 1
2026-01-17 13:42:04,754 : worker.worker : DEBUG : Step 195996, finished rewards 14.96, envs finished 1
2026-01-17 13:42:04,760 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:42:04,828 : agent.on_policy : DEBUG : Mean Losses: [4.74145832657814]
2026-01-17 13:42:04,902 : worker.worker : DEBUG : Step 196005, finished rewards 36.17, envs finished 1
2026-01-17 13:42:04,948 : worker.worker : DEBUG : Step 196010, finished rewards 22.58, envs finished 1
2026-01-17 13:42:04,998 : worker.worker : DEBUG : Step 196019, finished rewards 38.04, envs finished 1
2026-01-17 13:42:05,170 : agent.on_policy : DEBUG : Mean Losses: [3.978964641690254]
2026-01-17 13:42:05,246 : worker.worker : DEBUG : Step 196041, finished rewards 24.23, envs finished 1
2026-01-17 13:42:05,289 : worker.worker : DEBUG : Step 196045, finished rewards -0.21, envs finished 1
2026-01-17 13:42:05,507 : agent.on_policy : DEBUG : Mean Losses: [3.9649808295071125]
2026-01-17 13:42:05,618 : worker.worker : DEBUG : Step 196078, finished rewards 19.39, envs finished 1
2026-01-17 13:42:05,636 : worker.worker : DEBUG : Step 196082, finished rewards 18.98, envs finished 1
2026-01-17 13:42:05,647 : worker.worker : DEBUG : Step 196084, finished rewards 29.51, envs finished 1
2026-01-17 13:42:05,949 : agent.on_policy : DEBUG : Mean Losses: [4.326534463092685]
2026-01-17 13:42:05,999 : worker.worker : DEBUG : Step 196104, finished rewards 23.95, envs finished 1
2026-01-17 13:42:06,047 : worker.worker : DEBUG : Step 196114, finished rewards 11.19, envs finished 1
2026-01-17 13:42:06,056 : worker.worker : DEBUG : Step 196116, finished rewards 20.93, envs finished 1
2026-01-17 13:42:06,227 : agent.on_policy : DEBUG : Mean Losses: [3.1494521871209145]
2026-01-17 13:42:06,337 : worker.worker : DEBUG : Step 196141, finished rewards 19.76, envs finished 1
2026-01-17 13:42:06,373 : worker.worker : DEBUG : Step 196147, finished rewards 16.81, envs finished 1
2026-01-17 13:42:06,599 : agent.on_policy : DEBUG : Mean Losses: [2.656912323087454]
2026-01-17 13:42:06,667 : worker.worker : DEBUG : Step 196179, finished rewards 19.69, envs finished 1
2026-01-17 13:42:06,689 : worker.worker : DEBUG : Step 196185, finished rewards 41.49, envs finished 1
2026-01-17 13:42:06,864 : agent.on_policy : DEBUG : Mean Losses: [5.325110269710422]
2026-01-17 13:42:06,897 : worker.worker : DEBUG : Step 196200, finished rewards 31.67, envs finished 1
2026-01-17 13:42:06,909 : worker.worker : DEBUG : Step 196203, finished rewards 2.96, envs finished 1
2026-01-17 13:42:07,005 : worker.worker : DEBUG : Step 196211, finished rewards 2.56, envs finished 1
2026-01-17 13:42:07,205 : agent.on_policy : DEBUG : Mean Losses: [4.764918744564056]
2026-01-17 13:42:07,338 : worker.worker : DEBUG : Step 196244, finished rewards 16.94, envs finished 1
2026-01-17 13:42:07,367 : worker.worker : DEBUG : Step 196248, finished rewards 20.19, envs finished 1
2026-01-17 13:42:07,716 : agent.on_policy : DEBUG : Mean Losses: [3.882930900901556]
2026-01-17 13:42:07,793 : worker.worker : DEBUG : Step 196270, finished rewards 29.91, envs finished 1
2026-01-17 13:42:07,799 : worker.worker : DEBUG : Step 196271, finished rewards 25.43, envs finished 1
2026-01-17 13:42:08,012 : agent.on_policy : DEBUG : Mean Losses: [3.9438188523054123]
2026-01-17 13:42:08,019 : worker.worker : DEBUG : Step 196289, finished rewards -46.83, envs finished 1
2026-01-17 13:42:08,086 : worker.worker : DEBUG : Step 196296, finished rewards 24.16, envs finished 1
2026-01-17 13:42:08,363 : agent.on_policy : DEBUG : Mean Losses: [4.40672592818737]
2026-01-17 13:42:08,379 : worker.worker : DEBUG : Step 196324, finished rewards 13.96, envs finished 1
2026-01-17 13:42:08,648 : agent.on_policy : DEBUG : Mean Losses: [5.560592360794544]
2026-01-17 13:42:08,661 : worker.worker : DEBUG : Step 196354, finished rewards 10.40, envs finished 1
2026-01-17 13:42:08,778 : worker.worker : DEBUG : Step 196376, finished rewards 14.51, envs finished 1
2026-01-17 13:42:08,965 : agent.on_policy : DEBUG : Mean Losses: [7.264352798461914]
2026-01-17 13:42:09,078 : worker.worker : DEBUG : Step 196396, finished rewards 13.60, envs finished 1
2026-01-17 13:42:09,105 : worker.worker : DEBUG : Step 196400, finished rewards -33.97, envs finished 1
2026-01-17 13:42:09,123 : worker.worker : DEBUG : Step 196402, finished rewards 1.49, envs finished 1
2026-01-17 13:42:09,221 : worker.worker : DEBUG : Step 196407, finished rewards 13.41, envs finished 1
2026-01-17 13:42:09,283 : worker.worker : DEBUG : Step 196411, finished rewards -13.08, envs finished 1
2026-01-17 13:42:09,318 : worker.worker : DEBUG : Step 196413, finished rewards 27.71, envs finished 1
2026-01-17 13:42:09,544 : agent.on_policy : DEBUG : Mean Losses: [8.061444468796253]
2026-01-17 13:42:09,778 : worker.worker : DEBUG : Step 196442, finished rewards 30.11, envs finished 1
2026-01-17 13:42:09,977 : agent.on_policy : DEBUG : Mean Losses: [2.1256224904209375]
2026-01-17 13:42:10,131 : worker.worker : DEBUG : Step 196460, finished rewards 31.70, envs finished 1
2026-01-17 13:42:10,336 : worker.worker : DEBUG : Step 196475, finished rewards 46.27, envs finished 1
2026-01-17 13:42:10,624 : agent.on_policy : DEBUG : Mean Losses: [5.891890689730644]
2026-01-17 13:42:10,707 : worker.worker : DEBUG : Step 196490, finished rewards 27.39, envs finished 1
2026-01-17 13:42:10,809 : worker.worker : DEBUG : Step 196500, finished rewards 22.03, envs finished 1
2026-01-17 13:42:10,824 : worker.worker : DEBUG : Step 196501, finished rewards 28.09, envs finished 1
2026-01-17 13:42:10,918 : worker.worker : DEBUG : Step 196506, finished rewards 10.20, envs finished 1
2026-01-17 13:42:11,139 : agent.on_policy : DEBUG : Mean Losses: [6.136018306016922]
2026-01-17 13:42:11,142 : worker.worker : DEBUG : Step 196512, finished rewards 43.16, envs finished 1
2026-01-17 13:42:11,469 : agent.on_policy : DEBUG : Mean Losses: [3.6465019769966602]
2026-01-17 13:42:11,485 : worker.worker : DEBUG : Step 196547, finished rewards 40.97, envs finished 1
2026-01-17 13:42:11,757 : agent.on_policy : DEBUG : Mean Losses: [5.6509119449183345]
2026-01-17 13:42:11,766 : worker.worker : DEBUG : Step 196578, finished rewards 34.04, envs finished 2
2026-01-17 13:42:11,772 : worker.worker : DEBUG : Step 196579, finished rewards -11.61, envs finished 1
2026-01-17 13:42:11,785 : worker.worker : DEBUG : Step 196581, finished rewards 33.27, envs finished 1
2026-01-17 13:42:11,815 : worker.worker : DEBUG : Step 196586, finished rewards 29.81, envs finished 1
2026-01-17 13:42:11,878 : worker.worker : DEBUG : Step 196600, finished rewards -7.56, envs finished 1
2026-01-17 13:42:12,075 : agent.on_policy : DEBUG : Mean Losses: [5.711437866091728]
2026-01-17 13:42:12,091 : worker.worker : DEBUG : Step 196611, finished rewards 46.15, envs finished 1
2026-01-17 13:42:12,098 : worker.worker : DEBUG : Step 196612, finished rewards 18.21, envs finished 1
2026-01-17 13:42:12,379 : agent.on_policy : DEBUG : Mean Losses: [1.956110157072544]
2026-01-17 13:42:12,452 : worker.worker : DEBUG : Step 196657, finished rewards 33.84, envs finished 1
2026-01-17 13:42:12,509 : worker.worker : DEBUG : Step 196667, finished rewards 26.93, envs finished 1
2026-01-17 13:42:12,544 : worker.worker : DEBUG : Step 196670, finished rewards 40.97, envs finished 1
2026-01-17 13:42:12,795 : agent.on_policy : DEBUG : Mean Losses: [6.2645625695586205]
2026-01-17 13:42:12,910 : worker.worker : DEBUG : Step 196699, finished rewards 7.34, envs finished 1
2026-01-17 13:42:13,142 : agent.on_policy : DEBUG : Mean Losses: [3.7650336995720863]
2026-01-17 13:42:13,178 : worker.worker : DEBUG : Step 196706, finished rewards 24.53, envs finished 1
2026-01-17 13:42:13,337 : worker.worker : DEBUG : Step 196722, finished rewards 9.79, envs finished 1
2026-01-17 13:42:13,489 : worker.worker : DEBUG : Step 196730, finished rewards 10.23, envs finished 1
2026-01-17 13:42:13,731 : agent.on_policy : DEBUG : Mean Losses: [5.015915356576443]
2026-01-17 13:42:13,965 : worker.worker : DEBUG : Step 196764, finished rewards 45.56, envs finished 1
2026-01-17 13:42:14,235 : agent.on_policy : DEBUG : Mean Losses: [6.021277144551277]
2026-01-17 13:42:14,239 : worker.worker : DEBUG : Step 196768, finished rewards 20.37, envs finished 1
2026-01-17 13:42:14,369 : worker.worker : DEBUG : Step 196777, finished rewards -38.21, envs finished 1
2026-01-17 13:42:14,459 : worker.worker : DEBUG : Step 196789, finished rewards 2.46, envs finished 1
2026-01-17 13:42:14,541 : worker.worker : DEBUG : Step 196793, finished rewards 28.55, envs finished 1
2026-01-17 13:42:14,550 : worker.worker : DEBUG : Step 196794, finished rewards 46.05, envs finished 1
2026-01-17 13:42:13,989 : agent.on_policy : DEBUG : Mean Losses: [7.188818924129009]
2026-01-17 13:42:14,007 : worker.worker : DEBUG : Step 196802, finished rewards -14.52, envs finished 1
2026-01-17 13:42:14,078 : worker.worker : DEBUG : Step 196807, finished rewards 29.55, envs finished 1
2026-01-17 13:42:14,311 : agent.on_policy : DEBUG : Mean Losses: [1.845039639621973]
2026-01-17 13:42:14,327 : worker.worker : DEBUG : Step 196836, finished rewards 39.67, envs finished 1
2026-01-17 13:42:14,347 : worker.worker : DEBUG : Step 196841, finished rewards 46.22, envs finished 1
2026-01-17 13:42:14,486 : agent.on_policy : DEBUG : Mean Losses: [4.724926680326462]
2026-01-17 13:42:14,543 : worker.worker : DEBUG : Step 196867, finished rewards 21.22, envs finished 1
2026-01-17 13:42:14,589 : worker.worker : DEBUG : Step 196872, finished rewards 42.67, envs finished 1
2026-01-17 13:42:14,607 : worker.worker : DEBUG : Step 196874, finished rewards 30.54, envs finished 1
2026-01-17 13:42:14,768 : worker.worker : DEBUG : Step 196890, finished rewards 30.71, envs finished 1
2026-01-17 13:42:14,875 : agent.on_policy : DEBUG : Mean Losses: [5.244634136557579]
2026-01-17 13:42:14,955 : worker.worker : DEBUG : Step 196903, finished rewards 21.77, envs finished 1
2026-01-17 13:42:14,998 : worker.worker : DEBUG : Step 196911, finished rewards 42.41, envs finished 1
2026-01-17 13:42:15,190 : agent.on_policy : DEBUG : Mean Losses: [5.000824265182018]
2026-01-17 13:42:15,381 : agent.on_policy : DEBUG : Mean Losses: [3.7989370077848434]
2026-01-17 13:42:15,429 : worker.worker : DEBUG : Step 196961, finished rewards 23.85, envs finished 1
2026-01-17 13:42:15,467 : worker.worker : DEBUG : Step 196968, finished rewards -21.19, envs finished 1
2026-01-17 13:42:15,500 : worker.worker : DEBUG : Step 196973, finished rewards 42.52, envs finished 1
2026-01-17 13:42:15,507 : worker.worker : DEBUG : Step 196974, finished rewards 30.70, envs finished 1
2026-01-17 13:42:15,519 : worker.worker : DEBUG : Step 196976, finished rewards 16.87, envs finished 1
2026-01-17 13:42:15,543 : worker.worker : DEBUG : Step 196980, finished rewards 14.20, envs finished 1
2026-01-17 13:42:15,589 : worker.worker : DEBUG : Step 196986, finished rewards -9.28, envs finished 1
2026-01-17 13:42:15,669 : agent.on_policy : DEBUG : Mean Losses: [6.3204477690160275]
2026-01-17 13:42:15,706 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:42:15,733 : worker.worker : DEBUG : Step 197002, finished rewards 26.32, envs finished 1
2026-01-17 13:42:16,025 : agent.on_policy : DEBUG : Mean Losses: [1.2470084177330136]
2026-01-17 13:42:16,091 : worker.worker : DEBUG : Step 197038, finished rewards 46.01, envs finished 1
2026-01-17 13:42:16,144 : worker.worker : DEBUG : Step 197049, finished rewards 27.96, envs finished 1
2026-01-17 13:42:16,194 : worker.worker : DEBUG : Step 197055, finished rewards 27.58, envs finished 1
2026-01-17 13:42:16,330 : agent.on_policy : DEBUG : Mean Losses: [4.982799991965294]
2026-01-17 13:42:16,354 : worker.worker : DEBUG : Step 197061, finished rewards 33.19, envs finished 1
2026-01-17 13:42:16,412 : worker.worker : DEBUG : Step 197066, finished rewards 45.97, envs finished 1
2026-01-17 13:42:16,612 : worker.worker : DEBUG : Step 197083, finished rewards 16.40, envs finished 1
2026-01-17 13:42:16,691 : agent.on_policy : DEBUG : Mean Losses: [5.455895055085421]
2026-01-17 13:42:16,719 : worker.worker : DEBUG : Step 197095, finished rewards 12.83, envs finished 1
2026-01-17 13:42:16,837 : worker.worker : DEBUG : Step 197110, finished rewards 3.67, envs finished 1
2026-01-17 13:42:17,068 : agent.on_policy : DEBUG : Mean Losses: [3.3616335168480873]
2026-01-17 13:42:17,125 : worker.worker : DEBUG : Step 197131, finished rewards 23.92, envs finished 1
2026-01-17 13:42:17,132 : worker.worker : DEBUG : Step 197132, finished rewards 31.92, envs finished 1
2026-01-17 13:42:17,358 : agent.on_policy : DEBUG : Mean Losses: [4.236069571226835]
2026-01-17 13:42:17,364 : worker.worker : DEBUG : Step 197153, finished rewards 24.77, envs finished 1
2026-01-17 13:42:17,425 : worker.worker : DEBUG : Step 197163, finished rewards 21.06, envs finished 1
2026-01-17 13:42:17,435 : worker.worker : DEBUG : Step 197164, finished rewards 11.83, envs finished 1
2026-01-17 13:42:17,452 : worker.worker : DEBUG : Step 197166, finished rewards 42.22, envs finished 1
2026-01-17 13:42:17,662 : agent.on_policy : DEBUG : Mean Losses: [4.685975022614002]
2026-01-17 13:42:17,671 : worker.worker : DEBUG : Step 197186, finished rewards 27.95, envs finished 2
2026-01-17 13:42:17,858 : worker.worker : DEBUG : Step 197215, finished rewards 31.48, envs finished 1
2026-01-17 13:42:17,915 : agent.on_policy : DEBUG : Mean Losses: [3.1802642568945885]
2026-01-17 13:42:17,973 : worker.worker : DEBUG : Step 197230, finished rewards 19.84, envs finished 1
2026-01-17 13:42:18,166 : agent.on_policy : DEBUG : Mean Losses: [3.6520741544663906]
2026-01-17 13:42:18,266 : worker.worker : DEBUG : Step 197260, finished rewards 24.17, envs finished 1
2026-01-17 13:42:18,317 : worker.worker : DEBUG : Step 197270, finished rewards 15.07, envs finished 1
2026-01-17 13:42:18,581 : agent.on_policy : DEBUG : Mean Losses: [7.631603941321373]
2026-01-17 13:42:18,660 : worker.worker : DEBUG : Step 197291, finished rewards 15.26, envs finished 1
2026-01-17 13:42:18,721 : worker.worker : DEBUG : Step 197303, finished rewards 28.31, envs finished 1
2026-01-17 13:42:18,801 : worker.worker : DEBUG : Step 197308, finished rewards -10.95, envs finished 1
2026-01-17 13:42:18,896 : agent.on_policy : DEBUG : Mean Losses: [5.071355737745762]
2026-01-17 13:42:18,977 : worker.worker : DEBUG : Step 197318, finished rewards -1.91, envs finished 1
2026-01-17 13:42:19,147 : worker.worker : DEBUG : Step 197343, finished rewards 40.87, envs finished 1
2026-01-17 13:42:19,298 : agent.on_policy : DEBUG : Mean Losses: [3.9957571141421795]
2026-01-17 13:42:19,341 : worker.worker : DEBUG : Step 197355, finished rewards 46.11, envs finished 1
2026-01-17 13:42:19,378 : worker.worker : DEBUG : Step 197364, finished rewards 4.86, envs finished 2
2026-01-17 13:42:19,383 : worker.worker : DEBUG : Step 197365, finished rewards -40.55, envs finished 1
2026-01-17 13:42:19,477 : agent.on_policy : DEBUG : Mean Losses: [5.709094264544547]
2026-01-17 13:42:19,864 : agent.on_policy : DEBUG : Mean Losses: [2.7271450757980347]
2026-01-17 13:42:19,900 : worker.worker : DEBUG : Step 197414, finished rewards 22.77, envs finished 1
2026-01-17 13:42:19,917 : worker.worker : DEBUG : Step 197416, finished rewards 39.35, envs finished 1
2026-01-17 13:42:20,018 : worker.worker : DEBUG : Step 197428, finished rewards 4.07, envs finished 1
2026-01-17 13:42:20,197 : agent.on_policy : DEBUG : Mean Losses: [5.5316243171691895]
2026-01-17 13:42:20,216 : worker.worker : DEBUG : Step 197444, finished rewards 27.11, envs finished 1
2026-01-17 13:42:20,434 : worker.worker : DEBUG : Step 197465, finished rewards 17.17, envs finished 1
2026-01-17 13:42:20,464 : worker.worker : DEBUG : Step 197469, finished rewards 16.60, envs finished 1
2026-01-17 13:42:20,525 : agent.on_policy : DEBUG : Mean Losses: [5.385371055454016]
2026-01-17 13:42:20,562 : worker.worker : DEBUG : Step 197480, finished rewards 9.04, envs finished 1
2026-01-17 13:42:20,941 : agent.on_policy : DEBUG : Mean Losses: [2.6200769376009703]
2026-01-17 13:42:20,962 : worker.worker : DEBUG : Step 197507, finished rewards 22.86, envs finished 1
2026-01-17 13:42:21,012 : worker.worker : DEBUG : Step 197514, finished rewards 23.46, envs finished 1
2026-01-17 13:42:21,046 : worker.worker : DEBUG : Step 197518, finished rewards -37.09, envs finished 1
2026-01-17 13:42:21,100 : worker.worker : DEBUG : Step 197521, finished rewards 27.43, envs finished 1
2026-01-17 13:42:21,144 : worker.worker : DEBUG : Step 197526, finished rewards 32.27, envs finished 1
2026-01-17 13:42:21,216 : worker.worker : DEBUG : Step 197533, finished rewards 46.12, envs finished 1
2026-01-17 13:42:21,333 : agent.on_policy : DEBUG : Mean Losses: [7.450275897979736]
2026-01-17 13:42:21,409 : worker.worker : DEBUG : Step 197545, finished rewards 45.94, envs finished 1
2026-01-17 13:42:21,890 : agent.on_policy : DEBUG : Mean Losses: [2.6354198027402163]
2026-01-17 13:42:21,989 : worker.worker : DEBUG : Step 197577, finished rewards 25.21, envs finished 2
2026-01-17 13:42:22,133 : worker.worker : DEBUG : Step 197594, finished rewards 38.92, envs finished 1
2026-01-17 13:42:22,221 : agent.on_policy : DEBUG : Mean Losses: [5.174474611878395]
2026-01-17 13:42:22,256 : worker.worker : DEBUG : Step 197602, finished rewards 28.03, envs finished 1
2026-01-17 13:42:22,371 : worker.worker : DEBUG : Step 197617, finished rewards 39.84, envs finished 1
2026-01-17 13:42:22,485 : worker.worker : DEBUG : Step 197627, finished rewards 12.95, envs finished 1
2026-01-17 13:42:22,651 : agent.on_policy : DEBUG : Mean Losses: [4.650134239345789]
2026-01-17 13:42:22,661 : worker.worker : DEBUG : Step 197632, finished rewards 16.94, envs finished 1
2026-01-17 13:42:22,757 : worker.worker : DEBUG : Step 197641, finished rewards 45.90, envs finished 1
2026-01-17 13:42:22,917 : worker.worker : DEBUG : Step 197656, finished rewards 1.24, envs finished 1
2026-01-17 13:42:22,956 : worker.worker : DEBUG : Step 197658, finished rewards 45.85, envs finished 1
2026-01-17 13:42:22,975 : worker.worker : DEBUG : Step 197661, finished rewards 31.00, envs finished 1
2026-01-17 13:42:23,156 : agent.on_policy : DEBUG : Mean Losses: [7.29732309281826]
2026-01-17 13:42:23,258 : worker.worker : DEBUG : Step 197670, finished rewards 41.77, envs finished 1
2026-01-17 13:42:23,552 : worker.worker : DEBUG : Step 197694, finished rewards 38.36, envs finished 1
2026-01-17 13:42:23,638 : agent.on_policy : DEBUG : Mean Losses: [3.0408274568617344]
2026-01-17 13:42:23,641 : worker.worker : DEBUG : Step 197696, finished rewards 46.20, envs finished 1
2026-01-17 13:42:23,908 : agent.on_policy : DEBUG : Mean Losses: [3.3160227462649345]
2026-01-17 13:42:23,926 : worker.worker : DEBUG : Step 197732, finished rewards 42.36, envs finished 1
2026-01-17 13:42:23,960 : worker.worker : DEBUG : Step 197739, finished rewards 12.20, envs finished 1
2026-01-17 13:42:23,988 : worker.worker : DEBUG : Step 197746, finished rewards 14.23, envs finished 1
2026-01-17 13:42:24,090 : agent.on_policy : DEBUG : Mean Losses: [6.046532861888409]
2026-01-17 13:42:24,128 : worker.worker : DEBUG : Step 197771, finished rewards 37.77, envs finished 1
2026-01-17 13:42:24,217 : worker.worker : DEBUG : Step 197777, finished rewards 8.57, envs finished 1
2026-01-17 13:42:24,426 : agent.on_policy : DEBUG : Mean Losses: [4.265281461179256]
2026-01-17 13:42:24,517 : worker.worker : DEBUG : Step 197806, finished rewards 15.35, envs finished 1
2026-01-17 13:42:24,562 : worker.worker : DEBUG : Step 197810, finished rewards 41.56, envs finished 1
2026-01-17 13:42:24,606 : worker.worker : DEBUG : Step 197818, finished rewards 0.53, envs finished 1
2026-01-17 13:42:24,901 : agent.on_policy : DEBUG : Mean Losses: [4.673726782202721]
2026-01-17 13:42:24,954 : worker.worker : DEBUG : Step 197831, finished rewards 30.87, envs finished 1
2026-01-17 13:42:25,001 : worker.worker : DEBUG : Step 197841, finished rewards 11.88, envs finished 1
2026-01-17 13:42:25,013 : worker.worker : DEBUG : Step 197843, finished rewards 41.12, envs finished 1
2026-01-17 13:42:25,263 : agent.on_policy : DEBUG : Mean Losses: [3.949068583548069]
2026-01-17 13:42:25,285 : worker.worker : DEBUG : Step 197861, finished rewards 29.84, envs finished 1
2026-01-17 13:42:25,341 : worker.worker : DEBUG : Step 197874, finished rewards 45.90, envs finished 1
2026-01-17 13:42:25,384 : worker.worker : DEBUG : Step 197885, finished rewards 33.47, envs finished 1
2026-01-17 13:42:25,535 : agent.on_policy : DEBUG : Mean Losses: [5.708711743354797]
2026-01-17 13:42:25,554 : worker.worker : DEBUG : Step 197891, finished rewards 29.73, envs finished 1
2026-01-17 13:42:25,598 : worker.worker : DEBUG : Step 197900, finished rewards 33.43, envs finished 1
2026-01-17 13:42:25,789 : agent.on_policy : DEBUG : Mean Losses: [3.1358827613294125]
2026-01-17 13:42:25,833 : worker.worker : DEBUG : Step 197931, finished rewards 20.54, envs finished 1
2026-01-17 13:42:25,897 : worker.worker : DEBUG : Step 197949, finished rewards 45.84, envs finished 1
2026-01-17 13:42:25,987 : agent.on_policy : DEBUG : Mean Losses: [4.584727466106415]
2026-01-17 13:42:26,087 : worker.worker : DEBUG : Step 197958, finished rewards 7.07, envs finished 1
2026-01-17 13:42:26,094 : worker.worker : DEBUG : Step 197959, finished rewards 9.03, envs finished 1
2026-01-17 13:42:26,137 : worker.worker : DEBUG : Step 197966, finished rewards 26.04, envs finished 1
2026-01-17 13:42:26,205 : worker.worker : DEBUG : Step 197970, finished rewards 14.57, envs finished 1
2026-01-17 13:42:26,245 : worker.worker : DEBUG : Step 197973, finished rewards 38.54, envs finished 1
2026-01-17 13:42:26,439 : agent.on_policy : DEBUG : Mean Losses: [5.186418652534485]
2026-01-17 13:42:26,531 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:42:26,751 : agent.on_policy : DEBUG : Mean Losses: [2.9443454220891]
2026-01-17 13:42:26,891 : worker.worker : DEBUG : Step 198028, finished rewards 35.69, envs finished 1
2026-01-17 13:42:26,936 : worker.worker : DEBUG : Step 198035, finished rewards 38.26, envs finished 1
2026-01-17 13:42:27,060 : worker.worker : DEBUG : Step 198044, finished rewards 30.36, envs finished 1
2026-01-17 13:42:27,155 : agent.on_policy : DEBUG : Mean Losses: [5.57496090233326]
2026-01-17 13:42:27,225 : worker.worker : DEBUG : Step 198052, finished rewards 5.70, envs finished 1
2026-01-17 13:42:27,245 : worker.worker : DEBUG : Step 198056, finished rewards 32.04, envs finished 1
2026-01-17 13:42:27,263 : worker.worker : DEBUG : Step 198058, finished rewards -7.01, envs finished 1
2026-01-17 13:42:27,405 : worker.worker : DEBUG : Step 198071, finished rewards 19.06, envs finished 1
2026-01-17 13:42:27,581 : agent.on_policy : DEBUG : Mean Losses: [4.530569888651371]
2026-01-17 13:42:27,584 : worker.worker : DEBUG : Step 198080, finished rewards 13.35, envs finished 1
2026-01-17 13:42:28,044 : agent.on_policy : DEBUG : Mean Losses: [2.0868575423955917]
2026-01-17 13:42:28,070 : worker.worker : DEBUG : Step 198115, finished rewards 41.53, envs finished 1
2026-01-17 13:42:28,109 : worker.worker : DEBUG : Step 198124, finished rewards 39.85, envs finished 1
2026-01-17 13:42:28,220 : agent.on_policy : DEBUG : Mean Losses: [6.090837389230728]
2026-01-17 13:42:28,368 : worker.worker : DEBUG : Step 198160, finished rewards 24.51, envs finished 1
2026-01-17 13:42:28,580 : agent.on_policy : DEBUG : Mean Losses: [3.804499864578247]
2026-01-17 13:42:28,603 : worker.worker : DEBUG : Step 198183, finished rewards -2.88, envs finished 1
2026-01-17 13:42:28,629 : worker.worker : DEBUG : Step 198185, finished rewards 44.18, envs finished 1
2026-01-17 13:42:28,745 : worker.worker : DEBUG : Step 198197, finished rewards 4.78, envs finished 1
2026-01-17 13:42:28,759 : worker.worker : DEBUG : Step 198199, finished rewards -30.35, envs finished 1
2026-01-17 13:42:28,932 : agent.on_policy : DEBUG : Mean Losses: [6.032149598002434]
2026-01-17 13:42:29,093 : worker.worker : DEBUG : Step 198231, finished rewards 15.63, envs finished 1
2026-01-17 13:42:29,127 : worker.worker : DEBUG : Step 198235, finished rewards 1.63, envs finished 1
2026-01-17 13:42:29,242 : agent.on_policy : DEBUG : Mean Losses: [3.859206528402865]
2026-01-17 13:42:29,284 : worker.worker : DEBUG : Step 198247, finished rewards 37.40, envs finished 1
2026-01-17 13:42:29,413 : worker.worker : DEBUG : Step 198263, finished rewards 45.82, envs finished 1
2026-01-17 13:42:29,511 : worker.worker : DEBUG : Step 198271, finished rewards 35.32, envs finished 1
2026-01-17 13:42:29,577 : agent.on_policy : DEBUG : Mean Losses: [5.233980283141136]
2026-01-17 13:42:29,673 : worker.worker : DEBUG : Step 198282, finished rewards 21.26, envs finished 1
2026-01-17 13:42:29,747 : worker.worker : DEBUG : Step 198295, finished rewards 2.14, envs finished 1
2026-01-17 13:42:29,988 : agent.on_policy : DEBUG : Mean Losses: [3.4039801326580346]
2026-01-17 13:42:30,336 : worker.worker : DEBUG : Step 198334, finished rewards 30.86, envs finished 1
2026-01-17 13:42:30,352 : worker.worker : DEBUG : Step 198335, finished rewards 19.09, envs finished 1
2026-01-17 13:42:30,417 : agent.on_policy : DEBUG : Mean Losses: [4.108460955321789]
2026-01-17 13:42:30,445 : worker.worker : DEBUG : Step 198343, finished rewards 41.36, envs finished 1
2026-01-17 13:42:30,461 : worker.worker : DEBUG : Step 198346, finished rewards 32.29, envs finished 1
2026-01-17 13:42:30,472 : worker.worker : DEBUG : Step 198347, finished rewards 45.38, envs finished 1
2026-01-17 13:42:30,490 : worker.worker : DEBUG : Step 198349, finished rewards 10.50, envs finished 1
2026-01-17 13:42:30,541 : worker.worker : DEBUG : Step 198351, finished rewards 30.50, envs finished 1
2026-01-17 13:42:30,809 : agent.on_policy : DEBUG : Mean Losses: [5.163466716185212]
2026-01-17 13:42:30,919 : worker.worker : DEBUG : Step 198399, finished rewards 45.93, envs finished 1
2026-01-17 13:42:31,072 : agent.on_policy : DEBUG : Mean Losses: [3.3087569512426853]
2026-01-17 13:42:31,076 : worker.worker : DEBUG : Step 198400, finished rewards 44.60, envs finished 1
2026-01-17 13:42:31,096 : worker.worker : DEBUG : Step 198403, finished rewards 12.02, envs finished 1
2026-01-17 13:42:31,218 : worker.worker : DEBUG : Step 198411, finished rewards 46.09, envs finished 1
2026-01-17 13:42:31,423 : worker.worker : DEBUG : Step 198428, finished rewards 32.75, envs finished 1
2026-01-17 13:42:31,599 : agent.on_policy : DEBUG : Mean Losses: [4.866166345775127]
2026-01-17 13:42:31,768 : worker.worker : DEBUG : Step 198450, finished rewards 19.37, envs finished 1
2026-01-17 13:42:31,777 : worker.worker : DEBUG : Step 198451, finished rewards 15.81, envs finished 1
2026-01-17 13:42:31,898 : agent.on_policy : DEBUG : Mean Losses: [3.1002264618873596]
2026-01-17 13:42:31,913 : worker.worker : DEBUG : Step 198466, finished rewards 7.98, envs finished 1
2026-01-17 13:42:31,924 : worker.worker : DEBUG : Step 198467, finished rewards 45.90, envs finished 1
2026-01-17 13:42:32,185 : worker.worker : DEBUG : Step 198494, finished rewards 27.24, envs finished 2
2026-01-17 13:42:32,197 : worker.worker : DEBUG : Step 198495, finished rewards 21.55, envs finished 1
2026-01-17 13:42:32,310 : agent.on_policy : DEBUG : Mean Losses: [4.735060746781528]
2026-01-17 13:42:32,489 : worker.worker : DEBUG : Step 198515, finished rewards 45.89, envs finished 1
2026-01-17 13:42:32,711 : agent.on_policy : DEBUG : Mean Losses: [3.190307818353176]
2026-01-17 13:42:32,714 : worker.worker : DEBUG : Step 198528, finished rewards 18.84, envs finished 1
2026-01-17 13:42:32,830 : worker.worker : DEBUG : Step 198551, finished rewards 30.15, envs finished 1
2026-01-17 13:42:33,098 : agent.on_policy : DEBUG : Mean Losses: [3.295679200440645]
2026-01-17 13:42:33,117 : worker.worker : DEBUG : Step 198564, finished rewards 18.84, envs finished 1
2026-01-17 13:42:33,127 : worker.worker : DEBUG : Step 198565, finished rewards 41.62, envs finished 1
2026-01-17 13:42:33,209 : worker.worker : DEBUG : Step 198580, finished rewards 28.68, envs finished 1
2026-01-17 13:42:33,218 : worker.worker : DEBUG : Step 198581, finished rewards 14.72, envs finished 2
2026-01-17 13:42:33,464 : agent.on_policy : DEBUG : Mean Losses: [6.199210047721863]
2026-01-17 13:42:33,572 : worker.worker : DEBUG : Step 198615, finished rewards 19.15, envs finished 1
2026-01-17 13:42:33,629 : worker.worker : DEBUG : Step 198622, finished rewards 40.55, envs finished 1
2026-01-17 13:42:33,771 : agent.on_policy : DEBUG : Mean Losses: [3.8276312574744225]
2026-01-17 13:42:33,983 : worker.worker : DEBUG : Step 198645, finished rewards 45.41, envs finished 1
2026-01-17 13:42:34,041 : worker.worker : DEBUG : Step 198653, finished rewards 27.61, envs finished 1
2026-01-17 13:42:34,103 : agent.on_policy : DEBUG : Mean Losses: [6.259914129972458]
2026-01-17 13:42:34,237 : worker.worker : DEBUG : Step 198669, finished rewards 27.07, envs finished 1
2026-01-17 13:42:34,283 : worker.worker : DEBUG : Step 198675, finished rewards 25.46, envs finished 1
2026-01-17 13:42:34,395 : worker.worker : DEBUG : Step 198683, finished rewards 17.79, envs finished 1
2026-01-17 13:42:34,420 : worker.worker : DEBUG : Step 198686, finished rewards 46.48, envs finished 1
2026-01-17 13:42:34,553 : agent.on_policy : DEBUG : Mean Losses: [6.69609684497118]
2026-01-17 13:42:34,625 : worker.worker : DEBUG : Step 198699, finished rewards -18.57, envs finished 1
2026-01-17 13:42:34,902 : agent.on_policy : DEBUG : Mean Losses: [2.326749861240387]
2026-01-17 13:42:34,924 : worker.worker : DEBUG : Step 198724, finished rewards 42.06, envs finished 1
2026-01-17 13:42:34,942 : worker.worker : DEBUG : Step 198727, finished rewards 13.88, envs finished 1
2026-01-17 13:42:34,955 : worker.worker : DEBUG : Step 198729, finished rewards 31.09, envs finished 1
2026-01-17 13:42:34,998 : worker.worker : DEBUG : Step 198738, finished rewards 46.56, envs finished 1
2026-01-17 13:42:35,007 : worker.worker : DEBUG : Step 198740, finished rewards 41.40, envs finished 1
2026-01-17 13:42:35,103 : agent.on_policy : DEBUG : Mean Losses: [6.200271859765053]
2026-01-17 13:42:35,145 : worker.worker : DEBUG : Step 198762, finished rewards 36.13, envs finished 1
2026-01-17 13:42:35,498 : agent.on_policy : DEBUG : Mean Losses: [2.674480088055134]
2026-01-17 13:42:35,699 : worker.worker : DEBUG : Step 198807, finished rewards 15.33, envs finished 1
2026-01-17 13:42:35,861 : agent.on_policy : DEBUG : Mean Losses: [4.33622720092535]
2026-01-17 13:42:35,917 : worker.worker : DEBUG : Step 198823, finished rewards 26.22, envs finished 2
2026-01-17 13:42:35,982 : worker.worker : DEBUG : Step 198831, finished rewards 22.87, envs finished 1
2026-01-17 13:42:35,997 : worker.worker : DEBUG : Step 198832, finished rewards 7.43, envs finished 1
2026-01-17 13:42:36,037 : worker.worker : DEBUG : Step 198834, finished rewards 40.13, envs finished 1
2026-01-17 13:42:36,144 : worker.worker : DEBUG : Step 198843, finished rewards 11.06, envs finished 1
2026-01-17 13:42:36,192 : worker.worker : DEBUG : Step 198847, finished rewards 9.66, envs finished 1
2026-01-17 13:42:36,360 : agent.on_policy : DEBUG : Mean Losses: [6.70377317070961]
2026-01-17 13:42:36,644 : agent.on_policy : DEBUG : Mean Losses: [0.7558175772428513]
2026-01-17 13:42:36,715 : worker.worker : DEBUG : Step 198900, finished rewards 23.88, envs finished 1
2026-01-17 13:42:36,731 : worker.worker : DEBUG : Step 198903, finished rewards 40.86, envs finished 2
2026-01-17 13:42:36,748 : worker.worker : DEBUG : Step 198906, finished rewards 32.18, envs finished 1
2026-01-17 13:42:36,757 : worker.worker : DEBUG : Step 198907, finished rewards 46.25, envs finished 1
2026-01-17 13:42:36,942 : agent.on_policy : DEBUG : Mean Losses: [7.927741006016731]
2026-01-17 13:42:36,949 : worker.worker : DEBUG : Step 198913, finished rewards 26.27, envs finished 1
2026-01-17 13:42:37,094 : worker.worker : DEBUG : Step 198935, finished rewards 19.65, envs finished 1
2026-01-17 13:42:37,196 : agent.on_policy : DEBUG : Mean Losses: [2.3949820064008236]
2026-01-17 13:42:37,346 : worker.worker : DEBUG : Step 198966, finished rewards 6.89, envs finished 1
2026-01-17 13:42:37,357 : worker.worker : DEBUG : Step 198967, finished rewards 45.87, envs finished 1
2026-01-17 13:42:37,681 : agent.on_policy : DEBUG : Mean Losses: [5.501773625612259]
2026-01-17 13:42:37,706 : worker.worker : DEBUG : Step 198977, finished rewards 40.61, envs finished 1
2026-01-17 13:42:37,723 : worker.worker : DEBUG : Step 198979, finished rewards 34.12, envs finished 1
2026-01-17 13:42:37,894 : worker.worker : DEBUG : Step 198998, finished rewards 22.21, envs finished 1
2026-01-17 13:42:37,896 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:42:38,013 : worker.worker : DEBUG : Step 199007, finished rewards 23.45, envs finished 1
2026-01-17 13:42:38,075 : agent.on_policy : DEBUG : Mean Losses: [5.148214213550091]
2026-01-17 13:42:38,365 : agent.on_policy : DEBUG : Mean Losses: [2.2378656826913357]
2026-01-17 13:42:38,384 : worker.worker : DEBUG : Step 199045, finished rewards 34.50, envs finished 1
2026-01-17 13:42:38,429 : worker.worker : DEBUG : Step 199054, finished rewards 35.35, envs finished 1
2026-01-17 13:42:38,438 : worker.worker : DEBUG : Step 199055, finished rewards 3.88, envs finished 1
2026-01-17 13:42:38,461 : worker.worker : DEBUG : Step 199058, finished rewards 24.21, envs finished 1
2026-01-17 13:42:38,485 : worker.worker : DEBUG : Step 199062, finished rewards 46.50, envs finished 1
2026-01-17 13:42:38,611 : agent.on_policy : DEBUG : Mean Losses: [7.480535268783569]
2026-01-17 13:42:38,697 : worker.worker : DEBUG : Step 199078, finished rewards 42.17, envs finished 1
2026-01-17 13:42:38,798 : worker.worker : DEBUG : Step 199098, finished rewards 7.94, envs finished 1
2026-01-17 13:42:38,966 : agent.on_policy : DEBUG : Mean Losses: [3.0181965231895447]
2026-01-17 13:42:39,105 : worker.worker : DEBUG : Step 199117, finished rewards -31.60, envs finished 1
2026-01-17 13:42:39,138 : worker.worker : DEBUG : Step 199118, finished rewards 40.98, envs finished 1
2026-01-17 13:42:39,178 : worker.worker : DEBUG : Step 199125, finished rewards 41.55, envs finished 1
2026-01-17 13:42:39,201 : worker.worker : DEBUG : Step 199126, finished rewards 42.22, envs finished 1
2026-01-17 13:42:39,462 : agent.on_policy : DEBUG : Mean Losses: [5.106092497706413]
2026-01-17 13:42:39,512 : worker.worker : DEBUG : Step 199147, finished rewards 28.20, envs finished 1
2026-01-17 13:42:39,547 : worker.worker : DEBUG : Step 199153, finished rewards 25.39, envs finished 1
2026-01-17 13:42:39,766 : agent.on_policy : DEBUG : Mean Losses: [2.826664051041007]
2026-01-17 13:42:39,877 : worker.worker : DEBUG : Step 199193, finished rewards 22.60, envs finished 1
2026-01-17 13:42:39,897 : worker.worker : DEBUG : Step 199198, finished rewards 21.88, envs finished 2
2026-01-17 13:42:40,061 : agent.on_policy : DEBUG : Mean Losses: [4.823816105723381]
2026-01-17 13:42:40,228 : worker.worker : DEBUG : Step 199225, finished rewards 17.20, envs finished 1
2026-01-17 13:42:40,250 : worker.worker : DEBUG : Step 199226, finished rewards 12.19, envs finished 1
2026-01-17 13:42:40,489 : agent.on_policy : DEBUG : Mean Losses: [3.5451601147651672]
2026-01-17 13:42:40,582 : worker.worker : DEBUG : Step 199247, finished rewards 18.44, envs finished 1
2026-01-17 13:42:40,595 : worker.worker : DEBUG : Step 199248, finished rewards 15.20, envs finished 1
2026-01-17 13:42:40,959 : agent.on_policy : DEBUG : Mean Losses: [2.9147216752171516]
2026-01-17 13:42:41,093 : worker.worker : DEBUG : Step 199275, finished rewards 5.94, envs finished 1
2026-01-17 13:42:41,225 : worker.worker : DEBUG : Step 199295, finished rewards 21.38, envs finished 1
2026-01-17 13:42:41,341 : agent.on_policy : DEBUG : Mean Losses: [2.8734554201364517]
2026-01-17 13:42:41,360 : worker.worker : DEBUG : Step 199299, finished rewards 18.03, envs finished 1
2026-01-17 13:42:41,449 : worker.worker : DEBUG : Step 199303, finished rewards 16.60, envs finished 1
2026-01-17 13:42:41,481 : worker.worker : DEBUG : Step 199308, finished rewards 33.75, envs finished 1
2026-01-17 13:42:41,716 : agent.on_policy : DEBUG : Mean Losses: [4.29003338329494]
2026-01-17 13:42:41,777 : worker.worker : DEBUG : Step 199346, finished rewards 7.00, envs finished 1
2026-01-17 13:42:41,796 : worker.worker : DEBUG : Step 199351, finished rewards 20.54, envs finished 1
2026-01-17 13:42:41,815 : worker.worker : DEBUG : Step 199355, finished rewards 17.12, envs finished 1
2026-01-17 13:42:41,989 : agent.on_policy : DEBUG : Mean Losses: [4.002178274095058]
2026-01-17 13:42:42,021 : worker.worker : DEBUG : Step 199365, finished rewards 24.03, envs finished 1
2026-01-17 13:42:42,028 : worker.worker : DEBUG : Step 199366, finished rewards 42.04, envs finished 1
2026-01-17 13:42:42,257 : agent.on_policy : DEBUG : Mean Losses: [2.2070447504520416]
2026-01-17 13:42:42,264 : worker.worker : DEBUG : Step 199393, finished rewards 26.99, envs finished 2
2026-01-17 13:42:42,442 : agent.on_policy : DEBUG : Mean Losses: [3.1365318968892097]
2026-01-17 13:42:42,523 : worker.worker : DEBUG : Step 199433, finished rewards 28.18, envs finished 1
2026-01-17 13:42:42,553 : worker.worker : DEBUG : Step 199438, finished rewards 41.29, envs finished 1
2026-01-17 13:42:42,763 : agent.on_policy : DEBUG : Mean Losses: [5.811211749911308]
2026-01-17 13:42:42,770 : worker.worker : DEBUG : Step 199457, finished rewards 27.80, envs finished 1
2026-01-17 13:42:42,807 : worker.worker : DEBUG : Step 199466, finished rewards 8.22, envs finished 1
2026-01-17 13:42:42,831 : worker.worker : DEBUG : Step 199470, finished rewards 8.83, envs finished 1
2026-01-17 13:42:42,935 : agent.on_policy : DEBUG : Mean Losses: [6.033641278743744]
2026-01-17 13:42:42,938 : worker.worker : DEBUG : Step 199488, finished rewards 22.68, envs finished 1
2026-01-17 13:42:42,954 : worker.worker : DEBUG : Step 199492, finished rewards -24.83, envs finished 1
2026-01-17 13:42:43,091 : worker.worker : DEBUG : Step 199504, finished rewards 41.88, envs finished 1
2026-01-17 13:42:43,133 : worker.worker : DEBUG : Step 199509, finished rewards 14.23, envs finished 1
2026-01-17 13:42:43,363 : agent.on_policy : DEBUG : Mean Losses: [4.605566127225757]
2026-01-17 13:42:43,387 : worker.worker : DEBUG : Step 199525, finished rewards 27.76, envs finished 1
2026-01-17 13:42:43,540 : worker.worker : DEBUG : Step 199540, finished rewards 31.83, envs finished 1
2026-01-17 13:42:43,658 : worker.worker : DEBUG : Step 199551, finished rewards 29.96, envs finished 1
2026-01-17 13:42:43,736 : agent.on_policy : DEBUG : Mean Losses: [3.976037912070751]
2026-01-17 13:42:43,889 : worker.worker : DEBUG : Step 199568, finished rewards 45.98, envs finished 1
2026-01-17 13:42:43,617 : worker.worker : DEBUG : Step 199575, finished rewards 31.63, envs finished 1
2026-01-17 13:42:43,515 : agent.on_policy : DEBUG : Mean Losses: [5.1592551823705435]
2026-01-17 13:42:43,605 : worker.worker : DEBUG : Step 199591, finished rewards 12.69, envs finished 1
2026-01-17 13:42:44,065 : agent.on_policy : DEBUG : Mean Losses: [3.3780175298452377]
2026-01-17 13:42:44,144 : worker.worker : DEBUG : Step 199631, finished rewards 13.61, envs finished 1
2026-01-17 13:42:44,163 : worker.worker : DEBUG : Step 199635, finished rewards -8.48, envs finished 1
2026-01-17 13:42:44,206 : worker.worker : DEBUG : Step 199644, finished rewards 17.54, envs finished 1
2026-01-17 13:42:44,271 : worker.worker : DEBUG : Step 199647, finished rewards 41.26, envs finished 1
2026-01-17 13:42:44,401 : agent.on_policy : DEBUG : Mean Losses: [6.221311375498772]
2026-01-17 13:42:44,488 : worker.worker : DEBUG : Step 199663, finished rewards 24.77, envs finished 1
2026-01-17 13:42:44,690 : agent.on_policy : DEBUG : Mean Losses: [3.4542720690369606]
2026-01-17 13:42:44,703 : worker.worker : DEBUG : Step 199683, finished rewards -36.04, envs finished 1
2026-01-17 13:42:44,713 : worker.worker : DEBUG : Step 199685, finished rewards 24.48, envs finished 1
2026-01-17 13:42:44,864 : worker.worker : DEBUG : Step 199702, finished rewards 41.65, envs finished 1
2026-01-17 13:42:45,046 : agent.on_policy : DEBUG : Mean Losses: [4.454649606719613]
2026-01-17 13:42:45,057 : worker.worker : DEBUG : Step 199714, finished rewards 42.48, envs finished 1
2026-01-17 13:42:45,118 : worker.worker : DEBUG : Step 199718, finished rewards -34.06, envs finished 1
2026-01-17 13:42:45,304 : worker.worker : DEBUG : Step 199742, finished rewards 23.65, envs finished 1
2026-01-17 13:42:45,506 : agent.on_policy : DEBUG : Mean Losses: [4.121268339455128]
2026-01-17 13:42:45,515 : worker.worker : DEBUG : Step 199745, finished rewards 16.85, envs finished 1
2026-01-17 13:42:45,710 : worker.worker : DEBUG : Step 199767, finished rewards 34.50, envs finished 1
2026-01-17 13:42:45,729 : worker.worker : DEBUG : Step 199770, finished rewards 23.06, envs finished 1
2026-01-17 13:42:45,803 : worker.worker : DEBUG : Step 199774, finished rewards 27.38, envs finished 1
2026-01-17 13:42:45,944 : agent.on_policy : DEBUG : Mean Losses: [5.2141932882368565]
2026-01-17 13:42:46,088 : worker.worker : DEBUG : Step 199796, finished rewards 33.57, envs finished 1
2026-01-17 13:42:46,370 : agent.on_policy : DEBUG : Mean Losses: [2.3369388040155172]
2026-01-17 13:42:46,427 : worker.worker : DEBUG : Step 199821, finished rewards 9.97, envs finished 1
2026-01-17 13:42:46,443 : worker.worker : DEBUG : Step 199824, finished rewards 34.88, envs finished 1
2026-01-17 13:42:46,485 : worker.worker : DEBUG : Step 199833, finished rewards 28.88, envs finished 1
2026-01-17 13:42:46,502 : worker.worker : DEBUG : Step 199835, finished rewards 45.72, envs finished 1
2026-01-17 13:42:46,528 : worker.worker : DEBUG : Step 199837, finished rewards 42.94, envs finished 1
2026-01-17 13:42:46,669 : agent.on_policy : DEBUG : Mean Losses: [8.731972143054008]
2026-01-17 13:42:46,752 : worker.worker : DEBUG : Step 199845, finished rewards 40.28, envs finished 1
2026-01-17 13:42:46,894 : worker.worker : DEBUG : Step 199871, finished rewards -4.91, envs finished 1
2026-01-17 13:42:47,052 : agent.on_policy : DEBUG : Mean Losses: [2.751697985455394]
2026-01-17 13:42:47,311 : agent.on_policy : DEBUG : Mean Losses: [3.0657292008399963]
2026-01-17 13:42:47,320 : worker.worker : DEBUG : Step 199906, finished rewards 26.36, envs finished 2
2026-01-17 13:42:47,347 : worker.worker : DEBUG : Step 199910, finished rewards 34.89, envs finished 1
2026-01-17 13:42:47,383 : worker.worker : DEBUG : Step 199916, finished rewards 41.15, envs finished 1
2026-01-17 13:42:47,394 : worker.worker : DEBUG : Step 199917, finished rewards 31.95, envs finished 1
2026-01-17 13:42:47,432 : worker.worker : DEBUG : Step 199920, finished rewards 31.80, envs finished 1
2026-01-17 13:42:47,512 : worker.worker : DEBUG : Step 199933, finished rewards 24.42, envs finished 1
2026-01-17 13:42:47,596 : agent.on_policy : DEBUG : Mean Losses: [5.8872213661670685]
2026-01-17 13:42:47,924 : agent.on_policy : DEBUG : Mean Losses: [2.046014804393053]
2026-01-17 13:42:47,975 : worker.worker : DEBUG : Step 199978, finished rewards 40.48, envs finished 1
2026-01-17 13:42:47,990 : worker.worker : DEBUG : Step 199981, finished rewards 11.33, envs finished 1
2026-01-17 13:42:48,032 : worker.worker : DEBUG : Step 199988, finished rewards 41.67, envs finished 2
2026-01-17 13:42:48,096 : agent.exploration.egreedy : DEBUG : Current epsilon for egreedy 0.02
2026-01-17 13:42:48,153 : worker.worker : INFO : Step 200000, Avg Reward 22.6726, Max Reward 52.4462, Loss [4.52513676]
2026-01-17 13:42:48,172 : network.model : INFO : Saved model to logs/Acrobot-Sarsa/model.pt
2026-01-17 13:42:49,450 : evaluate.evaluate : INFO : Evaluation results: mean = -103.00, std = 0.00, min = -103.00, max = -103.00, count = 1
2026-01-17 13:43:57,195 : evaluate.evaluate : INFO : Evaluation results: mean = -150.10, std = 46.76, min = -500.00, max = -82.00, count = 1000
2026-01-17 13:43:57,264 : worker.worker : INFO : ==================== End training ====================
