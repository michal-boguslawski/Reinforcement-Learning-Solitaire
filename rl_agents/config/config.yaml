experiment_name: CartPole-PPO

env_kwargs:
  id: CartPole-v1
  vectorization_mode: async
  num_envs: 8

policy:
  type: ppo
  kwargs:
    gamma: 0.99
    lambda_: 0.95
    value_loss_coef: 0.5
    entropy_coef: 0.001
    entropy_decay: 0.99
    lr: 0.0003
    num_epochs: 10
    clip_epsilon: 0.2
    exploration_method: distribution
    advantage_normalize: batch

worker_kwargs:
  device: auto
  record_step: 50000

train_kwargs:
  num_steps: 200000
  batch_size: 256
  minibatch_size: 64

network:
  kwargs:
    initial_log_std: -1.
    num_features: 64
    backbone_name: mlp
    feature_extractor_name: shared
    head_name: actor_critic
    policy_name: actor_critic
    distribution: categorical
